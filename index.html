<html><div id="dlpage">
  <h1>Computer Science </h1>
  <h2>New submissions</h2>
  <div class="list-dateline">Submissions received from  Fri 26 Apr 24  to  Mon 29 Apr 24, announced Tue, 30 Apr 24</div>
  <ul>
  <li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
  <li><a href="#item635">Cross-lists</a></li>
  <li><a href="#item705">Replacements</a></li>
  </ul>
  <small>[ total of 1174 entries:  <b>1-1174</b>  ]</small><br>
  <small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br>
  <h3>New submissions for Tue, 30 Apr 24</h3>
  <dl>
  <dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17581" title="Abstract">arXiv:2404.17581</a> [<a href="/pdf/2404.17581" title="Download PDF">pdf</a>, <a href="/ps/2404.17581" title="Download PostScript">ps</a>, <a href="/format/2404.17581" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Deepfake Labels Restore Reality, Especially for Those Who Dislike the  Speaker
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tenhundfeld%2C+N+L">Nathan L. Tenhundfeld</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Weber%2C+R">Ryan Weber</a>, 
  <a href="/search/cs?searchtype=author&amp;query=MacKenzie%2C+W+I">William I. MacKenzie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Barr%2C+H+M">Hannah M. Barr</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lanius%2C+C">Candice Lanius</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">Deepfake videos create dangerous possibilities for public misinformation. In
  this experiment (N=204), we investigated whether labeling videos as containing
  actual or deepfake statements from US President Biden helps participants later
  differentiate between true and fake information. People accurately recalled
  93.8% of deepfake videos and 84.2% of actual videos, suggesting that labeling
  videos can help combat misinformation. Individuals who identify as Republican
  and had lower favorability ratings of Biden performed better in distinguishing
  between actual and deepfake videos, a result explained by the elaboration
  likelihood model (ELM), which predicts that people who distrust a message
  source will more critically evaluate the message.
  </p>
  </div>
  </dd>
  <dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17582" title="Abstract">arXiv:2404.17582</a> [<a href="/pdf/2404.17582" title="Download PDF">pdf</a>, <a href="/format/2404.17582" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Data Quality in Crowdsourcing and Spamming Behavior Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ba%2C+Y">Yang Ba</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mancenido%2C+M+V">Michelle V. Mancenido</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chiou%2C+E+K">Erin K. Chiou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+R">Rong Pan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Preprint paper, under review on Behavior Research Methods. 45 pages, 10 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Applications (stat.AP)
  
  </div>
  <p class="mathjax">As crowdsourcing emerges as an efficient and cost-effective method for
  obtaining labels for machine learning datasets, it is important to assess the
  quality of crowd-provided data, so as to improve analysis performance and
  reduce biases in subsequent machine learning tasks. Given the lack of ground
  truth in most cases of crowdsourcing, we refer to data quality as annotators'
  consistency and credibility. Unlike the simple scenarios where Kappa
  coefficient and intraclass correlation coefficient usually can apply, online
  crowdsourcing requires dealing with more complex situations. We introduce a
  systematic method for evaluating data quality and detecting spamming threats
  via variance decomposition, and we classify spammers into three categories
  based on their different behavioral patterns. A spammer index is proposed to
  assess entire data consistency and two metrics are developed to measure crowd
  worker's credibility by utilizing the Markov chain and generalized random
  effects models. Furthermore, we showcase the practicality of our techniques and
  their advantages by applying them on a face verification task with both
  simulation and real-world data collected from two crowdsourcing platforms.
  </p>
  </div>
  </dd>
  <dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17585" title="Abstract">arXiv:2404.17585</a> [<a href="/pdf/2404.17585" title="Download PDF">pdf</a>, <a href="/format/2404.17585" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> NeuroNet: A Novel Hybrid Self-Supervised Learning Framework for Sleep  Stage Classification Using Single-Channel EEG
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+C">Cheol-Hui Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+H">Hakseung Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+H">Hyun-jee Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jung%2C+M">Min-Kyung Jung</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yoon%2C+B+C">Byung C. Yoon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D">Dong-Joo Kim</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, 4 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)
  
  </div>
  <p class="mathjax">The classification of sleep stages is a pivotal aspect of diagnosing sleep
  disorders and evaluating sleep quality. However, the conventional manual
  scoring process, conducted by clinicians, is time-consuming and prone to human
  bias. Recent advancements in deep learning have substantially propelled the
  automation of sleep stage classification. Nevertheless, challenges persist,
  including the need for large datasets with labels and the inherent biases in
  human-generated annotations. This paper introduces NeuroNet, a self-supervised
  learning (SSL) framework designed to effectively harness unlabeled
  single-channel sleep electroencephalogram (EEG) signals by integrating
  contrastive learning tasks and masked prediction tasks. NeuroNet demonstrates
  superior performance over existing SSL methodologies through extensive
  experimentation conducted across three polysomnography (PSG) datasets.
  Additionally, this study proposes a Mamba-based temporal context module to
  capture the relationships among diverse EEG epochs. Combining NeuroNet with the
  Mamba-based temporal context module has demonstrated the capability to achieve,
  or even surpass, the performance of the latest supervised learning
  methodologies, even with a limited amount of labeled data. This study is
  expected to establish a new benchmark in sleep stage classification, promising
  to guide future research and applications in the field of sleep analysis.
  </p>
  </div>
  </dd>
  <dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17586" title="Abstract">arXiv:2404.17586</a> [<a href="/pdf/2404.17586" title="Download PDF">pdf</a>, <a href="/ps/2404.17586" title="Download PostScript">ps</a>, <a href="/format/2404.17586" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Future of Scientific Publishing: Automated Article Generation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Harper%2C+J+R">Jeremy R. Harper</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Keywords: automated academic writing, Python code, software tool, article generation, natural language processing, scholarly publishing, code analysis, academic article automation, research dissemination, programming and publishing integration
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)
  
  </div>
  <p class="mathjax">This study introduces a novel software tool leveraging large language model
  (LLM) prompts, designed to automate the generation of academic articles from
  Python code a significant advancement in the fields of biomedical informatics
  and computer science. Selected for its widespread adoption and analytical
  versatility, Python served as a foundational proof of concept; however, the
  underlying methodology and framework exhibit adaptability across various GitHub
  repo's underlining the tool's broad applicability (Harper 2024). By mitigating
  the traditionally time-intensive academic writing process, particularly in
  synthesizing complex datasets and coding outputs, this approach signifies a
  monumental leap towards streamlining research dissemination. The development
  was achieved without reliance on advanced language model agents, ensuring high
  fidelity in the automated generation of coherent and comprehensive academic
  content. This exploration not only validates the successful application and
  efficiency of the software but also projects how future integration of LLM
  agents which could amplify its capabilities, propelling towards a future where
  scientific findings are disseminated more swiftly and accessibly.
  </p>
  </div>
  </dd>
  <dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17587" title="Abstract">arXiv:2404.17587</a> [<a href="/pdf/2404.17587" title="Download PDF">pdf</a>, <a href="/format/2404.17587" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Uncovering the Metaverse within Everyday Environments: a Coarse-to-Fine  Approach
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+L">Liming Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Towey%2C+D">Dave Towey</a>, 
  <a href="/search/cs?searchtype=author&amp;query=French%2C+A+P">Andrew P. French</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Benford%2C+S">Steve Benford</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This paper has been accepted by The 48th IEEE International Conference on Computers, Software, and Applications (COMPSAC 2024) for publication. It includes around 5600 words, 11 pages, 15 figures, and 1 table
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">The recent release of the Apple Vision Pro has reignited interest in the
  metaverse, showcasing the intensified efforts of technology giants in
  developing platforms and devices to facilitate its growth. As the metaverse
  continues to proliferate, it is foreseeable that everyday environments will
  become increasingly saturated with its presence. Consequently, uncovering links
  to these metaverse items will be a crucial first step to interacting with this
  new augmented world. In this paper, we address the problem of establishing
  connections with virtual worlds within everyday environments, especially those
  that are not readily discernible through direct visual inspection. We introduce
  a vision-based approach leveraging Artcode visual markers to uncover hidden
  metaverse links embedded in our ambient surroundings. This approach
  progressively localises the access points to the metaverse, transitioning from
  coarse to fine localisation, thus facilitating an exploratory interaction
  process. Detailed experiments are conducted to study the performance of the
  proposed approach, demonstrating its effectiveness in Artcode localisation and
  enabling new interaction opportunities.
  </p>
  </div>
  </dd>
  <dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17588" title="Abstract">arXiv:2404.17588</a> [<a href="/pdf/2404.17588" title="Download PDF">pdf</a>, <a href="/ps/2404.17588" title="Download PostScript">ps</a>, <a href="/format/2404.17588" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring Vulnerabilities in Remote VR User Studies
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Paneva%2C+V">Viktorija Paneva</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Alt%2C+F">Florian Alt</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Workshop Paper for CHI'24 Shaping The Future: Developing Principles for Policy Recommendations for Responsible Innovation in Virtual Worlds
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">This position paper explores the possibilities and challenges of using
  Virtual Reality (VR) in remote user studies. Highlighting the immersive nature
  of VR, the paper identifies key vulnerabilities, including varying technical
  proficiency, privacy concerns, ethical considerations, and data security risks.
  To address these issues, proposed mitigation strategies encompass comprehensive
  onboarding, prioritized informed consent, implementing privacy-by-design
  principles, and adherence to ethical guidelines. Secure data handling,
  including encryption and disposal protocols, is advocated. In conclusion, while
  remote VR studies present unique opportunities, carefully considering and
  implementing mitigation strategies is essential to uphold reliability, ethical
  integrity, and security, ensuring responsible and effective use of VR in user
  research. Ongoing efforts are crucial for adapting to the evolving landscape of
  VR technology in user studies.
  </p>
  </div>
  </dd>
  <dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17589" title="Abstract">arXiv:2404.17589</a> [<a href="/pdf/2404.17589" title="Download PDF">pdf</a>, <a href="/ps/2404.17589" title="Download PostScript">ps</a>, <a href="/format/2404.17589" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An Off-Policy Reinforcement Learning Algorithm Customized for Multi-Task  Fusion in Large-Scale Recommender Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+P">Peng Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+C">Cong Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+M">Ming Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jiawei Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bin Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+Y">Yi Ren</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Recommender Systems (RSs) are widely used to provide personalized
  recommendation service. As the last critical stage of RSs, Multi-Task Fusion
  (MTF) is responsible for combining multiple scores outputted by Multi-Task
  Learning (MTL) into a final score to maximize user satisfaction, which
  determines the ultimate recommendation results. Recently, to optimize long-term
  user satisfaction within a recommendation session, Reinforcement Learning (RL)
  is used for MTF in the industry. However, the off-policy RL algorithms used for
  MTF so far have the following severe problems: 1) to avoid out-of-distribution
  (OOD) problem, their constraints are overly strict, which seriously damage
  their performance; 2) they are unaware of the exploration policy used for
  producing training data and never interact with real environment, so only
  suboptimal policy can be learned; 3) the traditional exploration policies are
  inefficient and hurt user experience. To solve the above problems, we propose a
  novel off-policy RL algorithm customized for MTF in large-scale RSs. Our RL-MTF
  algorithm integrates off-policy RL model with our online exploration policy to
  relax overstrict and complicated constraints, which significantly improves the
  performance of our RL model. We also design an extremely efficient exploration
  policy, which eliminates low-value exploration space and focuses on exploring
  potential high-value state-action pairs. Moreover, we adopt progressive
  training mode to further enhance our RL model's performance with the help of
  our exploration policy. We conduct extensive offline and online experiments in
  the short video channel of Tencent News. The results demonstrate that our
  RL-MTF model outperforms other models remarkably. Our RL-MTF model has been
  fully deployed in the short video channel of Tencent News for about one year.
  In addition, our solution has been used in other large-scale RSs in Tencent.
  </p>
  </div>
  </dd>
  <dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17590" title="Abstract">arXiv:2404.17590</a> [<a href="/pdf/2404.17590" title="Download PDF">pdf</a>, <a href="/format/2404.17590" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Leveraging Intra-modal and Inter-modal Interaction for Multi-Modal  Entity Alignment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+Z">Zhiwei Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guti%C3%A9rrez-Basulto%2C+V">Víctor Gutiérrez-Basulto</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiang%2C+Z">Zhiliang Xiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+R">Ru Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+J+Z">Jeff Z. Pan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Multi-modal entity alignment (MMEA) aims to identify equivalent entity pairs
  across different multi-modal knowledge graphs (MMKGs). Existing approaches
  focus on how to better encode and aggregate information from different
  modalities. However, it is not trivial to leverage multi-modal knowledge in
  entity alignment due to the modal heterogeneity. In this paper, we propose a
  Multi-Grained Interaction framework for Multi-Modal Entity Alignment (MIMEA),
  which effectively realizes multi-granular interaction within the same modality
  or between different modalities. MIMEA is composed of four modules: i) a
  Multi-modal Knowledge Embedding module, which extracts modality-specific
  representations with multiple individual encoders; ii) a Probability-guided
  Modal Fusion module, which employs a probability guided approach to integrate
  uni-modal representations into joint-modal embeddings, while considering the
  interaction between uni-modal representations; iii) an Optimal Transport Modal
  Alignment module, which introduces an optimal transport mechanism to encourage
  the interaction between uni-modal and joint-modal embeddings; iv) a
  Modal-adaptive Contrastive Learning module, which distinguishes the embeddings
  of equivalent entities from those of non-equivalent ones, for each modality.
  Extensive experiments conducted on two real-world datasets demonstrate the
  strong performance of MIMEA compared to the SoTA. Datasets and code have been
  submitted as supplementary materials.
  </p>
  </div>
  </dd>
  <dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17591" title="Abstract">arXiv:2404.17591</a> [<a href="/pdf/2404.17591" title="Download PDF">pdf</a>, <a href="/format/2404.17591" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Large Language Models for Next Point-of-Interest Recommendation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+P">Peibo Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=de+Rijke%2C+M">Maarten de Rijke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+H">Hao Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ao%2C+S">Shuang Ao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+Y">Yang Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Salim%2C+F+D">Flora D. Salim</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">The next Point of Interest (POI) recommendation task is to predict users'
  immediate next POI visit given their historical data. Location-Based Social
  Network (LBSN) data, which is often used for the next POI recommendation task,
  comes with challenges. One frequently disregarded challenge is how to
  effectively use the abundant contextual information present in LBSN data.
  Previous methods are limited by their numerical nature and fail to address this
  challenge. In this paper, we propose a framework that uses pretrained Large
  Language Models (LLMs) to tackle this challenge. Our framework allows us to
  preserve heterogeneous LBSN data in its original format, hence avoiding the
  loss of contextual information. Furthermore, our framework is capable of
  comprehending the inherent meaning of contextual information due to the
  inclusion of commonsense knowledge. In experiments, we test our framework on
  three real-world LBSN datasets. Our results show that the proposed framework
  outperforms the state-of-the-art models in all three datasets. Our analysis
  demonstrates the effectiveness of the proposed framework in using contextual
  information as well as alleviating the commonly encountered cold-start and
  short trajectory problems.
  </p>
  </div>
  </dd>
  <dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17592" title="Abstract">arXiv:2404.17592</a> [<a href="/pdf/2404.17592" title="Download PDF">pdf</a>, <a href="/format/2404.17592" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Low-Rank Online Dynamic Assortment with Dual Contextual Information
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+S+J">Seong Jin Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+W+W">Will Wei Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yufeng Liu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">As e-commerce expands, delivering real-time personalized recommendations from
  vast catalogs poses a critical challenge for retail platforms. Maximizing
  revenue requires careful consideration of both individual customer
  characteristics and available item features to optimize assortments over time.
  In this paper, we consider the dynamic assortment problem with dual contexts --
  user and item features. In high-dimensional scenarios, the quadratic growth of
  dimensions complicates computation and estimation. To tackle this challenge, we
  introduce a new low-rank dynamic assortment model to transform this problem
  into a manageable scale. Then we propose an efficient algorithm that estimates
  the intrinsic subspaces and utilizes the upper confidence bound approach to
  address the exploration-exploitation trade-off in online decision making.
  Theoretically, we establish a regret bound of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1" style="width: 8.415em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.834em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.471em, 1006.778em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="texatom" id="MathJax-Span-3"><span class="mrow" id="MathJax-Span-4"><span class="munderover" id="MathJax-Span-5"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-6" style="font-family: STIXGeneral-Italic;">O</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.288em; left: 0.172em;"><span style="height: 0em; vertical-align: 0em; width: 0.398em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-7" style="font-family: STIXGeneral-Regular;"><span style="margin-left: -0.392em;">̃</span><span style="height: 0em; vertical-align: 0em; margin-left: -0.054em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-8" style="font-family: STIXGeneral-Regular;">(</span><span class="mo" id="MathJax-Span-9" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-10"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-11" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="mn" id="MathJax-Span-12" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-13" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">+</span><span class="msubsup" id="MathJax-Span-14" style="padding-left: 0.229em;"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-15" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="mn" id="MathJax-Span-16" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-17" style="font-family: STIXGeneral-Regular;">)</span><span class="mi" id="MathJax-Span-18" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="msqrt" id="MathJax-Span-19"><span style="display: inline-block; position: relative; width: 1.414em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.624em, 4.181em, -999.997em); top: -4.006em; left: 0.737em;"><span class="mrow" id="MathJax-Span-20"><span class="mi" id="MathJax-Span-21" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(2.995em, 1000.68em, 3.39em, -999.997em); top: -4.006em; left: 0.737em;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; font-family: STIXGeneral-Regular; top: -4.006em; left: 0em;">‾<span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; font-family: STIXGeneral-Regular; top: -4.006em; left: 0.172em;">‾<span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(2.882em, 1000.793em, 4.181em, -999.997em); top: -3.893em; left: 0em;"><span style="font-family: STIXVariants;">√</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-22" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-1">\tilde{O}((d_1+d_2)r\sqrt{T})</script>,
  where <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-23" style="width: 2.826em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.261em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.261em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-24"><span class="msubsup" id="MathJax-Span-25"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-26" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="mn" id="MathJax-Span-27" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-28" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-29" style="padding-left: 0.172em;"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-30" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="mn" id="MathJax-Span-31" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-2">d_1, d_2</script> represent the dimensions of the user and item features
  respectively, <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-32" style="width: 0.511em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.398em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.398em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-33"><span class="mi" id="MathJax-Span-34" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-3">r</script> is the rank of the parameter matrix, and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-35" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-36"><span class="mi" id="MathJax-Span-37" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-4">T</script> denotes the time
  horizon. This bound represents a substantial improvement over prior literature,
  made possible by leveraging the low-rank structure. Extensive simulations and
  an application to the Expedia hotel recommendation dataset further demonstrate
  the advantages of our proposed method.
  </p>
  </div>
  </dd>
  <dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17593" title="Abstract">arXiv:2404.17593</a> [<a href="/pdf/2404.17593" title="Download PDF">pdf</a>, <a href="/format/2404.17593" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Continual Relation Extraction Approach for Knowledge Graph  Completeness
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Efeoglu%2C+S">Sefika Efeoglu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Published at TPDL 2022
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> TPDL 2022: 26th International Conference on Theory and Practice of
    Digital Libraries, 20-23 September 2022, Padua, Italy
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Representing unstructured data in a structured form is most significant for
  information system management to analyze and interpret it. To do this, the
  unstructured data might be converted into Knowledge Graphs, by leveraging an
  information extraction pipeline whose main tasks are named entity recognition
  and relation extraction. This thesis aims to develop a novel continual relation
  extraction method to identify relations (interconnections) between entities in
  a data stream coming from the real world. Domain-specific data of this thesis
  is corona news from German and Austrian newspapers.
  </p>
  </div>
  </dd>
  <dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17595" title="Abstract">arXiv:2404.17595</a> [<a href="/pdf/2404.17595" title="Download PDF">pdf</a>, <a href="/ps/2404.17595" title="Download PostScript">ps</a>, <a href="/format/2404.17595" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> TICE and normalisation, pour une r{é}novation universitaire dans les  pays du Sud
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Henda%2C+M+B">Mokhtar Ben Henda</a> (MICA, ISD, GRESIC, ISIC, Chaire Unesco-ITEN)
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Colloque international " Les usages intelligents des technologies
    de l'information et de la communication dans la r{\'e}organisation
    universitaire '', Africampus; Universit{\'e} Omar Bongo, Jun 2008,
    Libreville, Gabon. pp.437-458
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC); Information Theory (cs.IT)
  
  </div>
  <p class="mathjax">University renovation is a recurring fact generated by permanent
  technological innovations and new methods of organizing universities and
  training offers. Technological interoperability standards play a determining
  role, not only by providing added value in terms of saving space and time, but
  also by changing educational models and knowledge acquisition processes. The
  countries of sub-Saharan Africa present an institutional framework and a
  particular type of university organization which requires an in-depth rereading
  of their operating methods for a better recovery on the path to renovation
  through ICT. This document offers avenues for reflection and action frameworks
  that focus on the achievements of norms and interoperability standards.
  </p>
  </div>
  </dd>
  <dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17597" title="Abstract">arXiv:2404.17597</a> [<a href="/pdf/2404.17597" title="Download PDF">pdf</a>, <a href="/format/2404.17597" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> KamerRaad: Enhancing Information Retrieval in Belgian National Politics  through Hierarchical Summarization and Conversational Interfaces
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rogiers%2C+A">Alexander Rogiers</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Buyl%2C+M">Maarten Buyl</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kang%2C+B">Bo Kang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Bie%2C+T">Tijl De Bie</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 4 pages, 2 figures, submitted to 2024 ECML-PKDD demo track
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">KamerRaad is an AI tool that leverages large language models to help citizens
  interactively engage with Belgian political information. The tool extracts and
  concisely summarizes key excerpts from parliamentary proceedings, followed by
  the potential for interaction based on generative AI that allows users to
  steadily build up their understanding. KamerRaad's front-end, built with
  Streamlit, facilitates easy interaction, while the back-end employs open-source
  models for text embedding and generation to ensure accurate and relevant
  responses. By collecting feedback, we intend to enhance the relevancy of our
  source retrieval and the quality of our summarization, thereby enriching the
  user experience with a focus on source-driven dialogue.
  </p>
  </div>
  </dd>
  <dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17598" title="Abstract">arXiv:2404.17598</a> [<a href="/pdf/2404.17598" title="Download PDF">pdf</a>, <a href="/format/2404.17598" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Revealing and Utilizing In-group Favoritism for Graph-based  Collaborative Filtering
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jung%2C+H">Hoin Jung</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cho%2C+H">Hyunsoo Cho</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Choi%2C+M">Myungje Choi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Joowon Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Park%2C+J+H">Jung Ho Park</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kang%2C+M">Myungjoo Kang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 6 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)
  
  </div>
  <p class="mathjax">When it comes to a personalized item recommendation system, It is essential
  to extract users' preferences and purchasing patterns. Assuming that users in
  the real world form a cluster and there is common favoritism in each cluster,
  in this work, we introduce Co-Clustering Wrapper (CCW). We compute co-clusters
  of users and items with co-clustering algorithms and add CF subnetworks for
  each cluster to extract the in-group favoritism. Combining the features from
  the networks, we obtain rich and unified information about users. We
  experimented real world datasets considering two aspects: Finding the number of
  groups divided according to in-group preference, and measuring the quantity of
  improvement of the performance.
  </p>
  </div>
  </dd>
  <dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17602" title="Abstract">arXiv:2404.17602</a> [<a href="/pdf/2404.17602" title="Download PDF">pdf</a>, <a href="/format/2404.17602" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Human-AI Collaborative Big-Thick Data Collection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Haonan Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kayongo%2C+I">Ivan Kayongo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Malcotti%2C+L">Leonardo Malcotti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Giunchiglia%2C+F">Fausto Giunchiglia</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 3 pages, 2 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">By Big-Thick data, we mean large-scale sensor data (big data) which provides
  an objective view of reality, coupled with thick data, i.e., data generated by
  people, which describes their subjective view of the reality described by big
  data. Big-thick data enables a machine understanding of human behavior and
  activities, as well as the human interpretation of what they are doing, i.e.,
  their own personal descriptions of the why, what, and how. The goal of this
  short paper is to provide a high-level description of a platform, called i-Log,
  that enables the collection of big-thick data. Its core components are: tools
  for collecting sensor data as well as the user feedback (e.g., user answers to
  machine questions), and a dashboard which provides visual qualitative and
  quantitative feedback on how things are evolving, as well as suitable
  notifications to the user.
  </p>
  </div>
  </dd>
  <dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17604" title="Abstract">arXiv:2404.17604</a> [<a href="/pdf/2404.17604" title="Download PDF">pdf</a>, <a href="/format/2404.17604" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring Remote Hands-on Support for Collaborative Embedded Systems  Development
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yan Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jones%2C+J">Jasmine Jones</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">Embedded systems development is a complex task that often requires team
  collaboration. Given the growing market of freelancers and the global shift to
  remote work, remote collaboration has become a necessity for many developers
  and clients. While existing communication and coordination tools help users
  share, discuss, and edit code collaboratively, these tools were specifically
  designed for software rather than hardware development. In this work, our goal
  is to explore the design space of remote support tools for embedded systems
  development. To do this, we interviewed 12 seasoned embedded systems developers
  regarding their current remote work practices, issues, and needs. We then
  conducted a user enactment study with a bespoke remote manipulation agent,
  Handy, as a hypothetical assistant to elicit the types of support developers
  desire from a collaborator. Our findings describe the scenarios and strategies
  in which remote work takes place; the support needs and information,
  coordination, and implementation challenges expressed by developers; and the
  privacy, control, and trust concerns that developers have when working on their
  projects with remote physical manipulation tools. This research contributes to
  the literature by bringing embedded systems development in line with remote,
  on-demand collaboration and help-seeking in software environments. The
  empirical basis of this work provides a rich foundation of documented needs,
  preferences, and desires that can ground future work on remote manipulation
  agents and enhance collaboration support in the domain of embedded systems
  development.
  </p>
  </div>
  </dd>
  <dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17606" title="Abstract">arXiv:2404.17606</a> [<a href="/pdf/2404.17606" title="Download PDF">pdf</a>, <a href="/format/2404.17606" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SetCSE: Set Operations using Contrastive Learning of Sentence Embeddings
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+K">Kang Liu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Taking inspiration from Set Theory, we introduce SetCSE, an innovative
  information retrieval framework. SetCSE employs sets to represent complex
  semantics and incorporates well-defined operations for structured information
  querying under the provided context. Within this framework, we introduce an
  inter-set contrastive learning objective to enhance comprehension of sentence
  embedding models concerning the given semantics. Furthermore, we present a
  suite of operations, including SetCSE intersection, difference, and operation
  series, that leverage sentence embeddings of the enhanced model for complex
  sentence retrieval tasks. Throughout this paper, we demonstrate that SetCSE
  adheres to the conventions of human language expressions regarding compounded
  semantics, provides a significant enhancement in the discriminatory capability
  of underlying sentence embedding models, and enables numerous information
  retrieval tasks involving convoluted and intricate prompts which cannot be
  achieved using existing querying methods.
  </p>
  </div>
  </dd>
  <dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17607" title="Abstract">arXiv:2404.17607</a> [<a href="/pdf/2404.17607" title="Download PDF">pdf</a>, <a href="/format/2404.17607" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Utilizing Large Language Models to Identify Reddit Users Considering  Vaping Cessation for Digital Interventions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Vuruma%2C+S+K+R">Sai Krishna Revanth Vuruma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+D">Dezhi Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+S+S">Saborny Sen Gupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aust%2C+L">Lucas Aust</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lookingbill%2C+V">Valerie Lookingbill</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Henry%2C+C">Caleb Henry</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+Y">Yang Ren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kasson%2C+E">Erin Kasson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Li-Shiun Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cavazos-Rehg%2C+P">Patricia Cavazos-Rehg</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+D">Dian Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+M">Ming Huang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Social and Information Networks (cs.SI)
  
  </div>
  <p class="mathjax">The widespread adoption of social media platforms globally not only enhances
  users' connectivity and communication but also emerges as a vital channel for
  the dissemination of health-related information, thereby establishing social
  media data as an invaluable organic data resource for public health research.
  The surge in popularity of vaping or e-cigarette use in the United States and
  other countries has caused an outbreak of e-cigarette and vaping use-associated
  lung injury (EVALI), leading to hospitalizations and fatalities in 2019,
  highlighting the urgency to comprehend vaping behaviors and develop effective
  strategies for cession. In this study, we extracted a sample dataset from one
  vaping sub-community on Reddit to analyze users' quit vaping intentions.
  Leveraging large language models including both the latest GPT-4 and
  traditional BERT-based language models for sentence-level quit-vaping intention
  prediction tasks, this study compares the outcomes of these models against
  human annotations. Notably, when compared to human evaluators, GPT-4 model
  demonstrates superior consistency in adhering to annotation guidelines and
  processes, showcasing advanced capabilities to detect nuanced user quit-vaping
  intentions that human evaluators might overlook. These preliminary findings
  emphasize the potential of GPT-4 in enhancing the accuracy and reliability of
  social media data analysis, especially in identifying subtle users' intentions
  that may elude human detection.
  </p>
  </div>
  </dd>
  <dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17608" title="Abstract">arXiv:2404.17608</a> [<a href="/pdf/2404.17608" title="Download PDF">pdf</a>, <a href="/ps/2404.17608" title="Download PostScript">ps</a>, <a href="/format/2404.17608" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Synthesizing Audio from Silent Video using Sequence to Sequence Modeling
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Belinchon%2C+H+G">Hugo Garrido-Lestache Belinchon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mulugeta%2C+H">Helina Mulugeta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Haile%2C+A">Adam Haile</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">Generating audio from a video's visual context has multiple practical
  applications in improving how we interact with audio-visual media - for
  example, enhancing CCTV footage analysis, restoring historical videos (e.g.,
  silent movies), and improving video generation models. We propose a novel
  method to generate audio from video using a sequence-to-sequence model,
  improving on prior work that used CNNs and WaveNet and faced sound diversity
  and generalization challenges. Our approach employs a 3D Vector Quantized
  Variational Autoencoder (VQ-VAE) to capture the video's spatial and temporal
  structures, decoding with a custom audio decoder for a broader range of sounds.
  Trained on the Youtube8M dataset segment, focusing on specific domains, our
  model aims to enhance applications like CCTV footage analysis, silent movie
  restoration, and video generation models.
  </p>
  </div>
  </dd>
  <dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17609" title="Abstract">arXiv:2404.17609</a> [<a href="/pdf/2404.17609" title="Download PDF">pdf</a>, <a href="/format/2404.17609" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CoSD: Collaborative Stance Detection with Contrastive Heterogeneous  Topic Graph Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Y">Yinghan Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+C">Chongyang Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+L">Liang Xiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hao%2C+S">Shufeng Hao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+L">Liang Hu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  <p class="mathjax">Stance detection seeks to identify the viewpoints of individuals either in
  favor or against a given target or a controversial topic. Current advanced
  neural models for stance detection typically employ fully parametric softmax
  classifiers. However, these methods suffer from several limitations, including
  lack of explainability, insensitivity to the latent data structure, and
  unimodality, which greatly restrict their performance and applications. To
  address these challenges, we present a novel collaborative stance detection
  framework called (CoSD) which leverages contrastive heterogeneous topic graph
  learning to learn topic-aware semantics and collaborative signals among texts,
  topics, and stance labels for enhancing stance detection. During training, we
  construct a heterogeneous graph to structurally organize texts and stances
  through implicit topics via employing latent Dirichlet allocation. We then
  perform contrastive graph learning to learn heterogeneous node representations,
  aggregating informative multi-hop collaborative signals via an elaborate
  Collaboration Propagation Aggregation (CPA) module. During inference, we
  introduce a hybrid similarity scoring module to enable the comprehensive
  incorporation of topic-aware semantics and collaborative signals for stance
  detection. Extensive experiments on two benchmark datasets demonstrate the
  state-of-the-art detection performance of CoSD, verifying the effectiveness and
  explainability of our collaborative framework.
  </p>
  </div>
  </dd>
  <dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17610" title="Abstract">arXiv:2404.17610</a> [<a href="/pdf/2404.17610" title="Download PDF">pdf</a>, <a href="/format/2404.17610" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Regression of Dense Distortion Field from a Single Fingerprint Image
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Guan%2C+X">Xiongjun Guan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Duan%2C+Y">Yongjie Duan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+J">Jianjiang Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jie Zhou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2404.17148">arXiv:2404.17148</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Forensics and Security, vol. 18,
    pp. 4377-4390, 2023
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Skin distortion is a long standing challenge in fingerprint matching, which
  causes false non-matches. Previous studies have shown that the recognition rate
  can be improved by estimating the distortion field from a distorted fingerprint
  and then rectifying it into a normal fingerprint. However, existing
  rectification methods are based on principal component representation of
  distortion fields, which is not accurate and are very sensitive to finger pose.
  In this paper, we propose a rectification method where a self-reference based
  network is utilized to directly estimate the dense distortion field of
  distorted fingerprint instead of its low dimensional representation. This
  method can output accurate distortion fields of distorted fingerprints with
  various finger poses and distortion patterns. We conducted experiments on
  FVC2004 DB1\_A, expanded Tsinghua Distorted Fingerprint database (with
  additional distorted fingerprints in diverse finger poses and distortion
  patterns) and a latent fingerprint database. Experimental results demonstrate
  that our proposed method achieves the state-of-the-art rectification
  performance in terms of distortion field estimation and rectified fingerprint
  matching.
  </p>
  </div>
  </dd>
  <dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17617" title="Abstract">arXiv:2404.17617</a> [<a href="/pdf/2404.17617" title="Download PDF">pdf</a>, <a href="/format/2404.17617" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Beyond Traditional Threats: A Persistent Backdoor Attack on Federated  Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+T">Tao Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuhang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Z">Zhu Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhiqin Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+C">Chen Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Man%2C+D">Dapeng Man</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+W">Wu Yang</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Proceedings of the AAAI Conference on Artificial Intelligence.
    2024, 38(19): 21359-21367
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Backdoors on federated learning will be diluted by subsequent benign updates.
  This is reflected in the significant reduction of attack success rate as
  iterations increase, ultimately failing. We use a new metric to quantify the
  degree of this weakened backdoor effect, called attack persistence. Given that
  research to improve this performance has not been widely noted,we propose a
  Full Combination Backdoor Attack (FCBA) method. It aggregates more combined
  trigger information for a more complete backdoor pattern in the global model.
  Trained backdoored global model is more resilient to benign updates, leading to
  a higher attack success rate on the test set. We test on three datasets and
  evaluate with two models across various settings. FCBA's persistence
  outperforms SOTA federated learning backdoor attacks. On GTSRB, postattack 120
  rounds, our attack success rate rose over 50% from baseline. The core code of
  our method is available at https://github.com/PhD-TaoLiu/FCBA.
  </p>
  </div>
  </dd>
  <dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17619" title="Abstract">arXiv:2404.17619</a> [<a href="/pdf/2404.17619" title="Download PDF">pdf</a>, <a href="/format/2404.17619" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> VisAnywhere: Developing Multi-platform Scientific Visualization  Applications
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Marrinan%2C+T">Thomas Marrinan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Moeller%2C+M">Madeleine Moeller</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kanayinkal%2C+A">Alina Kanayinkal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mateevitsi%2C+V+A">Victor A. Mateevitsi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Papka%2C+M+E">Michael E. Papka</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)
  
  </div>
  <p class="mathjax">Scientists often explore and analyze large-scale scientific simulation data
  by leveraging two- and three-dimensional visualizations. The data and tasks can
  be complex and therefore best supported using myriad display technologies, from
  mobile devices to large high-resolution display walls to virtual reality
  headsets. Using a simulation of neuron connections in the human brain, we
  present our work leveraging various web technologies to create a multi-platform
  scientific visualization application. Users can spread visualization and
  interaction across multiple devices to support flexible user interfaces and
  both co-located and remote collaboration. Drawing inspiration from responsive
  web design principles, this work demonstrates that a single codebase can be
  adapted to develop scientific visualization applications that operate
  everywhere.
  </p>
  </div>
  </dd>
  <dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17620" title="Abstract">arXiv:2404.17620</a> [<a href="/pdf/2404.17620" title="Download PDF">pdf</a>, <a href="/format/2404.17620" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Neural Modes: Self-supervised Learning of Nonlinear Modal Subspaces
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiahong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Du%2C+Y">Yinwei Du</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Coros%2C+S">Stelian Coros</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Thomaszewski%2C+B">Bernhard Thomaszewski</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to CVPR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)
  
  </div>
  <p class="mathjax">We propose a self-supervised approach for learning physics-based subspaces
  for real-time simulation. Existing learning-based methods construct subspaces
  by approximating pre-defined simulation data in a purely geometric way.
  However, this approach tends to produce high-energy configurations, leads to
  entangled latent space dimensions, and generalizes poorly beyond the training
  set. To overcome these limitations, we propose a self-supervised approach that
  directly minimizes the system's mechanical energy during training. We show that
  our method leads to learned subspaces that reflect physical equilibrium
  constraints, resolve overfitting issues of previous methods, and offer
  interpretable latent space parameters.
  </p>
  </div>
  </dd>
  <dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17625" title="Abstract">arXiv:2404.17625</a> [<a href="/pdf/2404.17625" title="Download PDF">pdf</a>, <a href="/format/2404.17625" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Alice's Adventures in a Differentiable Wonderland -- Volume I, A Tour of  the Land
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Scardapane%2C+S">Simone Scardapane</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Companion website for additional chapters: <a href="https://www.sscardapane.it/alice-book">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">This book is a self-contained introduction to the design of modern (deep)
  neural networks. Because the term "neural" comes with a lot of historical
  baggage, I prefer the simpler term "differentiable models" in the text. The
  focus of this 250-pages volume is on building efficient blocks for processing
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-38" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-39"><span class="mi" id="MathJax-Span-40" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-5">n</script>D data, including convolutions, transformers, graph layers, and modern
  recurrent models (including linearized transformers and structured state-space
  models). Because the field is evolving quickly, I have tried to strike a good
  balance between theory and code, historical considerations and recent trends. I
  assume the reader has some exposure to machine learning and linear algebra, but
  I try to cover the preliminaries when necessary.
  <br>The volume is a refined draft from a set of lecture notes for a course called
  Neural Networks for Data Science Applications that I teach in Sapienza. I do
  not cover many advanced topics (generative modeling, explainability, prompting,
  agents), which will be published over time in the companion website.
  </p>
  </div>
  </dd>
  <dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17626" title="Abstract">arXiv:2404.17626</a> [<a href="/pdf/2404.17626" title="Download PDF">pdf</a>, <a href="/format/2404.17626" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Using Pre-training and Interaction Modeling for ancestry-specific  disease prediction in UK Biobank
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Menestrel%2C+T+L">Thomas Le Menestrel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Craig%2C+E">Erin Craig</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tibshirani%2C+R">Robert Tibshirani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hastie%2C+T">Trevor Hastie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rivas%2C+M">Manuel Rivas</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM); Applications (stat.AP); Computation (stat.CO)
  
  </div>
  <p class="mathjax">Recent genome-wide association studies (GWAS) have uncovered the genetic
  basis of complex traits, but show an under-representation of non-European
  descent individuals, underscoring a critical gap in genetic research. Here, we
  assess whether we can improve disease prediction across diverse ancestries
  using multiomic data. We evaluate the performance of Group-LASSO
  INTERaction-NET (glinternet) and pretrained lasso in disease prediction
  focusing on diverse ancestries in the UK Biobank. Models were trained on data
  from White British and other ancestries and validated across a cohort of over
  96,000 individuals for 8 diseases. Out of 96 models trained, we report 16 with
  statistically significant incremental predictive performance in terms of
  ROC-AUC scores. These findings suggest that advanced statistical methods that
  borrow information across multiple ancestries may improve disease risk
  prediction, but with limited benefit.
  </p>
  </div>
  </dd>
  <dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17627" title="Abstract">arXiv:2404.17627</a> [<a href="/pdf/2404.17627" title="Download PDF">pdf</a>, <a href="/format/2404.17627" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Impact of Traffic-Following on Order of Autonomous Airspace Operations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jain%2C+A">Anahita Jain</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Idris%2C+H+R">Husni R. Idris</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Clarke%2C+J">John-Paul Clarke</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Computational Engineering, Finance, and Science (cs.CE); Emerging Technologies (cs.ET); Systems and Control (eess.SY)
  
  </div>
  <p class="mathjax">In this paper, we investigate the dynamic emergence of traffic order in a
  distributed multi-agent system, aiming to minimize inefficiencies that stem
  from unnecessary structural impositions. We introduce a methodology for
  developing a dynamically-updating traffic pattern map of the airspace by
  leveraging information about the consistency and frequency of flow directions
  used by current as well as preceding traffic. Informed by this map, an agent
  can discern the degree to which it is advantageous to follow traffic by trading
  off utilities such as time and order. We show that for the traffic levels
  studied, for low degrees of traffic-following behavior, there is minimal
  penalty in terms of aircraft travel times while improving the overall
  orderliness of the airspace. On the other hand, heightened traffic-following
  behavior may result in increased aircraft travel times, while marginally
  reducing the overall entropy of the airspace. Ultimately, the methods and
  metrics presented in this paper can be used to optimally and dynamically adjust
  an agent's traffic-following behavior based on these trade-offs.
  </p>
  </div>
  </dd>
  <dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17642" title="Abstract">arXiv:2404.17642</a> [<a href="/pdf/2404.17642" title="Download PDF">pdf</a>, <a href="/format/2404.17642" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Empowering Large Language Models for Textual Data Augmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yichuan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+K">Kaize Ding</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianling Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+K">Kyumin Lee</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">With the capabilities of understanding and executing natural language
  instructions, Large language models (LLMs) can potentially act as a powerful
  tool for textual data augmentation. However, the quality of augmented data
  depends heavily on the augmentation instructions provided, and the
  effectiveness can fluctuate across different downstream tasks. While manually
  crafting and selecting instructions can offer some improvement, this approach
  faces scalability and consistency issues in practice due to the diversity of
  downstream tasks. In this work, we address these limitations by proposing a new
  solution, which can automatically generate a large pool of augmentation
  instructions and select the most suitable task-informed instructions, thereby
  empowering LLMs to create high-quality augmented data for different downstream
  tasks. Empirically, the proposed approach consistently generates augmented data
  with better quality compared to non-LLM and LLM-based data augmentation
  methods, leading to the best performance on 26 few-shot learning tasks sourced
  from a wide range of application domains.
  </p>
  </div>
  </dd>
  <dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17645" title="Abstract">arXiv:2404.17645</a> [<a href="/pdf/2404.17645" title="Download PDF">pdf</a>, <a href="/format/2404.17645" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Técnicas Quantum-Inspired en Tensor Networks para Contextos  Industriales
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ali%2C+A+M">Alejandro Mata Ali</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Delgado%2C+I+P">Iñigo Perez Delgado</a>, 
  <a href="/search/cs?searchtype=author&amp;query=de+Leceta%2C+A+M+F">Aitor Moreno Fdez. de Leceta</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, in Spanish language, 5 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Quantum Physics (quant-ph)
  
  </div>
  <p class="mathjax">In this paper we present a study of the applicability and feasibility of
  quantum-inspired algorithms and techniques in tensor networks for industrial
  environments and contexts, with a compilation of the available literature and
  an analysis of the use cases that may be affected by such methods. In addition,
  we explore the limitations of such techniques in order to determine their
  potential scalability.
  </p>
  </div>
  </dd>
  <dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17648" title="Abstract">arXiv:2404.17648</a> [<a href="/pdf/2404.17648" title="Download PDF">pdf</a>, <a href="/format/2404.17648" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Consolidating LAMA with Best-First Width Search
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Corr%C3%AAa%2C+A+B">Augusto B. Corrêa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Seipp%2C+J">Jendrik Seipp</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)
  
  </div>
  <p class="mathjax">One key decision for heuristic search algorithms is how to balance
  exploration and exploitation. In classical planning, novelty search has come
  out as the most successful approach in this respect. The idea is to favor
  states that contain previously unseen facts when searching for a plan. This is
  done by maintaining a record of the tuples of facts observed in previous
  states. Then the novelty of a state is the size of the smallest previously
  unseen tuple. The most successful version of novelty search is best-first width
  search (BFWS), which combines novelty measures with heuristic estimates. An
  orthogonal approach to balance exploration-exploitation is to use several
  open-lists. These open-lists are ordered using different heuristic estimates,
  which diversify the information used in the search. The search algorithm then
  alternates between these open-lists, trying to exploit these different
  estimates. This is the approach used by LAMA, a classical planner that, a
  decade after its release, is still considered state-of-the-art in agile
  planning. In this paper, we study how to combine LAMA and BFWS. We show that
  simply adding the strongest open-list used in BFWS to LAMA harms performance.
  However, we show that combining only parts of each planner leads to a new
  state-of-the-art agile planner.
  </p>
  </div>
  </dd>
  <dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17651" title="Abstract">arXiv:2404.17651</a> [<a href="/pdf/2404.17651" title="Download PDF">pdf</a>, <a href="/format/2404.17651" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Hard ASH: Sparsity and the right optimizer make a continual learner
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Keskinen%2C+S">Santtu Keskinen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICLR 2024 TinyPaper
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">In class incremental learning, neural networks typically suffer from
  catastrophic forgetting. We show that an MLP featuring a sparse activation
  function and an adaptive learning rate optimizer can compete with established
  regularization techniques in the Split-MNIST task. We highlight the
  effectiveness of the Adaptive SwisH (ASH) activation function in this context
  and introduce a novel variant, Hard Adaptive SwisH (Hard ASH) to further
  enhance the learning retention.
  </p>
  </div>
  </dd>
  <dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17661" title="Abstract">arXiv:2404.17661</a> [<a href="/pdf/2404.17661" title="Download PDF">pdf</a>, <a href="/format/2404.17661" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A High-order Arbitrary Lagrangian-Eulerian Virtual Element Method for  Convection-Diffusion Problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Wells%2C+H">H. Wells</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">A virtual element discretisation of an Arbitrary Lagrangian-Eulerian method
  for two-dimensional convection-diffusion equations is proposed employing an
  isoparametric Virtual Element Method to achieve higher-order convergence rates
  on curved edged polygonal meshes. The proposed method is validated with
  numerical experiments in which optimal <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-6-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-41" style="width: 1.64em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.301em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-42"><span class="msubsup" id="MathJax-Span-43"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.793em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-44" style="font-family: STIXGeneral-Italic;">H<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.85em;"><span class="mn" id="MathJax-Span-45" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-6">H^1</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-46" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.076em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-47"><span class="msubsup" id="MathJax-Span-48"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-49" style="font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.624em;"><span class="mn" id="MathJax-Span-50" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-7">L^2</script> convergence are
  observed. This method is then successfully applied to an existing moving mesh
  algorithm for implicit moving boundary problems in which higher-order
  convergence is achieved.
  </p>
  </div>
  </dd>
  <dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17662" title="Abstract">arXiv:2404.17662</a> [<a href="/pdf/2404.17662" title="Download PDF">pdf</a>, <a href="/format/2404.17662" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction  in Murder Mystery Games
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qinglin Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+R">Runcong Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Du%2C+J">Jinhua Du</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gui%2C+L">Lin Gui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+Y">Yulan He</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Recent advancements in Large Language Models (LLMs) have enhanced the
  efficacy of agent communication and social interactions. Despite these
  advancements, building LLM-based agents for reasoning in dynamic environments
  involving competition and collaboration remains challenging due to the
  limitations of informed graph-based search methods. We propose PLAYER*, a novel
  framework based on an anytime sampling-based planner, which utilises sensors
  and pruners to enable a purely question-driven searching framework for complex
  reasoning tasks. We also introduce a quantifiable evaluation method using
  multiple-choice questions and construct the WellPlay dataset with 1,482 QA
  pairs. Experiments demonstrate PLAYER*'s efficiency and performance
  enhancements compared to existing methods in complex, dynamic environments with
  quantifiable results.
  </p>
  </div>
  </dd>
  <dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17663" title="Abstract">arXiv:2404.17663</a> [<a href="/pdf/2404.17663" title="Download PDF">pdf</a>, <a href="/ps/2404.17663" title="Download PostScript">ps</a>, <a href="/format/2404.17663" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An analysis of the suitability of OpenAlex for bibliometric analyses
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Alperin%2C+J+P">Juan Pablo Alperin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Portenoy%2C+J">Jason Portenoy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Demes%2C+K">Kyle Demes</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Larivi%C3%A8re%2C+V">Vincent Larivière</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Haustein%2C+S">Stefanie Haustein</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>
  
  </div>
  <p class="mathjax">Scopus and the Web of Science have been the foundation for research in the
  science of science even though these traditional databases systematically
  underrepresent certain disciplines and world regions. In response, new
  inclusive databases, notably OpenAlex, have emerged. While many studies have
  begun using OpenAlex as a data source, few critically assess its limitations.
  This study, conducted in collaboration with the OpenAlex team, addresses this
  gap by comparing OpenAlex to Scopus across a number of dimensions. The analysis
  concludes that OpenAlex is a superset of Scopus and can be a reliable
  alternative for some analyses, particularly at the country level. Despite this,
  issues of metadata accuracy and completeness show that additional research is
  needed to fully comprehend and address OpenAlex's limitations. Doing so will be
  necessary to confidently use OpenAlex across a wider set of analyses, including
  those that are not at all possible with more constrained databases.
  </p>
  </div>
  </dd>
  <dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17668" title="Abstract">arXiv:2404.17668</a> [<a href="/pdf/2404.17668" title="Download PDF">pdf</a>, <a href="/format/2404.17668" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Precise Object Placement Using Force-Torque Feedback
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lerner%2C+O">Osher Lerner</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tam%2C+Z">Zachary Tam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Equi%2C+M">Michael Equi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Precise object manipulation and placement is a common problem for household
  robots, surgery robots, and robots working on in-situ construction. Prior work
  using computer vision, depth sensors, and reinforcement learning lacks the
  ability to reactively recover from planning errors, execution errors, or sensor
  noise. This work introduces a method that uses force-torque sensing to robustly
  place objects in stable poses, even in adversarial environments. On 46 trials,
  our method finds success rates of 100% for basic stacking, and 17% for cases
  requiring adjustment.
  </p>
  </div>
  </dd>
  <dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17669" title="Abstract">arXiv:2404.17669</a> [<a href="/pdf/2404.17669" title="Download PDF">pdf</a>, <a href="/ps/2404.17669" title="Download PostScript">ps</a>, <a href="/format/2404.17669" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Approximation Algorithms for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-51" style="width: 1.346em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.078em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(0.181em, 1001.078em, 1.436em, -999.998em); top: -0.983em; left: 0em;"><span class="mrow" id="MathJax-Span-52"><span class="msubsup" id="MathJax-Span-53"><span style="display: inline-block; position: relative; width: 1.033em; height: 0px;"><span style="position: absolute; clip: rect(3.183em, 1000.585em, 4.124em, -999.998em); top: -3.985em; left: 0em;"><span class="mi" id="MathJax-Span-54" style="font-family: STIXGeneral-Italic;">ℓ</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.585em;"><span class="mi" id="MathJax-Span-55" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">p</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 0.988em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.442em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.336em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-8">\ell_p</script>-Shortest Path and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-56" style="width: 1.346em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.078em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(0.181em, 1001.078em, 1.436em, -999.998em); top: -0.983em; left: 0em;"><span class="mrow" id="MathJax-Span-57"><span class="msubsup" id="MathJax-Span-58"><span style="display: inline-block; position: relative; width: 1.033em; height: 0px;"><span style="position: absolute; clip: rect(3.183em, 1000.585em, 4.124em, -999.998em); top: -3.985em; left: 0em;"><span class="mi" id="MathJax-Span-59" style="font-family: STIXGeneral-Italic;">ℓ</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.585em;"><span class="mi" id="MathJax-Span-60" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">p</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 0.988em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.442em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.336em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-9">\ell_p</script>-Group  Steiner Tree
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Makarychev%2C+Y">Yury Makarychev</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ovsiankin%2C+M">Max Ovsiankin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tani%2C+E">Erasmo Tani</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  <p class="mathjax">We present polylogarithmic approximation algorithms for variants of the
  Shortest Path, Group Steiner Tree, and Group ATSP problems with vector costs.
  In these problems, each edge e has a non-negative vector cost <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-61" style="width: 4.802em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.898em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1003.898em, 3.052em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-62"><span class="msubsup" id="MathJax-Span-63"><span style="display: inline-block; position: relative; width: 0.85em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-64" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.454em;"><span class="mi" id="MathJax-Span-65" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">e</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-66" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="msubsup" id="MathJax-Span-67" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-68"><span class="mrow" id="MathJax-Span-69"><span class="mi" id="MathJax-Span-70" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.334em, 1000.511em, 4.181em, -999.997em); top: -4.401em; left: 0.737em;"><span class="texatom" id="MathJax-Span-71"><span class="mrow" id="MathJax-Span-72"><span class="mi" id="MathJax-Span-73" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">ℓ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.39em, 1000.906em, 4.237em, -999.997em); top: -3.723em; left: 0.737em;"><span class="texatom" id="MathJax-Span-74"><span class="mrow" id="MathJax-Span-75"><span class="mo" id="MathJax-Span-76" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">≥</span><span class="mn" id="MathJax-Span-77" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.67em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-10">c_e \in
  \mathbb{R}^{\ell}_{\ge 0}</script>. For a feasible solution - a path, subtree, or tour
  (respectively) - we find the total vector cost of all the edges in the solution
  and then compute the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-78" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.471em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-79"><span class="msubsup" id="MathJax-Span-80"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-81" style="font-family: STIXGeneral-Italic;">ℓ</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.567em;"><span class="mi" id="MathJax-Span-82" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">p</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.413em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.323em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-11">\ell_p</script>-norm of the obtained cost vector (we assume that
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-83" style="width: 2.995em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.431em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.318em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-84"><span class="mi" id="MathJax-Span-85" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-86" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≥</span><span class="mn" id="MathJax-Span-87" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-12">p \ge 1</script> is an integer). Our algorithms for series-parallel graphs run in
  polynomial time and those for arbitrary graphs run in quasi-polynomial time. To
  obtain our results, we introduce and use new flow-based Sum-of-Squares
  relaxations. We also obtain a number of hardness results.
  </p>
  </div>
  </dd>
  <dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17671" title="Abstract">arXiv:2404.17671</a> [<a href="/pdf/2404.17671" title="Download PDF">pdf</a>, <a href="/format/2404.17671" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Membrane Computing Approach to the Generalized Nash Equilibrium
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Luque-Cerpa%2C+A">Alejandro Luque-Cerpa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guti%C3%A9rrez-Naranjo%2C+M+A">Miguel A. Gutiérrez-Naranjo</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>
  
  </div>
  <p class="mathjax">In Evolutionary Game Theory (EGT), a population reaches a Nash equilibrium
  when none of the agents can improve its objective by solely changing its
  strategy on its own. Roughly speaking, this equilibrium is a protection against
  betrayal. Generalized Nash Equilibrium (GNE) is a more complex version of this
  idea with important implications in real-life problems in economics, wireless
  communication, the electricity market, or engineering among other areas. In
  this paper, we propose a first approach to GNE with Membrane Computing
  techniques and show how GNE problems can be modeled with P systems, bridging
  both areas and opening a door for a flow of problems and solutions in both
  directions.
  </p>
  </div>
  </dd>
  <dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17672" title="Abstract">arXiv:2404.17672</a> [<a href="/pdf/2404.17672" title="Download PDF">pdf</a>, <a href="/format/2404.17672" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> BlenderAlchemy: Editing 3D Graphics with Vision-Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+I">Ian Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+G">Guandao Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guibas%2C+L">Leonidas Guibas</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
  
  </div>
  <p class="mathjax">Graphics design is important for various applications, including movie
  production and game design. To create a high-quality scene, designers usually
  need to spend hours in software like Blender, in which they might need to
  interleave and repeat operations, such as connecting material nodes, hundreds
  of times. Moreover, slightly different design goals may require completely
  different sequences, making automation difficult. In this paper, we propose a
  system that leverages Vision-Language Models (VLMs), like GPT-4V, to
  intelligently search the design action space to arrive at an answer that can
  satisfy a user's intent. Specifically, we design a vision-based edit generator
  and state evaluator to work together to find the correct sequence of actions to
  achieve the goal. Inspired by the role of visual imagination in the human
  design process, we supplement the visual reasoning capabilities of VLMs with
  "imagined" reference images from image-generation models, providing visual
  grounding of abstract language descriptions. In this paper, we provide
  empirical evidence suggesting our system can produce simple but tedious Blender
  editing sequences for tasks such as editing procedural materials from text
  and/or reference images, as well as adjusting lighting configurations for
  product renderings in complex scenes.
  </p>
  </div>
  </dd>
  <dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17673" title="Abstract">arXiv:2404.17673</a> [<a href="/pdf/2404.17673" title="Download PDF">pdf</a>, <a href="/format/2404.17673" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning Manipulation Tasks in Dynamic and Shared 3D Spaces
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Arunachalam%2C+H">Hariharan Arunachalam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hanheide%2C+M">Marc Hanheide</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mghames%2C+S">Sariah Mghames</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 5 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)
  
  </div>
  <p class="mathjax">Automating the segregation process is a need for every sector experiencing a
  high volume of materials handling, repetitive and exhaustive operations, in
  addition to risky exposures. Learning automated pick-and-place operations can
  be efficiently done by introducing collaborative autonomous systems (e.g.
  manipulators) in the workplace and among human operators. In this paper, we
  propose a deep reinforcement learning strategy to learn the place task of
  multi-categorical items from a shared workspace between dual-manipulators and
  to multi-goal destinations, assuming the pick has been already completed. The
  learning strategy leverages first a stochastic actor-critic framework to train
  an agent's policy network, and second, a dynamic 3D Gym environment where both
  static and dynamic obstacles (e.g. human factors and robot mate) constitute the
  state space of a Markov decision process. Learning is conducted in a Gazebo
  simulator and experiments show an increase in cumulative reward function for
  the agent further away from human factors. Future investigations will be
  conducted to enhance the task performance for both agents simultaneously.
  </p>
  </div>
  </dd>
  <dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17674" title="Abstract">arXiv:2404.17674</a> [<a href="/pdf/2404.17674" title="Download PDF">pdf</a>, <a href="/format/2404.17674" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Center-Based Relaxed Learning Against Membership Inference Attacks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+X">Xingli Fang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">Jung-Eun Kim</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
  
  </div>
  <p class="mathjax">Membership inference attacks (MIAs) are currently considered one of the main
  privacy attack strategies, and their defense mechanisms have also been
  extensively explored. However, there is still a gap between the existing
  defense approaches and ideal models in performance and deployment costs. In
  particular, we observed that the privacy vulnerability of the model is closely
  correlated with the gap between the model's data-memorizing ability and
  generalization ability. To address this, we propose a new architecture-agnostic
  training paradigm called center-based relaxed learning (CRL), which is adaptive
  to any classification model and provides privacy preservation by sacrificing a
  minimal or no loss of model generalizability. We emphasize that CRL can better
  maintain the model's consistency between member and non-member data. Through
  extensive experiments on standard classification datasets, we empirically show
  that this approach exhibits comparable performance without requiring additional
  model capacity or data costs.
  </p>
  </div>
  </dd>
  <dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17679" title="Abstract">arXiv:2404.17679</a> [<a href="/pdf/2404.17679" title="Download PDF">pdf</a>, <a href="/format/2404.17679" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Recent Increments in Incremental View Maintenance
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Olteanu%2C+D">Dan Olteanu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 18 pages, 7 figures, Gems of PODS 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)
  
  </div>
  <p class="mathjax">We overview recent progress on the longstanding problem of incremental view
  maintenance (IVM), with a focus on the fine-grained complexity and optimality
  of IVM for classes of conjunctive queries. This theoretical progress guided the
  development of IVM engines that reported practical benefits in academic papers
  and industrial settings. When taken in isolation, each of the reported
  advancements is but a small increment. Yet when taken together, they may well
  pave the way to a deeper understanding of the IVM problem.
  <br>This paper accompanies the invited Gems of PODS 2024 talk with the same
  title. Some of the works highlighted in this paper are based on prior or
  on-going collaborations with: Ahmet Kara, Milos Nikolic, and Haozhe Zhang in
  the F-IVM project; and Mahmoud Abo Khamis, Niko G\"obel, Hung Ngo, and Dan
  Suciu at RelationalAI.
  </p>
  </div>
  </dd>
  <dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17681" title="Abstract">arXiv:2404.17681</a> [<a href="/pdf/2404.17681" title="Download PDF">pdf</a>, <a href="/ps/2404.17681" title="Download PostScript">ps</a>, <a href="/format/2404.17681" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Extrapolating on Taylor Series Solutions of Homotopies with Nearby Poles
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Verschelde%2C+J">Jan Verschelde</a>, 
  <a href="/search/math?searchtype=author&amp;query=Viswanathan%2C+K">Kylash Viswanathan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Keywords: continuation, extrapolation, homotopy, pole, polynomial, Taylor, series, singularity
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">A polynomial homotopy is a family of polynomial systems in one parameter,
  which defines solution paths starting from known solutions and ending at
  solutions of a system that has to be solved. We consider paths leading to
  isolated singular solutions, to which the Taylor series converges
  logarithmically. Whether or not extrapolation algorithms manage to accelerate
  the slowly converging series depends on the proximity of poles close to the
  disk of convergence of the Taylor series.
  </p>
  </div>
  </dd>
  <dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17684" title="Abstract">arXiv:2404.17684</a> [<a href="/pdf/2404.17684" title="Download PDF">pdf</a>, <a href="/format/2404.17684" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generalize by Touching: Tactile Ensemble Skill Transfer for Robotic  Furniture Assembly
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+H">Haohong Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Corcodel%2C+R">Radu Corcodel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+D">Ding Zhao</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Furniture assembly remains an unsolved problem in robotic manipulation due to
  its long task horizon and nongeneralizable operations plan. This paper presents
  the Tactile Ensemble Skill Transfer (TEST) framework, a pioneering offline
  reinforcement learning (RL) approach that incorporates tactile feedback in the
  control loop. TEST's core design is to learn a skill transition model for
  high-level planning, along with a set of adaptive intra-skill goal-reaching
  policies. Such design aims to solve the robotic furniture assembly problem in a
  more generalizable way, facilitating seamless chaining of skills for this
  long-horizon task. We first sample demonstration from a set of heuristic
  policies and trajectories consisting of a set of randomized sub-skill segments,
  enabling the acquisition of rich robot trajectories that capture skill stages,
  robot states, visual indicators, and crucially, tactile signals. Leveraging
  these trajectories, our offline RL method discerns skill termination conditions
  and coordinates skill transitions. Our evaluations highlight the proficiency of
  TEST on the in-distribution furniture assemblies, its adaptability to unseen
  furniture configurations, and its robustness against visual disturbances.
  Ablation studies further accentuate the pivotal role of two algorithmic
  components: the skill transition model and tactile ensemble policies. Results
  indicate that TEST can achieve a success rate of 90\% and is over 4 times more
  efficient than the heuristic policy in both in-distribution and generalization
  settings, suggesting a scalable skill transfer approach for contact-rich
  manipulation.
  </p>
  </div>
  </dd>
  <dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17685" title="Abstract">arXiv:2404.17685</a> [<a href="/pdf/2404.17685" title="Download PDF">pdf</a>, <a href="/ps/2404.17685" title="Download PostScript">ps</a>, <a href="/format/2404.17685" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Localization Through Particle Filter Powered Neural Network Estimated  Monocular Camera Poses
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yi Shen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Hao Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xinxin Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+W">Wenjing Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chang Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yizhou Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">The reduced cost and computational and calibration requirements of monocular
  cameras make them ideal positioning sensors for mobile robots, albeit at the
  expense of any meaningful depth measurement. Solutions proposed by some
  scholars to this localization problem involve fusing pose estimates from
  convolutional neural networks (CNNs) with pose estimates from geometric
  constraints on motion to generate accurate predictions of robot trajectories.
  However, the distribution of attitude estimation based on CNN is not uniform,
  resulting in certain translation problems in the prediction of robot
  trajectories. This paper proposes improving these CNN-based pose estimates by
  propagating a SE(3) uniform distribution driven by a particle filter. The
  particles utilize the same motion model used by the CNN, while updating their
  weights using CNN-based estimates. The results show that while the rotational
  component of pose estimation does not consistently improve relative to
  CNN-based estimation, the translational component is significantly more
  accurate. This factor combined with the superior smoothness of the filtered
  trajectories shows that the use of particle filters significantly improves the
  performance of CNN-based localization algorithms.
  </p>
  </div>
  </dd>
  <dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17686" title="Abstract">arXiv:2404.17686</a> [<a href="/pdf/2404.17686" title="Download PDF">pdf</a>, <a href="/format/2404.17686" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On the Benefits of Coding for Network Slicing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Esfahanizadeh%2C+H">Homa Esfahanizadeh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vasudevan%2C+V+A">Vipindev Adat Vasudevan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+B+D">Benjamin D. Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Siva%2C+S">Shruti Siva</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">Jennifer Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cohen%2C+A">Alejandro Cohen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=M%C3%A9dard%2C+M">Muriel Médard</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT)
  
  </div>
  <p class="mathjax">Network slicing has emerged as an integral concept in 5G, aiming to partition
  the physical network infrastructure into isolated slices, customized for
  specific applications. We theoretically formulate the key performance metrics
  of an application, in terms of goodput and delivery delay, at a cost of network
  resources in terms of bandwidth. We explore an un-coded communication protocol
  that uses feedback-based repetitions, and a coded protocol, implementing random
  linear network coding and using coding-aware acknowledgments. We find that
  coding reduces the resource demands of a slice to meet the requirements for an
  application, thereby serving more applications efficiently. Coded slices thus
  free up resources for other slices, be they coded or not. Based on these
  results, we propose a hybrid approach, wherein coding is introduced selectively
  in certain network slices. This approach not only facilitates a smoother
  transition from un-coded systems to coded systems but also reduces costs across
  all slices. Theoretical findings in this paper are validated and expanded upon
  through real-time simulations of the network.
  </p>
  </div>
  </dd>
  <dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17687" title="Abstract">arXiv:2404.17687</a> [<a href="/pdf/2404.17687" title="Download PDF">pdf</a>, <a href="/format/2404.17687" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Knowledge Transfer for Cross-Domain Reinforcement Learning: A Systematic  Review
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Serrano%2C+S+A">Sergio A. Serrano</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Martinez-Carranza%2C+J">Jose Martinez-Carranza</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sucar%2C+L+E">L. Enrique Sucar</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)
  
  </div>
  <p class="mathjax">Reinforcement Learning (RL) provides a framework in which agents can be
  trained, via trial and error, to solve complex decision-making problems.
  Learning with little supervision causes RL methods to require large amounts of
  data, which renders them too expensive for many applications (e.g. robotics).
  By reusing knowledge from a different task, knowledge transfer methods present
  an alternative to reduce the training time in RL. Given how severe data
  scarcity can be, there has been a growing interest for methods capable of
  transferring knowledge across different domains (i.e. problems with different
  representation) due to the flexibility they offer. This review presents a
  unifying analysis of methods focused on transferring knowledge across different
  domains. Through a taxonomy based on a transfer-approach categorization, and a
  characterization of works based on their data-assumption requirements, the
  objectives of this article are to 1) provide a comprehensive and systematic
  revision of knowledge transfer methods for the cross-domain RL setting, 2)
  categorize and characterize these methods to provide an analysis based on
  relevant features such as their transfer approach and data requirements, and 3)
  discuss the main challenges regarding cross-domain knowledge transfer, as well
  as ideas of future directions worth exploring to address these problems.
  </p>
  </div>
  </dd>
  <dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17688" title="Abstract">arXiv:2404.17688</a> [<a href="/pdf/2404.17688" title="Download PDF">pdf</a>, <a href="/format/2404.17688" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Seizing the Means of Production: Exploring the Landscape of Crafting,  Adapting and Navigating Generative AI Models in the Visual Arts
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Abuzuraiq%2C+A+M">Ahmed M. Abuzuraiq</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pasquier%2C+P">Philippe Pasquier</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to CHI 2024 workshop on Generative AI and HCI
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">In this paper, we map out the landscape of options available to visual
  artists for creating personal artworks, including crafting, adapting and
  navigating deep generative models. Following that, we argue for revisiting
  model crafting, defined as the design and manipulation of generative models for
  creative goals, and motivate studying and designing for model crafting as a
  creative activity in its own right.
  </p>
  </div>
  </dd>
  <dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17690" title="Abstract">arXiv:2404.17690</a> [<a href="/pdf/2404.17690" title="Download PDF">pdf</a>, <a href="/format/2404.17690" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Biased Estimator for MinMax Sampling and Distributed Aggregation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wolfrath%2C+J">Joel Wolfrath</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chandra%2C+A">Abhishek Chandra</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Applications (stat.AP)
  
  </div>
  <p class="mathjax">MinMax sampling is a technique for downsampling a real-valued vector which
  minimizes the maximum variance over all vector components. This approach is
  useful for reducing the amount of data that must be sent over a constrained
  network link (e.g. in the wide-area). MinMax can provide unbiased estimates of
  the vector elements, along with unbiased estimates of aggregates when vectors
  are combined from multiple locations. In this work, we propose a biased MinMax
  estimation scheme, B-MinMax, which trades an increase in estimator bias for a
  reduction in variance. We prove that when no aggregation is performed, B-MinMax
  obtains a strictly lower MSE compared to the unbiased MinMax estimator. When
  aggregation is required, B-MinMax is preferable when sample sizes are small or
  the number of aggregated vectors is limited. Our experiments show that this
  approach can substantially reduce the MSE for MinMax sampling in many practical
  settings.
  </p>
  </div>
  </dd>
  <dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17695" title="Abstract">arXiv:2404.17695</a> [<a href="/pdf/2404.17695" title="Download PDF">pdf</a>, <a href="/format/2404.17695" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SIM2VR: Towards Automated Biomechanical Testing in VR
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fischer%2C+F">Florian Fischer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ikkala%2C+A">Aleksi Ikkala</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Klar%2C+M">Markus Klar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fleig%2C+A">Arthur Fleig</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bachinski%2C+M">Miroslav Bachinski</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Murray-Smith%2C+R">Roderick Murray-Smith</a>, 
  <a href="/search/cs?searchtype=author&amp;query=H%C3%A4m%C3%A4l%C3%A4inen%2C+P">Perttu Hämäläinen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oulasvirta%2C+A">Antti Oulasvirta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+J">Jörg Müller</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 22 pages, 10 figures, 2 tables; Supplementary Material: 7 pages, 4 figures, 1 table
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">Automated biomechanical testing has great potential for the development of VR
  applications, as initial insights into user behaviour can be gained in silico
  early in the design process. In particular, it allows prediction of user
  movements and ergonomic variables, such as fatigue, prior to conducting user
  studies. However, there is a fundamental disconnect between simulators hosting
  state-of-the-art biomechanical user models and simulators used to develop and
  run VR applications. Existing user simulators often struggle to capture the
  intricacies and nuances of real-world VR applications, reducing ecological
  validity of user predictions. In this paper, we introduce SIM2VR, a system that
  aligns user simulation with a given VR application by establishing a continuous
  closed loop between the two processes. This, for the first time, enables
  training simulated users directly in the same VR application that real users
  interact with. We demonstrate that SIM2VR can predict differences in user
  performance, ergonomics and strategies in a fast-paced, dynamic arcade game. In
  order to expand the scope of automated biomechanical testing beyond simple
  visuomotor tasks, advances in cognitive models and reward function design will
  be needed.
  </p>
  </div>
  </dd>
  <dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17697" title="Abstract">arXiv:2404.17697</a> [<a href="/pdf/2404.17697" title="Download PDF">pdf</a>, <a href="/ps/2404.17697" title="Download PostScript">ps</a>, <a href="/format/2404.17697" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhancing Track Management Systems with Vehicle-To-Vehicle Enabled  Sensor Fusion
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Billington%2C+T">Thomas Billington</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gwash%2C+A">Ansh Gwash</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kothari%2C+A">Aadi Kothari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Izquierdo%2C+L">Lucas Izquierdo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Talty%2C+T">Timothy Talty</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages, 5 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">In the rapidly advancing landscape of connected and automated vehicles (CAV),
  the integration of Vehicle-to-Everything (V2X) communication in traditional
  fusion systems presents a promising avenue for enhancing vehicle perception.
  Addressing current limitations with vehicle sensing, this paper proposes a
  novel Vehicle-to-Vehicle (V2V) enabled track management system that leverages
  the synergy between V2V signals and detections from radar and camera sensors.
  The core innovation lies in the creation of independent priority track lists,
  consisting of fused detections validated through V2V communication. This
  approach enables more flexible and resilient thresholds for track management,
  particularly in scenarios with numerous occlusions where the tracked objects
  move outside the field of view of the perception sensors. The proposed system
  considers the implications of falsification of V2X signals which is combated
  through an initial vehicle identification process using detection from
  perception sensors. Presented are the fusion algorithm, simulated environments,
  and validation mechanisms. Experimental results demonstrate the improved
  accuracy and robustness of the proposed system in common driving scenarios,
  highlighting its potential to advance the reliability and efficiency of
  autonomous vehicles.
  </p>
  </div>
  </dd>
  <dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17698" title="Abstract">arXiv:2404.17698</a> [<a href="/pdf/2404.17698" title="Download PDF">pdf</a>, <a href="/format/2404.17698" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> "Actually I Can Count My Blessings": User-Centered Design of an  Application to Promote Gratitude Among Young Adults
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bhattacharjee%2C+A">Ananya Bhattacharjee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gong%2C+Z">Zichen Gong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bingcheng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luckcock%2C+T+J">Timothy James Luckcock</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Watson%2C+E">Emma Watson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Abellan%2C+E+A">Elena Allica Abellan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gutman%2C+L">Leslie Gutman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hsu%2C+A">Anne Hsu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Williams%2C+J+J">Joseph Jay Williams</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">Regular practice of gratitude has the potential to enhance psychological
  wellbeing and foster stronger social connections among young adults. However,
  there is a lack of research investigating user needs and expectations regarding
  gratitude-promoting applications. To address this gap, we employed a
  user-centered design approach to develop a mobile application that facilitates
  gratitude practice. Our formative study involved 20 participants who utilized
  an existing application, providing insights into their preferences for
  organizing expressions of gratitude and the significance of prompts for
  reflection and mood labeling after working hours. Building on these findings,
  we conducted a deployment study with 26 participants using our custom-designed
  application, which confirmed the positive impact of structured options to guide
  gratitude practice and highlighted the advantages of passive engagement with
  the application during busy periods. Our study contributes to the field by
  identifying key design considerations for promoting gratitude among young
  adults.
  </p>
  </div>
  </dd>
  <dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17699" title="Abstract">arXiv:2404.17699</a> [<a href="/pdf/2404.17699" title="Download PDF">pdf</a>, <a href="/format/2404.17699" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Deep Learning for Melt Pool Depth Contour Prediction From Surface  Thermal Images via Vision Transformers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ogoke%2C+F">Francis Ogoke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pak%2C+P+M">Peter Myung-Won Pak</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Myers%2C+A">Alexander Myers</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Quirarte%2C+G">Guadalupe Quirarte</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Beuth%2C+J">Jack Beuth</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Malen%2C+J">Jonathan Malen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Farimani%2C+A+B">Amir Barati Farimani</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Insufficient overlap between the melt pools produced during Laser Powder Bed
  Fusion (L-PBF) can lead to lack-of-fusion defects and deteriorated mechanical
  and fatigue performance. In-situ monitoring of the melt pool subsurface
  morphology requires specialized equipment that may not be readily accessible or
  scalable. Therefore, we introduce a machine learning framework to correlate
  in-situ two-color thermal images observed via high-speed color imaging to the
  two-dimensional profile of the melt pool cross-section. Specifically, we employ
  a hybrid CNN-Transformer architecture to establish a correlation between single
  bead off-axis thermal image sequences and melt pool cross-section contours
  measured via optical microscopy. In this architecture, a ResNet model embeds
  the spatial information contained within the thermal images to a latent vector,
  while a Transformer model correlates the sequence of embedded vectors to
  extract temporal information. Our framework is able to model the curvature of
  the subsurface melt pool structure, with improved performance in high energy
  density regimes compared to analytical melt pool models. The performance of
  this model is evaluated through dimensional and geometric comparisons to the
  corresponding experimental melt pool observations.
  </p>
  </div>
  </dd>
  <dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17701" title="Abstract">arXiv:2404.17701</a> [<a href="/pdf/2404.17701" title="Download PDF">pdf</a>, <a href="/format/2404.17701" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Embedded FPGA Developments in 130nm and 28nm CMOS for Machine Learning  in Particle Detector Readout
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gonski%2C+J">Julia Gonski</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+A">Aseem Gupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jia%2C+H">Haoyi Jia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+H">Hyunjoon Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rota%2C+L">Lorenzo Rota</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ruckman%2C+L">Larry Ruckman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dragone%2C+A">Angelo Dragone</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Herbst%2C+R">Ryan Herbst</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages, 12 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Instrumentation and Detectors (physics.ins-det)
  
  </div>
  <p class="mathjax">Embedded field programmable gate array (eFPGA) technology allows the
  implementation of reconfigurable logic within the design of an
  application-specific integrated circuit (ASIC). This approach offers the low
  power and efficiency of an ASIC along with the ease of FPGA configuration,
  particularly beneficial for the use case of machine learning in the data
  pipeline of next-generation collider experiments. An open-source framework
  called "FABulous" was used to design eFPGAs using 130 nm and 28 nm CMOS
  technology nodes, which were subsequently fabricated and verified through
  testing. The capability of an eFPGA to act as a front-end readout chip was
  tested using simulation of high energy particles passing through a silicon
  pixel sensor. A machine learning-based classifier, designed for reduction of
  sensor data at the source, was synthesized and configured onto the eFPGA. A
  successful proof-of-concept was demonstrated through reproduction of the
  expected algorithm result on the eFPGA with perfect accuracy. Further
  development of the eFPGA technology and its application to collider detector
  readout is discussed.
  </p>
  </div>
  </dd>
  <dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17702" title="Abstract">arXiv:2404.17702</a> [<a href="/pdf/2404.17702" title="Download PDF">pdf</a>, <a href="/format/2404.17702" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Stocking and Harvesting Effects in Advection-Reaction-Diffusion Model:  Exploring Decoupled Algorithms and Analysis
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Tisha%2C+M+S">Mayesha Sharmim Tisha</a>, 
  <a href="/search/math?searchtype=author&amp;query=Kamrujjaman%2C+M">Md. Kamrujjaman</a>, 
  <a href="/search/math?searchtype=author&amp;query=Mohebujjaman%2C+M">Muhammad Mohebujjaman</a>, 
  <a href="/search/math?searchtype=author&amp;query=Khan%2C+T">Taufiquar Khan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 24 pages, 11 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Dynamical Systems (math.DS)
  
  </div>
  <p class="mathjax">We propose a time-dependent Advection Reaction Diffusion (ARD) <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-88" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-89"><span class="mi" id="MathJax-Span-90" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-13">N</script>-species
  competition model to investigate the Stocking and Harvesting (SH) effect on
  population dynamics. For ongoing analysis, we explore the outcomes of a
  competition between two competing species in a heterogeneous environment under
  no-flux boundary conditions, meaning no individual can cross the boundaries. We
  establish results concerning the existence, uniqueness, and positivity of the
  solution. As a continuation, we propose, analyze, and test two novel fully
  discrete decoupled linearized algorithms for a nonlinearly coupled ARD
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-91" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-92"><span class="mi" id="MathJax-Span-93" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-14">N</script>-species competition model with SH effort. The time-stepping algorithms are
  first and second order accurate in time and optimally accurate in space.
  Stability and optimal convergence theorems of the decoupled schemes are proved
  rigorously. We verify the predicted convergence rates of our analysis and the
  efficacy of the algorithms using numerical experiments and synthetic data for
  analytical test problems. We also study the effect of harvesting or stocking
  and diffusion parameters on the evolution of species population density
  numerically and observe the coexistence scenario subject to optimal stocking or
  harvesting.
  </p>
  </div>
  </dd>
  <dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17711" title="Abstract">arXiv:2404.17711</a> [<a href="/pdf/2404.17711" title="Download PDF">pdf</a>, <a href="/format/2404.17711" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Optimal Delivery with a Faulty Drone
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Coleman%2C+J">Jared Coleman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Krizanc%2C+D">Danny Krizanc</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kranakis%2C+E">Evangelos Kranakis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Morales-Ponce%2C+O">Oscar Morales-Ponce</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>
  
  </div>
  <p class="mathjax">We introduce and study a new cooperative delivery problem inspired by
  drone-assisted package delivery. We consider a scenario where a drone, en route
  to deliver a package to a destination (a point on the plane), unexpectedly
  loses communication with its central command station. The command station
  cannot know whether the drone's system has wholly malfunctioned or merely
  experienced a communications failure. Consequently, a second, helper drone must
  be deployed to retrieve the package to ensure successful delivery. The central
  question of this study is to find the optimal trajectory for this second drone.
  We demonstrate that the optimal solution relies heavily on the relative spatial
  positioning of the command station, the destination point, and the last known
  location of the disconnected drone.
  </p>
  </div>
  </dd>
  <dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17714" title="Abstract">arXiv:2404.17714</a> [<a href="/pdf/2404.17714" title="Download PDF">pdf</a>, <a href="/format/2404.17714" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Lower Bounds for Private Estimation of Gaussian Covariance Matrices  under All Reasonable Parameter Regimes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Portella%2C+V+S">Victor S. Portella</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Harvey%2C+N">Nick Harvey</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 27 pages, preprint
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">We prove lower bounds on the number of samples needed to privately estimate
  the covariance matrix of a Gaussian distribution. Our bounds match existing
  upper bounds in the widest known setting of parameters. Our analysis relies on
  the Stein-Haff identity, an extension of the classical Stein's identity used in
  previous fingerprinting lemma arguments.
  </p>
  </div>
  </dd>
  <dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17716" title="Abstract">arXiv:2404.17716</a> [<a href="/pdf/2404.17716" title="Download PDF">pdf</a>, <a href="/ps/2404.17716" title="Download PostScript">ps</a>, <a href="/format/2404.17716" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Airlift Challenge: A Competition for Optimizing Cargo Delivery
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Delanovic%2C+A">Adis Delanovic</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chiu%2C+C">Carmen Chiu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Beckus%2C+A">Andre Beckus</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  <p class="mathjax">Airlift operations require the timely distribution of various cargo, much of
  which is time sensitive and valuable. However, these operations have to contend
  with sudden disruptions from weather and malfunctions, requiring immediate
  rescheduling. The Airlift Challenge competition seeks possible solutions via a
  simulator that provides a simplified abstraction of the airlift problem. The
  simulator uses an OpenAI gym interface that allows participants to create an
  algorithm for planning agent actions. The algorithm is scored using a remote
  evaluator against scenarios of ever-increasing difficulty. The second iteration
  of the competition was underway from November 2023 to April 2024. In this
  paper, we describe the competition and simulation environment. As a step
  towards applying generalized planning techniques to the problem, we present a
  temporal PDDL domain for the Pickup and Delivery Problem, a model which lies at
  the core of the Airlift Challenge.
  </p>
  </div>
  </dd>
  <dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17718" title="Abstract">arXiv:2404.17718</a> [<a href="/pdf/2404.17718" title="Download PDF">pdf</a>, <a href="/format/2404.17718" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Lessons from Deploying CropFollow++: Under-Canopy Agricultural  Navigation with Keypoints
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sivakumar%2C+A+N">Arun N. Sivakumar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gasparino%2C+M+V">Mateus V. Gasparino</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McGuire%2C+M">Michael McGuire</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Higuti%2C+V+A+H">Vitor A. H. Higuti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Akcal%2C+M+U">M. Ugur Akcal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chowdhary%2C+G">Girish Chowdhary</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the IEEE ICRA Workshop on Field Robotics 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">We present a vision-based navigation system for under-canopy agricultural
  robots using semantic keypoints. Autonomous under-canopy navigation is
  challenging due to the tight spacing between the crop rows (<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-94" style="width: 3.503em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.826em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.769em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-95"><span class="mo" id="MathJax-Span-96" style="font-family: STIXGeneral-Regular;">∼</span><span class="mn" id="MathJax-Span-97" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">0.75</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-15">\sim 0.75</script> m),
  degradation in RTK-GPS accuracy due to multipath error, and noise in LiDAR
  measurements from the excessive clutter. Our system, CropFollow++, introduces
  modular and interpretable perception architecture with a learned semantic
  keypoint representation. We deployed CropFollow++ in multiple under-canopy
  cover crop planting robots on a large scale (25 km in total) in various field
  conditions and we discuss the key lessons learned from this.
  </p>
  </div>
  </dd>
  <dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17719" title="Abstract">arXiv:2404.17719</a> [<a href="/pdf/2404.17719" title="Download PDF">pdf</a>, <a href="/format/2404.17719" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Stochastic Spiking Neural Networks with First-to-Spike Coding
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yi Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+S">Sen Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sengupta%2C+A">Abhronil Sengupta</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>
  
  </div>
  <p class="mathjax">Spiking Neural Networks (SNNs), recognized as the third generation of neural
  networks, are known for their bio-plausibility and energy efficiency,
  especially when implemented on neuromorphic hardware. However, the majority of
  existing studies on SNNs have concentrated on deterministic neurons with rate
  coding, a method that incurs substantial computational overhead due to lengthy
  information integration times and fails to fully harness the brain's
  probabilistic inference capabilities and temporal dynamics. In this work, we
  explore the merger of novel computing and information encoding schemes in SNN
  architectures where we integrate stochastic spiking neuron models with temporal
  coding techniques. Through extensive benchmarking with other deterministic SNNs
  and rate-based coding, we investigate the tradeoffs of our proposal in terms of
  accuracy, inference latency, spiking sparsity, energy consumption, and
  robustness. Our work is the first to extend the scalability of direct training
  approaches of stochastic SNNs with temporal encoding to VGG architectures and
  beyond-MNIST datasets.
  </p>
  </div>
  </dd>
  <dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17721" title="Abstract">arXiv:2404.17721</a> [<a href="/pdf/2404.17721" title="Download PDF">pdf</a>, <a href="/ps/2404.17721" title="Download PostScript">ps</a>, <a href="/format/2404.17721" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An RFP dataset for Real, Fake, and Partially fake audio detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=AlAli%2C+A">Abdulazeez AlAli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Theodorakopoulos%2C+G">George Theodorakopoulos</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Cryptography and Security (cs.CR); Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">Recent advances in deep learning have enabled the creation of
  natural-sounding synthesised speech. However, attackers have also utilised
  these tech-nologies to conduct attacks such as phishing. Numerous public
  datasets have been created to facilitate the development of effective detection
  models. How-ever, available datasets contain only entirely fake audio;
  therefore, detection models may miss attacks that replace a short section of
  the real audio with fake audio. In recognition of this problem, the current
  paper presents the RFP da-taset, which comprises five distinct audio types:
  partial fake (PF), audio with noise, voice conversion (VC), text-to-speech
  (TTS), and real. The data are then used to evaluate several detection models,
  revealing that the available detec-tion models incur a markedly higher equal
  error rate (EER) when detecting PF audio instead of entirely fake audio. The
  lowest EER recorded was 25.42%. Therefore, we believe that creators of
  detection models must seriously consid-er using datasets like RFP that include
  PF and other types of fake audio.
  </p>
  </div>
  </dd>
  <dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17723" title="Abstract">arXiv:2404.17723</a> [<a href="/pdf/2404.17723" title="Download PDF">pdf</a>, <a href="/format/2404.17723" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Retrieval-Augmented Generation with Knowledge Graphs for Customer  Service Question Answering
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhentao Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cruz%2C+M+J">Mark Jerome Cruz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guevara%2C+M">Matthew Guevara</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Tie Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Deshpande%2C+M">Manasi Deshpande</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaofeng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zheng Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">In customer service technical support, swiftly and accurately retrieving
  relevant past issues is critical for efficiently resolving customer inquiries.
  The conventional retrieval methods in retrieval-augmented generation (RAG) for
  large language models (LLMs) treat a large corpus of past issue tracking
  tickets as plain text, ignoring the crucial intra-issue structure and
  inter-issue relations, which limits performance. We introduce a novel customer
  service question-answering method that amalgamates RAG with a knowledge graph
  (KG). Our method constructs a KG from historical issues for use in retrieval,
  retaining the intra-issue structure and inter-issue relations. During the
  question-answering phase, our method parses consumer queries and retrieves
  related sub-graphs from the KG to generate answers. This integration of a KG
  not only improves retrieval accuracy by preserving customer service structure
  information but also enhances answering quality by mitigating the effects of
  text segmentation. Empirical assessments on our benchmark datasets, utilizing
  key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR)
  metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by
  0.32 in BLEU. Our method has been deployed within LinkedIn's customer service
  team for approximately six months and has reduced the median per-issue
  resolution time by 28.6%.
  </p>
  </div>
  </dd>
  <dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17725" title="Abstract">arXiv:2404.17725</a> [<a href="/pdf/2404.17725" title="Download PDF">pdf</a>, <a href="/format/2404.17725" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Boltzmann State-Dependent Rationality
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lerner%2C+O">Osher Lerner</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)
  
  </div>
  <p class="mathjax">This paper expands on existing learned models of human behavior via a
  measured step in structured irrationality. Specifically, by replacing the
  suboptimality constant <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-98" style="width: 0.737em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.567em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.567em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-99"><span class="mi" id="MathJax-Span-100" style="font-family: STIXGeneral-Italic;">β<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-16">\beta</script> in a Boltzmann rationality model with a function
  over states <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-101" style="width: 1.979em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.584em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.527em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-102"><span class="mi" id="MathJax-Span-103" style="font-family: STIXGeneral-Italic;">β<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-104" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-105" style="font-family: STIXGeneral-Italic;">s</span><span class="mo" id="MathJax-Span-106" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-17">\beta(s)</script>, we gain natural expressivity in a computationally
  tractable manner. This paper discusses relevant mathematical theory, sets up
  several experimental designs, presents limited preliminary results, and
  proposes future investigations.
  </p>
  </div>
  </dd>
  <dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17729" title="Abstract">arXiv:2404.17729</a> [<a href="/pdf/2404.17729" title="Download PDF">pdf</a>, <a href="/format/2404.17729" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for  Complex Problem Solving
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+P">Pei Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+B">Boran Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shuai Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to NAACL 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Large Language Models (LLMs) have shown great ability in solving traditional
  natural language tasks and elementary reasoning tasks with appropriate
  prompting techniques. However, their ability is still limited in solving
  complicated science problems. In this work, we aim to push the upper bound of
  the reasoning capability of LLMs by proposing a collaborative multi-agent,
  multi-reasoning-path (CoMM) prompting framework. Specifically, we prompt LLMs
  to play different roles in a problem-solving team, and encourage different
  role-play agents to collaboratively solve the target task. In particular, we
  discover that applying different reasoning paths for different roles is an
  effective strategy to implement few-shot prompting approaches in the
  multi-agent scenarios. Empirical results demonstrate the effectiveness of the
  proposed methods on two college-level science problems over competitive
  baselines. Our further analysis shows the necessity of prompting LLMs to play
  different roles or experts independently. We release the code at:
  https://github.com/amazon-science/comm-prompt
  </p>
  </div>
  </dd>
  <dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17730" title="Abstract">arXiv:2404.17730</a> [<a href="/pdf/2404.17730" title="Download PDF">pdf</a>, <a href="/format/2404.17730" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bridging the Social &amp; Technical Divide in Augmentative and Alternative  Communication (AAC) Applications for Autistic Adults
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Martin%2C+L+J">Lara J. Martin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nagalakshmi%2C+M">Malathy Nagalakshmi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)
  
  </div>
  <p class="mathjax">Natural Language Processing (NLP) techniques are being used more frequently
  to improve high-tech Augmentative and Alternative Communication (AAC), but many
  of these techniques are integrated without the inclusion of the users'
  perspectives. As many of these tools are created with children in mind,
  autistic adults are often neglected in the design of AAC tools to begin with.
  We conducted in-depth interviews with 12 autistic adults to find the pain
  points of current AAC and determine what general technological advances they
  would find helpful. We found that in addition to technological issues, there
  are many societal issues as well. We found 9 different categories of themes
  from our interviews: input options, output options, selecting or adapting AAC
  for a good fit, when to start or swap AAC, benefits (of use), access (to AAC),
  stumbling blocks for continued use, social concerns, and lack of control. In
  this paper, we go through these nine categories in depth and then suggest
  possible guidelines for the NLP community, AAC application makers, and policy
  makers to improve AAC use for autistic adults.
  </p>
  </div>
  </dd>
  <dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17731" title="Abstract">arXiv:2404.17731</a> [<a href="/pdf/2404.17731" title="Download PDF">pdf</a>, <a href="/format/2404.17731" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MedBike: A Cardiac Patient Monitoring System Enhanced through  Gamification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hossain%2C+T">Tahmim Hossain</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sayed%2C+F">Faisal Sayed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rai%2C+Y">Yugesh Rai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bansod%2C+K">Kalpak Bansod</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sadik%2C+M+N">Md Nahid Sadik</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 5 pages, 11 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">The "MedBike" is an innovative project in the field of pediatric cardiac
  rehabilitation. It is a 2D interactive game created specifically for children
  under the age of 18 who have cardiac conditions. This game is part of the
  MedBike system, a novel rehabilitation tool combining physical exercise with
  the spirit of gaming. The MedBike game provides children with a safe,
  controlled, and engaging environment in which to exercise and recover. It has
  three distinct levels of increasing intensity, each with its own set of
  environments and challenges that are tailored to different stages of
  rehabilitation. This report dives into the details of the MedBike game,
  highlighting its unique features and gameplay.
  </p>
  </div>
  </dd>
  <dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17732" title="Abstract">arXiv:2404.17732</a> [<a href="/pdf/2404.17732" title="Download PDF">pdf</a>, <a href="/format/2404.17732" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generative Dataset Distillation: Balancing Global Structure and Local  Details
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Longzhen Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Guang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Togo%2C+R">Ren Togo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Maeda%2C+K">Keisuke Maeda</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ogawa%2C+T">Takahiro Ogawa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Haseyama%2C+M">Miki Haseyama</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by the 1st CVPR Workshop on Dataset Distillation
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">In this paper, we propose a new dataset distillation method that considers
  balancing global structure and local details when distilling the information
  from a large dataset into a generative model. Dataset distillation has been
  proposed to reduce the size of the required dataset when training models. The
  conventional dataset distillation methods face the problem of long redeployment
  time and poor cross-architecture performance. Moreover, previous methods
  focused too much on the high-level semantic attributes between the synthetic
  dataset and the original dataset while ignoring the local features such as
  texture and shape. Based on the above understanding, we propose a new method
  for distilling the original image dataset into a generative model. Our method
  involves using a conditional generative adversarial network to generate the
  distilled dataset. Subsequently, we ensure balancing global structure and local
  details in the distillation process, continuously optimizing the generator for
  more information-dense dataset generation.
  </p>
  </div>
  </dd>
  <dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17733" title="Abstract">arXiv:2404.17733</a> [<a href="/pdf/2404.17733" title="Download PDF">pdf</a>, <a href="/format/2404.17733" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Building a Large Japanese Web Corpus for Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Okazaki%2C+N">Naoaki Okazaki</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hattori%2C+K">Kakeru Hattori</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shota%2C+H">Hirai Shota</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Iida%2C+H">Hiroki Iida</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ohi%2C+M">Masanari Ohi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fujii%2C+K">Kazuki Fujii</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nakamura%2C+T">Taishi Nakamura</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Loem%2C+M">Mengsay Loem</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yokota%2C+R">Rio Yokota</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mizuki%2C+S">Sakae Mizuki</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 17 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Open Japanese large language models (LLMs) have been trained on the Japanese
  portions of corpora such as CC-100, mC4, and OSCAR. However, these corpora were
  not created for the quality of Japanese texts. This study builds a large
  Japanese web corpus by extracting and refining text from the Common Crawl
  archive (21 snapshots of approximately 63.4 billion pages crawled between 2020
  and 2023). This corpus consists of approximately 312.1 billion characters
  (approximately 173 million pages), which is the largest of all available
  training corpora for Japanese LLMs, surpassing CC-100 (approximately 25.8
  billion characters), mC4 (approximately 239.7 billion characters) and OSCAR
  23.10 (approximately 74 billion characters). To confirm the quality of the
  corpus, we performed continual pre-training on Llama 2 7B, 13B, 70B, Mistral 7B
  v0.1, and Mixtral 8x7B Instruct as base LLMs and gained consistent (6.6-8.1
  points) improvements on Japanese benchmark datasets. We also demonstrate that
  the improvement on Llama 2 13B brought from the presented corpus was the
  largest among those from other existing corpora.
  </p>
  </div>
  </dd>
  <dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17735" title="Abstract">arXiv:2404.17735</a> [<a href="/pdf/2404.17735" title="Download PDF">pdf</a>, <a href="/format/2404.17735" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Causal Diffusion Autoencoders: Toward Counterfactual Generation via  Diffusion Probabilistic Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Komanduri%2C+A">Aneesh Komanduri</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+C">Chen Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+F">Feng Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xintao Wu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)
  
  </div>
  <p class="mathjax">Diffusion probabilistic models (DPMs) have become the state-of-the-art in
  high-quality image generation. However, DPMs have an arbitrary noisy latent
  space with no interpretable or controllable semantics. Although there has been
  significant research effort to improve image sample quality, there is little
  work on representation-controlled generation using diffusion models.
  Specifically, causal modeling and controllable counterfactual generation using
  DPMs is an underexplored area. In this work, we propose CausalDiffAE, a
  diffusion-based causal representation learning framework to enable
  counterfactual generation according to a specified causal model. Our key idea
  is to use an encoder to extract high-level semantically meaningful causal
  variables from high-dimensional data and model stochastic variation using
  reverse diffusion. We propose a causal encoding mechanism that maps
  high-dimensional data to causally related latent factors and parameterize the
  causal mechanisms among latent factors using neural networks. To enforce the
  disentanglement of causal variables, we formulate a variational objective and
  leverage auxiliary label information in a prior to regularize the latent space.
  We propose a DDIM-based counterfactual generation procedure subject to
  do-interventions. Finally, to address the limited label supervision scenario,
  we also study the application of CausalDiffAE when a part of the training data
  is unlabeled, which also enables granular control over the strength of
  interventions in generating counterfactuals during inference. We empirically
  show that CausalDiffAE learns a disentangled latent space and is capable of
  generating high-quality counterfactual images.
  </p>
  </div>
  </dd>
  <dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17739" title="Abstract">arXiv:2404.17739</a> [<a href="/pdf/2404.17739" title="Download PDF">pdf</a>, <a href="/format/2404.17739" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> How LLMs Aid in UML Modeling: An Exploratory Study with Novice Analysts
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Beian Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+P">Peng Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bing Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+C">Cheng Zeng</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Since the emergence of GPT-3, Large Language Models (LLMs) have caught the
  eyes of researchers, practitioners, and educators in the field of software
  engineering. However, there has been relatively little investigation regarding
  the performance of LLMs in assisting with requirements analysis and UML
  modeling. This paper explores how LLMs can assist novice analysts in creating
  three types of typical UML models: use case models, class diagrams, and
  sequence diagrams. For this purpose, we designed the modeling tasks of these
  three UML models for 45 undergraduate students who participated in a
  requirements modeling course, with the help of LLMs. By analyzing their project
  reports, we found that LLMs can assist undergraduate students as notice
  analysts in UML modeling tasks, but LLMs also have shortcomings and
  limitations.
  </p>
  </div>
  </dd>
  <dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17745" title="Abstract">arXiv:2404.17745</a> [<a href="/pdf/2404.17745" title="Download PDF">pdf</a>, <a href="/ps/2404.17745" title="Download PostScript">ps</a>, <a href="/format/2404.17745" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An Attention-Based Deep Learning Architecture for Real-Time Monocular  Visual Odometry: Applications to GPS-free Drone Navigation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dufour%2C+O+B">Olivier Brochu Dufour</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mohebbi%2C+A">Abolfazl Mohebbi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Achiche%2C+S">Sofiane Achiche</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 22 Pages, 3 Tables, 9 Figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)
  
  </div>
  <p class="mathjax">Drones are increasingly used in fields like industry, medicine, research,
  disaster relief, defense, and security. Technical challenges, such as
  navigation in GPS-denied environments, hinder further adoption. Research in
  visual odometry is advancing, potentially solving GPS-free navigation issues.
  Traditional visual odometry methods use geometry-based pipelines which, while
  popular, often suffer from error accumulation and high computational demands.
  Recent studies utilizing deep neural networks (DNNs) have shown improved
  performance, addressing these drawbacks. Deep visual odometry typically employs
  convolutional neural networks (CNNs) and sequence modeling networks like
  recurrent neural networks (RNNs) to interpret scenes and deduce visual odometry
  from video sequences. This paper presents a novel real-time monocular visual
  odometry model for drones, using a deep neural architecture with a
  self-attention module. It estimates the ego-motion of a camera on a drone,
  using consecutive video frames. An inference utility processes the live video
  feed, employing deep learning to estimate the drone's trajectory. The
  architecture combines a CNN for image feature extraction and a long short-term
  memory (LSTM) network with a multi-head attention module for video sequence
  modeling. Tested on two visual odometry datasets, this model converged 48%
  faster than a previous RNN model and showed a 22% reduction in mean
  translational drift and a 12% improvement in mean translational absolute
  trajectory error, demonstrating enhanced robustness to noise.
  </p>
  </div>
  </dd>
  <dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17746" title="Abstract">arXiv:2404.17746</a> [<a href="/pdf/2404.17746" title="Download PDF">pdf</a>, <a href="/format/2404.17746" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On the Rashomon ratio of infinite hypothesis sets
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Coupkova%2C+E">Evzenie Coupkova</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Boutin%2C+M">Mireille Boutin</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">Given a classification problem and a family of classifiers, the Rashomon
  ratio measures the proportion of classifiers that yield less than a given loss.
  Previous work has explored the advantage of a large Rashomon ratio in the case
  of a finite family of classifiers. Here we consider the more general case of an
  infinite family. We show that a large Rashomon ratio guarantees that choosing
  the classifier with the best empirical accuracy among a random subset of the
  family, which is likely to improve generalizability, will not increase the
  empirical loss too much. We quantify the Rashomon ratio in two examples
  involving infinite classifier families in order to illustrate situations in
  which it is large. In the first example, we estimate the Rashomon ratio of the
  classification of normally distributed classes using an affine classifier. In
  the second, we obtain a lower bound for the Rashomon ratio of a classification
  problem with a modified Gram matrix when the classifier family consists of
  two-layer ReLU neural networks. In general, we show that the Rashomon ratio can
  be estimated using a training dataset along with random samples from the
  classifier family and we provide guarantees that such an estimation is close to
  the true value of the Rashomon ratio.
  </p>
  </div>
  </dd>
  <dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17747" title="Abstract">arXiv:2404.17747</a> [<a href="/pdf/2404.17747" title="Download PDF">pdf</a>, <a href="/format/2404.17747" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MMA-UNet: A Multi-Modal Asymmetric UNet Architecture for Infrared and  Visible Image Fusion
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jingxue Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xilai Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tan%2C+T">Tianshu Tan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaosong Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+T">Tao Ye</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Multi-modal image fusion (MMIF) maps useful information from various
  modalities into the same representation space, thereby producing an informative
  fused image. However, the existing fusion algorithms tend to symmetrically fuse
  the multi-modal images, causing the loss of shallow information or bias towards
  a single modality in certain regions of the fusion results. In this study, we
  analyzed the spatial distribution differences of information in different
  modalities and proved that encoding features within the same network is not
  conducive to achieving simultaneous deep feature space alignment for
  multi-modal images. To overcome this issue, a Multi-Modal Asymmetric UNet
  (MMA-UNet) was proposed. We separately trained specialized feature encoders for
  different modal and implemented a cross-scale fusion strategy to maintain the
  features from different modalities within the same representation space,
  ensuring a balanced information fusion process. Furthermore, extensive fusion
  and downstream task experiments were conducted to demonstrate the efficiency of
  MMA-UNet in fusing infrared and visible image information, producing visually
  natural and semantically rich fusion results. Its performance surpasses that of
  the state-of-the-art comparison fusion methods.
  </p>
  </div>
  </dd>
  <dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17749" title="Abstract">arXiv:2404.17749</a> [<a href="/pdf/2404.17749" title="Download PDF">pdf</a>, <a href="/format/2404.17749" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> UMass-BioNLP at MEDIQA-M3G 2024: DermPrompt -- A Systematic Exploration  of Prompt Engineering with GPT-4V for Dermatological Diagnosis
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Vashisht%2C+P">Parth Vashisht</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lodha%2C+A">Abhilasha Lodha</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Maddipatla%2C+M">Mukta Maddipatla</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yao%2C+Z">Zonghai Yao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mitra%2C+A">Avijit Mitra</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhichao Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Junda Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kwon%2C+S">Sunjae Kwon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Hong Yu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at NAACL-ClinicalNLP workshop 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
  
  </div>
  <p class="mathjax">This paper presents our team's participation in the MEDIQA-ClinicalNLP2024
  shared task B. We present a novel approach to diagnosing clinical dermatology
  cases by integrating large multimodal models, specifically leveraging the
  capabilities of GPT-4V under a retriever and a re-ranker framework. Our
  investigation reveals that GPT-4V, when used as a retrieval agent, can
  accurately retrieve the correct skin condition 85% of the time using
  dermatological images and brief patient histories. Additionally, we empirically
  show that Naive Chain-of-Thought (CoT) works well for retrieval while Medical
  Guidelines Grounded CoT is required for accurate dermatological diagnosis.
  Further, we introduce a Multi-Agent Conversation (MAC) framework and show its
  superior performance and potential over the best CoT strategy. The experiments
  suggest that using naive CoT for retrieval and multi-agent conversation for
  critique-based diagnosis, GPT-4V can lead to an early and accurate diagnosis of
  dermatological conditions. The implications of this work extend to improving
  diagnostic workflows, supporting dermatological education, and enhancing
  patient care by providing a scalable, accessible, and accurate diagnostic tool.
  </p>
  </div>
  </dd>
  <dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17750" title="Abstract">arXiv:2404.17750</a> [<a href="/pdf/2404.17750" title="Download PDF">pdf</a>, <a href="/format/2404.17750" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Fast Iterative Solver For Neural Network Method: I. 1D Diffusion  Problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Cai%2C+Z">Zhiqiang Cai</a>, 
  <a href="/search/math?searchtype=author&amp;query=Doktorova%2C+A">Anastassia Doktorova</a>, 
  <a href="/search/math?searchtype=author&amp;query=Falgout%2C+R+D">Robert D. Falgout</a>, 
  <a href="/search/math?searchtype=author&amp;query=Herrera%2C+C">César Herrera</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">The discretization of the deep Ritz method [18] for the Poisson equation
  leads to a high-dimensional non-convex minimization problem, that is difficult
  and expensive to solve numerically. In this paper, we consider the shallow Ritz
  approximation to one-dimensional diffusion problems and introduce an effective
  and efficient iterative method, a damped block Newton (dBN) method, for solving
  the resulting non-convex minimization problem.
  <br>The method employs the block Gauss-Seidel method as an outer iteration by
  dividing the parameters of a shallow neural network into the linear parameters
  (the weights and bias of the output layer) and the non-linear parameters (the
  weights and bias of the hidden layer). Per each outer iteration, the linear and
  the non-linear parameters are updated by exact inversion and one step of a
  damped Newton method, respectively. Inverses of the coefficient matrix and the
  Hessian matrix are tridiagonal and diagonal, respectively, and hence the cost
  of each dBN iteration is <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-18-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-107" style="width: 2.374em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.922em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(2.205em, 1001.866em, 3.39em, -999.997em); top: -3.046em; left: 0em;"><span class="mrow" id="MathJax-Span-108"><span class="texatom" id="MathJax-Span-109"><span class="mrow" id="MathJax-Span-110"><span class="mi" id="MathJax-Span-111" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-112" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-113" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-114" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 3.052em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-18">\mathcal{O}(n)</script>. To move the breakpoints (the
  non-linear parameters) more efficiently, we propose an adaptive damped block
  Newton (AdBN) method by combining the dBN with the adaptive neuron enhancement
  (ANE) method [25]. Numerical examples demonstrate the ability of dBN and AdBN
  not only to move the breakpoints quickly and efficiently but also to achieve a
  nearly optimal order of convergence for AdBN. These iterative solvers are
  capable of outperforming BFGS for select examples.
  </p>
  </div>
  </dd>
  <dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17753" title="Abstract">arXiv:2404.17753</a> [<a href="/pdf/2404.17753" title="Download PDF">pdf</a>, <a href="/format/2404.17753" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Leveraging Cross-Modal Neighbor Representation for Improved CLIP  Classification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yi%2C+C">Chao Yi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+L">Lu Ren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhan%2C+D">De-Chuan Zhan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+H">Han-Jia Ye</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">CLIP showcases exceptional cross-modal matching capabilities due to its
  training on image-text contrastive learning tasks. However, without specific
  optimization for unimodal scenarios, its performance in single-modality feature
  extraction might be suboptimal. Despite this, some studies have directly used
  CLIP's image encoder for tasks like few-shot classification, introducing a
  misalignment between its pre-training objectives and feature extraction
  methods. This inconsistency can diminish the quality of the image's feature
  representation, adversely affecting CLIP's effectiveness in target tasks. In
  this paper, we view text features as precise neighbors of image features in
  CLIP's space and present a novel CrOss-moDal nEighbor Representation(CODER)
  based on the distance structure between images and their neighbor texts. This
  feature extraction method aligns better with CLIP's pre-training objectives,
  thereby fully leveraging CLIP's robust cross-modal capabilities. The key to
  construct a high-quality CODER lies in how to create a vast amount of
  high-quality and diverse texts to match with images. We introduce the Auto Text
  Generator(ATG) to automatically generate the required texts in a data-free and
  training-free manner. We apply CODER to CLIP's zero-shot and few-shot image
  classification tasks. Experiment results across various datasets and models
  confirm CODER's effectiveness. Code is available
  at:https://github.com/YCaigogogo/CVPR24-CODER.
  </p>
  </div>
  </dd>
  <dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17754" title="Abstract">arXiv:2404.17754</a> [<a href="/pdf/2404.17754" title="Download PDF">pdf</a>, <a href="/format/2404.17754" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Development of an Estimation Method for the Seismic Motion  Reproducibility of a Three-dimensional Ground Structure Model by combining  Surface-observed Seismic Motion and Three-dimensional Seismic Motion Analysis
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ichimura%2C+T">Tsuyoshi Ichimura</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fujita%2C+K">Kohei Fujita</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kusakabe%2C+R">Ryota Kusakabe</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fujiwara%2C+H">Hiroyuki Fujiwara</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hori%2C+M">Muneo Hori</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lalith%2C+M">Maddegedara Lalith</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 16 pages, 10 figures, accepted for IHPCES/ICCS 2024 (14th International Workshop on Advances in High-Performance Computational Earth Sciences: NumericalMethods, Frameworks &amp; Applications / 24th International Conference on Computational Science)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>
  
  </div>
  <p class="mathjax">The ground structure can substantially influence seismic ground motion
  underscoring the need to develop a ground structure model with sufficient
  reliability in terms of ground motion estimation for earthquake damage
  mitigation. While many methods for generating ground structure models have been
  proposed and used in practice, there remains room for enhancing their
  reliability. In this study, amid many candidate 3D ground structure models
  generated from geotechnical engineering knowledge, we propose a method for
  selecting a credible 3D ground structure model capable of reproducing observed
  earthquake ground motion, utilizing seismic ground motion data solely observed
  at the ground surface and employing 3D seismic ground motion analysis. Through
  a numerical experiment, we illustrate the efficacy of this approach. By
  conducting <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-19-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-115" style="width: 1.81em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1001.471em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-116"><span class="msubsup" id="MathJax-Span-117"><span style="display: inline-block; position: relative; width: 1.414em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.963em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mn" id="MathJax-Span-118" style="font-family: STIXGeneral-Regular;">10</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.019em;"><span class="mn" id="MathJax-Span-119" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-19">10^2</script>-<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-20-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-120" style="width: 1.81em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1001.471em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-121"><span class="msubsup" id="MathJax-Span-122"><span style="display: inline-block; position: relative; width: 1.414em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.963em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mn" id="MathJax-Span-123" style="font-family: STIXGeneral-Regular;">10</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.019em;"><span class="mn" id="MathJax-Span-124" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-20">10^3</script> cases of fast 3D seismic wave propagation analyses
  using graphic processing units (GPUs), we demonstrate that a credible 3D ground
  structure model is selected according to the quantity of seismic motion
  information. We show the effectiveness of the proposed method by showing that
  the accuracy of seismic motions using ground structure models that were
  selected from the pool of candidate models is higher than that using ground
  structure models that were not selected from the pool of candidate models.
  </p>
  </div>
  </dd>
  <dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17757" title="Abstract">arXiv:2404.17757</a> [<a href="/pdf/2404.17757" title="Download PDF">pdf</a>, <a href="/ps/2404.17757" title="Download PostScript">ps</a>, <a href="/format/2404.17757" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Middle Architecture Criteria
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Beverley%2C+J">John Beverley</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Colle%2C+G">Giacomo De Colle</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jensen%2C+M">Mark Jensen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Benson%2C+C">Carter Benson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Smith%2C+B">Barry Smith</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB); Logic in Computer Science (cs.LO)
  
  </div>
  <p class="mathjax">Mid-level ontologies are used to integrate terminologies and data across
  disparate domains. There are, however, no clear, defensible criteria for
  determining whether a given ontology should count as mid-level, because we lack
  a rigorous characterization of what the middle level of generality is supposed
  to contain. Attempts to provide such a characterization have failed, we
  believe, because they have focused on the goal of specifying what is
  characteristic of those single ontologies that have been advanced as mid-level
  ontologies. Unfortunately, single ontologies of this sort are generally a
  mixture of top- and mid-level, and sometimes even of domain-level terms. To
  gain clarity, we aim to specify the necessary and sufficient conditions for a
  collection of one or more ontologies to inhabit what we call a mid-level
  architecture.
  </p>
  </div>
  </dd>
  <dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17758" title="Abstract">arXiv:2404.17758</a> [<a href="/pdf/2404.17758" title="Download PDF">pdf</a>, <a href="/ps/2404.17758" title="Download PostScript">ps</a>, <a href="/format/2404.17758" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Common Core Ontologies
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jensen%2C+M">Mark Jensen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Colle%2C+G">Giacomo De Colle</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kindya%2C+S">Sean Kindya</a>, 
  <a href="/search/cs?searchtype=author&amp;query=More%2C+C">Cameron More</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cox%2C+A+P">Alexander P. Cox</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Beverley%2C+J">John Beverley</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB); Logic in Computer Science (cs.LO)
  
  </div>
  <p class="mathjax">The Common Core Ontologies (CCO) are designed as a mid-level ontology suite
  that extends the Basic Formal Ontology. CCO has since been increasingly adopted
  by a broad group of users and applications and is proposed as the first
  standard mid-level ontology. Despite these successes, documentation of the
  contents and design patterns of the CCO has been comparatively minimal. This
  paper is a step toward providing enhanced documentation for the mid-level
  ontology suite through a discussion of the contents of the eleven ontologies
  that collectively comprise the Common Core Ontology suite.
  </p>
  </div>
  </dd>
  <dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17759" title="Abstract">arXiv:2404.17759</a> [<a href="/pdf/2404.17759" title="Download PDF">pdf</a>, <a href="/format/2404.17759" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Modular, Resilient, and Scalable System Design Approaches -- Lessons  learned in the years after DARPA Subterranean Challenge
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sriganesh%2C+P">Prasanna Sriganesh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Maier%2C+J">James Maier</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Johnson%2C+A">Adam Johnson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shirose%2C+B">Burhanuddin Shirose</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chandrasekar%2C+R">Rohan Chandrasekar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Noren%2C+C">Charles Noren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Spisak%2C+J">Joshua Spisak</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Darnley%2C+R">Ryan Darnley</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vundurthy%2C+B">Bhaskar Vundurthy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Travers%2C+M">Matthew Travers</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the IEEE ICRA Workshop on Field Robotics 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Field robotics applications, such as search and rescue, involve robots
  operating in large, unknown areas. These environments present unique challenges
  that compound the difficulties faced by a robot operator. The use of
  multi-robot teams, assisted by carefully designed autonomy, help reduce
  operator workload and allow the operator to effectively coordinate robot
  capabilities. In this work, we present a system architecture designed to
  optimize both robot autonomy and the operator experience in multi-robot
  scenarios. Drawing on lessons learned from our team's participation in the
  DARPA SubT Challenge, our architecture emphasizes modularity and
  interoperability. We empower the operator by allowing for adjustable levels of
  autonomy ("sliding mode autonomy"). We enhance the operator experience by using
  intuitive, adaptive interfaces that suggest context-aware actions to simplify
  control. Finally, we describe how the proposed architecture enables streamlined
  development of new capabilities for effective deployment of robot autonomy in
  the field.
  </p>
  </div>
  </dd>
  <dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17760" title="Abstract">arXiv:2404.17760</a> [<a href="/pdf/2404.17760" title="Download PDF">pdf</a>, <a href="/format/2404.17760" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Adversarial Examples: Generation Proposal in the Context of Facial  Recognition Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fuster%2C+M">Marina Fuster</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vidaurreta%2C+I">Ignacio Vidaurreta</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">In this paper we investigate the vulnerability that facial recognition
  systems present to adversarial examples by introducing a new methodology from
  the attacker perspective. The technique is based on the use of the autoencoder
  latent space, organized with principal component analysis. We intend to analyze
  the potential to craft adversarial examples suitable for both dodging and
  impersonation attacks, against state-of-the-art systems. Our initial
  hypothesis, which was not strongly favoured by the results, stated that it
  would be possible to separate between the "identity" and "facial expression"
  features to produce high-quality examples. Despite the findings not supporting
  it, the results sparked insights into adversarial examples generation and
  opened new research avenues in the area.
  </p>
  </div>
  </dd>
  <dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17761" title="Abstract">arXiv:2404.17761</a> [<a href="/pdf/2404.17761" title="Download PDF">pdf</a>, <a href="/format/2404.17761" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Un análisis bibliométrico de la producción científica acerca del  agrupamiento de trayectorias GPS
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Reyes%2C+G">Gary Reyes</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lanzarini%2C+L">Laura Lanzarini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Estrebou%2C+C">César Estrebou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bariviera%2C+A+F">Aurelio F. Bariviera</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 16 pages, in Spanish, 8 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Digital Libraries (cs.DL)
  
  </div>
  <p class="mathjax">Clustering algorithms or methods for GPS trajectories are in constant
  evolution due to the interest aroused in part of the scientific community. With
  the development of clustering algorithms considered traditional, improvements
  to these algorithms and even unique methods considered as "novelty" for science
  have emerged. This work aims to analyze the scientific production that exists
  around the topic "GPS trajectory clustering" by means of bibliometrics.
  Therefore, a total of 559 articles from the main collection of Scopus were
  analyzed, previously filtering the generated sample to discard any article that
  does not have a direct relationship with the topic to be analyzed. This
  analysis establishes an ideal environment for other disciplines and
  researchers, since it provides a current state of the trend of the subject of
  study in their field of research.
  <br>--
  <br>Los algoritmos o m\'etodos de agrupamiento para trayectorias GPS se
  encuentran en constante evoluci\'on debido al inter\'es que despierta en parte
  de la comunidad cient\'ifica. Con el desarrollo de los algoritmos de
  agrupamiento considerados tradicionales han surgido mejoras a estos algoritmos
  e incluso m\'etodos \'unicos considerados como "novedad" para la ciencia. Este
  trabajo tiene como objetivo analizar la producci\'on cient\'ifica que existe
  alrededor del tema "agrupamiento de trayectorias GPS" mediante la
  bibliometr\'ia. Por lo tanto, fueron analizados un total de 559 art\'iculos de
  la colecci\'on principal de Scopus, realizando previamente un filtrado de la
  muestra generada para descartar todo aquel art\'iculo que no tenga una
  relaci\'on directa con el tema a analizar. Este an\'alisis establece un
  ambiente ideal para otras disciplinas e investigadores, ya que entrega un
  estado actual de la tendencia que lleva la tem\'atica de estudio en su campo de
  investigaci\'on.
  </p>
  </div>
  </dd>
  <dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17762" title="Abstract">arXiv:2404.17762</a> [<a href="/pdf/2404.17762" title="Download PDF">pdf</a>, <a href="/format/2404.17762" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Large Multi-modality Model Assisted AI-Generated Image Quality  Assessment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+P">Puyi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+W">Wei Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zicheng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jia%2C+J">Jun Jia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yanwei Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhichao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Min%2C+X">Xiongkuo Min</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+G">Guangtao Zhai</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Traditional deep neural network (DNN)-based image quality assessment (IQA)
  models leverage convolutional neural networks (CNN) or Transformer to learn the
  quality-aware feature representation, achieving commendable performance on
  natural scene images. However, when applied to AI-Generated images (AGIs),
  these DNN-based IQA models exhibit subpar performance. This situation is
  largely due to the semantic inaccuracies inherent in certain AGIs caused by
  uncontrollable nature of the generation process. Thus, the capability to
  discern semantic content becomes crucial for assessing the quality of AGIs.
  Traditional DNN-based IQA models, constrained by limited parameter complexity
  and training data, struggle to capture complex fine-grained semantic features,
  making it challenging to grasp the existence and coherence of semantic content
  of the entire image. To address the shortfall in semantic content perception of
  current IQA models, we introduce a large Multi-modality model Assisted
  AI-Generated Image Quality Assessment (MA-AGIQA) model, which utilizes
  semantically informed guidance to sense semantic information and extract
  semantic vectors through carefully designed text prompts. Moreover, it employs
  a mixture of experts (MoE) structure to dynamically integrate the semantic
  information with the quality-aware features extracted by traditional DNN-based
  IQA models. Comprehensive experiments conducted on two AI-generated content
  datasets, AIGCQA-20k and AGIQA-3k show that MA-AGIQA achieves state-of-the-art
  performance, and demonstrate its superior generalization capabilities on
  assessing the quality of AGIs. Code is available at
  https://github.com/wangpuyi/MA-AGIQA.
  </p>
  </div>
  </dd>
  <dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17765" title="Abstract">arXiv:2404.17765</a> [<a href="/pdf/2404.17765" title="Download PDF">pdf</a>, <a href="/ps/2404.17765" title="Download PostScript">ps</a>, <a href="/format/2404.17765" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> RFL-CDNet: Towards Accurate Change Detection via Richer Feature Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gan%2C+Y">Yuhang Gan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xuan%2C+W">Wenjie Xuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hang Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Juhua Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Du%2C+B">Bo Du</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by PR, volume 153
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Change Detection is a crucial but extremely challenging task of remote
  sensing image analysis, and much progress has been made with the rapid
  development of deep learning. However, most existing deep learning-based change
  detection methods mainly focus on intricate feature extraction and multi-scale
  feature fusion, while ignoring the insufficient utilization of features in the
  intermediate stages, thus resulting in sub-optimal results. To this end, we
  propose a novel framework, named RFL-CDNet, that utilizes richer feature
  learning to boost change detection performance. Specifically, we first
  introduce deep multiple supervision to enhance intermediate representations,
  thus unleashing the potential of backbone feature extractor at each stage.
  Furthermore, we design the Coarse-To-Fine Guiding (C2FG) module and the
  Learnable Fusion (LF) module to further improve feature learning and obtain
  more discriminative feature representations. The C2FG module aims to seamlessly
  integrate the side prediction from the previous coarse-scale into the current
  fine-scale prediction in a coarse-to-fine manner, while LF module assumes that
  the contribution of each stage and each spatial location is independent, thus
  designing a learnable module to fuse multiple predictions. Experiments on
  several benchmark datasets show that our proposed RFL-CDNet achieves
  state-of-the-art performance on WHU cultivated land dataset and CDD dataset,
  and the second-best performance on WHU building dataset. The source code and
  models are publicly available at https://github.com/Hhaizee/RFL-CDNet.
  </p>
  </div>
  </dd>
  <dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17766" title="Abstract">arXiv:2404.17766</a> [<a href="/pdf/2404.17766" title="Download PDF">pdf</a>, <a href="/format/2404.17766" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Implementation of Big AI Models for Wireless Networks with Collaborative  Edge Computing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+L">Liekang Zeng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+S">Shengyuan Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xu Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yang Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)
  
  </div>
  <p class="mathjax">Big Artificial Intelligence (AI) models have emerged as a crucial element in
  various intelligent applications at the edge, such as voice assistants in smart
  homes and autonomous robotics in smart factories. Training big AI models, e.g.,
  for personalized fine-tuning and continual model refinement, poses significant
  challenges to edge devices due to the inherent conflict between limited
  computing resources and intensive workload associated with training. Despite
  the constraints of on-device training, traditional approaches usually resort to
  aggregating training data and sending it to a remote cloud for centralized
  training. Nevertheless, this approach is neither sustainable, which strains
  long-range backhaul transmission and energy-consuming datacenters, nor safely
  private, which shares users' raw data with remote infrastructures. To address
  these challenges, we alternatively observe that prevalent edge environments
  usually contain a diverse collection of trusted edge devices with untapped idle
  resources, which can be leveraged for edge training acceleration. Motivated by
  this, in this article, we propose collaborative edge training, a novel training
  mechanism that orchestrates a group of trusted edge devices as a resource pool
  for expedited, sustainable big AI model training at the edge. As an initial
  step, we present a comprehensive framework for building collaborative edge
  training systems and analyze in-depth its merits and sustainable scheduling
  choices following its workflow. To further investigate the impact of its
  parallelism design, we empirically study a case of four typical parallelisms
  from the perspective of energy demand with realistic testbeds. Finally, we
  discuss open challenges for sustainable collaborative edge training to point to
  future directions of edge-centric big AI model training.
  </p>
  </div>
  </dd>
  <dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17767" title="Abstract">arXiv:2404.17767</a> [<a href="/pdf/2404.17767" title="Download PDF">pdf</a>, <a href="/ps/2404.17767" title="Download PostScript">ps</a>, <a href="/format/2404.17767" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Novel Scheme for Coded Caching with Coded Placement in Small Memory  Regime
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yinbin Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tuninetti%2C+D">Daniela Tuninetti</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">This paper presents a novel achievable scheme for coded caching systems with
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-21-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-125" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-126"><span class="mi" id="MathJax-Span-127" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-21">N</script> files and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-22-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-128" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-129"><span class="mi" id="MathJax-Span-130" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-22">K</script> users, specifically when <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-23-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-131" style="width: 3.503em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.826em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.826em, 2.826em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-132"><span class="mi" id="MathJax-Span-133" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-134" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≤</span><span class="mi" id="MathJax-Span-135" style="font-family: STIXGeneral-Italic; padding-left: 0.342em;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-23">N \leq K</script>. This new scheme employs
  linear coding both during the placement phase - where cache contents are linear
  combinations of files from the library - and the delivery phase. The multi-step
  delivery phase enables users to decode the cached coded content and eliminate
  interference effectively. In the small memory regime, the proposed scheme
  outperforms existing methods, particularly when <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-24-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-136" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-137"><span class="mi" id="MathJax-Span-138" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-24">K</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-25-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-139" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-140"><span class="mi" id="MathJax-Span-141" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-25">N</script> values are similar,
  it maintains manageable sub-packetization levels, and operates over a finite
  field of size <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-26-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-142" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-143"><span class="mn" id="MathJax-Span-144" style="font-family: STIXGeneral-Regular;">3</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-26">3</script> regardless of the system parameters.
  </p>
  </div>
  </dd>
  <dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17768" title="Abstract">arXiv:2404.17768</a> [<a href="/pdf/2404.17768" title="Download PDF">pdf</a>, <a href="/format/2404.17768" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Make the Most of Your Data: Changing the Training Data Distribution to  Improve In-distribution Generalization Performance
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+D">Dang Nguyen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Haddad%2C+P">Paymon Haddad</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gan%2C+E">Eric Gan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mirzasoleiman%2C+B">Baharan Mirzasoleiman</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 32 pages, 11 figures, 6 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Can we modify the training data distribution to encourage the underlying
  optimization method toward finding solutions with superior generalization
  performance on in-distribution data? In this work, we approach this question
  for the first time by comparing the inductive bias of gradient descent (GD)
  with that of sharpness-aware minimization (SAM). By studying a two-layer CNN,
  we prove that SAM learns easy and difficult features more uniformly,
  particularly in early epochs. That is, SAM is less susceptible to simplicity
  bias compared to GD. Based on this observation, we propose USEFUL, an algorithm
  that clusters examples based on the network output early in training and
  upsamples examples with no easy features to alleviate the pitfalls of the
  simplicity bias. We show empirically that modifying the training data
  distribution in this way effectively improves the generalization performance on
  the original data distribution when training with (S)GD by mimicking the
  training dynamics of SAM. Notably, we demonstrate that our method can be
  combined with SAM and existing data augmentation strategies to achieve, to the
  best of our knowledge, state-of-the-art performance for training ResNet18 on
  CIFAR10, STL10, CINIC10, Tiny-ImageNet; ResNet34 on CIFAR100; and VGG19 and
  DenseNet121 on CIFAR10.
  </p>
  </div>
  </dd>
  <dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17769" title="Abstract">arXiv:2404.17769</a> [<a href="/pdf/2404.17769" title="Download PDF">pdf</a>, <a href="/format/2404.17769" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Conformal Ranked Retrieval
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yunpeng Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+W">Wenge Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zhi Wei</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, 6 figures, 1 table; 7 supplementary pages, 12 supplementary figures, 2 supplementary tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Methodology (stat.ME); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">Given the wide adoption of ranked retrieval techniques in various information
  systems that significantly impact our daily lives, there is an increasing need
  to assess and address the uncertainty inherent in their predictions. This paper
  introduces a novel method using the conformal risk control framework to
  quantitatively measure and manage risks in the context of ranked retrieval
  problems. Our research focuses on a typical two-stage ranked retrieval problem,
  where the retrieval stage generates candidates for subsequent ranking. By
  carefully formulating the conformal risk for each stage, we have developed
  algorithms to effectively control these risks within their specified bounds.
  The efficacy of our proposed methods has been demonstrated through
  comprehensive experiments on three large-scale public datasets for ranked
  retrieval tasks, including the MSLR-WEB dataset, the Yahoo LTRC dataset and the
  MS MARCO dataset.
  </p>
  </div>
  </dd>
  <dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17771" title="Abstract">arXiv:2404.17771</a> [<a href="/pdf/2404.17771" title="Download PDF">pdf</a>, <a href="/ps/2404.17771" title="Download PostScript">ps</a>, <a href="/format/2404.17771" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Charaterization of dim light response in DVS pixel: Discontinuity of  event triggering time
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xiao Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+F">Fei Zhou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages, 4 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Dynamic Vision Sensors (DVS) have recently generated great interest because
  of the advantages of wide dynamic range and low latency compared with
  conventional frame-based cameras. However, the complicated behaviors in dim
  light conditions are still not clear, restricting the applications of DVS. In
  this paper, we analyze the typical DVS circuit, and find that there exists
  discontinuity of event triggering time. In dim light conditions, the
  discontinuity becomes prominent. We point out that the discontinuity depends
  exclusively on the changing speed of light intensity. Experimental results on
  real event data validate the analysis and the existence of discontinuity that
  reveals the non-first-order behaviors of DVS in dim light conditions.
  </p>
  </div>
  </dd>
  <dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17773" title="Abstract">arXiv:2404.17773</a> [<a href="/pdf/2404.17773" title="Download PDF">pdf</a>, <a href="/format/2404.17773" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Compressing Latent Space via Least Volume
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qiuyi Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fuge%2C+M">Mark Fuge</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 24 pages, International Conference on Learning Representations 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">This paper introduces Least Volume-a simple yet effective regularization
  inspired by geometric intuition-that can reduce the necessary number of latent
  dimensions needed by an autoencoder without requiring any prior knowledge of
  the intrinsic dimensionality of the dataset. We show that the Lipschitz
  continuity of the decoder is the key to making it work, provide a proof that
  PCA is just a linear special case of it, and reveal that it has a similar
  PCA-like importance ordering effect when applied to nonlinear models. We
  demonstrate the intuition behind the regularization on some pedagogical toy
  problems, and its effectiveness on several benchmark problems, including MNIST,
  CIFAR-10 and CelebA.
  </p>
  </div>
  </dd>
  <dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17774" title="Abstract">arXiv:2404.17774</a> [<a href="/pdf/2404.17774" title="Download PDF">pdf</a>, <a href="/format/2404.17774" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> High-quality Surface Reconstruction using Gaussian Surfels
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dai%2C+P">Pinxuan Dai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Jiamin Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+W">Wenxiang Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xinguo Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Huamin Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Weiwei Xu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Original version
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
  
  </div>
  <p class="mathjax">We propose a novel point-based representation, Gaussian surfels, to combine
  the advantages of the flexible optimization procedure in 3D Gaussian points and
  the surface alignment property of surfels. This is achieved by directly setting
  the z-scale of 3D Gaussian points to 0, effectively flattening the original 3D
  ellipsoid into a 2D ellipse. Such a design provides clear guidance to the
  optimizer. By treating the local z-axis as the normal direction, it greatly
  improves optimization stability and surface alignment. While the derivatives to
  the local z-axis computed from the covariance matrix are zero in this setting,
  we design a self-supervised normal-depth consistency loss to remedy this issue.
  Monocular normal priors and foreground masks are incorporated to enhance the
  quality of the reconstruction, mitigating issues related to highlights and
  background. We propose a volumetric cutting method to aggregate the information
  of Gaussian surfels so as to remove erroneous points in depth maps generated by
  alpha blending. Finally, we apply screened Poisson reconstruction method to the
  fused depth maps to extract the surface mesh. Experimental results show that
  our method demonstrates superior performance in surface reconstruction compared
  to state-of-the-art neural volume rendering and point-based rendering methods.
  </p>
  </div>
  </dd>
  <dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17775" title="Abstract">arXiv:2404.17775</a> [<a href="/pdf/2404.17775" title="Download PDF">pdf</a>, <a href="/format/2404.17775" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Limits of Sequential Local Algorithms on the Random <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-27-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-145" style="width: 0.585em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.45em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1000.45em, 2.646em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-146"><span class="mi" id="MathJax-Span-147" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.947em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-27">k</script>-XORSAT Problem
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yung%2C+K">Kingsley Yung</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> full version; to be published in ICALP 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>
  
  </div>
  <p class="mathjax">The random <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-28-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-148" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-149"><span class="mi" id="MathJax-Span-150" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-28">k</script>-XORSAT problem is a random constraint satisfaction problem of
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-29-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-151" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-152"><span class="mi" id="MathJax-Span-153" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-29">n</script> Boolean variables and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-30-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-154" style="width: 3.673em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.995em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1002.995em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-155"><span class="mi" id="MathJax-Span-156" style="font-family: STIXGeneral-Italic;">m</span><span class="mo" id="MathJax-Span-157" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mi" id="MathJax-Span-158" style="font-family: STIXGeneral-Italic; padding-left: 0.342em;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-159" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-30">m=rn</script> clauses, which a random instance can be
  expressed as a <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-31-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-160" style="width: 3.052em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.487em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.431em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-161"><span class="mi" id="MathJax-Span-162" style="font-family: STIXGeneral-Italic;">G</span><span class="texatom" id="MathJax-Span-163"><span class="mrow" id="MathJax-Span-164"><span class="mi" id="MathJax-Span-165" style="font-family: STIXGeneral-Regular;">𝔽<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.116em;"></span></span></span></span><span class="mo" id="MathJax-Span-166" style="font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-167" style="font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-168" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-31">G\mathbb{F}(2)</script> linear system of the form <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-32-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-169" style="width: 3.616em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.939em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.939em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-170"><span class="mi" id="MathJax-Span-171" style="font-family: STIXGeneral-Italic;">A</span><span class="mi" id="MathJax-Span-172" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-173" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mi" id="MathJax-Span-174" style="font-family: STIXGeneral-Italic; padding-left: 0.342em;">b</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-32">Ax=b</script>, where <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-33-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-175" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.567em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-176"><span class="mi" id="MathJax-Span-177" style="font-family: STIXGeneral-Italic;">A</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-33">A</script> is
  a random <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-34-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-178" style="width: 2.939em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.374em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.866em, 1002.374em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-179"><span class="mi" id="MathJax-Span-180" style="font-family: STIXGeneral-Italic;">m</span><span class="mo" id="MathJax-Span-181" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">×</span><span class="mi" id="MathJax-Span-182" style="font-family: STIXGeneral-Italic; padding-left: 0.229em;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.837em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-34">m \times n</script> matrix with <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-35-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-183" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-184"><span class="mi" id="MathJax-Span-185" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-35">k</script> ones per row, and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-36-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-186" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-187"><span class="mi" id="MathJax-Span-188" style="font-family: STIXGeneral-Italic;">b</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-36">b</script> is a random vector.
  It is known that there exist two distinct thresholds <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-37-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-189" style="width: 8.189em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.665em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1006.609em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-190"><span class="msubsup" id="MathJax-Span-191"><span style="display: inline-block; position: relative; width: 1.753em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-192" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.398em;"><span class="texatom" id="MathJax-Span-193"><span class="mrow" id="MathJax-Span-194"><span class="mi" id="MathJax-Span-195" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-196" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-197" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-198" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">e</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-199" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-200" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-201" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-202" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">&lt;</span><span class="msubsup" id="MathJax-Span-203" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-204" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.398em;"><span class="texatom" id="MathJax-Span-205"><span class="mrow" id="MathJax-Span-206"><span class="mi" id="MathJax-Span-207" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">s</span><span class="mi" id="MathJax-Span-208" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-209" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-210" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-211" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-212" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-37">r_{core}(k) < r_{sat}(k)</script>
  such that as <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-38-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-213" style="width: 3.786em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.052em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1002.995em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-214"><span class="mi" id="MathJax-Span-215" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-216" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">→</span><span class="mi" id="MathJax-Span-217" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∞</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-38">n \rightarrow \infty</script> for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-39-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-218" style="width: 5.141em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.181em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1004.124em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-219"><span class="mi" id="MathJax-Span-220" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-221" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">&lt;</span><span class="msubsup" id="MathJax-Span-222" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-223" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.398em;"><span class="texatom" id="MathJax-Span-224"><span class="mrow" id="MathJax-Span-225"><span class="mi" id="MathJax-Span-226" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">s</span><span class="mi" id="MathJax-Span-227" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-228" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-229" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-230" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-231" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-39">r < r_{sat}(k)</script> the random instance
  has solutions with high probability, while for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-40-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-232" style="width: 9.036em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.342em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1007.286em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-233"><span class="msubsup" id="MathJax-Span-234"><span style="display: inline-block; position: relative; width: 1.753em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-235" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.398em;"><span class="texatom" id="MathJax-Span-236"><span class="mrow" id="MathJax-Span-237"><span class="mi" id="MathJax-Span-238" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-239" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-240" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-241" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">e</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-242" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">&lt;</span><span class="mi" id="MathJax-Span-243" style="font-family: STIXGeneral-Italic; padding-left: 0.342em;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-244" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">&lt;</span><span class="msubsup" id="MathJax-Span-245" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-246" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.398em;"><span class="texatom" id="MathJax-Span-247"><span class="mrow" id="MathJax-Span-248"><span class="mi" id="MathJax-Span-249" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">s</span><span class="mi" id="MathJax-Span-250" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-251" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-252" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-253" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-254" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-40">r_{core} < r < r_{sat}(k)</script> the
  solution space shatters into an exponential number of clusters. Sequential
  local algorithms are a natural class of algorithms which assign values to
  variables one by one iteratively. In each iteration, the algorithm runs some
  heuristics, called local rules, to decide the value assigned, based on the
  local neighborhood of the selected variables under the factor graph
  representation of the instance.
  <br>We prove that for any <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-41-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-255" style="width: 5.705em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.632em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1004.576em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-256"><span class="mi" id="MathJax-Span-257" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-258" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">&gt;</span><span class="msubsup" id="MathJax-Span-259" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 1.753em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-260" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.398em;"><span class="texatom" id="MathJax-Span-261"><span class="mrow" id="MathJax-Span-262"><span class="mi" id="MathJax-Span-263" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-264" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-265" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-266" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">e</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-267" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-268" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-269" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-41">r > r_{core}(k)</script> the sequential local algorithms with
  certain local rules fail to solve the random <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-42-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-270" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-271"><span class="mi" id="MathJax-Span-272" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-42">k</script>-XORSAT with high probability.
  They include (1) the algorithm using the Unit Clause Propagation as local rule
  for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-43-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-273" style="width: 2.882em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.261em, 2.826em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-274"><span class="mi" id="MathJax-Span-275" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-276" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≥</span><span class="mn" id="MathJax-Span-277" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">9</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-43">k \ge 9</script>, and (2) the algorithms using any local rule that can calculate
  the exact marginal probabilities of variables in instances with factor graphs
  that are trees, for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-44-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-278" style="width: 3.503em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.826em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.769em, 2.826em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-279"><span class="mi" id="MathJax-Span-280" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-281" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≥</span><span class="mn" id="MathJax-Span-282" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">13</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-44">k\ge 13</script>. The well-known Belief Propagation and Survey
  Propagation are included in (2). Meanwhile, the best known linear-time
  algorithm succeeds with high probability for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-45-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-283" style="width: 5.705em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.632em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1004.576em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-284"><span class="mi" id="MathJax-Span-285" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-286" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">&lt;</span><span class="msubsup" id="MathJax-Span-287" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 1.753em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-288" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.398em;"><span class="texatom" id="MathJax-Span-289"><span class="mrow" id="MathJax-Span-290"><span class="mi" id="MathJax-Span-291" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-292" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-293" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-294" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">e</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-295" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-296" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-297" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-45">r < r_{core}(k)</script>. Our results
  support the intuition that <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-46-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-298" style="width: 3.56em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.882em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.826em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-299"><span class="msubsup" id="MathJax-Span-300"><span style="display: inline-block; position: relative; width: 1.753em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-301" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.398em;"><span class="texatom" id="MathJax-Span-302"><span class="mrow" id="MathJax-Span-303"><span class="mi" id="MathJax-Span-304" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-305" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-306" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-307" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">e</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-308" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-309" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-310" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-46">r_{core}(k)</script> is the sharp threshold for the
  existence of a linear-time algorithm for random <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-47-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-311" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-312"><span class="mi" id="MathJax-Span-313" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-47">k</script>-XORSAT.
  </p>
  </div>
  </dd>
  <dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17778" title="Abstract">arXiv:2404.17778</a> [<a href="/pdf/2404.17778" title="Download PDF">pdf</a>, <a href="/format/2404.17778" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MRScore: Evaluating Radiology Report Generation with LLM-based Reward  System
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yunyi Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhanyu Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yingshu Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+X">Xinyu Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+L">Lingqiao Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+L">Luping Zhou</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">In recent years, automated radiology report generation has experienced
  significant growth. This paper introduces MRScore, an automatic evaluation
  metric tailored for radiology report generation by leveraging Large Language
  Models (LLMs). Conventional NLG (natural language generation) metrics like BLEU
  are inadequate for accurately assessing the generated radiology reports, as
  systematically demonstrated by our observations within this paper. To address
  this challenge, we collaborated with radiologists to develop a framework that
  guides LLMs for radiology report evaluation, ensuring alignment with human
  analysis. Our framework includes two key components: i) utilizing GPT to
  generate large amounts of training data, i.e., reports with different
  qualities, and ii) pairing GPT-generated reports as accepted and rejected
  samples and training LLMs to produce MRScore as the model reward. Our
  experiments demonstrate MRScore's higher correlation with human judgments and
  superior performance in model selection compared to traditional metrics. Our
  code and datasets will be available on GitHub.
  </p>
  </div>
  </dd>
  <dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17779" title="Abstract">arXiv:2404.17779</a> [<a href="/pdf/2404.17779" title="Download PDF">pdf</a>, <a href="/format/2404.17779" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Medical Vision-Language Pre-Training for Brain Abnormalities
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Monajatipoor%2C+M">Masoud Monajatipoor</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dou%2C+Z">Zi-Yi Dou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chien%2C+A">Aichi Chien</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+N">Nanyun Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chang%2C+K">Kai-Wei Chang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Vision-language models have become increasingly powerful for tasks that
  require an understanding of both visual and linguistic elements, bridging the
  gap between these modalities. In the context of multimodal clinical AI, there
  is a growing need for models that possess domain-specific knowledge, as
  existing models often lack the expertise required for medical applications. In
  this paper, we take brain abnormalities as an example to demonstrate how to
  automatically collect medical image-text aligned data for pretraining from
  public resources such as PubMed. In particular, we present a pipeline that
  streamlines the pre-training process by initially collecting a large brain
  image-text dataset from case reports and published journals and subsequently
  constructing a high-performance vision-language model tailored to specific
  medical tasks. We also investigate the unique challenge of mapping subfigures
  to subcaptions in the medical domain. We evaluated the resulting model with
  quantitative and qualitative intrinsic evaluations. The resulting dataset and
  our code can be found here
  https://github.com/masoud-monajati/MedVL_pretraining_pipeline
  </p>
  </div>
  </dd>
  <dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17780" title="Abstract">arXiv:2404.17780</a> [<a href="/pdf/2404.17780" title="Download PDF">pdf</a>, <a href="/format/2404.17780" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Verco: Learning Coordinated Verbal Communication for Multi-agent  Reinforcement Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Dapeng Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+H">Hang Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Lu Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qiao%2C+B">Bo Qiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qin%2C+S">Si Qin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Q">Qingwei Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+D">Dongmei Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhiwei Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+B">Bin Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+G">Guoliang Fan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages, 6 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">In recent years, multi-agent reinforcement learning algorithms have made
  significant advancements in diverse gaming environments, leading to increased
  interest in the broader application of such techniques. To address the
  prevalent challenge of partial observability, communication-based algorithms
  have improved cooperative performance through the sharing of numerical
  embedding between agents. However, the understanding of the formation of
  collaborative mechanisms is still very limited, making designing a
  human-understandable communication mechanism a valuable problem to address. In
  this paper, we propose a novel multi-agent reinforcement learning algorithm
  that embeds large language models into agents, endowing them with the ability
  to generate human-understandable verbal communication. The entire framework has
  a message module and an action module. The message module is responsible for
  generating and sending verbal messages to other agents, effectively enhancing
  information sharing among agents. To further enhance the message module, we
  employ a teacher model to generate message labels from the global view and
  update the student model through Supervised Fine-Tuning (SFT). The action
  module receives messages from other agents and selects actions based on current
  local observations and received messages. Experiments conducted on the
  Overcooked game demonstrate our method significantly enhances the learning
  efficiency and performance of existing methods, while also providing an
  interpretable tool for humans to understand the process of multi-agent
  cooperation.
  </p>
  </div>
  </dd>
  <dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17781" title="Abstract">arXiv:2404.17781</a> [<a href="/pdf/2404.17781" title="Download PDF">pdf</a>, <a href="/ps/2404.17781" title="Download PostScript">ps</a>, <a href="/format/2404.17781" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Value-Oriented Investigation of Photoshop's Generative Fill
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Swift%2C+I+P">Ian P. Swift</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chattopadhyay%2C+D">Debaleena Chattopadhyay</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">The creative industry is both concerned and enthusiastic about how generative
  AI will reshape creativity. How might these tools interact with the workflow
  values of creative artists? In this paper, we adopt a value-sensitive design
  framework to examine how generative AI, particularly Photoshop's Generative
  Fill (GF), helps or hinders creative professionals' values. We obtained 566
  unique posts about GF from online forums for creative professionals who use
  Photoshop in their current work practices. We conducted reflexive thematic
  analysis focusing on usefulness, ease of use, and user values. Users found GF
  useful in doing touch-ups, expanding images, and generating composite images.
  GF helped users' values of productivity by making work efficient but created a
  value tension around creativity: it helped reduce barriers to creativity but
  hindered distinguishing 'human' from algorithmic art. Furthermore, GF hindered
  lived experiences shaping creativity and hindered the honed prideful skills of
  creative work.
  </p>
  </div>
  </dd>
  <dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17783" title="Abstract">arXiv:2404.17783</a> [<a href="/pdf/2404.17783" title="Download PDF">pdf</a>, <a href="/format/2404.17783" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> KnapsackLB: Enabling Performance-Aware Layer-4 Load Balancing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gandhi%2C+R">Rohan Gandhi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Narayana%2C+S">Srinivas Narayana</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>
  
  </div>
  <p class="mathjax">Layer-4 load balancer (LB) is a key building block of online services. In
  this paper, we empower such LBs to adapt to different and dynamic performance
  of backend instances (DIPs). Our system, KNAPSACKLB, is generic (can work with
  variety of LBs), does not require agents on DIPs, LBs or clients, and scales to
  large numbers of DIPs. KNAPSACKLB uses judicious active probes to learn a
  mapping from LB weights to the response latency of each DIP, and then applies
  Integer Linear Programming (ILP) to calculate LB weights that optimize latency,
  using an iterative method to scale the computation to large numbers of DIPs.
  Using testbed experiments and simulations, we show that KNAPSACKLB load
  balances traffic as per the performance and cuts average latency by up to 45%
  compared to existing designs.
  </p>
  </div>
  </dd>
  <dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17785" title="Abstract">arXiv:2404.17785</a> [<a href="/pdf/2404.17785" title="Download PDF">pdf</a>, <a href="/format/2404.17785" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Temporal Scaling Law for Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+Y">Yizhe Xiong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiansheng Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+X">Xin Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hui Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zijia Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lian%2C+H">Haoran Lian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Niu%2C+J">Jianwei Niu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+G">Guiguang Ding</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Work in progress
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Recently, Large Language Models (LLMs) are widely adopted in a wide range of
  tasks, leading to increasing attention towards the research on how scaling LLMs
  affects their performance. Existing works, termed as Scaling Laws, have
  discovered that the loss of LLMs scales as power laws with model size,
  computational budget, and dataset size. However, the performance of LLMs
  throughout the training process remains untouched. In this paper, we propose
  the novel concept of Temporal Scaling Law and study the loss of LLMs from the
  temporal dimension. We first investigate the imbalance of loss on each token
  positions and develop a reciprocal-law across model scales and training stages.
  We then derive the temporal scaling law by studying the temporal patterns of
  the reciprocal-law parameters. Results on both in-distribution (IID) data and
  out-of-distribution (OOD) data demonstrate that our temporal scaling law
  accurately predicts the performance of LLMs in future training stages.
  Moreover, the temporal scaling law reveals that LLMs learn uniformly on
  different token positions, despite the loss imbalance. Experiments on
  pre-training LLMs in various scales show that this phenomenon verifies the
  default training paradigm for generative language models, in which no
  re-weighting strategies are attached during training. Overall, the temporal
  scaling law provides deeper insight into LLM pre-training.
  </p>
  </div>
  </dd>
  <dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17787" title="Abstract">arXiv:2404.17787</a> [<a href="/pdf/2404.17787" title="Download PDF">pdf</a>, <a href="/ps/2404.17787" title="Download PostScript">ps</a>, <a href="/format/2404.17787" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quantum resistant multi-signature scheme with optimal communication  round: A Blockchain-based approach
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rahmati%2C+H">Hamidreza Rahmati</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rahmati%2C+F">Farhad Rahmati</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This article has 18 pages, 6 figures, and 4 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT)
  
  </div>
  <p class="mathjax">Blockchain is a decentralized network to increase trust, integrity, and
  transparency of transactions. With the exponential growth of transactions in
  the realm of Blockchain, especially in Bitcoin, Blockchain size increases as
  all transactions must be stored and verified. In Bitcoin, validating M of N
  transactions involves the necessity of M authentic signatures out of the total
  N transactions. This procedure is so time-consuming and needs a significant
  storage capacity. To address these issues, several multi signature schemes have
  been proposed, enabling users to interactively generate a common signature on a
  single message. Recently, some lattice based multi signature schemes have been
  presented to deal with the threats of quantum computers. However, none of them
  have met all desirable features of multi signature schemes like aggregate
  public key, low numbers of communication rounds, or resistant to quantum
  computers. Within this paper, we present a new multi signature scheme based on
  lattices, known as Razhims, that has aggregate public key, necessitates solely
  a single round of communication, and is resistant to quantum computers. In
  Razhims, the aggregate public key size and the final signature size are equal
  to the public key size and the final signature size of a standard signature
  respectively, and are independent of the number of signers.
  </p>
  </div>
  </dd>
  <dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17789" title="Abstract">arXiv:2404.17789</a> [<a href="/pdf/2404.17789" title="Download PDF">pdf</a>, <a href="/format/2404.17789" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> BiLO: Bilevel Local Operator Learning for PDE inverse problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R+Z">Ray Zirui Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+X">Xiaohui Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lowengrub%2C+J">John Lowengrub</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)
  
  </div>
  <p class="mathjax">We propose a new neural network based method for solving inverse problems for
  partial differential equations (PDEs) by formulating the PDE inverse problem as
  a bilevel optimization problem. At the upper level, we minimize the data loss
  with respect to the PDE parameters. At the lower level, we train a neural
  network to locally approximate the PDE solution operator in the neighborhood of
  a given set of PDE parameters, which enables an accurate approximation of the
  descent direction for the upper level optimization problem. The lower level
  loss function includes the L2 norms of both the residual and its derivative
  with respect to the PDE parameters. We apply gradient descent simultaneously on
  both the upper and lower level optimization problems, leading to an effective
  and fast algorithm. The method, which we refer to as BiLO (Bilevel Local
  Operator learning), is also able to efficiently infer unknown functions in the
  PDEs through the introduction of an auxiliary variable. We demonstrate that our
  method enforces strong PDE constraints, is robust to sparse and noisy data, and
  eliminates the need to balance the residual and the data loss, which is
  inherent to soft PDE constraints.
  </p>
  </div>
  </dd>
  <dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17790" title="Abstract">arXiv:2404.17790</a> [<a href="/pdf/2404.17790" title="Download PDF">pdf</a>, <a href="/format/2404.17790" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing  Japanese Language Capabilities
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fujii%2C+K">Kazuki Fujii</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nakamura%2C+T">Taishi Nakamura</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Loem%2C+M">Mengsay Loem</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Iida%2C+H">Hiroki Iida</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ohi%2C+M">Masanari Ohi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hattori%2C+K">Kakeru Hattori</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shota%2C+H">Hirai Shota</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mizuki%2C+S">Sakae Mizuki</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yokota%2C+R">Rio Yokota</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Okazaki%2C+N">Naoaki Okazaki</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Cross-lingual continual pre-training of large language models (LLMs)
  initially trained on English corpus allows us to leverage the vast amount of
  English language resources and reduce the pre-training cost. In this study, we
  constructed Swallow, an LLM with enhanced Japanese capability, by extending the
  vocabulary of Llama 2 to include Japanese characters and conducting continual
  pre-training on a large Japanese web corpus. Experimental results confirmed
  that the performance on Japanese tasks drastically improved through continual
  pre-training, and the performance monotonically increased with the amount of
  training data up to 100B tokens. Consequently, Swallow achieved superior
  performance compared to other LLMs that were trained from scratch in English
  and Japanese. An analysis of the effects of continual pre-training revealed
  that it was particularly effective for Japanese question answering tasks.
  Furthermore, to elucidate effective methodologies for cross-lingual continual
  pre-training from English to Japanese, we investigated the impact of vocabulary
  expansion and the effectiveness of incorporating parallel corpora. The results
  showed that the efficiency gained through vocabulary expansion had no negative
  impact on performance, except for the summarization task, and that the combined
  use of parallel corpora enhanced translation ability.
  </p>
  </div>
  </dd>
  <dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17791" title="Abstract">arXiv:2404.17791</a> [<a href="/pdf/2404.17791" title="Download PDF">pdf</a>, <a href="/format/2404.17791" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> HIPer: A Human-Inspired Scene Perception Model for Multifunctional  Mobile Robots
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Graf%2C+F">Florenz Graf</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lindermayr%2C+J">Jochen Lindermayr</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Graf%2C+B">Birgit Graf</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kraus%2C+W">Werner Kraus</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huber%2C+M+F">Marco F. Huber</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Taking over arbitrary tasks like humans do with a mobile service robot in
  open-world settings requires a holistic scene perception for decision-making
  and high-level control. This paper presents a human-inspired scene perception
  model to minimize the gap between human and robotic capabilities. The approach
  takes over fundamental neuroscience concepts, such as a triplet perception
  split into recognition, knowledge representation, and knowledge interpretation.
  A recognition system splits the background and foreground to integrate
  exchangeable image-based object detectors and SLAM, a multi-layer knowledge
  base represents scene information in a hierarchical structure and offers
  interfaces for high-level control, and knowledge interpretation methods deploy
  spatio-temporal scene analysis and perceptual learning for self-adjustment. A
  single-setting ablation study is used to evaluate the impact of each component
  on the overall performance for a fetch-and-carry scenario in two simulated and
  one real-world environment.
  </p>
  </div>
  </dd>
  <dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17793" title="Abstract">arXiv:2404.17793</a> [<a href="/pdf/2404.17793" title="Download PDF">pdf</a>, <a href="/format/2404.17793" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CLFT: Camera-LiDAR Fusion Transformer for Semantic Segmentation in  Autonomous Driving
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gu%2C+J">Junyi Gu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bellone%2C+M">Mauro Bellone</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pivo%C5%88ka%2C+T">Tomáš Pivoňka</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sell%2C+R">Raivo Sell</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Intelligent Vehicles
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
  
  </div>
  <p class="mathjax">Critical research about camera-and-LiDAR-based semantic object segmentation
  for autonomous driving significantly benefited from the recent development of
  deep learning. Specifically, the vision transformer is the novel ground-breaker
  that successfully brought the multi-head-attention mechanism to computer vision
  applications. Therefore, we propose a vision-transformer-based network to carry
  out camera-LiDAR fusion for semantic segmentation applied to autonomous
  driving. Our proposal uses the novel progressive-assemble strategy of vision
  transformers on a double-direction network and then integrates the results in a
  cross-fusion strategy over the transformer decoder layers. Unlike other works
  in the literature, our camera-LiDAR fusion transformers have been evaluated in
  challenging conditions like rain and low illumination, showing robust
  performance. The paper reports the segmentation results over the vehicle and
  human classes in different modalities: camera-only, LiDAR-only, and
  camera-LiDAR fusion. We perform coherent controlled benchmark experiments of
  CLFT against other networks that are also designed for semantic segmentation.
  The experiments aim to evaluate the performance of CLFT independently from two
  perspectives: multimodal sensor fusion and backbone architectures. The
  quantitative assessments show our CLFT networks yield an improvement of up to
  10\% for challenging dark-wet conditions when comparing with
  Fully-Convolutional-Neural-Network-based (FCN) camera-LiDAR fusion neural
  network. Contrasting to the network with transformer backbone but using single
  modality input, the all-around improvement is 5-10\%.
  </p>
  </div>
  </dd>
  <dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17794" title="Abstract">arXiv:2404.17794</a> [<a href="/pdf/2404.17794" title="Download PDF">pdf</a>, <a href="/format/2404.17794" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> GPT for Games: A Scoping Review (2020-2023)
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+D">Daijin Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kleinman%2C+E">Erica Kleinman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Harteveld%2C+C">Casper Harteveld</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> To be published in IEEE Conference on Games 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">This paper introduces a scoping review of 55 articles to explore GPT's
  potential for games, offering researchers a comprehensive understanding of the
  current applications and identifying both emerging trends and unexplored areas.
  We identify five key applications of GPT in current game research: procedural
  content generation, mixed-initiative game design, mixed-initiative gameplay,
  playing games, and game user research. Drawing from insights in each of these
  application areas, we propose directions for future research in each one. This
  review aims to lay the groundwork by illustrating the state of the art for
  innovative GPT applications in games, promising to enrich game development and
  enhance player experiences with cutting-edge AI innovations.
  </p>
  </div>
  </dd>
  <dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17796" title="Abstract">arXiv:2404.17796</a> [<a href="/pdf/2404.17796" title="Download PDF">pdf</a>, <a href="/format/2404.17796" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Modified Trapezoidal Product Cubature Rules. Definiteness, Monotonicity  and a Posteriori Error Estimates
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Nikolov%2C+G">Geno Nikolov</a>, 
  <a href="/search/math?searchtype=author&amp;query=Nikolov%2C+P">Petar Nikolov</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 18 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Classical Analysis and ODEs (math.CA)
  
  </div>
  <p class="mathjax">We study two modifications of the trapezoidal product cubature formulae,
  approximating double integrals over the square domain <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-48-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-314" style="width: 11.295em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.149em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1009.036em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-315"><span class="mo" id="MathJax-Span-316" style="font-family: STIXGeneral-Regular;">[</span><span class="mi" id="MathJax-Span-317" style="font-family: STIXGeneral-Italic;">a</span><span class="mo" id="MathJax-Span-318" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-319" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">b</span><span class="msubsup" id="MathJax-Span-320"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.229em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="mo" id="MathJax-Span-321" style="font-family: STIXGeneral-Regular;">]</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.342em;"><span class="mn" id="MathJax-Span-322" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-323" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mo" id="MathJax-Span-324" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">[</span><span class="mi" id="MathJax-Span-325" style="font-family: STIXGeneral-Italic;">a</span><span class="mo" id="MathJax-Span-326" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-327" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">b</span><span class="mo" id="MathJax-Span-328" style="font-family: STIXGeneral-Regular;">]</span><span class="mo" id="MathJax-Span-329" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">×</span><span class="mo" id="MathJax-Span-330" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">[</span><span class="mi" id="MathJax-Span-331" style="font-family: STIXGeneral-Italic;">a</span><span class="mo" id="MathJax-Span-332" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-333" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">b</span><span class="mo" id="MathJax-Span-334" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-48">[a,b]^2=[a,b]\times
  [a,b]</script>. Our modified cubature formulae use mixed type data: except evaluations
  of the integrand on the points forming a uniform grid on <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-49-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-335" style="width: 3.165em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.543em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1002.543em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-336"><span class="mo" id="MathJax-Span-337" style="font-family: STIXGeneral-Regular;">[</span><span class="mi" id="MathJax-Span-338" style="font-family: STIXGeneral-Italic;">a</span><span class="mo" id="MathJax-Span-339" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-340" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">b</span><span class="msubsup" id="MathJax-Span-341"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.229em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="mo" id="MathJax-Span-342" style="font-family: STIXGeneral-Regular;">]</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.342em;"><span class="mn" id="MathJax-Span-343" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-49">[a,b]^2</script>, they
  involve two or four univariate integrals. An useful property of these cubature
  formulae is that they are definite of order <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-50-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-344" style="width: 2.6em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.092em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.035em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-345"><span class="mo" id="MathJax-Span-346" style="font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-347" style="font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-348" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-349" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">2</span><span class="mo" id="MathJax-Span-350" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-50">(2,2)</script>, that is, they provide
  one-sided approximation to the double integral for real-valued integrands from
  the class <span class="MathJax_Preview" style="display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-51-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="MathJax-Span-351" style="width: 39.129em; display: inline-block;"><span style="display: inline-block; position: relative; width: 31.789em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.85em, 1031.733em, 3.673em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-352"><span class="msubsup" id="MathJax-Span-353"><span style="display: inline-block; position: relative; width: 1.584em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-354"><span class="mrow" id="MathJax-Span-355"><span class="mi" id="MathJax-Span-356" style="font-family: STIXNonUnicode-Italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.624em;"><span class="texatom" id="MathJax-Span-357"><span class="mrow" id="MathJax-Span-358"><span class="mn" id="MathJax-Span-359" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-360" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-361" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-362" style="font-family: STIXGeneral-Regular;">[</span><span class="mi" id="MathJax-Span-363" style="font-family: STIXGeneral-Italic;">a</span><span class="mo" id="MathJax-Span-364" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-365" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">b</span><span class="mo" id="MathJax-Span-366" style="font-family: STIXGeneral-Regular;">]</span><span class="mo" id="MathJax-Span-367" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mo" id="MathJax-Span-368" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">{</span><span class="mi" id="MathJax-Span-369" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.172em;"></span></span><span class="mo" id="MathJax-Span-370" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-371" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-372" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-373" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">y</span><span class="mo" id="MathJax-Span-374" style="font-family: STIXGeneral-Regular;">)</span><span class="mspace" id="MathJax-Span-375" style="height: 0em; vertical-align: 0em; width: 0.172em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-376" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">:</span><span class="mspace" id="MathJax-Span-377" style="height: 0em; vertical-align: 0em; width: 0.172em; display: inline-block; overflow: hidden;"></span><span class="mfrac" id="MathJax-Span-378" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 2.882em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(2.995em, 1001.301em, 4.407em, -999.997em); top: -4.683em; left: 50%; margin-left: -0.675em;"><span class="mrow" id="MathJax-Span-379"><span class="msubsup" id="MathJax-Span-380"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-381" style="font-family: STIXGeneral-Regular;">∂</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.454em;"><span class="mn" id="MathJax-Span-382" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">4</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mi" id="MathJax-Span-383" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.172em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.052em, 1002.769em, 4.407em, -999.997em); top: -3.272em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-384"><span class="mi" id="MathJax-Span-385" style="font-family: STIXGeneral-Regular;">∂</span><span class="msubsup" id="MathJax-Span-386"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-387" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.288em; left: 0.511em;"><span class="mn" id="MathJax-Span-388" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mi" id="MathJax-Span-389" style="font-family: STIXGeneral-Regular;">∂</span><span class="msubsup" id="MathJax-Span-390"><span style="display: inline-block; position: relative; width: 0.85em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.407em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-391" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.288em; left: 0.454em;"><span class="mn" id="MathJax-Span-392" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1002.882em, 1.245em, -999.997em); top: -1.296em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 2.882em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span class="mtext" id="MathJax-Span-393" style="font-family: STIXGeneral-Regular;">&nbsp;</span><span class="mtext" id="MathJax-Span-394" style="font-family: STIXGeneral-Regular;">continuous and does not change sign in</span><span class="mtext" id="MathJax-Span-395" style="font-family: STIXGeneral-Regular;">&nbsp;</span><span class="mo" id="MathJax-Span-396" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-397" style="font-family: STIXGeneral-Italic;">a</span><span class="mo" id="MathJax-Span-398" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-399" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">b</span><span class="msubsup" id="MathJax-Span-400"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.285em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="mo" id="MathJax-Span-401" style="font-family: STIXGeneral-Regular;">)</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.342em;"><span class="mn" id="MathJax-Span-402" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-403" style="font-family: STIXGeneral-Regular;">}</span><span class="mo" id="MathJax-Span-404" style="font-family: STIXGeneral-Regular;">.</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.247em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 3.198em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-51"> \mathcal{C}^{2,2}[a,b]=\{f(x,y)\,:\,\frac{\partial^4 f}{\partial
  x^2\partial y^2}\ \text{continuous and does not change sign in}\ (a,b)^2\}. </script>
  For integrands from <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-52-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-405" style="width: 4.576em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.729em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.471em, 1003.616em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-406"><span class="msubsup" id="MathJax-Span-407"><span style="display: inline-block; position: relative; width: 1.584em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-408"><span class="mrow" id="MathJax-Span-409"><span class="mi" id="MathJax-Span-410" style="font-family: STIXNonUnicode-Italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.624em;"><span class="texatom" id="MathJax-Span-411"><span class="mrow" id="MathJax-Span-412"><span class="mn" id="MathJax-Span-413" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-414" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-415" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-416" style="font-family: STIXGeneral-Regular;">[</span><span class="mi" id="MathJax-Span-417" style="font-family: STIXGeneral-Italic;">a</span><span class="mo" id="MathJax-Span-418" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-419" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">b</span><span class="mo" id="MathJax-Span-420" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-52">\mathcal{C}^{2,2}[a,b]</script> we prove monotonicity of the
  remainders and derive a-posteriori error estimates.
  </p>
  </div>
  </dd>
  <dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17799" title="Abstract">arXiv:2404.17799</a> [<a href="/pdf/2404.17799" title="Download PDF">pdf</a>, <a href="/format/2404.17799" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Personalized Federated Learning via Sequential Layer Expansion in  Representation Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jang%2C+J">Jaewon Jang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Choi%2C+B">Bonjun Choi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages, 7 figure
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Federated learning ensures the privacy of clients by conducting distributed
  training on individual client devices and sharing only the model weights with a
  central server. However, in real-world scenarios, the heterogeneity of data
  among clients necessitates appropriate personalization methods. In this paper,
  we aim to address this heterogeneity using a form of parameter decoupling known
  as representation learning. Representation learning divides deep learning
  models into 'base' and 'head' components. The base component, capturing common
  features across all clients, is shared with the server, while the head
  component, capturing unique features specific to individual clients, remains
  local. We propose a new representation learning-based approach that suggests
  decoupling the entire deep learning model into more densely divided parts with
  the application of suitable scheduling methods, which can benefit not only data
  heterogeneity but also class heterogeneity. In this paper, we compare and
  analyze two layer scheduling approaches, namely forward (\textit{Vanilla}) and
  backward (\textit{Anti}), in the context of data and class heterogeneity among
  clients. Our experimental results show that the proposed algorithm, when
  compared to existing personalized federated learning algorithms, achieves
  increased accuracy, especially under challenging conditions, while reducing
  computation costs.
  </p>
  </div>
  </dd>
  <dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17801" title="Abstract">arXiv:2404.17801</a> [<a href="/pdf/2404.17801" title="Download PDF">pdf</a>, <a href="/ps/2404.17801" title="Download PostScript">ps</a>, <a href="/format/2404.17801" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Dynamical Mode Recognition of Coupled Flame Oscillators by Supervised  and Unsupervised Learning Approaches
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Weiming Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+T">Tao Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+P">Peng Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> research paper (21 pages, 15 figures)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Combustion instability in gas turbines and rocket engines, as one of the most
  challenging problems in combustion research, arises from the complex
  interactions among flames, which are also influenced by chemical reactions,
  heat and mass transfer, and acoustics. Identifying and understanding combustion
  instability is essential to ensure the safe and reliable operation of many
  combustion systems, where exploring and classifying the dynamical behaviors of
  complex flame systems is a core take. To facilitate fundamental studies, the
  present work concerns dynamical mode recognition of coupled flame oscillators
  made of flickering buoyant diffusion flames, which have gained increasing
  attention in recent years but are not sufficiently understood. The time series
  data of flame oscillators are generated by fully validated reacting flow
  simulations. Due to limitations of expertise-based models, a data-driven
  approach is adopted. In this study, a nonlinear dimensional reduction model of
  variational autoencoder (VAE) is used to project the simulation data onto a
  2-dimensional latent space. Based on the phase trajectories in latent space,
  both supervised and unsupervised classifiers are proposed for datasets with
  well known labeling and without, respectively. For labeled datasets, we
  establish the Wasserstein-distance-based classifier (WDC) for mode recognition;
  for unlabeled datasets, we develop a novel unsupervised classifier (GMM-DTWC)
  combining dynamic time warping (DTW) and Gaussian mixture model (GMM). Through
  comparing with conventional approaches for dimensionality reduction and
  classification, the proposed supervised and unsupervised VAE-based approaches
  exhibit a prominent performance for distinguishing dynamical modes, implying
  their potential extension to dynamical mode recognition of complex combustion
  problems.
  </p>
  </div>
  </dd>
  <dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17802" title="Abstract">arXiv:2404.17802</a> [<a href="/pdf/2404.17802" title="Download PDF">pdf</a>, <a href="/format/2404.17802" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Empirical Analysis of Dialogue Relation Extraction with Large Language  Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Guozheng Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zijie Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shang%2C+Z">Ziyu Shang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiajun Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ji%2C+K">Ke Ji</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yikai Guo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> IJCAI 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Dialogue relation extraction (DRE) aims to extract relations between two
  arguments within a dialogue, which is more challenging than standard RE due to
  the higher person pronoun frequency and lower information density in dialogues.
  However, existing DRE methods still suffer from two serious issues: (1) hard to
  capture long and sparse multi-turn information, and (2) struggle to extract
  golden relations based on partial dialogues, which motivates us to discover
  more effective methods that can alleviate the above issues. We notice that the
  rise of large language models (LLMs) has sparked considerable interest in
  evaluating their performance across diverse tasks. To this end, we initially
  investigate the capabilities of different LLMs in DRE, considering both
  proprietary models and open-source models. Interestingly, we discover that LLMs
  significantly alleviate two issues in existing DRE methods. Generally, we have
  following findings: (1) scaling up model size substantially boosts the overall
  DRE performance and achieves exceptional results, tackling the difficulty of
  capturing long and sparse multi-turn information; (2) LLMs encounter with much
  smaller performance drop from entire dialogue setting to partial dialogue
  setting compared to existing methods; (3) LLMs deliver competitive or superior
  performances under both full-shot and few-shot settings compared to current
  state-of-the-art; (4) LLMs show modest performances on inverse relations but
  much stronger improvements on general relations, and they can handle dialogues
  of various lengths especially for longer sequences.
  </p>
  </div>
  </dd>
  <dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17805" title="Abstract">arXiv:2404.17805</a> [<a href="/pdf/2404.17805" title="Download PDF">pdf</a>, <a href="/format/2404.17805" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> From Optimization to Generalization: Fair Federated Learning against  Quality Shift via Inter-Client Sharpness Matching
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+N">Nannan Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kuang%2C+Z">Zhuo Kuang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Z">Zengqiang Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+L">Li Yu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This paper is accepted at IJCAI'24 (Main Track)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Due to escalating privacy concerns, federated learning has been recognized as
  a vital approach for training deep neural networks with decentralized medical
  data. In practice, it is challenging to ensure consistent imaging quality
  across various institutions, often attributed to equipment malfunctions
  affecting a minority of clients. This imbalance in image quality can cause the
  federated model to develop an inherent bias towards higher-quality images, thus
  posing a severe fairness issue. In this study, we pioneer the identification
  and formulation of this new fairness challenge within the context of the
  imaging quality shift. Traditional methods for promoting fairness in federated
  learning predominantly focus on balancing empirical risks across diverse client
  distributions. This strategy primarily facilitates fair optimization across
  different training data distributions, yet neglects the crucial aspect of
  generalization. To address this, we introduce a solution termed Federated
  learning with Inter-client Sharpness Matching (FedISM). FedISM enhances both
  local training and global aggregation by incorporating sharpness-awareness,
  aiming to harmonize the sharpness levels across clients for fair
  generalization. Our empirical evaluations, conducted using the widely-used ICH
  and ISIC 2019 datasets, establish FedISM's superiority over current
  state-of-the-art federated learning methods in promoting fairness. Code is
  available at https://github.com/wnn2000/FFL4MIA.
  </p>
  </div>
  </dd>
  <dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17806" title="Abstract">arXiv:2404.17806</a> [<a href="/pdf/2404.17806" title="Download PDF">pdf</a>, <a href="/format/2404.17806" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> T-CLAP: Temporal-Enhanced Contrastive Language-Audio Pretraining
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yi Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhuo Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xubo Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Haohe Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+X">Xuenan Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jia%2C+D">Dongya Jia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuanzhe Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Plumbley%2C+M+D">Mark D. Plumbley</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenwu Wang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Preprint submitted to IEEE MLSP 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">Contrastive language-audio pretraining~(CLAP) has been developed to align the
  representations of audio and language, achieving remarkable performance in
  retrieval and classification tasks. However, current CLAP struggles to capture
  temporal information within audio and text features, presenting substantial
  limitations for tasks such as audio retrieval and generation. To address this
  gap, we introduce T-CLAP, a temporal-enhanced CLAP model. We use Large Language
  Models~(LLMs) and mixed-up strategies to generate temporal-contrastive captions
  for audio clips from extensive audio-text datasets. Subsequently, a new
  temporal-focused contrastive loss is designed to fine-tune the CLAP model by
  incorporating these synthetic data. We conduct comprehensive experiments and
  analysis in multiple downstream tasks. T-CLAP shows improved capability in
  capturing the temporal relationship of sound events and outperforms
  state-of-the-art models by a significant margin.
  </p>
  </div>
  </dd>
  <dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17807" title="Abstract">arXiv:2404.17807</a> [<a href="/pdf/2404.17807" title="Download PDF">pdf</a>, <a href="/format/2404.17807" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Meta In-Context Learning Makes Large Language Models Better Zero and  Few-Shot Relation Extractors
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Guozheng Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+P">Peng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiajun Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yikai Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ji%2C+K">Ke Ji</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shang%2C+Z">Ziyu Shang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zijie Xu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> IJCAI 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Relation extraction (RE) is an important task that aims to identify the
  relationships between entities in texts. While large language models (LLMs)
  have revealed remarkable in-context learning (ICL) capability for general zero
  and few-shot learning, recent studies indicate that current LLMs still struggle
  with zero and few-shot RE. Previous studies are mainly dedicated to design
  prompt formats and select good examples for improving ICL-based RE. Although
  both factors are vital for ICL, if one can fundamentally boost the ICL
  capability of LLMs in RE, the zero and few-shot RE performance via ICL would be
  significantly improved. To this end, we introduce \textsc{Micre} (\textbf{M}eta
  \textbf{I}n-\textbf{C}ontext learning of LLMs for \textbf{R}elation
  \textbf{E}xtraction), a new meta-training framework for zero and few-shot RE
  where an LLM is tuned to do ICL on a diverse collection of RE datasets (i.e.,
  learning to learn in context for RE). Through meta-training, the model becomes
  more effectively to learn a new RE task in context by conditioning on a few
  training examples with no parameter updates or task-specific templates at
  inference time, enabling better zero and few-shot task generalization. We
  experiment \textsc{Micre} on various LLMs with different model scales and 12
  public RE datasets, and then evaluate it on unseen RE benchmarks under zero and
  few-shot settings. \textsc{Micre} delivers comparable or superior performance
  compared to a range of baselines including supervised fine-tuning and typical
  in-context learning methods. We find that the gains are particular significant
  for larger model scales, and using a diverse set of the meta-training RE
  datasets is key to improvements. Empirically, we show that \textsc{Micre} can
  transfer the relation semantic knowledge via relation label name during
  inference on target RE datasets.
  </p>
  </div>
  </dd>
  <dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17808" title="Abstract">arXiv:2404.17808</a> [<a href="/pdf/2404.17808" title="Download PDF">pdf</a>, <a href="/format/2404.17808" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Scaffold-BPE: Enhancing Byte Pair Encoding with Simple and Effective  Scaffold Token Removal
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lian%2C+H">Haoran Lian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+Y">Yizhe Xiong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Niu%2C+J">Jianwei Niu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mo%2C+S">Shasha Mo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Su%2C+Z">Zhenpeng Su</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zijia Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+P">Peng Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hui Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+G">Guiguang Ding</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Byte Pair Encoding (BPE) serves as a foundation method for text tokenization
  in the Natural Language Processing (NLP) field. Despite its wide adoption, the
  original BPE algorithm harbors an inherent flaw: it inadvertently introduces a
  frequency imbalance for tokens in the text corpus. Since BPE iteratively merges
  the most frequent token pair in the text corpus while keeping all tokens that
  have been merged in the vocabulary, it unavoidably holds tokens that primarily
  represent subwords of complete words and appear infrequently on their own in
  the text corpus. We term such tokens as Scaffold Tokens. Due to their
  infrequent appearance in the text corpus, Scaffold Tokens pose a learning
  imbalance issue for language models. To address that issue, we propose
  Scaffold-BPE, which incorporates a dynamic scaffold token removal mechanism by
  parameter-free, computation-light, and easy-to-implement modifications to the
  original BPE. This novel approach ensures the exclusion of low-frequency
  Scaffold Tokens from the token representations for the given texts, thereby
  mitigating the issue of frequency imbalance and facilitating model training. On
  extensive experiments across language modeling tasks and machine translation
  tasks, Scaffold-BPE consistently outperforms the original BPE, well
  demonstrating its effectiveness and superiority.
  </p>
  </div>
  </dd>
  <dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17809" title="Abstract">arXiv:2404.17809</a> [<a href="/pdf/2404.17809" title="Download PDF">pdf</a>, <a href="/format/2404.17809" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Recall, Retrieve and Reason: Towards Better In-Context Relation  Extraction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Guozheng Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+P">Peng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ke%2C+W">Wenjun Ke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yikai Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ji%2C+K">Ke Ji</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shang%2C+Z">Ziyu Shang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiajun Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zijie Xu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> IJCAI 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Relation extraction (RE) aims to identify relations between entities
  mentioned in texts. Although large language models (LLMs) have demonstrated
  impressive in-context learning (ICL) abilities in various tasks, they still
  suffer from poor performances compared to most supervised fine-tuned RE
  methods. Utilizing ICL for RE with LLMs encounters two challenges: (1)
  retrieving good demonstrations from training examples, and (2) enabling LLMs
  exhibit strong ICL abilities in RE. On the one hand, retrieving good
  demonstrations is a non-trivial process in RE, which easily results in low
  relevance regarding entities and relations. On the other hand, ICL with an LLM
  achieves poor performance in RE while RE is different from language modeling in
  nature or the LLM is not large enough. In this work, we propose a novel
  recall-retrieve-reason RE framework that synergizes LLMs with retrieval corpora
  (training examples) to enable relevant retrieving and reliable in-context
  reasoning. Specifically, we distill the consistently ontological knowledge from
  training datasets to let LLMs generate relevant entity pairs grounded by
  retrieval corpora as valid queries. These entity pairs are then used to
  retrieve relevant training examples from the retrieval corpora as
  demonstrations for LLMs to conduct better ICL via instruction tuning. Extensive
  experiments on different LLMs and RE datasets demonstrate that our method
  generates relevant and valid entity pairs and boosts ICL abilities of LLMs,
  achieving competitive or new state-of-the-art performance on sentence-level RE
  compared to previous supervised fine-tuning methods and ICL-based methods.
  </p>
  </div>
  </dd>
  <dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17811" title="Abstract">arXiv:2404.17811</a> [<a href="/pdf/2404.17811" title="Download PDF">pdf</a>, <a href="/ps/2404.17811" title="Download PostScript">ps</a>, <a href="/format/2404.17811" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Efficient Bi-manipulation using RGBD Multi-model Fusion based on  Attention Mechanism
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shen%2C+J">Jian Shen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jiaxin Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+Z">Zhigong Song</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages,5 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Dual-arm robots have great application prospects in intelligent manufacturing
  due to their human-like structure when deployed with advanced intelligence
  algorithm. However, the previous visuomotor policy suffers from perception
  deficiencies in environments where features of images are impaired by the
  various conditions, such as abnormal lighting, occlusion and shadow etc. The
  Focal CVAE framework is proposed for RGB-D multi-modal data fusion to address
  this challenge. In this study, a mixed focal attention module is designed for
  the fusion of RGB images containing color features and depth images containing
  3D shape and structure information. This module highlights the prominent local
  features and focuses on the relevance of RGB and depth via cross-attention. A
  saliency attention module is proposed to improve its computational efficiency,
  which is applied in the encoder and the decoder of the framework. We illustrate
  the effectiveness of the proposed method via extensive simulation and
  experiments. It's shown that the performances of bi-manipulation are all
  significantly improved in the four real-world tasks with lower computational
  cost. Besides, the robustness is validated through experiments under different
  scenarios where there is a perception deficiency problem, demonstrating the
  feasibility of the method.
  </p>
  </div>
  </dd>
  <dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17815" title="Abstract">arXiv:2404.17815</a> [<a href="/pdf/2404.17815" title="Download PDF">pdf</a>, <a href="/format/2404.17815" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning-based Hierarchical Control: Emulating the Central Nervous  System for Bio-Inspired Legged Robot Locomotion
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+G">Ge Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shafiee%2C+M">Milad Shafiee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+P">Peizhuo Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bellegarda%2C+G">Guillaume Bellegarda</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ijspeert%2C+A">Auke Ijspeert</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sartoretti%2C+G">Guillaume Sartoretti</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Animals possess a remarkable ability to navigate challenging terrains,
  achieved through the interplay of various pathways between the brain, central
  pattern generators (CPGs) in the spinal cord, and musculoskeletal system.
  Traditional bioinspired control frameworks often rely on a singular control
  policy that models both higher (supraspinal) and spinal cord functions. In this
  work, we build upon our previous research by introducing two distinct neural
  networks: one tasked with modulating the frequency and amplitude of CPGs to
  generate the basic locomotor rhythm (referred to as the spinal policy, SCP),
  and the other responsible for receiving environmental perception data and
  directly modulating the rhythmic output from the SCP to execute precise
  movements on challenging terrains (referred to as the descending modulation
  policy). This division of labor more closely mimics the hierarchical locomotor
  control systems observed in legged animals, thereby enhancing the robot's
  ability to navigate various uneven surfaces, including steps, high obstacles,
  and terrains with gaps. Additionally, we investigate the impact of sensorimotor
  delays within our framework, validating several biological assumptions about
  animal locomotion systems. Specifically, we demonstrate that spinal circuits
  play a crucial role in generating the basic locomotor rhythm, while descending
  pathways are essential for enabling appropriate gait modifications to
  accommodate uneven terrain. Notably, our findings also reveal that the
  multi-layered control inherent in animals exhibits remarkable robustness
  against time delays. Through these investigations, this paper contributes to a
  deeper understanding of the fundamental principles of interplay between spinal
  and supraspinal mechanisms in biological locomotion. It also supports the
  development of locomotion controllers in parallel to biological structures
  which are ...
  </p>
  </div>
  </dd>
  <dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17818" title="Abstract">arXiv:2404.17818</a> [<a href="/pdf/2404.17818" title="Download PDF">pdf</a>, <a href="/ps/2404.17818" title="Download PostScript">ps</a>, <a href="/format/2404.17818" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Automatic Build Repair for Test Cases using Incompatible Java Versions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mak%2C+C+H">Ching Hang Mak</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheung%2C+S">Shing-Chi Cheung</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 44 pages, 22 figures (incl. tables and listings); To be published in Information and Software Technology. Link to artifact is available within the paper
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Context: Bug bisection is a common technique used to identify a revision that
  introduces a bug or indirectly fixes a bug, and often involves executing
  multiple revisions of a project to determine whether the bug is present within
  the revision. However, many legacy revisions often cannot be successfully
  compiled due to changes in the programming language or tools used in the
  compilation process, adding complexity and preventing automation in the
  bisection process.
  <br>Objective: In this paper, we introduce an approach to repair test cases of
  Java projects by performing dependency minimization. Our approach aims to
  remove classes and methods that are not required for the execution of one or
  more test cases. Unlike existing state-of-the-art techniques, our approach
  performs minimization at source-level, which allows compile-time errors to be
  fixed.
  <br>Method: A standalone Java tool implementing our technique was developed, and
  we evaluated our technique using subjects from Defects4J retargeted against
  Java 8 and 17.
  <br>Results: Our evaluation showed that a majority of subjects can be repaired
  solely by performing minimization, including replicating the test results of
  the original version. Furthermore, our technique is also shown to achieve
  accurate minimized results, while only adding a small overhead to the bisection
  process.
  <br>Conclusion: Our proposed technique is shown to be effective for repairing
  build failures with minimal overhead, making it suitable for use in automated
  bug bisection. Our tool can also be adapted for use cases such as bug corpus
  creation and refactoring.
  </p>
  </div>
  </dd>
  <dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17820" title="Abstract">arXiv:2404.17820</a> [<a href="/pdf/2404.17820" title="Download PDF">pdf</a>, <a href="/format/2404.17820" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Motion planning for off-road autonomous driving based on human-like  cognition and weight adaptation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuchun Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gong%2C+C">Cheng Gong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gong%2C+J">Jianwei Gong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jia%2C+P">Peng Jia</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Journal of Field Robotics,2024,1-22
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Driving in an off-road environment is challenging for autonomous vehicles due
  to the complex and varied terrain. To ensure stable and efficient travel, the
  vehicle requires consideration and balancing of environmental factors, such as
  undulations, roughness, and obstacles, to generate optimal trajectories that
  can adapt to changing scenarios. However, traditional motion planners often
  utilize a fixed cost function for trajectory optimization, making it difficult
  to adapt to different driving strategies in challenging irregular terrains and
  uncommon scenarios. To address these issues, we propose an adaptive motion
  planner based on human-like cognition and cost evaluation for off-road driving.
  First, we construct a multi-layer map describing different features of off-road
  terrains, including terrain elevation, roughness, obstacle, and artificial
  potential field map. Subsequently, we employ a CNN-LSTM network to learn the
  trajectories planned by human drivers in various off-road scenarios. Then,
  based on human-like generated trajectories in different environments, we design
  a primitive-based trajectory planner that aims to mimic human trajectories and
  cost weight selection, generating trajectories that are consistent with the
  dynamics of off-road vehicles. Finally, we compute optimal cost weights and
  select and extend behavioral primitives to generate highly adaptive, stable,
  and efficient trajectories.
  <br>We validate the effectiveness of the proposed method through experiments in a
  desert off-road environment with complex terrain and varying road conditions.
  The experimental results show that the proposed human-like motion planner has
  excellent adaptability to different off-road conditions. It shows real-time
  operation, greater stability, and more human-like planning ability in diverse
  and challenging scenarios.
  </p>
  </div>
  </dd>
  <dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17821" title="Abstract">arXiv:2404.17821</a> [<a href="/pdf/2404.17821" title="Download PDF">pdf</a>, <a href="/ps/2404.17821" title="Download PostScript">ps</a>, <a href="/format/2404.17821" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An automatic mixing speech enhancement system for multi-track audio
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaojing Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mourgela%2C+A">Angeliki Mourgela</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ai%2C+H">Hongwei Ai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Reiss%2C+J+D">Joshua D. Reiss</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 5 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">We propose a speech enhancement system for multitrack audio. The system will
  minimize auditory masking while allowing one to hear multiple simultaneous
  speakers. The system can be used in multiple communication scenarios e.g.,
  teleconferencing, invoice gaming, and live streaming. The ITU-R BS.1387
  Perceptual Evaluation of Audio Quality (PEAQ) model is used to evaluate the
  amount of masking in the audio signals. Different audio effects e.g., level
  balance, equalization, dynamic range compression, and spatialization are
  applied via an iterative Harmony searching algorithm that aims to minimize the
  masking. In the subjective listening test, the designed system can compete with
  mixes by professional sound engineers and outperforms mixes by existing
  auto-mixing systems.
  </p>
  </div>
  </dd>
  <dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17822" title="Abstract">arXiv:2404.17822</a> [<a href="/pdf/2404.17822" title="Download PDF">pdf</a>, <a href="/ps/2404.17822" title="Download PostScript">ps</a>, <a href="/format/2404.17822" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> GenAI Distortion: The Effect of GenAI Fluency and Positive Affect
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiantong Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Mengmeng Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">The introduction of generative artificial intelligence (GenAI) into
  educational practices has been transformative, yet it brings a crucial concern
  about the potential distortion of users' beliefs. Given the prevalence of GenAI
  among college students, examining the psychological mechanisms that lead to
  GenAI distortion from both technological factors and the individual's
  psychological processes is a critical priority. A mixed-methods approach is
  employed to test the proposed hypotheses. Study 1 (N = 10) revealed through
  qualitative analysis that GenAI's fluent outputs significantly engaged college
  students, eliciting positive emotional responses during an interaction. GenAI's
  tendency to conflate fact with fiction often led to presentations of
  unrealistic and exaggerated information, potentially distorting users'
  perceptions of reality-a phenomenon termed GenAI distortion. Following these
  insights, Study 2 (cross-sectional survey, N = 999) and Study 3 (experimental
  manipulation, N = 175) explored how GenAI fluency affects college students'
  GenAI distortion and examined the mediating effect of positive affect. The
  results indicated that GenAI fluency predicts GenAI distortion via the
  mediating role of positive affect. Our findings provide theoretical foundations
  and practical implications for understanding GenAI distortion among college
  students.
  </p>
  </div>
  </dd>
  <dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17825" title="Abstract">arXiv:2404.17825</a> [<a href="/pdf/2404.17825" title="Download PDF">pdf</a>, <a href="/format/2404.17825" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ODCR: Orthogonal Decoupling Contrastive Regularization for Unpaired  Image Dehazing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhongze Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Haitao Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+J">Jingchao Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yao%2C+L">Lujian Yao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+K">Kaijie Zhao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by CVPR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Unpaired image dehazing (UID) holds significant research importance due to
  the challenges in acquiring haze/clear image pairs with identical backgrounds.
  This paper proposes a novel method for UID named Orthogonal Decoupling
  Contrastive Regularization (ODCR). Our method is grounded in the assumption
  that an image consists of both haze-related features, which influence the
  degree of haze, and haze-unrelated features, such as texture and semantic
  information. ODCR aims to ensure that the haze-related features of the dehazing
  result closely resemble those of the clear image, while the haze-unrelated
  features align with the input hazy image. To accomplish the motivation,
  Orthogonal MLPs optimized geometrically on the Stiefel manifold are proposed,
  which can project image features into an orthogonal space, thereby reducing the
  relevance between different features. Furthermore, a task-driven Depth-wise
  Feature Classifier (DWFC) is proposed, which assigns weights to the orthogonal
  features based on the contribution of each channel's feature in predicting
  whether the feature source is hazy or clear in a self-supervised fashion.
  Finally, a Weighted PatchNCE (WPNCE) loss is introduced to achieve the pulling
  of haze-related features in the output image toward those of clear images,
  while bringing haze-unrelated features close to those of the hazy input.
  Extensive experiments demonstrate the superior performance of our ODCR method
  on UID.
  </p>
  </div>
  </dd>
  <dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17826" title="Abstract">arXiv:2404.17826</a> [<a href="/pdf/2404.17826" title="Download PDF">pdf</a>, <a href="/format/2404.17826" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Taxation Perspective for Fair Re-ranking
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+C">Chen Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+X">Xiaopeng Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenjie Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pang%2C+L">Liang Pang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Jun Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chua%2C+T">Tat-Seng Chua</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted in SIGIR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">Fair re-ranking aims to redistribute ranking slots among items more equitably
  to ensure responsibility and ethics. The exploration of redistribution problems
  has a long history in economics, offering valuable insights for conceptualizing
  fair re-ranking as a taxation process. Such a formulation provides us with a
  fresh perspective to re-examine fair re-ranking and inspire the development of
  new methods. From a taxation perspective, we theoretically demonstrate that
  most previous fair re-ranking methods can be reformulated as an item-level tax
  policy. Ideally, a good tax policy should be effective and conveniently
  controllable to adjust ranking resources. However, both empirical and
  theoretical analyses indicate that the previous item-level tax policy cannot
  meet two ideal controllable requirements: (1) continuity, ensuring minor
  changes in tax rates result in small accuracy and fairness shifts; (2)
  controllability over accuracy loss, ensuring precise estimation of the accuracy
  loss under a specific tax rate. To overcome these challenges, we introduce a
  new fair re-ranking method named Tax-rank, which levies taxes based on the
  difference in utility between two items. Then, we efficiently optimize such an
  objective by utilizing the Sinkhorn algorithm in optimal transport. Upon a
  comprehensive analysis, Our model Tax-rank offers a superior tax policy for
  fair re-ranking, theoretically demonstrating both continuity and
  controllability over accuracy loss. Experimental results show that Tax-rank
  outperforms all state-of-the-art baselines in terms of effectiveness and
  efficiency on recommendation and advertising tasks.
  </p>
  </div>
  </dd>
  <dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17830" title="Abstract">arXiv:2404.17830</a> [<a href="/pdf/2404.17830" title="Download PDF">pdf</a>, <a href="/format/2404.17830" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Dynamic Against Dynamic: An Open-set Self-learning Framework
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+H">Haifeng Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Geng%2C+C">Chuanxing Geng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuen%2C+P">PongChi Yuen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Songcan Chen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The first two authors contributed equally to this work. Accepted at IJCAI2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">In open-set recognition, existing methods generally learn statically fixed
  decision boundaries using known classes to reject unknown classes. Though they
  have achieved promising results, such decision boundaries are evidently
  insufficient for universal unknown classes in dynamic and open scenarios as
  they can potentially appear at any position in the feature space. Moreover,
  these methods just simply reject unknown class samples during testing without
  any effective utilization for them. In fact, such samples completely can
  constitute the true instantiated representation of the unknown classes to
  further enhance the model's performance. To address these issues, this paper
  proposes a novel dynamic against dynamic idea, i.e., dynamic method against
  dynamic changing open-set world, where an open-set self-learning (OSSL)
  framework is correspondingly developed. OSSL starts with a good closed-set
  classifier trained by known classes and utilizes available test samples for
  model adaptation during testing, thus gaining the adaptability to changing data
  distributions. In particular, a novel self-matching module is designed for
  OSSL, which can achieve the adaptation in automatically identifying known class
  samples while rejecting unknown class samples which are further utilized to
  enhance the discriminability of the model as the instantiated representation of
  unknown classes. Our method establishes new performance milestones respectively
  in almost all standard and cross-data benchmarks.
  </p>
  </div>
  </dd>
  <dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17832" title="Abstract">arXiv:2404.17832</a> [<a href="/pdf/2404.17832" title="Download PDF">pdf</a>, <a href="/format/2404.17832" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Evaluation of Few-Shot Learning for Classification Tasks in the Polish  Language
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hadeliya%2C+T">Tsimur Hadeliya</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kajtoch%2C+D">Dariusz Kajtoch</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 34 pages, 3 figures, 10 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">We introduce a few-shot benchmark consisting of 7 different classification
  tasks native to the Polish language. We conducted an empirical comparison with
  0 and 16 shots between fine-tuning, linear probing, SetFit, and in-context
  learning (ICL) using various pre-trained commercial and open-source models. Our
  findings reveal that ICL achieves the best performance, with commercial models
  like GPT-3.5 and GPT-4 attaining the best performance. However, there remains a
  significant 14 percentage points gap between our best few-shot learning score
  and the performance of HerBERT-large fine-tuned on the entire training dataset.
  Among the techniques, SetFit emerges as the second-best approach, closely
  followed by linear probing. We observed the worst and most unstable performance
  with non-linear head fine-tuning. Results for ICL indicate that continual
  pre-training of models like Mistral-7b or Llama-2-13b on Polish corpora is
  beneficial. This is confirmed by the improved performances of Bielik-7b and
  Trurl-13b, respectively. To further support experiments in few-shot learning
  for Polish, we are releasing handcrafted templates for the ICL.
  </p>
  </div>
  </dd>
  <dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17833" title="Abstract">arXiv:2404.17833</a> [<a href="/pdf/2404.17833" title="Download PDF">pdf</a>, <a href="/format/2404.17833" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Testing and Understanding Erroneous Planning in LLM Agents through  Synthesized User Inputs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ji%2C+Z">Zhenlan Ji</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+D">Daoyuan Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+P">Pingchuan Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zongjie Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuai Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Programming Languages (cs.PL)
  
  </div>
  <p class="mathjax">Agents based on large language models (LLMs) have demonstrated effectiveness
  in solving a wide range of tasks by integrating LLMs with key modules such as
  planning, memory, and tool usage. Increasingly, customers are adopting LLM
  agents across a variety of commercial applications critical to reliability,
  including support for mental well-being, chemical synthesis, and software
  development. Nevertheless, our observations and daily use of LLM agents
  indicate that they are prone to making erroneous plans, especially when the
  tasks are complex and require long-term planning.
  <br>In this paper, we propose PDoctor, a novel and automated approach to testing
  LLM agents and understanding their erroneous planning. As the first work in
  this direction, we formulate the detection of erroneous planning as a
  constraint satisfiability problem: an LLM agent's plan is considered erroneous
  if its execution violates the constraints derived from the user inputs. To this
  end, PDoctor first defines a domain-specific language (DSL) for user queries
  and synthesizes varying inputs with the assistance of the Z3 constraint solver.
  These synthesized inputs are natural language paragraphs that specify the
  requirements for completing a series of tasks. Then, PDoctor derives
  constraints from these requirements to form a testing oracle. We evaluate
  PDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5
  and GPT-4). The results show that PDoctor can effectively detect diverse errors
  in agent planning and provide insights and error characteristics that are
  valuable to both agent developers and users. We conclude by discussing
  potential alternative designs and directions to extend PDoctor.
  </p>
  </div>
  </dd>
  <dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17834" title="Abstract">arXiv:2404.17834</a> [<a href="/pdf/2404.17834" title="Download PDF">pdf</a>, <a href="/format/2404.17834" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Efficient Reactive Synthesis
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+X">Xin Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ruess%2C+H">Harald Ruess</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  <p class="mathjax">Our main result is a polynomial time algorithm for deciding realizability for
  the GXU sublogic of linear temporal logic. This logic is particularly suitable
  for the specification of embedded control systems, and it is more expressive
  than GR(1). Reactive control programs for GXU specifications are represented as
  Mealy machines, which are extended by the monitoring of input events. Now,
  realizability for GXU specifications is shown to be equivalent to solving a
  certain subclass of 2QBF satisfiability problems. These logical problems can be
  solved in cubic time in the size of GXU specifications. For unrealizable GXU
  specifications, stronger environment assumptions are mined from failed
  consistency checks based on Padoa's characterization of definability and Craig
  interpolation.
  </p>
  </div>
  </dd>
  <dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17835" title="Abstract">arXiv:2404.17835</a> [<a href="/pdf/2404.17835" title="Download PDF">pdf</a>, <a href="/format/2404.17835" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> VANER: Leveraging Large Language Model for Versatile and Adaptive  Biomedical Named Entity Recognition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Biana%2C+J">Junyi Biana</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+W">Weiqi Zhai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+X">Xiaodi Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+J">Jiaxuan Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+S">Shanfeng Zhu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Prevalent solution for BioNER involves using representation learning
  techniques coupled with sequence labeling. However, such methods are inherently
  task-specific, demonstrate poor generalizability, and often require dedicated
  model for each dataset. To leverage the versatile capabilities of recently
  remarkable large language models (LLMs), several endeavors have explored
  generative approaches to entity extraction. Yet, these approaches often fall
  short of the effectiveness of previouly sequence labeling approaches. In this
  paper, we utilize the open-sourced LLM LLaMA2 as the backbone model, and design
  specific instructions to distinguish between different types of entities and
  datasets. By combining the LLM's understanding of instructions with sequence
  labeling techniques, we use mix of datasets to train a model capable of
  extracting various types of entities. Given that the backbone LLMs lacks
  specialized medical knowledge, we also integrate external entity knowledge
  bases and employ instruction tuning to compel the model to densely recognize
  carefully curated entities. Our model VANER, trained with a small partition of
  parameters, significantly outperforms previous LLMs-based models and, for the
  first time, as a model based on LLM, surpasses the majority of conventional
  state-of-the-art BioNER systems, achieving the highest F1 scores across three
  datasets.
  </p>
  </div>
  </dd>
  <dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17837" title="Abstract">arXiv:2404.17837</a> [<a href="/pdf/2404.17837" title="Download PDF">pdf</a>, <a href="/format/2404.17837" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Hybrid 3D Human Pose Estimation with Monocular Video and Sparse IMUs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bao%2C+Y">Yiming Bao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xu Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qian%2C+D">Dahong Qian</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 5 figures, Under Review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)
  
  </div>
  <p class="mathjax">Temporal 3D human pose estimation from monocular videos is a challenging task
  in human-centered computer vision due to the depth ambiguity of 2D-to-3D
  lifting. To improve accuracy and address occlusion issues, inertial sensor has
  been introduced to provide complementary source of information. However, it
  remains challenging to integrate heterogeneous sensor data for producing
  physically rational 3D human poses. In this paper, we propose a novel
  framework, Real-time Optimization and Fusion (RTOF), to address this issue. We
  first incorporate sparse inertial orientations into a parametric human skeleton
  to refine 3D poses in kinematics. The poses are then optimized by energy
  functions built on both visual and inertial observations to reduce the temporal
  jitters. Our framework outputs smooth and biomechanically plausible human
  motion. Comprehensive experiments with ablation studies demonstrate its
  rationality and efficiency. On Total Capture dataset, the pose estimation error
  is significantly decreased compared to the baseline method.
  </p>
  </div>
  </dd>
  <dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17839" title="Abstract">arXiv:2404.17839</a> [<a href="/pdf/2404.17839" title="Download PDF">pdf</a>, <a href="/format/2404.17839" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Improving Smart Contract Security with Contrastive Learning-based  Vulnerability Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yizhou Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zeyu Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gong%2C+Z">Zhihao Gong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hao%2C+D">Dan Hao</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> 2024 IEEE/ACM 46th International Conference on Software
    Engineering (ICSE '24)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">Currently, smart contract vulnerabilities (SCVs) have emerged as a major
  factor threatening the transaction security of blockchain. Existing
  state-of-the-art methods rely on deep learning to mitigate this threat. They
  treat each input contract as an independent entity and feed it into a deep
  learning model to learn vulnerability patterns by fitting vulnerability labels.
  It is a pity that they disregard the correlation between contracts, failing to
  consider the commonalities between contracts of the same type and the
  differences among contracts of different types. As a result, the performance of
  these methods falls short of the desired level.
  <br>To tackle this problem, we propose a novel Contrastive Learning Enhanced
  Automated Recognition Approach for Smart Contract Vulnerabilities, named Clear.
  In particular, Clear employs a contrastive learning (CL) model to capture the
  fine-grained correlation information among contracts and generates correlation
  labels based on the relationships between contracts to guide the training
  process of the CL model. Finally, it combines the correlation and the semantic
  information of the contract to detect SCVs. Through an empirical evaluation of
  a large-scale real-world dataset of over 40K smart contracts and compare 13
  state-of-the-art baseline methods. We show that Clear achieves (1) optimal
  performance over all baseline methods; (2) 9.73%-39.99% higher F1-score than
  existing deep learning methods.
  </p>
  </div>
  </dd>
  <dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17841" title="Abstract">arXiv:2404.17841</a> [<a href="/pdf/2404.17841" title="Download PDF">pdf</a>, <a href="/format/2404.17841" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Toxicity Classification in Ukrainian
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dementieva%2C+D">Daryna Dementieva</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khylenko%2C+V">Valeriia Khylenko</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Babakov%2C+N">Nikolay Babakov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Groh%2C+G">Georg Groh</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to WOAH, NAACL, 2024. arXiv admin note: text overlap with <a href="/abs/2404.02043">arXiv:2404.02043</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">The task of toxicity detection is still a relevant task, especially in the
  context of safe and fair LMs development. Nevertheless, labeled binary toxicity
  classification corpora are not available for all languages, which is
  understandable given the resource-intensive nature of the annotation process.
  Ukrainian, in particular, is among the languages lacking such resources. To our
  knowledge, there has been no existing toxicity classification corpus in
  Ukrainian. In this study, we aim to fill this gap by investigating
  cross-lingual knowledge transfer techniques and creating labeled corpora by:
  (i)~translating from an English corpus, (ii)~filtering toxic samples using
  keywords, and (iii)~annotating with crowdsourcing. We compare LLMs prompting
  and other cross-lingual transfer approaches with and without fine-tuning
  offering insights into the most robust and efficient baselines.
  </p>
  </div>
  </dd>
  <dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17842" title="Abstract">arXiv:2404.17842</a> [<a href="/pdf/2404.17842" title="Download PDF">pdf</a>, <a href="/format/2404.17842" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Using LLMs in Software Requirements Specifications: An Empirical  Evaluation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Krishna%2C+M">Madhava Krishna</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gaur%2C+B">Bhagesh Gaur</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Verma%2C+A">Arsh Verma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jalote%2C+P">Pankaj Jalote</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to RE@Next! at the IEEE International Requirements Engineering Conference 2024 at Reykjavik, Iceland
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">The creation of a Software Requirements Specification (SRS) document is
  important for any software development project. Given the recent prowess of
  Large Language Models (LLMs) in answering natural language queries and
  generating sophisticated textual outputs, our study explores their capability
  to produce accurate, coherent, and structured drafts of these documents to
  accelerate the software development lifecycle. We assess the performance of
  GPT-4 and CodeLlama in drafting an SRS for a university club management system
  and compare it against human benchmarks using eight distinct criteria. Our
  results suggest that LLMs can match the output quality of an entry-level
  software engineer to generate an SRS, delivering complete and consistent
  drafts. We also evaluate the capabilities of LLMs to identify and rectify
  problems in a given requirements document. Our experiments indicate that GPT-4
  is capable of identifying issues and giving constructive feedback for
  rectifying them, while CodeLlama's results for validation were not as
  encouraging. We repeated the generation exercise for four distinct use cases to
  study the time saved by employing LLMs for SRS generation. The experiment
  demonstrates that LLMs may facilitate a significant reduction in development
  time for entry-level software engineers. Hence, we conclude that the LLMs can
  be gainfully used by software engineers to increase productivity by saving time
  and effort in generating, validating and rectifying software requirements.
  </p>
  </div>
  </dd>
  <dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17844" title="Abstract">arXiv:2404.17844</a> [<a href="/pdf/2404.17844" title="Download PDF">pdf</a>, <a href="/format/2404.17844" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Robust Recommendation: A Review and an Adversarial Robustness  Evaluation Library
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+L">Lei Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+X">Xiaowen Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sang%2C+J">Jitao Sang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Jian Yu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">Recently, recommender system has achieved significant success. However, due
  to the openness of recommender systems, they remain vulnerable to malicious
  attacks. Additionally, natural noise in training data and issues such as data
  sparsity can also degrade the performance of recommender systems. Therefore,
  enhancing the robustness of recommender systems has become an increasingly
  important research topic. In this survey, we provide a comprehensive overview
  of the robustness of recommender systems. Based on our investigation, we
  categorize the robustness of recommender systems into adversarial robustness
  and non-adversarial robustness. In the adversarial robustness, we introduce the
  fundamental principles and classical methods of recommender system adversarial
  attacks and defenses. In the non-adversarial robustness, we analyze
  non-adversarial robustness from the perspectives of data sparsity, natural
  noise, and data imbalance. Additionally, we summarize commonly used datasets
  and evaluation metrics for evaluating the robustness of recommender systems.
  Finally, we also discuss the current challenges in the field of recommender
  system robustness and potential future research directions. Additionally, to
  facilitate fair and efficient evaluation of attack and defense methods in
  adversarial robustness, we propose an adversarial robustness evaluation
  library--ShillingREC, and we conduct evaluations of basic attack models and
  recommendation models. ShillingREC project is released at
  https://github.com/chengleileilei/ShillingREC.
  </p>
  </div>
  </dd>
  <dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17845" title="Abstract">arXiv:2404.17845</a> [<a href="/pdf/2404.17845" title="Download PDF">pdf</a>, <a href="/format/2404.17845" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Instance-free Text to Point Cloud Localization with Relative Position  Awareness
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Lichao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Z">Zhihao Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+J">Jinke Ren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cui%2C+S">Shuguang Cui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhen Li</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages, 10 figures, conference
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Text-to-point-cloud cross-modal localization is an emerging vision-language
  task critical for future robot-human collaboration. It seeks to localize a
  position from a city-scale point cloud scene based on a few natural language
  instructions. In this paper, we address two key limitations of existing
  approaches: 1) their reliance on ground-truth instances as input; and 2) their
  neglect of the relative positions among potential instances. Our proposed model
  follows a two-stage pipeline, including a coarse stage for text-cell retrieval
  and a fine stage for position estimation. In both stages, we introduce an
  instance query extractor, in which the cells are encoded by a 3D sparse
  convolution U-Net to generate the multi-scale point cloud features, and a set
  of queries iteratively attend to these features to represent instances. In the
  coarse stage, a row-column relative position-aware self-attention (RowColRPA)
  module is designed to capture the spatial relations among the instance queries.
  In the fine stage, a multi-modal relative position-aware cross-attention (RPCA)
  module is developed to fuse the text and point cloud features along with
  spatial relations for improving fine position estimation. Experiment results on
  the KITTI360Pose dataset demonstrate that our model achieves competitive
  performance with the state-of-the-art models without taking ground-truth
  instances as input.
  </p>
  </div>
  </dd>
  <dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17847" title="Abstract">arXiv:2404.17847</a> [<a href="/pdf/2404.17847" title="Download PDF">pdf</a>, <a href="/format/2404.17847" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> pFedAFM: Adaptive Feature Mixture for Batch-Level Personalization in  Heterogeneous Federated Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yi%2C+L">Liping Yi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Han Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+C">Chao Ren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Heng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+G">Gang Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaoguang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaoxiao Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Model-heterogeneous personalized federated learning (MHPFL) enables FL
  clients to train structurally different personalized models on non-independent
  and identically distributed (non-IID) local data. Existing MHPFL methods focus
  on achieving client-level personalization, but cannot address batch-level data
  heterogeneity. To bridge this important gap, we propose a model-heterogeneous
  personalized Federated learning approach with Adaptive Feature Mixture
  (pFedAFM) for supervised learning tasks. It consists of three novel designs: 1)
  A sharing global homogeneous small feature extractor is assigned alongside each
  client's local heterogeneous model (consisting of a heterogeneous feature
  extractor and a prediction header) to facilitate cross-client knowledge fusion.
  The two feature extractors share the local heterogeneous model's prediction
  header containing rich personalized prediction knowledge to retain personalized
  prediction capabilities. 2) An iterative training strategy is designed to
  alternately train the global homogeneous small feature extractor and the local
  heterogeneous large model for effective global-local knowledge exchange. 3) A
  trainable weight vector is designed to dynamically mix the features extracted
  by both feature extractors to adapt to batch-level data heterogeneity.
  Theoretical analysis proves that pFedAFM can converge over time. Extensive
  experiments on 2 benchmark datasets demonstrate that it significantly
  outperforms 7 state-of-the-art MHPFL methods, achieving up to 7.93% accuracy
  improvement while incurring low communication and computation costs.
  </p>
  </div>
  </dd>
  <dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17854" title="Abstract">arXiv:2404.17854</a> [<a href="/pdf/2404.17854" title="Download PDF">pdf</a>, <a href="/format/2404.17854" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> GLIMS: Attention-Guided Lightweight Multi-Scale Hybrid Network for  Volumetric Semantic Segmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yaz%C4%B1c%C4%B1%2C+Z+A">Ziya Ata Yazıcı</a>, 
  <a href="/search/cs?searchtype=author&amp;query=%C3%96ks%C3%BCz%2C+%C4%B0">İlkay Öksüz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ekenel%2C+H+K">Hazım Kemal Ekenel</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The article was accepted for publication in the Image and Vision Computing journal
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Convolutional Neural Networks (CNNs) have become widely adopted for medical
  image segmentation tasks, demonstrating promising performance. However, the
  inherent inductive biases in convolutional architectures limit their ability to
  model long-range dependencies and spatial correlations. While recent
  transformer-based architectures address these limitations by leveraging
  self-attention mechanisms to encode long-range dependencies and learn
  expressive representations, they often struggle to extract low-level features
  and are highly dependent on data availability. This motivated us for the
  development of GLIMS, a data-efficient attention-guided hybrid volumetric
  segmentation network. GLIMS utilizes Dilated Feature Aggregator Convolutional
  Blocks (DACB) to capture local-global feature correlations efficiently.
  Furthermore, the incorporated Swin Transformer-based bottleneck bridges the
  local and global features to improve the robustness of the model. Additionally,
  GLIMS employs an attention-guided segmentation approach through Channel and
  Spatial-Wise Attention Blocks (CSAB) to localize expressive features for
  fine-grained border segmentation. Quantitative and qualitative results on
  glioblastoma and multi-organ CT segmentation tasks demonstrate GLIMS'
  effectiveness in terms of complexity and accuracy. GLIMS demonstrated
  outstanding performance on BraTS2021 and BTCV datasets, surpassing the
  performance of Swin UNETR. Notably, GLIMS achieved this high performance with a
  significantly reduced number of trainable parameters. Specifically, GLIMS has
  47.16M trainable parameters and 72.30G FLOPs, while Swin UNETR has 61.98M
  trainable parameters and 394.84G FLOPs. The code is publicly available on
  https://github.com/yaziciz/GLIMS.
  </p>
  </div>
  </dd>
  <dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17855" title="Abstract">arXiv:2404.17855</a> [<a href="/pdf/2404.17855" title="Download PDF">pdf</a>, <a href="/format/2404.17855" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Recontextualized Knowledge and Narrative Coalitions on Telegram
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Willaert%2C+T">Tom Willaert</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Book chapter submitted to Advances in Sociolinguistics (Bloomsbury)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>
  
  </div>
  <p class="mathjax">A defining characteristic of conspiracy texts is that they negotiate power
  and identity by recontextualizing prior knowledge. This dynamic has been shown
  to intensify on social media, where knowledge sources can readily be integrated
  into antagonistic narratives through hyperlinks. The objective of the present
  chapter is to further our understanding of this dynamic by surfacing and
  examining 1) how online conspiracy narratives recontextualize prior knowledge
  by coupling it with heterogeneous antagonistic elements, and 2) how such
  recontextualizing narratives operate as connectors around which diverse actors
  might form narrative coalitions. To this end, the chapter offers an empirical
  analysis of links to prior knowledge in public messaging channels from the
  Pushshift Telegram dataset. Using transferable methods from the field of
  bibliometrics, we find that politically extreme Telegram channels engage with a
  variety of established knowledge sources, including scientific journals,
  scientific repositories and other sources associated with the system of
  scholarly communication. Channels engaging with shared knowledge sources
  thereby form narrative coalitions ranging from scientific and technological
  imaginaries to far-right extremist and antisemitic conspiracy theories. Our
  analysis of these coalitions reveals (i) linguistic, political, and thematic
  forces that shape conspiracy narratives, (ii) emerging ideological,
  epistemological and ontological positions associated with online conspiracism,
  and (iii) how references to shared knowledge contribute to the communicability
  of conspiracy narratives.
  </p>
  </div>
  </dd>
  <dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17858" title="Abstract">arXiv:2404.17858</a> [<a href="/pdf/2404.17858" title="Download PDF">pdf</a>, <a href="/format/2404.17858" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Revisiting Multi-modal Emotion Learning with Broad State Space Models  and Probability-guidance Fusion
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shou%2C+Y">Yuntao Shou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Meng%2C+T">Tao Meng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+F">Fuchen Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yin%2C+N">Nan Yin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+K">Keqin Li</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 6 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Multi-modal Emotion Recognition in Conversation (MERC) has received
  considerable attention in various fields, e.g., human-computer interaction and
  recommendation systems. Most existing works perform feature disentanglement and
  fusion to extract emotional contextual information from multi-modal features
  and emotion classification. After revisiting the characteristic of MERC, we
  argue that long-range contextual semantic information should be extracted in
  the feature disentanglement stage and the inter-modal semantic information
  consistency should be maximized in the feature fusion stage. Inspired by recent
  State Space Models (SSMs), Mamba can efficiently model long-distance
  dependencies. Therefore, in this work, we fully consider the above insights to
  further improve the performance of MERC. Specifically, on the one hand, in the
  feature disentanglement stage, we propose a Broad Mamba, which does not rely on
  a self-attention mechanism for sequence modeling, but uses state space models
  to compress emotional representation, and utilizes broad learning systems to
  explore the potential data distribution in broad space. Different from previous
  SSMs, we design a bidirectional SSM convolution to extract global context
  information. On the other hand, we design a multi-modal fusion strategy based
  on probability guidance to maximize the consistency of information between
  modalities. Experimental results show that the proposed method can overcome the
  computational and memory limitations of Transformer when modeling long-distance
  contexts, and has great potential to become a next-generation general
  architecture in MERC.
  </p>
  </div>
  </dd>
  <dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17859" title="Abstract">arXiv:2404.17859</a> [<a href="/pdf/2404.17859" title="Download PDF">pdf</a>, <a href="/format/2404.17859" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Formal Specification of a Data Model for Malaria Surveillance in the  Developing World
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tuyishimire%2C+E">Emmanuel Tuyishimire</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This paper has been accepted at 2024 The 7th International Conference on Information and Computer Technologies. Due to funding constraints, the paper cannot be published
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Computers and Society (cs.CY)
  
  </div>
  <p class="mathjax">The fourth Industrial Revolution(4IR), together with the COVID-19 pandemic
  have made a loud call for digitizing diagnosis processes. The world is now
  convinced that it is imperative to digitize the diagnosis of long standing
  diseases such as malaria for more efficient treatment and control. It has been
  seen that malaria control would benefit a lot from digitizing its diagnosis
  processes such as data gathering. We propose, in this paper, the architecture
  of a digital data collection system and how it is used to gather data for
  malaria awareness. The system is formally specified using Z notation, and based
  on the capability of the system, possible malaria determinants are defined and
  their retrieving mechanisms are discussed.
  </p>
  </div>
  </dd>
  <dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17861" title="Abstract">arXiv:2404.17861</a> [<a href="/pdf/2404.17861" title="Download PDF">pdf</a>, <a href="/ps/2404.17861" title="Download PostScript">ps</a>, <a href="/format/2404.17861" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> BoostRad: Enhancing Object Detection by Boosting Radar Reflections
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Haitman%2C+Y">Yuval Haitman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bialer%2C+O">Oded Bialer</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> WACV2024
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> 2024 IEEE/CVF Winter Conference on Applications of Computer Vision
    (WACV), Waikoloa, HI, USA, 2024, pp. 1627-1636
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Automotive radars have an important role in autonomous driving systems. The
  main challenge in automotive radar detection is the radar's wide point spread
  function (PSF) in the angular domain that causes blurriness and clutter in the
  radar image. Numerous studies suggest employing an 'end-to-end' learning
  strategy using a Deep Neural Network (DNN) to directly detect objects from
  radar images. This approach implicitly addresses the PSF's impact on objects of
  interest. In this paper, we propose an alternative approach, which we term
  "Boosting Radar Reflections" (BoostRad). In BoostRad, a first DNN is trained to
  narrow the PSF for all the reflection points in the scene. The output of the
  first DNN is a boosted reflection image with higher resolution and reduced
  clutter, resulting in a sharper and cleaner image. Subsequently, a second DNN
  is employed to detect objects within the boosted reflection image. We develop a
  novel method for training the boosting DNN that incorporates domain knowledge
  of radar's PSF characteristics. BoostRad's performance is evaluated using the
  RADDet and CARRADA datasets, revealing its superiority over reference methods.
  </p>
  </div>
  </dd>
  <dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17862" title="Abstract">arXiv:2404.17862</a> [<a href="/pdf/2404.17862" title="Download PDF">pdf</a>, <a href="/format/2404.17862" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Revisiting Multimodal Emotion Recognition in Conversation from the  Perspective of Graph Spectrum
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Meng%2C+T">Tao Meng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+F">Fuchen Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shou%2C+Y">Yuntao Shou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ai%2C+W">Wei Ai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yin%2C+N">Nan Yin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+K">Keqin Li</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 4 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Efficiently capturing consistent and complementary semantic features in a
  multimodal conversation context is crucial for Multimodal Emotion Recognition
  in Conversation (MERC). Existing methods mainly use graph structures to model
  dialogue context semantic dependencies and employ Graph Neural Networks (GNN)
  to capture multimodal semantic features for emotion recognition. However, these
  methods are limited by some inherent characteristics of GNN, such as
  over-smoothing and low-pass filtering, resulting in the inability to learn
  long-distance consistency information and complementary information
  efficiently. Since consistency and complementarity information correspond to
  low-frequency and high-frequency information, respectively, this paper revisits
  the problem of multimodal emotion recognition in conversation from the
  perspective of the graph spectrum. Specifically, we propose a
  Graph-Spectrum-based Multimodal Consistency and Complementary collaborative
  learning framework GS-MCC. First, GS-MCC uses a sliding window to construct a
  multimodal interaction graph to model conversational relationships and uses
  efficient Fourier graph operators to extract long-distance high-frequency and
  low-frequency information, respectively. Then, GS-MCC uses contrastive learning
  to construct self-supervised signals that reflect complementarity and
  consistent semantic collaboration with high and low-frequency signals, thereby
  improving the ability of high and low-frequency information to reflect real
  emotions. Finally, GS-MCC inputs the collaborative high and low-frequency
  information into the MLP network and softmax function for emotion prediction.
  Extensive experiments have proven the superiority of the GS-MCC architecture
  proposed in this paper on two benchmark data sets.
  </p>
  </div>
  </dd>
  <dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17864" title="Abstract">arXiv:2404.17864</a> [<a href="/pdf/2404.17864" title="Download PDF">pdf</a>, <a href="/ps/2404.17864" title="Download PostScript">ps</a>, <a href="/format/2404.17864" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Solvent: liquidity verification of smart contracts
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bartoletti%2C+M">Massimo Bartoletti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ferrando%2C+A">Angelo Ferrando</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lipparini%2C+E">Enrico Lipparini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Malvone%2C+V">Vadim Malvone</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL)
  
  </div>
  <p class="mathjax">Smart contracts are programs executed by blockchains networks to regulate the
  exchange of crypto-assets between untrusted users. Due to their immutability,
  public accessibility and high value at stake, smart contracts are an attractive
  target for attackers, as evidenced by a long history of security incidents.
  This has been a driving factor for the application of formal methods to
  Ethereum, the leading smart contract platform, and Solidity, its main smart
  contract language, which have become the target of dozens of verification tools
  with varying objectives. A current limitation of these tools is that they are
  not really effective in expressing and verifying liquidity properties regarding
  the exchange of crypto-assets: for example, is it true that in every reachable
  state a user can fire a sequence of transactions to withdraw a given amount of
  crypto-assets? We propose Solvent, a tool aimed at verifying these kinds of
  properties, which are beyond the reach of existing verification tools for
  Solidity. We evaluate the effectiveness and performance of Solvent through a
  common benchmark of smart contracts.
  </p>
  </div>
  </dd>
  <dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17865" title="Abstract">arXiv:2404.17865</a> [<a href="/pdf/2404.17865" title="Download PDF">pdf</a>, <a href="/format/2404.17865" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Vision-based Discovery of Nonlinear Dynamics for 3D Moving Target
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zitong Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+H">Hao Sun</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 17 pages
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> IJCAI 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Chaotic Dynamics (nlin.CD)
  
  </div>
  <p class="mathjax">Data-driven discovery of governing equations has kindled significant
  interests in many science and engineering areas. Existing studies primarily
  focus on uncovering equations that govern nonlinear dynamics based on direct
  measurement of the system states (e.g., trajectories). Limited efforts have
  been placed on distilling governing laws of dynamics directly from videos for
  moving targets in a 3D space. To this end, we propose a vision-based approach
  to automatically uncover governing equations of nonlinear dynamics for 3D
  moving targets via raw videos recorded by a set of cameras. The approach is
  composed of three key blocks: (1) a target tracking module that extracts plane
  pixel motions of the moving target in each video, (2) a Rodrigues' rotation
  formula-based coordinate transformation learning module that reconstructs the
  3D coordinates with respect to a predefined reference point, and (3) a
  spline-enhanced library-based sparse regressor that uncovers the underlying
  governing law of dynamics. This framework is capable of effectively handling
  the challenges associated with measurement data, e.g., noise in the video,
  imprecise tracking of the target that causes data missing, etc. The efficacy of
  our method has been demonstrated through multiple sets of synthetic videos
  considering different nonlinear dynamics.
  </p>
  </div>
  </dd>
  <dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17866" title="Abstract">arXiv:2404.17866</a> [<a href="/pdf/2404.17866" title="Download PDF">pdf</a>, <a href="/format/2404.17866" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> IRatePL2C: Importance Rating-based Approach for Product Lines  Collaborative Configuration
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sassi%2C+S+B">Sihem Ben Sassi</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> the 19th International Conference on Evaluation of Novel
    Approaches to Software Engineering, ISBN 978-989-758-696-5, ISSN 2184-4895,
    2024, pages 784-791
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Some of them proposed an approach in which involved stakeholders can freely
  configure the product line without being constrained by the choices made the
  other ones. The core of any proposed approach in this context focuses on how
  conflictual situations are resolved. Few works consider stakeholders
  preferences in their resolution process. However, to generate a valid solution
  satisfying all constraints, they generally rely on a process of exponential
  complexity. In this work, we propose the IRatePL2C approach, which resolution
  strategy relies on importance degrees assigned by the stakeholders to their
  initial configuration choices. IRatePL2C starts by merging stakeholders'
  configurations and then detecting and resolving the conflicts according to
  their type: explicit or implicit in sequential steps. Finally, domain
  constraints are propagated and the process is reiterated to reach a final valid
  configuration. An illustrative example is presented to evaluate the approach.
  The complexity of IRatePL2C is polynomial which an important advantage compared
  with previous works.
  </p>
  </div>
  </dd>
  <dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17867" title="Abstract">arXiv:2404.17867</a> [<a href="/pdf/2404.17867" title="Download PDF">pdf</a>, <a href="/format/2404.17867" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Are Watermarks Bugs for Deepfake Detectors? Rethinking Proactive  Forensics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiaoshuai Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liao%2C+X">Xin Liao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ou%2C+B">Bo Ou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuling Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qin%2C+Z">Zheng Qin</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by IJCAI 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
  
  </div>
  <p class="mathjax">AI-generated content has accelerated the topic of media synthesis,
  particularly Deepfake, which can manipulate our portraits for positive or
  malicious purposes. Before releasing these threatening face images, one
  promising forensics solution is the injection of robust watermarks to track
  their own provenance. However, we argue that current watermarking models,
  originally devised for genuine images, may harm the deployed Deepfake detectors
  when directly applied to forged images, since the watermarks are prone to
  overlap with the forgery signals used for detection. To bridge this gap, we
  thus propose AdvMark, on behalf of proactive forensics, to exploit the
  adversarial vulnerability of passive detectors for good. Specifically, AdvMark
  serves as a plug-and-play procedure for fine-tuning any robust watermarking
  into adversarial watermarking, to enhance the forensic detectability of
  watermarked images; meanwhile, the watermarks can still be extracted for
  provenance tracking. Extensive experiments demonstrate the effectiveness of the
  proposed AdvMark, leveraging robust watermarking to fool Deepfake detectors,
  which can help improve the accuracy of downstream Deepfake detection without
  tuning the in-the-wild detectors. We believe this work will shed some light on
  the harmless proactive forensics against Deepfake.
  </p>
  </div>
  </dd>
  <dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17868" title="Abstract">arXiv:2404.17868</a> [<a href="/pdf/2404.17868" title="Download PDF">pdf</a>, <a href="/format/2404.17868" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Error analysis for finite element operator learning methods for solving  parametric second-order elliptic PDEs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Hong%2C+Y">Youngjoon Hong</a>, 
  <a href="/search/math?searchtype=author&amp;query=Ko%2C+S">Seungchan Ko</a>, 
  <a href="/search/math?searchtype=author&amp;query=Lee%2C+J">Jaeyong Lee</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">In this paper, we provide a theoretical analysis of a type of operator
  learning method without data reliance based on the classical finite element
  approximation, which is called the finite element operator network (FEONet). We
  first establish the convergence of this method for general second-order linear
  elliptic PDEs with respect to the parameters for neural network approximation.
  In this regard, we address the role of the condition number of the finite
  element matrix in the convergence of the method. Secondly, we derive an
  explicit error estimate for the self-adjoint case. For this, we investigate
  some regularity properties of the solution in certain function classes for a
  neural network approximation, verifying the sufficient condition for the
  solution to have the desired regularity. Finally, we will also conduct some
  numerical experiments that support the theoretical findings, confirming the
  role of the condition number of the finite element matrix in the overall
  convergence.
  </p>
  </div>
  </dd>
  <dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17870" title="Abstract">arXiv:2404.17870</a> [<a href="/pdf/2404.17870" title="Download PDF">pdf</a>, <a href="/format/2404.17870" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Comparative study of inner-outer Krylov solvers for linear systems in  structured and high-order unstructured CFD problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Jadoui%2C+M">Mehdi Jadoui</a>, 
  <a href="/search/math?searchtype=author&amp;query=Blondeau%2C+C">Christophe Blondeau</a>, 
  <a href="/search/math?searchtype=author&amp;query=Martin%2C+E">Emeric Martin</a>, 
  <a href="/search/math?searchtype=author&amp;query=Renac%2C+F">Florent Renac</a>, 
  <a href="/search/math?searchtype=author&amp;query=Roux%2C+F">François-Xavier Roux</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 22 pages, 10 figures
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Computers and Fluids, Volume 244, 15 August 2022, 105575
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">Advanced Krylov subspace methods are investigated for the solution of large
  sparse linear systems arising from stiff adjoint-based aerodynamic shape
  optimization problems. A special attention is paid to the flexible inner-outer
  GMRES strategy combined with most relevant preconditioning and deflation
  techniques. The choice of this specific class of Krylov solvers for challenging
  problems is based on its outstanding convergence properties. Typically in our
  implementation the efficiency of the preconditioner is enhanced with a domain
  decomposition method with overlapping. However, maintaining the performance of
  the preconditioner may be challenging since scalability and efficiency of a
  preconditioning technique are properties often antagonistic to each other. In
  this paper we demonstrate how flexible inner-outer Krylov methods are able to
  overcome this critical issue. A numerical study is performed considering either
  a Finite Volume (FV), or a high-order Discontinuous Galerkin (DG)
  discretization which affect the arithmetic intensity and memory-bandwith of the
  algebraic operations. We consider test cases of transonic turbulent flows with
  RANS modelling over the two-dimensional supercritical OAT15A airfoil and the
  three-dimensional ONERA M6 wing. Benefits in terms of robustness and
  convergence compared to standard GMRES solvers are obtained. Strong scalability
  analysis shows satisfactory results. Based on these representative problems a
  discussion of the recommended numerical practices is proposed.
  </p>
  </div>
  </dd>
  <dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17871" title="Abstract">arXiv:2404.17871</a> [<a href="/pdf/2404.17871" title="Download PDF">pdf</a>, <a href="/format/2404.17871" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Survey of Deep Learning Library Testing Methods
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaoyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+W">Weipeng Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shen%2C+C">Chao Shen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Q">Qi Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qian Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+C">Chenhao Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guan%2C+X">Xiaohong Guan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 34 pages, 8 figures, 4 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">In recent years, software systems powered by deep learning (DL) techniques
  have significantly facilitated people's lives in many aspects. As the backbone
  of these DL systems, various DL libraries undertake the underlying optimization
  and computation. However, like traditional software, DL libraries are not
  immune to bugs, which can pose serious threats to users' personal property and
  safety. Studying the characteristics of DL libraries, their associated bugs,
  and the corresponding testing methods is crucial for enhancing the security of
  DL systems and advancing the widespread application of DL technology. This
  paper provides an overview of the testing research related to various DL
  libraries, discusses the strengths and weaknesses of existing methods, and
  provides guidance and reference for the application of the DL library. This
  paper first introduces the workflow of DL underlying libraries and the
  characteristics of three kinds of DL libraries involved, namely DL framework,
  DL compiler, and DL hardware library. It then provides definitions for DL
  underlying library bugs and testing. Additionally, this paper summarizes the
  existing testing methods and tools tailored to these DL libraries separately
  and analyzes their effectiveness and limitations. It also discusses the
  existing challenges of DL library testing and outlines potential directions for
  future research.
  </p>
  </div>
  </dd>
  <dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17872" title="Abstract">arXiv:2404.17872</a> [<a href="/pdf/2404.17872" title="Download PDF">pdf</a>, <a href="/format/2404.17872" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generalizing Roberts' characterization of unit interval graphs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mart%C3%ADnez%2C+V+A">Virginia Ardévol Martínez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rizzi%2C+R">Romeo Rizzi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Saffidine%2C+A">Abdallah Saffidine</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sikora%2C+F">Florian Sikora</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vialette%2C+S">Stéphane Vialette</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS)
  
  </div>
  <p class="mathjax">For any natural number <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-53-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-421" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-422"><span class="mi" id="MathJax-Span-423" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-53">d</script>, a graph <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-54-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-424" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-425"><span class="mi" id="MathJax-Span-426" style="font-family: STIXGeneral-Italic;">G</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-54">G</script> is a (disjoint) <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-55-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-427" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-428"><span class="mi" id="MathJax-Span-429" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-55">d</script>-interval graph if
  it is the intersection graph of (disjoint) <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-56-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-430" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-431"><span class="mi" id="MathJax-Span-432" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-56">d</script>-intervals, the union of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-57-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-433" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-434"><span class="mi" id="MathJax-Span-435" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-57">d</script>
  (disjoint) intervals on the real line. Two important subclasses of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-58-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-436" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-437"><span class="mi" id="MathJax-Span-438" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-58">d</script>-interval
  graphs are unit and balanced <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-59-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-439" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-440"><span class="mi" id="MathJax-Span-441" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-59">d</script>-interval graphs (where every interval has unit
  length or all the intervals associated to a same vertex have the same length,
  respectively). A celebrated result by Roberts gives a simple characterization
  of unit interval graphs being exactly claw-free interval graphs. Here, we study
  the generalization of this characterization for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-60-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-442" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-443"><span class="mi" id="MathJax-Span-444" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-60">d</script>-interval graphs. In
  particular, we prove that for any <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-61-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-445" style="width: 2.939em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.374em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.374em, 2.826em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-446"><span class="mi" id="MathJax-Span-447" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-448" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≥</span><span class="mn" id="MathJax-Span-449" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-61">d \geq 2</script>, if <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-62-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-450" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-451"><span class="mi" id="MathJax-Span-452" style="font-family: STIXGeneral-Italic;">G</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-62">G</script> is a <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-63-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-453" style="width: 3.56em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.882em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1002.882em, 1.414em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-454"><span class="msubsup" id="MathJax-Span-455"><span style="display: inline-block; position: relative; width: 2.826em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-456" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="texatom" id="MathJax-Span-457"><span class="mrow" id="MathJax-Span-458"><span class="mn" id="MathJax-Span-459" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-460" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-461" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mi" id="MathJax-Span-462" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-463" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-464" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-63">K_{1,2d+1}</script>-free
  interval graph, then <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-64-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-465" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-466"><span class="mi" id="MathJax-Span-467" style="font-family: STIXGeneral-Italic;">G</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-64">G</script> is a unit <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-65-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-468" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-469"><span class="mi" id="MathJax-Span-470" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-65">d</script>-interval graph. However, somehow
  surprisingly, under the same assumptions, <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-66-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-471" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-472"><span class="mi" id="MathJax-Span-473" style="font-family: STIXGeneral-Italic;">G</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-66">G</script> is not always a \emph{disjoint}
  unit <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-67-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-474" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-475"><span class="mi" id="MathJax-Span-476" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-67">d</script>-interval graph. This implies that the class of disjoint unit
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-68-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-477" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-478"><span class="mi" id="MathJax-Span-479" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-68">d</script>-interval graphs is strictly included in the class of unit <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-69-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-480" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-481"><span class="mi" id="MathJax-Span-482" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-69">d</script>-interval
  graphs. Finally, we study the relationships between the classes obtained under
  disjoint and non-disjoint <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-70-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-483" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-484"><span class="mi" id="MathJax-Span-485" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-70">d</script>-intervals in the balanced case and show that the
  classes of disjoint balanced 2-intervals and balanced 2-intervals coincide, but
  this is no longer true for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-71-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-486" style="width: 2.939em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.374em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.374em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-487"><span class="mi" id="MathJax-Span-488" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-489" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">&gt;</span><span class="mn" id="MathJax-Span-490" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-71">d>2</script>.
  </p>
  </div>
  </dd>
  <dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17874" title="Abstract">arXiv:2404.17874</a> [<a href="/pdf/2404.17874" title="Download PDF">pdf</a>, <a href="/format/2404.17874" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> From Languages to Geographies: Towards Evaluating Cultural Bias in Hate  Speech Datasets
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tonneau%2C+M">Manuel Tonneau</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+D">Diyi Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fraiberger%2C+S">Samuel Fraiberger</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schroeder%2C+R">Ralph Schroeder</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hale%2C+S+A">Scott A. Hale</a>, 
  <a href="/search/cs?searchtype=author&amp;query=R%C3%B6ttger%2C+P">Paul Röttger</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at WOAH (NAACL 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Perceptions of hate can vary greatly across cultural contexts. Hate speech
  (HS) datasets, however, have traditionally been developed by language. This
  hides potential cultural biases, as one language may be spoken in different
  countries home to different cultures. In this work, we evaluate cultural bias
  in HS datasets by leveraging two interrelated cultural proxies: language and
  geography. We conduct a systematic survey of HS datasets in eight languages and
  confirm past findings on their English-language bias, but also show that this
  bias has been steadily decreasing in the past few years. For three
  geographically-widespread languages -- English, Arabic and Spanish -- we then
  leverage geographical metadata from tweets to approximate geo-cultural contexts
  by pairing language and country information. We find that HS datasets for these
  languages exhibit a strong geo-cultural bias, largely overrepresenting a
  handful of countries (e.g., US and UK for English) relative to their prominence
  in both the broader social media population and the general population speaking
  these languages. Based on these findings, we formulate recommendations for the
  creation of future HS datasets.
  </p>
  </div>
  </dd>
  <dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17875" title="Abstract">arXiv:2404.17875</a> [<a href="/pdf/2404.17875" title="Download PDF">pdf</a>, <a href="/format/2404.17875" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Noisy Node Classification by Bi-level Optimization based Multi-teacher  Distillation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yujing Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zongqian Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhengyu Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nie%2C+C">Ci Nie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wen%2C+G">Guoqiu Wen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+P">Ping Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xiaofeng Zhu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Previous graph neural networks (GNNs) usually assume that the graph data is
  with clean labels for representation learning, but it is not true in real
  applications. In this paper, we propose a new multi-teacher distillation method
  based on bi-level optimization (namely BO-NNC), to conduct noisy node
  classification on the graph data. Specifically, we first employ multiple
  self-supervised learning methods to train diverse teacher models, and then
  aggregate their predictions through a teacher weight matrix. Furthermore, we
  design a new bi-level optimization strategy to dynamically adjust the teacher
  weight matrix based on the training progress of the student model. Finally, we
  design a label improvement module to improve the label quality. Extensive
  experimental results on real datasets show that our method achieves the best
  results compared to state-of-the-art methods.
  </p>
  </div>
  </dd>
  <dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17876" title="Abstract">arXiv:2404.17876</a> [<a href="/pdf/2404.17876" title="Download PDF">pdf</a>, <a href="/format/2404.17876" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DF-SLAM: Neural Feature Rendering Based on Dictionary Factors  Representation for High-Fidelity Dense Visual SLAM System
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+W">Weifeng Wei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jie Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">We introduce a high-fidelity neural implicit dense visual Simultaneous
  Localization and Mapping (SLAM) system, termed DF-SLAM. In our work, we employ
  dictionary factors for scene representation, encoding the geometry and
  appearance information of the scene as a combination of basis and coefficient
  factors. Compared to neural implicit SLAM methods that directly encode scene
  information as features, our method exhibits superior scene detail
  reconstruction capabilities and more efficient memory usage, while our model
  size is insensitive to the size of the scene map, making our method more
  suitable for large-scale scenes. Additionally, we employ feature integration
  rendering to accelerate color rendering speed while ensuring color rendering
  quality, further enhancing the real-time performance of our neural SLAM method.
  Extensive experiments on synthetic and real-world datasets demonstrate that our
  method is competitive with existing state-of-the-art neural implicit SLAM
  methods in terms of real-time performance, localization accuracy, and scene
  reconstruction quality. Our source code is available at
  https://github.com/funcdecl/DF-SLAM.
  </p>
  </div>
  </dd>
  <dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17877" title="Abstract">arXiv:2404.17877</a> [<a href="/pdf/2404.17877" title="Download PDF">pdf</a>, <a href="/ps/2404.17877" title="Download PostScript">ps</a>, <a href="/format/2404.17877" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PromptCL: Improving Event Representation via Prompt Template and  Contrastive Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yubo Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Lishuang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiang%2C+Y">Yi Xiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qin%2C+X">Xueyang Qin</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> NLPCC 2023 Best Student Paper
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Natural Language Processing and Chinese Computing (NLPCC 2023)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">The representation of events in text plays a significant role in various NLP
  tasks. Recent research demonstrates that contrastive learning has the ability
  to improve event comprehension capabilities of Pre-trained Language Models
  (PLMs) and enhance the performance of event representation learning. However,
  the efficacy of event representation learning based on contrastive learning and
  PLMs is limited by the short length of event texts. The length of event texts
  differs significantly from the text length used in the pre-training of PLMs. As
  a result, there is inconsistency in the distribution of text length between
  pre-training and event representation learning, which may undermine the
  learning process of event representation based on PLMs. In this study, we
  present PromptCL, a novel framework for event representation learning that
  effectively elicits the capabilities of PLMs to comprehensively capture the
  semantics of short event texts. PromptCL utilizes a Prompt template borrowed
  from prompt learning to expand the input text during Contrastive Learning. This
  helps in enhancing the event representation learning by providing a structured
  outline of the event components. Moreover, we propose Subject-Predicate-Object
  (SPO) word order and Event-oriented Masked Language Modeling (EventMLM) to
  train PLMs to understand the relationships between event components. Our
  experimental results demonstrate that PromptCL outperforms state-of-the-art
  baselines on event related tasks. Additionally, we conduct a thorough analysis
  and demonstrate that using a prompt results in improved generalization
  capabilities for event representations. Our code will be available at
  https://github.com/YuboFeng2023/PromptCL.
  </p>
  </div>
  </dd>
  <dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17882" title="Abstract">arXiv:2404.17882</a> [<a href="/pdf/2404.17882" title="Download PDF">pdf</a>, <a href="/format/2404.17882" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Directed Isoperimetry and Monotonicity Testing: A Dynamical Approach
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pinto%2C+R+F">Renato Ferreira Pinto Jr</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 83 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  <p class="mathjax">This paper explores the connection between classical isoperimetric
  inequalities, their directed analogues, and monotonicity testing. We study the
  setting of real-valued functions <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-72-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-491" style="width: 7.794em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.326em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1006.27em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-492"><span class="mi" id="MathJax-Span-493" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.172em;"></span></span><span class="mo" id="MathJax-Span-494" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">:</span><span class="mo" id="MathJax-Span-495" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">[</span><span class="mn" id="MathJax-Span-496" style="font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-497" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-498" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">1</span><span class="msubsup" id="MathJax-Span-499"><span style="display: inline-block; position: relative; width: 0.793em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.229em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="mo" id="MathJax-Span-500" style="font-family: STIXGeneral-Regular;">]</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.342em;"><span class="mi" id="MathJax-Span-501" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-502" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">→</span><span class="texatom" id="MathJax-Span-503" style="padding-left: 0.342em;"><span class="mrow" id="MathJax-Span-504"><span class="mi" id="MathJax-Span-505" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-72">f : [0,1]^d \to \mathbb{R}</script> on the solid unit
  cube, where the goal is to test with respect to the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-73-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-506" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-507"><span class="msubsup" id="MathJax-Span-508"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-509" style="font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.624em;"><span class="mi" id="MathJax-Span-510" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">p</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-73">L^p</script> distance. Our goals
  are twofold: to further understand the relationship between classical and
  directed isoperimetry, and to give a monotonicity tester with sublinear query
  complexity in this setting.
  <br>Our main results are 1) an <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-74-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-511" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.076em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-512"><span class="msubsup" id="MathJax-Span-513"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-514" style="font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.624em;"><span class="mn" id="MathJax-Span-515" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-74">L^2</script> monotonicity tester for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-75-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-516" style="width: 1.132em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.906em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-517"><span class="mi" id="MathJax-Span-518" style="font-family: STIXGeneral-Italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-75">M</script>-Lipschitz
  functions with query complexity <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-76-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-519" style="width: 6.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.423em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.414em, 1005.366em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-520"><span class="texatom" id="MathJax-Span-521"><span class="mrow" id="MathJax-Span-522"><span class="munderover" id="MathJax-Span-523"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0.116em;"><span class="mi" id="MathJax-Span-524" style="font-family: STIXGeneral-Italic;">O</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.108em, 1000.963em, 3.56em, -999.997em); top: -4.232em; left: 0em;"><span class="mo" id="MathJax-Span-525" style=""><span style="font-family: STIXSizeTwoSym;">˜</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-526" style="font-family: STIXGeneral-Regular;">(</span><span class="msqrt" id="MathJax-Span-527"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0.737em;"><span class="mrow" id="MathJax-Span-528"><span class="mi" id="MathJax-Span-529" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(2.995em, 1000.567em, 3.39em, -999.997em); top: -4.006em; left: 0.737em;"><span style="display: inline-block; position: relative; width: 0.567em; height: 0px;"><span style="position: absolute; font-family: STIXGeneral-Regular; top: -4.006em; left: 0em;">‾<span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; font-family: STIXGeneral-Regular; top: -4.006em; left: 0.059em;">‾<span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(2.882em, 1000.793em, 4.181em, -999.997em); top: -3.893em; left: 0em;"><span style="font-family: STIXVariants;">√</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-530"><span style="display: inline-block; position: relative; width: 1.358em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.85em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-531" style="font-family: STIXGeneral-Italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.963em;"><span class="mn" id="MathJax-Span-532" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="texatom" id="MathJax-Span-533"><span class="mrow" id="MathJax-Span-534"><span class="mo" id="MathJax-Span-535" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="msubsup" id="MathJax-Span-536"><span style="display: inline-block; position: relative; width: 0.85em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-537" style="font-family: STIXGeneral-Italic;">ϵ</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.454em;"><span class="mn" id="MathJax-Span-538" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-539" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.531em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-76">\widetilde O(\sqrt{d} M^2 / \epsilon^2)</script> and,
  behind this result, 2) the directed Poincar\'e inequality
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-77-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-540" style="width: 13.214em; display: inline-block;"><span style="display: inline-block; position: relative; width: 10.73em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.471em, 1010.617em, 2.995em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-541"><span class="msubsup" id="MathJax-Span-542"><span style="display: inline-block; position: relative; width: 3.052em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1001.414em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-543"><span class="mrow" id="MathJax-Span-544"><span class="mi" id="MathJax-Span-545" style="font-family: STIXGeneral-Regular;">𝖽</span><span class="mi" id="MathJax-Span-546" style="font-family: STIXGeneral-Regular;">𝗂</span><span class="mi" id="MathJax-Span-547" style="font-family: STIXGeneral-Regular;">𝗌</span><span class="mi" id="MathJax-Span-548" style="font-family: STIXGeneral-Regular;">𝗍</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1001.64em, 4.181em, -999.997em); top: -4.401em; left: 1.414em;"><span class="texatom" id="MathJax-Span-549"><span class="mrow" id="MathJax-Span-550"><span class="texatom" id="MathJax-Span-551"><span class="mrow" id="MathJax-Span-552"><span class="mi" id="MathJax-Span-553" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">𝗆</span><span class="mi" id="MathJax-Span-554" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">𝗈</span><span class="mi" id="MathJax-Span-555" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">𝗇</span><span class="mi" id="MathJax-Span-556" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">𝗈</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -3.723em; left: 1.414em;"><span class="mn" id="MathJax-Span-557" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-558" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-559" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.172em;"></span></span><span class="msubsup" id="MathJax-Span-560"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.285em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="mo" id="MathJax-Span-561" style="font-family: STIXGeneral-Regular;">)</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.342em;"><span class="mn" id="MathJax-Span-562" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-563" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≤</span><span class="mi" id="MathJax-Span-564" style="font-family: STIXGeneral-Italic; padding-left: 0.342em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-565"><span class="mrow" id="MathJax-Span-566"><span class="mi" id="MathJax-Span-567" style="font-family: STIXGeneral-Regular;">𝔼</span></span></span><span class="mo" id="MathJax-Span-568" style="font-family: STIXGeneral-Regular;">[</span><span class="texatom" id="MathJax-Span-569"><span class="mrow" id="MathJax-Span-570"><span class="mo" id="MathJax-Span-571" style="font-family: STIXVariants;">|</span></span></span><span class="msubsup" id="MathJax-Span-572"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-573" style="font-family: STIXGeneral-Regular;">∇</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.737em;"><span class="mo" id="MathJax-Span-574" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mi" id="MathJax-Span-575" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.172em;"></span></span><span class="msubsup" id="MathJax-Span-576"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.172em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-577"><span class="mrow" id="MathJax-Span-578"><span class="mo" id="MathJax-Span-579" style="font-family: STIXVariants;">|</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.342em;"><span class="mn" id="MathJax-Span-580" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-581" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.413em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.531em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-77">\mathsf{dist}^{\mathsf{mono}}_2(f)^2 \le C \mathbb{E}[|\nabla^- f|^2]</script>, where
  the "directed gradient" operator <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-78-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-582" style="width: 1.697em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.358em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.116em, 1001.358em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-583"><span class="msubsup" id="MathJax-Span-584"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-585" style="font-family: STIXGeneral-Regular;">∇</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.737em;"><span class="mo" id="MathJax-Span-586" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-78">\nabla^-</script> measures the local violations of
  monotonicity of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-79-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-587" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-588"><span class="mi" id="MathJax-Span-589" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.172em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-79">f</script>.
  <br>To prove the second result, we introduce a partial differential equation
  (PDE), the directed heat equation, which takes a one-dimensional function <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-80-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-590" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-591"><span class="mi" id="MathJax-Span-592" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.172em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-80">f</script>
  into a monotone function <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-81-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-593" style="width: 1.245em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.019em, 1.414em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-594"><span class="msubsup" id="MathJax-Span-595"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.454em, 4.407em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-596" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.172em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="mo" id="MathJax-Span-597" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∗</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-81">f^*</script> over time and enjoys many desirable analytic
  properties. We obtain the directed Poincar\'e inequality by combining
  convergence aspects of this PDE with the theory of optimal transport. Crucially
  for our conceptual motivation, this proof is in complete analogy with the
  mathematical physics perspective on the classical Poincar\'e inequality, namely
  as characterizing the convergence of the standard heat equation toward
  equilibrium.
  </p>
  </div>
  </dd>
  <dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17883" title="Abstract">arXiv:2404.17883</a> [<a href="/pdf/2404.17883" title="Download PDF">pdf</a>, <a href="/format/2404.17883" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Underwater Variable Zoom-Depth-Guided Perception Network for Underwater  Image Enhancement
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhixiong Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinying Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jinjiang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shenglan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+L">Lin Feng</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Underwater scenes intrinsically involve degradation problems owing to
  heterogeneous ocean elements. Prevailing underwater image enhancement (UIE)
  methods stick to straightforward feature modeling to learn the mapping
  function, which leads to limited vision gain as it lacks more explicit physical
  cues (e.g., depth). In this work, we investigate injecting the depth prior into
  the deep UIE model for more precise scene enhancement capability. To this end,
  we present a novel depth-guided perception UIE framework, dubbed underwater
  variable zoom (UVZ). Specifically, UVZ resorts to a two-stage pipeline. First,
  a depth estimation network is designed to generate critical depth maps,
  combined with an auxiliary supervision network introduced to suppress
  estimation differences during training. Second, UVZ parses near-far scenarios
  by harnessing the predicted depth maps, enabling local and non-local perceiving
  in different regions. Extensive experiments on five benchmark datasets
  demonstrate that UVZ achieves superior visual gain and delivers promising
  quantitative metrics. Besides, UVZ is confirmed to exhibit good generalization
  in some visual tasks, especially in unusual lighting conditions. The code,
  models and results are available at: https://github.com/WindySprint/UVZ.
  </p>
  </div>
  </dd>
  <dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17886" title="Abstract">arXiv:2404.17886</a> [<a href="/pdf/2404.17886" title="Download PDF">pdf</a>, <a href="/format/2404.17886" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Feature graphs for interpretable unsupervised tree ensembles:  centrality, interaction, and application in disease subtyping
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sirocchi%2C+C">Christel Sirocchi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Urschler%2C+M">Martin Urschler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pfeifer%2C+B">Bastian Pfeifer</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Interpretable machine learning has emerged as central in leveraging
  artificial intelligence within high-stakes domains such as healthcare, where
  understanding the rationale behind model predictions is as critical as
  achieving high predictive accuracy. In this context, feature selection assumes
  a pivotal role in enhancing model interpretability by identifying the most
  important input features in black-box models. While random forests are
  frequently used in biomedicine for their remarkable performance on tabular
  datasets, the accuracy gained from aggregating decision trees comes at the
  expense of interpretability. Consequently, feature selection for enhancing
  interpretability in random forests has been extensively explored in supervised
  settings. However, its investigation in the unsupervised regime remains notably
  limited. To address this gap, the study introduces novel methods to construct
  feature graphs from unsupervised random forests and feature selection
  strategies to derive effective feature combinations from these graphs. Feature
  graphs are constructed for the entire dataset as well as individual clusters
  leveraging the parent-child node splits within the trees, such that feature
  centrality captures their relevance to the clustering task, while edge weights
  reflect the discriminating power of feature pairs. Graph-based feature
  selection methods are extensively evaluated on synthetic and benchmark datasets
  both in terms of their ability to reduce dimensionality while improving
  clustering performance, as well as to enhance model interpretability. An
  application on omics data for disease subtyping identifies the top features for
  each cluster, showcasing the potential of the proposed approach to enhance
  interpretability in clustering analyses and its utility in a real-world
  biomedical application.
  </p>
  </div>
  </dd>
  <dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17888" title="Abstract">arXiv:2404.17888</a> [<a href="/pdf/2404.17888" title="Download PDF">pdf</a>, <a href="/format/2404.17888" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Hybrid Approach for Document Layout Analysis in Document images
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shehzadi%2C+T">Tahira Shehzadi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stricker%2C+D">Didier Stricker</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Afzal%2C+M+Z">Muhammad Zeshan Afzal</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICDAR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Document layout analysis involves understanding the arrangement of elements
  within a document. This paper navigates the complexities of understanding
  various elements within document images, such as text, images, tables, and
  headings. The approach employs an advanced Transformer-based object detection
  network as an innovative graphical page object detector for identifying tables,
  figures, and displayed elements. We introduce a query encoding mechanism to
  provide high-quality object queries for contrastive learning, enhancing
  efficiency in the decoder phase. We also present a hybrid matching scheme that
  integrates the decoder's original one-to-one matching strategy with the
  one-to-many matching strategy during the training phase. This approach aims to
  improve the model's accuracy and versatility in detecting various graphical
  elements on a page. Our experiments on PubLayNet, DocLayNet, and PubTables
  benchmarks show that our approach outperforms current state-of-the-art methods.
  It achieves an average precision of 97.3% on PubLayNet, 81.6% on DocLayNet, and
  98.6 on PubTables, demonstrating its superior performance in layout analysis.
  These advancements not only enhance the conversion of document images into
  editable and accessible formats but also streamline information retrieval and
  data extraction processes.
  </p>
  </div>
  </dd>
  <dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17892" title="Abstract">arXiv:2404.17892</a> [<a href="/pdf/2404.17892" title="Download PDF">pdf</a>, <a href="/format/2404.17892" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Shared learning of powertrain control policies for vehicle fleets
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Kerbel%2C+L">Lindsey Kerbel</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Ayalew%2C+B">Beshah Ayalew</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Ivanco%2C+A">Andrej Ivanco</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Elsevier Applied Energy Volume 365, 1 July 2024, 123217
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Emerging data-driven approaches, such as deep reinforcement learning (DRL),
  aim at on-the-field learning of powertrain control policies that optimize fuel
  economy and other performance metrics. Indeed, they have shown great potential
  in this regard for individual vehicles on specific routes or drive cycles.
  However, for fleets of vehicles that must service a distribution of routes, DRL
  approaches struggle with learning stability issues that result in high
  variances and challenge their practical deployment. In this paper, we present a
  novel framework for shared learning among a fleet of vehicles through the use
  of a distilled group policy as the knowledge sharing mechanism for the policy
  learning computations at each vehicle. We detail the mathematical formulation
  that makes this possible. Several scenarios are considered to analyze the
  functionality, performance, and computational scalability of the framework with
  fleet size. Comparisons of the cumulative performance of fleets using our
  proposed shared learning approach with a baseline of individual learning agents
  and another state-of-the-art approach with a centralized learner show clear
  advantages to our approach. For example, we find a fleet average asymptotic
  improvement of 8.5 percent in fuel economy compared to the baseline while also
  improving on the metrics of acceleration error and shifting frequency for
  fleets serving a distribution of suburban routes. Furthermore, we include
  demonstrative results that show how the framework reduces variance within a
  fleet and also how it helps individual agents adapt better to new routes.
  </p>
  </div>
  </dd>
  <dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17894" title="Abstract">arXiv:2404.17894</a> [<a href="/pdf/2404.17894" title="Download PDF">pdf</a>, <a href="/ps/2404.17894" title="Download PostScript">ps</a>, <a href="/format/2404.17894" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Unpaired Multi-view Clustering via Reliable View Guidance
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xin%2C+L">Like Xin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+W">Wanqi Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+M">Ming Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">This paper focuses on unpaired multi-view clustering (UMC), a challenging
  problem where paired observed samples are unavailable across multiple views.
  The goal is to perform effective joint clustering using the unpaired observed
  samples in all views. In incomplete multi-view clustering, existing methods
  typically rely on sample pairing between views to capture their complementary.
  However, that is not applicable in the case of UMC. Hence, we aim to extract
  the consistent cluster structure across views. In UMC, two challenging issues
  arise: uncertain cluster structure due to lack of label and uncertain pairing
  relationship due to absence of paired samples. We assume that the view with a
  good cluster structure is the reliable view, which acts as a supervisor to
  guide the clustering of the other views. With the guidance of reliable views, a
  more certain cluster structure of these views is obtained while achieving
  alignment between reliable views and other views. Then we propose Reliable view
  Guidance with one reliable view (RG-UMC) and multiple reliable views (RGs-UMC)
  for UMC. Specifically, we design alignment modules with one reliable view and
  multiple reliable views, respectively, to adaptively guide the optimization
  process. Also, we utilize the compactness module to enhance the relationship of
  samples within the same cluster. Meanwhile, an orthogonal constraint is applied
  to latent representation to obtain discriminate features. Extensive experiments
  show that both RG-UMC and RGs-UMC outperform the best state-of-the-art method
  by an average of 24.14\% and 29.42\% in NMI, respectively.
  </p>
  </div>
  </dd>
  <dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17895" title="Abstract">arXiv:2404.17895</a> [<a href="/pdf/2404.17895" title="Download PDF">pdf</a>, <a href="/format/2404.17895" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Empowering Mobility: Brain-Computer Interface for Enhancing Wheelchair  Control for Individuals with Physical Disabilities
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ghasemi%2C+S">Shiva Ghasemi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gracanin%2C+D">Denis Gracanin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Azab%2C+M">Mohammad Azab</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 2024 HCI International Conference
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">The integration of brain-computer interfaces (BCIs) into the realm of smart
  wheelchair (SW) technology signifies a notable leap forward in enhancing the
  mobility and autonomy of individuals with physical disabilities. BCIs are a
  technology that enables direct communication between the brain and external
  devices. While BCIs systems offer remarkable opportunities for enhancing
  human-computer interaction and providing mobility solutions for individuals
  with disabilities, they also raise significant concerns regarding security,
  safety, and privacy that have not been thoroughly addressed by researchers on a
  large scale. Our research aims to enhance wheelchair control for individuals
  with physical disabilities by leveraging electroencephalography (EEG) signals
  for BCIs. We introduce a non-invasive BCI system that utilizes a neuro-signal
  acquisition headset to capture EEG signals. These signals are obtained from
  specific brain activities that individuals have been trained to produce,
  allowing for precise control of the wheelchair. EEG-based BCIs are instrumental
  in capturing the brain's electrical activity and translating these signals into
  actionable commands. The primary objective of our study is to demonstrate the
  system's capability to interpret EEG signals and decode specific thought
  patterns or mental commands issued by the user. By doing so, it aims to convert
  these into accurate control commands for the wheelchair. This process includes
  the recognition of navigational intentions, such as moving forward, backward,
  or executing turns, specifically tailored for wheelchair operation. Through
  this innovative approach, we aim to create a seamless interface between the
  user's cognitive intentions and the wheelchair's movements, enhancing autonomy
  and mobility for individuals with physical disabilities.
  </p>
  </div>
  </dd>
  <dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17896" title="Abstract">arXiv:2404.17896</a> [<a href="/pdf/2404.17896" title="Download PDF">pdf</a>, <a href="/format/2404.17896" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> How the Training Procedure Impacts the Performance of Deep  Learning-based Vulnerability Patching
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mastropaolo%2C+A">Antonio Mastropaolo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nardone%2C+V">Vittoria Nardone</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bavota%2C+G">Gabriele Bavota</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Di+Penta%2C+M">Massimiliano Di Penta</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Generative deep learning (DL) models have been successfully adopted for
  vulnerability patching. However, such models require the availability of a
  large dataset of patches to learn from. To overcome this issue, researchers
  have proposed to start from models pre-trained with general knowledge, either
  on the programming language or on similar tasks such as bug fixing. Despite the
  efforts in the area of automated vulnerability patching, there is a lack of
  systematic studies on how these different training procedures impact the
  performance of DL models for such a task. This paper provides a manyfold
  contribution to bridge this gap, by (i) comparing existing solutions of
  self-supervised and supervised pre-training for vulnerability patching; and
  (ii) for the first time, experimenting with different kinds of prompt-tuning
  for this task. The study required to train/test 23 DL models. We found that a
  supervised pre-training focused on bug-fixing, while expensive in terms of data
  collection, substantially improves DL-based vulnerability patching. When
  applying prompt-tuning on top of this supervised pre-trained model, there is no
  significant gain in performance. Instead, prompt-tuning is an effective and
  cheap solution to substantially boost the performance of self-supervised
  pre-trained models, i.e., those not relying on the bug-fixing pre-training.
  </p>
  </div>
  </dd>
  <dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17897" title="Abstract">arXiv:2404.17897</a> [<a href="/pdf/2404.17897" title="Download PDF">pdf</a>, <a href="/format/2404.17897" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Tool Calling: Enhancing Medication Consultation via Retrieval-Augmented  Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhongzhen Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+K">Kui Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+Y">Yongqi Fan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mu%2C+L">Linjie Mu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+R">Ruoyu Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ruan%2C+T">Tong Ruan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shaoting Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaofan Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Large-scale language models (LLMs) have achieved remarkable success across
  various language tasks but suffer from hallucinations and temporal
  misalignment. To mitigate these shortcomings, Retrieval-augmented generation
  (RAG) has been utilized to provide external knowledge to facilitate the answer
  generation. However, applying such models to the medical domain faces several
  challenges due to the lack of domain-specific knowledge and the intricacy of
  real-world scenarios. In this study, we explore LLMs with RAG framework for
  knowledge-intensive tasks in the medical field. To evaluate the capabilities of
  LLMs, we introduce MedicineQA, a multi-round dialogue benchmark that simulates
  the real-world medication consultation scenario and requires LLMs to answer
  with retrieved evidence from the medicine database. MedicineQA contains 300
  multi-round question-answering pairs, each embedded within a detailed dialogue
  history, highlighting the challenge posed by this knowledge-intensive task to
  current LLMs. We further propose a new \textit{Distill-Retrieve-Read} framework
  instead of the previous \textit{Retrieve-then-Read}. Specifically, the
  distillation and retrieval process utilizes a tool calling mechanism to
  formulate search queries that emulate the keyword-based inquiries used by
  search engines. With experimental results, we show that our framework brings
  notable performance improvements and surpasses the previous counterparts in the
  evidence retrieval process in terms of evidence retrieval accuracy. This
  advancement sheds light on applying RAG to the medical domain.
  </p>
  </div>
  </dd>
  <dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17900" title="Abstract">arXiv:2404.17900</a> [<a href="/pdf/2404.17900" title="Download PDF">pdf</a>, <a href="/format/2404.17900" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Unsupervised Anomaly Detection via Masked Diffusion Posterior Sampling
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+D">Di Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+S">Shicai Fan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xue Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+L">Li Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yuzhong Deng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zou%2C+J">Jianxiao Zou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+B">Baihong Lin</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> International Joint Conference on Artificial Intelligence 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Reconstruction-based methods have been commonly used for unsupervised anomaly
  detection, in which a normal image is reconstructed and compared with the given
  test image to detect and locate anomalies. Recently, diffusion models have
  shown promising applications for anomaly detection due to their powerful
  generative ability. However, these models lack strict mathematical support for
  normal image reconstruction and unexpectedly suffer from low reconstruction
  quality. To address these issues, this paper proposes a novel and
  highly-interpretable method named Masked Diffusion Posterior Sampling (MDPS).
  In MDPS, the problem of normal image reconstruction is mathematically modeled
  as multiple diffusion posterior sampling for normal images based on the devised
  masked noisy observation model and the diffusion-based normal image prior under
  Bayesian framework. Using a metric designed from pixel-level and
  perceptual-level perspectives, MDPS can effectively compute the difference map
  between each normal posterior sample and the given test image. Anomaly scores
  are obtained by averaging all difference maps for multiple posterior samples.
  Exhaustive experiments on MVTec and BTAD datasets demonstrate that MDPS can
  achieve state-of-the-art performance in normal image reconstruction quality as
  well as anomaly detection and localization.
  </p>
  </div>
  </dd>
  <dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17901" title="Abstract">arXiv:2404.17901</a> [<a href="/pdf/2404.17901" title="Download PDF">pdf</a>, <a href="/format/2404.17901" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Theory and Practice of Deductive Verification of OCaml Programs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pereira%2C+M">Mário Pereira</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  <p class="mathjax">Despite all the tremendous recent success of deductive verification, it is
  rarely the case that verification tools are applied to programs written in
  functional languages. When compared to the imperative world, there are only a
  handful of verification tools that can deal with functional programs. We
  believe the lack of pedagogical, problem-oriented documentation on how to use
  such tools might be one of the reasons behind this apparent mismatch between
  deductive verification and real-world functional software. In this paper, our
  goal is to drift away from this tendency. We chose the OCaml language as our
  working environment and provide a comprehensive, hands-on tutorial on how to
  apply different verification tools to OCaml-written programs. Our presentation
  takes an incremental approach: we first focus on purely functional programs;
  then on imperative programs, yet avoid pointers; finally, we use Separation
  Logic to reason about pointer-manipulating programs.
  </p>
  </div>
  </dd>
  <dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17906" title="Abstract">arXiv:2404.17906</a> [<a href="/pdf/2404.17906" title="Download PDF">pdf</a>, <a href="/format/2404.17906" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> VIEW: Visual Imitation Learning with Waypoints
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jonnavittula%2C+A">Ananth Jonnavittula</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Parekh%2C+S">Sagar Parekh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Losey%2C+D+P">Dylan P. Losey</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 27 pages, 17 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Robots can use Visual Imitation Learning (VIL) to learn everyday tasks from
  video demonstrations. However, translating visual observations into actionable
  robot policies is challenging due to the high-dimensional nature of video data.
  This challenge is further exacerbated by the morphological differences between
  humans and robots, especially when the video demonstrations feature humans
  performing tasks. To address these problems we introduce Visual Imitation
  lEarning with Waypoints (VIEW), an algorithm that significantly enhances the
  sample efficiency of human-to-robot VIL. VIEW achieves this efficiency using a
  multi-pronged approach: extracting a condensed prior trajectory that captures
  the demonstrator's intent, employing an agent-agnostic reward function for
  feedback on the robot's actions, and utilizing an exploration algorithm that
  efficiently samples around waypoints in the extracted trajectory. VIEW also
  segments the human trajectory into grasp and task phases to further accelerate
  learning efficiency. Through comprehensive simulations and real-world
  experiments, VIEW demonstrates improved performance compared to current
  state-of-the-art VIL methods. VIEW enables robots to learn a diverse range of
  manipulation tasks involving multiple objects from arbitrarily long video
  demonstrations. Additionally, it can learn standard manipulation tasks such as
  pushing or moving objects from a single video demonstration in under 30
  minutes, with fewer than 20 real-world rollouts. Code and videos here:
  https://collab.me.vt.edu/view/
  </p>
  </div>
  </dd>
  <dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17910" title="Abstract">arXiv:2404.17910</a> [<a href="/pdf/2404.17910" title="Download PDF">pdf</a>, <a href="/format/2404.17910" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Reliable Student: Addressing Noise in Semi-Supervised 3D Object  Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nozarian%2C+F">Farzad Nozarian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+S">Shashank Agarwal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rezaeianaran%2C+F">Farzaneh Rezaeianaran</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shahzad%2C+D">Danish Shahzad</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Poibrenski%2C+A">Atanas Poibrenski</a>, 
  <a href="/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+C">Christian Müller</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Slusallek%2C+P">Philipp Slusallek</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at CVPR Workshop L3D-IVU 2023. Code: <a href="https://github.com/fnozarian/ReliableStudent">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Semi-supervised 3D object detection can benefit from the promising
  pseudo-labeling technique when labeled data is limited. However, recent
  approaches have overlooked the impact of noisy pseudo-labels during training,
  despite efforts to enhance pseudo-label quality through confidence-based
  filtering. In this paper, we examine the impact of noisy pseudo-labels on
  IoU-based target assignment and propose the Reliable Student framework, which
  incorporates two complementary approaches to mitigate errors. First, it
  involves a class-aware target assignment strategy that reduces false negative
  assignments in difficult classes. Second, it includes a reliability weighting
  strategy that suppresses false positive assignment errors while also addressing
  remaining false negatives from the first step. The reliability weights are
  determined by querying the teacher network for confidence scores of the
  student-generated proposals. Our work surpasses the previous state-of-the-art
  on KITTI 3D object detection benchmark on point clouds in the semi-supervised
  setting. On 1% labeled data, our approach achieves a 6.2% AP improvement for
  the pedestrian class, despite having only 37 labeled samples available. The
  improvements become significant for the 2% setting, achieving 6.0% AP and 5.7%
  AP improvements for the pedestrian and cyclist classes, respectively.
  </p>
  </div>
  </dd>
  <dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17912" title="Abstract">arXiv:2404.17912</a> [<a href="/pdf/2404.17912" title="Download PDF">pdf</a>, <a href="/format/2404.17912" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision  Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kapadnis%2C+M+N">Manav Nitin Kapadnis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Patnaik%2C+S">Sohan Patnaik</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nandy%2C+A">Abhilash Nandy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ray%2C+S">Sourjyadip Ray</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Goyal%2C+P">Pawan Goyal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sheet%2C+D">Debdoot Sheet</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 3 figures, 4 tables, Accepted as oral at Clinical NLP workshop at NAACL 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large
  Language Models (MLLMs) can automate the creation of accurate and coherent
  radiological reports. Existing methods often hallucinate details in text-based
  reports that don't accurately reflect the image content. To mitigate this, we
  introduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort
  GENeraTion using Vision Language Models), which improves the R2Gen task by
  integrating a self-refining mechanism into the MLLM framework. We employ a
  unique self-supervised loss that leverages similarity between pooled image
  representations and the contextual representations of the generated
  radiological text, alongside the standard Causal Language Modeling objective,
  to refine image-text representations. This allows the model to scrutinize and
  align the generated text through dynamic interaction between a given image and
  the generated text, therefore reducing hallucination and continuously enhancing
  nuanced report generation. SERPENT-VLM outperforms existing baselines such as
  LLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and
  Radiology Objects in COntext (ROCO) datasets, and also proves to be robust
  against noisy images. A qualitative case study emphasizes the significant
  advancements towards more sophisticated MLLM frameworks for R2Gen, opening
  paths for further research into self-supervised refinement in the medical
  imaging domain.
  </p>
  </div>
  </dd>
  <dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17916" title="Abstract">arXiv:2404.17916</a> [<a href="/pdf/2404.17916" title="Download PDF">pdf</a>, <a href="/format/2404.17916" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FedCRL: Personalized Federated Learning with Contrastive Shared  Representations for Label Heterogeneity in Non-IID Data
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+C">Chenghao Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaolu Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yanru Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">To deal with heterogeneity resulting from label distribution skew and data
  scarcity in distributed machine learning scenarios, this paper proposes a novel
  Personalized Federated Learning (PFL) algorithm, named Federated Contrastive
  Representation Learning (FedCRL). FedCRL introduces contrastive representation
  learning (CRL) on shared representations to facilitate knowledge acquisition of
  clients. Specifically, both local model parameters and averaged values of local
  representations are considered as shareable information to the server, both of
  which are then aggregated globally. CRL is applied between local
  representations and global representations to regularize personalized training
  by drawing similar representations closer and separating dissimilar ones,
  thereby enhancing local models with external knowledge and avoiding being
  harmed by label distribution skew. Additionally, FedCRL adopts local
  aggregation between each local model and the global model to tackle data
  scarcity. A loss-wise weighting mechanism is introduced to guide the local
  aggregation using each local model's contrastive loss to coordinate the global
  model involvement in each client, thus helping clients with scarce data. Our
  simulations demonstrate FedCRL's effectiveness in mitigating label
  heterogeneity by achieving accuracy improvements over existing methods on
  datasets with varying degrees of label heterogeneity.
  </p>
  </div>
  </dd>
  <dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17917" title="Abstract">arXiv:2404.17917</a> [<a href="/pdf/2404.17917" title="Download PDF">pdf</a>, <a href="/format/2404.17917" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> EvaNet: Elevation-Guided Flood Extent Mapping on Earth Imagery
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sami%2C+M+T">Mirza Tanzim Sami</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+D">Da Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Adhikari%2C+S">Saugat Adhikari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+L">Lyuheng Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+J">Jiao Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Zhe Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khalil%2C+J">Jalal Khalil</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yang Zhou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at the International Joint Conference on Artificial Intelligence (IJCAI, 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
  
  </div>
  <p class="mathjax">Accurate and timely mapping of flood extent from high-resolution satellite
  imagery plays a crucial role in disaster management such as damage assessment
  and relief activities. However, current state-of-the-art solutions are based on
  U-Net, which can-not segment the flood pixels accurately due to the ambiguous
  pixels (e.g., tree canopies, clouds) that prevent a direct judgement from only
  the spectral features. Thanks to the digital elevation model (DEM) data readily
  available from sources such as United States Geological Survey (USGS), this
  work explores the use of an elevation map to improve flood extent mapping. We
  propose, EvaNet, an elevation-guided segmentation model based on the
  encoder-decoder architecture with two novel techniques: (1) a loss function
  encoding the physical law of gravity that if a location is flooded (resp. dry),
  then its adjacent locations with a lower (resp. higher) elevation must also be
  flooded (resp. dry); (2) a new (de)convolution operation that integrates the
  elevation map by a location sensitive gating mechanism to regulate how much
  spectral features flow through adjacent layers. Extensive experiments show that
  EvaNet significantly outperforms the U-Net baselines, and works as a perfect
  drop-in replacement for U-Net in existing solutions to flood extent mapping.
  </p>
  </div>
  </dd>
  <dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17918" title="Abstract">arXiv:2404.17918</a> [<a href="/pdf/2404.17918" title="Download PDF">pdf</a>, <a href="/format/2404.17918" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> I Have an Attention Bridge to Sell You: Generalization Capabilities of  Modular Translation Architectures
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mickus%2C+T">Timothee Mickus</a>, 
  <a href="/search/cs?searchtype=author&amp;query=V%C3%A1zquez%2C+R">Raúl Vázquez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Attieh%2C+J">Joseph Attieh</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Modularity is a paradigm of machine translation with the potential of
  bringing forth models that are large at training time and small during
  inference. Within this field of study, modular approaches, and in particular
  attention bridges, have been argued to improve the generalization capabilities
  of models by fostering language-independent representations. In the present
  paper, we study whether modularity affects translation quality; as well as how
  well modular architectures generalize across different evaluation scenarios.
  For a given computational budget, we find non-modular architectures to be
  always comparable or preferable to all modular designs we study.
  </p>
  </div>
  </dd>
  <dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17922" title="Abstract">arXiv:2404.17922</a> [<a href="/pdf/2404.17922" title="Download PDF">pdf</a>, <a href="/format/2404.17922" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Open-Set 3D Semantic Instance Maps for Vision Language Navigation --  O3D-SIM
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nanwani%2C+L">Laksh Nanwani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+K">Kumaraditya Gupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mathur%2C+A">Aditya Mathur</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agrawal%2C+S">Swayam Agrawal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hafez%2C+A+H+A">A.H. Abdul Hafez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Krishna%2C+K+M">K. Madhava Krishna</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
  
  </div>
  <p class="mathjax">Humans excel at forming mental maps of their surroundings, equipping them to
  understand object relationships and navigate based on language queries. Our
  previous work SI Maps [1] showed that having instance-level information and the
  semantic understanding of an environment helps significantly improve
  performance for language-guided tasks. We extend this instance-level approach
  to 3D while increasing the pipeline's robustness and improving quantitative and
  qualitative results. Our method leverages foundational models for object
  recognition, image segmentation, and feature extraction. We propose a
  representation that results in a 3D point cloud map with instance-level
  embeddings, which bring in the semantic understanding that natural language
  commands can query. Quantitatively, the work improves upon the success rate of
  language-guided tasks. At the same time, we qualitatively observe the ability
  to identify instances more clearly and leverage the foundational models and
  language and image-aligned embeddings to identify objects that, otherwise, a
  closed-set approach wouldn't be able to identify.
  </p>
  </div>
  </dd>
  <dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17924" title="Abstract">arXiv:2404.17924</a> [<a href="/pdf/2404.17924" title="Download PDF">pdf</a>, <a href="/format/2404.17924" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Results about sets of desirable gamble sets
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Campbell-Moore%2C+C">Catrin Campbell-Moore</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT)
  
  </div>
  <p class="mathjax">Coherent sets of desirable gamble sets is used as a model for representing an
  agents opinions and choice preferences under uncertainty. In this paper we
  provide some results about the axioms required for coherence and the natural
  extension of a given set of desirable gamble sets. We also show that coherent
  sets of desirable gamble sets can be represented by a proper filter of coherent
  sets of desirable gambles.
  </p>
  </div>
  </dd>
  <dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17925" title="Abstract">arXiv:2404.17925</a> [<a href="/pdf/2404.17925" title="Download PDF">pdf</a>, <a href="/format/2404.17925" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Accurate and fast anomaly detection in industrial processes and IoT  environments
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tonini%2C+S">Simone Tonini</a> (1), 
  <a href="/search/cs?searchtype=author&amp;query=Vandin%2C+A">Andrea Vandin</a> (1), 
  <a href="/search/cs?searchtype=author&amp;query=Chiaromonte%2C+F">Francesca Chiaromonte</a> (1 and 2), 
  <a href="/search/cs?searchtype=author&amp;query=Licari%2C+D">Daniele Licari</a> (3), 
  <a href="/search/cs?searchtype=author&amp;query=Barsacchi%2C+F">Fernando Barsacchi</a> (4) ((1) L'EMbeDS and Institute of Economics, Sant'Anna School of Advanced Studies, Pisa, (2) Dept. of Statistics, The Pennsylvania State University, (3) L'EMbeDS, Sant'Anna School of Advanced Studies, (4) A. Celli Group, Lucca)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)
  
  </div>
  <p class="mathjax">We present a novel, simple and widely applicable semi-supervised procedure
  for anomaly detection in industrial and IoT environments, SAnD (Simple Anomaly
  Detection). SAnD comprises 5 steps, each leveraging well-known statistical
  tools, namely; smoothing filters, variance inflation factors, the Mahalanobis
  distance, threshold selection algorithms and feature importance techniques. To
  our knowledge, SAnD is the first procedure that integrates these tools to
  identify anomalies and help decipher their putative causes. We show how each
  step contributes to tackling technical challenges that practitioners face when
  detecting anomalies in industrial contexts, where signals can be highly
  multicollinear, have unknown distributions, and intertwine short-lived noise
  with the long(er)-lived actual anomalies. The development of SAnD was motivated
  by a concrete case study from our industrial partner, which we use here to show
  its effectiveness. We also evaluate the performance of SAnD by comparing it
  with a selection of semi-supervised methods on public datasets from the
  literature on anomaly detection. We conclude that SAnD is effective, broadly
  applicable, and outperforms existing approaches in both anomaly detection and
  runtime.
  </p>
  </div>
  </dd>
  <dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17927" title="Abstract">arXiv:2404.17927</a> [<a href="/pdf/2404.17927" title="Download PDF">pdf</a>, <a href="/format/2404.17927" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Approximation and FPT Algorithms for Finding DM-Irreducible Spanning  Subgraphs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Norose%2C+R">Ryoma Norose</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yamaguchi%2C+Y">Yutaro Yamaguchi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages, 1 figure
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)
  
  </div>
  <p class="mathjax">Finding a minimum strongly connected spanning subgraph of a given directed
  graph generalizes the well-known strong connectivity augmentation problem, and
  it is NP-hard. For the weighted problem, a simple <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-82-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-598" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-599"><span class="mn" id="MathJax-Span-600" style="font-family: STIXGeneral-Regular;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-82">2</script>-approximation algorithm
  was proposed by Frederickson and J\'{a}j\'{a} (1981); surprisingly, it still
  achieves the best known approximation ratio in general. Also, the unweighted
  problem was shown to be FPT by Bang-Jensen and Yeo (2008), where the parameter
  is the difference from the trivial upper bound of the optimal value. In this
  paper, we consider a generalized problem related to the Dulmage--Mendelsohn
  decompositions of bipartite graphs instead of the strong connectivity of
  directed graphs, and extend the above approximation and FPT results to this
  setting.
  </p>
  </div>
  </dd>
  <dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17929" title="Abstract">arXiv:2404.17929</a> [<a href="/pdf/2404.17929" title="Download PDF">pdf</a>, <a href="/format/2404.17929" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Spatio-Temporal Side Tuning Pre-trained Foundation Models for  Video-based Pedestrian Attribute Recognition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qian Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jin%2C+J">Jiandong Jin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jun Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+F">Futian Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+B">Bo Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yaowei Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yonghong Tian</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Parameter Efficient Fine-Tuning Strategy for Video-based Pedestrian Attribute Recognition
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  <p class="mathjax">Existing pedestrian attribute recognition (PAR) algorithms are mainly
  developed based on a static image, however, the performance is unreliable in
  challenging scenarios, such as heavy occlusion, motion blur, etc. In this work,
  we propose to understand human attributes using video frames that can fully use
  temporal information by fine-tuning a pre-trained multi-modal foundation model
  efficiently. Specifically, we formulate the video-based PAR as a
  vision-language fusion problem and adopt a pre-trained foundation model CLIP to
  extract the visual features. More importantly, we propose a novel
  spatiotemporal side-tuning strategy to achieve parameter-efficient optimization
  of the pre-trained vision foundation model. To better utilize the semantic
  information, we take the full attribute list that needs to be recognized as
  another input and transform the attribute words/phrases into the corresponding
  sentence via split, expand, and prompt operations. Then, the text encoder of
  CLIP is utilized for embedding processed attribute descriptions. The averaged
  visual tokens and text tokens are concatenated and fed into a fusion
  Transformer for multi-modal interactive learning. The enhanced tokens will be
  fed into a classification head for pedestrian attribute prediction. Extensive
  experiments on two large-scale video-based PAR datasets fully validated the
  effectiveness of our proposed framework. The source code of this paper is
  available at https://github.com/Event-AHU/OpenPAR.
  </p>
  </div>
  </dd>
  <dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17930" title="Abstract">arXiv:2404.17930</a> [<a href="/pdf/2404.17930" title="Download PDF">pdf</a>, <a href="/format/2404.17930" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-Stream Cellular Test-Time Adaptation of Real-Time Models Evolving  in Dynamic Environments
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=G%C3%A9rin%2C+B">Benoît Gérin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Halin%2C+A">Anaïs Halin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cioppa%2C+A">Anthony Cioppa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Henry%2C+M">Maxim Henry</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ghanem%2C+B">Bernard Ghanem</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Macq%2C+B">Benoît Macq</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Vleeschouwer%2C+C">Christophe De Vleeschouwer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Van+Droogenbroeck%2C+M">Marc Van Droogenbroeck</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)
  
  </div>
  <p class="mathjax">In the era of the Internet of Things (IoT), objects connect through a dynamic
  network, empowered by technologies like 5G, enabling real-time data sharing.
  However, smart objects, notably autonomous vehicles, face challenges in
  critical local computations due to limited resources. Lightweight AI models
  offer a solution but struggle with diverse data distributions. To address this
  limitation, we propose a novel Multi-Stream Cellular Test-Time Adaptation
  (MSC-TTA) setup where models adapt on the fly to a dynamic environment divided
  into cells. Then, we propose a real-time adaptive student-teacher method that
  leverages the multiple streams available in each cell to quickly adapt to
  changing data distributions. We validate our methodology in the context of
  autonomous vehicles navigating across cells defined based on location and
  weather conditions. To facilitate future benchmarking, we release a new
  multi-stream large-scale synthetic semantic segmentation dataset, called DADE,
  and show that our multi-stream approach outperforms a single-stream baseline.
  We believe that our work will open research opportunities in the IoT and 5G
  eras, offering solutions for real-time model adaptation.
  </p>
  </div>
  </dd>
  <dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17931" title="Abstract">arXiv:2404.17931</a> [<a href="/pdf/2404.17931" title="Download PDF">pdf</a>, <a href="/ps/2404.17931" title="Download PostScript">ps</a>, <a href="/format/2404.17931" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Critical Review for One-class Classification: recent advances and the  reality behind them
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hayashi%2C+T">Toshitaka Hayashi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cimr%2C+D">Dalibor Cimr</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fujita%2C+H">Hamido Fujita</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cimler%2C+R">Richard Cimler</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">This paper offers a comprehensive review of one-class classification (OCC),
  examining the technologies and methodologies employed in its implementation. It
  delves into various approaches utilized for OCC across diverse data types, such
  as feature data, image, video, time series, and others. Through a systematic
  review, this paper synthesizes promi-nent strategies used in OCC from its
  inception to its current advance-ments, with a particular emphasis on the
  promising application. Moreo-ver, the article criticizes the state-of-the-art
  (SOTA) image anomaly de-tection (AD) algorithms dominating one-class
  experiments. These algo-rithms include outlier exposure (binary classification)
  and pretrained model (multi-class classification), conflicting with the
  fundamental con-cept of learning from one class. Our investigation reveals that
  the top nine algorithms for one-class CIFAR10 benchmark are not OCC. We ar-gue
  that binary/multi-class classification algorithms should not be com-pared with
  OCC.
  </p>
  </div>
  </dd>
  <dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17936" title="Abstract">arXiv:2404.17936</a> [<a href="/pdf/2404.17936" title="Download PDF">pdf</a>, <a href="/format/2404.17936" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FDCE-Net: Underwater Image Enhancement with Embedding Frequency and Dual  Color Encoder
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Z">Zheng Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+G">Guodong Fan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jingchun Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gan%2C+M">Min Gan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C+L+P">C. L. Philip Chen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 16pages,13 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Underwater images often suffer from various issues such as low brightness,
  color shift, blurred details, and noise due to light absorption and scattering
  caused by water and suspended particles. Previous underwater image enhancement
  (UIE) methods have primarily focused on spatial domain enhancement, neglecting
  the frequency domain information inherent in the images. However, the
  degradation factors of underwater images are closely intertwined in the spatial
  domain. Although certain methods focus on enhancing images in the frequency
  domain, they overlook the inherent relationship between the image degradation
  factors and the information present in the frequency domain. As a result, these
  methods frequently enhance certain attributes of the improved image while
  inadequately addressing or even exacerbating other attributes. Moreover, many
  existing methods heavily rely on prior knowledge to address color shift
  problems in underwater images, limiting their flexibility and robustness. In
  order to overcome these limitations, we propose the Embedding Frequency and
  Dual Color Encoder Network (FDCE-Net) in our paper. The FDCE-Net consists of
  two main structures: (1) Frequency Spatial Network (FS-Net) aims to achieve
  initial enhancement by utilizing our designed Frequency Spatial Residual Block
  (FSRB) to decouple image degradation factors in the frequency domain and
  enhance different attributes separately. (2) To tackle the color shift issue,
  we introduce the Dual-Color Encoder (DCE). The DCE establishes correlations
  between color and semantic representations through cross-attention and
  leverages multi-scale image features to guide the optimization of adaptive
  color query. The final enhanced images are generated by combining the outputs
  of FS-Net and DCE through a fusion network. These images exhibit rich details,
  clear textures, low noise and natural colors.
  </p>
  </div>
  </dd>
  <dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17937" title="Abstract">arXiv:2404.17937</a> [<a href="/pdf/2404.17937" title="Download PDF">pdf</a>, <a href="/format/2404.17937" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DTization: A New Method for Supervised Feature Scaling
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Islam%2C+N">Niful Islam</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Artificial intelligence is currently a dominant force in shaping various
  aspects of the world. Machine learning is a sub-field in artificial
  intelligence. Feature scaling is one of the data pre-processing techniques that
  improves the performance of machine learning algorithms. The traditional
  feature scaling techniques are unsupervised where they do not have influence of
  the dependent variable in the scaling process. In this paper, we have presented
  a novel feature scaling technique named DTization that employs decision tree
  and robust scaler for supervised feature scaling. The proposed method utilizes
  decision tree to measure the feature importance and based on the importance,
  different features get scaled differently with the robust scaler algorithm. The
  proposed method has been extensively evaluated on ten classification and
  regression datasets on various evaluation matrices and the results show a
  noteworthy performance improvement compared to the traditional feature scaling
  methods.
  </p>
  </div>
  </dd>
  <dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17940" title="Abstract">arXiv:2404.17940</a> [<a href="/pdf/2404.17940" title="Download PDF">pdf</a>, <a href="/ps/2404.17940" title="Download PostScript">ps</a>, <a href="/format/2404.17940" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CBMAP: Clustering-based manifold approximation and projection for  dimensionality reduction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dogan%2C+B">Berat Dogan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Dimensionality reduction methods are employed to decrease data
  dimensionality, either to enhance machine learning performance or to facilitate
  data visualization in two or three-dimensional spaces. These methods typically
  fall into two categories: feature selection and feature transformation. Feature
  selection retains significant features, while feature transformation projects
  data into a lower-dimensional space, with linear and nonlinear methods. While
  nonlinear methods excel in preserving local structures and capturing nonlinear
  relationships, they may struggle with interpreting global structures and can be
  computationally intensive. Recent algorithms, such as the t-SNE, UMAP, TriMap,
  and PaCMAP prioritize preserving local structures, often at the expense of
  accurately representing global structures, leading to clusters being spread out
  more in lower-dimensional spaces. Moreover, these methods heavily rely on
  hyperparameters, making their results sensitive to parameter settings. To
  address these limitations, this study introduces a clustering-based approach,
  namely CBMAP (Clustering-Based Manifold Approximation and Projection), for
  dimensionality reduction. CBMAP aims to preserve both global and local
  structures, ensuring that clusters in lower-dimensional spaces closely resemble
  those in high-dimensional spaces. Experimental evaluations on benchmark
  datasets demonstrate CBMAP's efficacy, offering speed, scalability, and minimal
  reliance on hyperparameters. Importantly, CBMAP enables low-dimensional
  projection of test data, addressing a critical need in machine learning
  applications. CBMAP is made freely available at
  https://github.com/doganlab/cbmap and can be installed from the Python Package
  Directory (PyPI) software repository with the command pip install cbmap.
  </p>
  </div>
  </dd>
  <dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17943" title="Abstract">arXiv:2404.17943</a> [<a href="/pdf/2404.17943" title="Download PDF">pdf</a>, <a href="/format/2404.17943" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Interaction Event Forecasting in Multi-Relational Recursive HyperGraphs:  A Temporal Point Process Approach
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gracious%2C+T">Tony Gracious</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dukkipati%2C+A">Ambedkar Dukkipati</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 4 figures, 5 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)
  
  </div>
  <p class="mathjax">Modeling the dynamics of interacting entities using an evolving graph is an
  essential problem in fields such as financial networks and e-commerce.
  Traditional approaches focus primarily on pairwise interactions, limiting their
  ability to capture the complexity of real-world interactions involving multiple
  entities and their intricate relationship structures. This work addresses the
  problem of forecasting higher-order interaction events in multi-relational
  recursive hypergraphs. This is done using a dynamic graph representation
  learning framework that can capture complex relationships involving multiple
  entities. The proposed model, \textit{Relational Recursive Hyperedge Temporal
  Point Process} (RRHyperTPP) uses an encoder that learns a dynamic node
  representation based on the historical interaction patterns and then a
  hyperedge link prediction based decoder to model the event's occurrence. These
  learned representations are then used for downstream tasks involving
  forecasting the type and time of interactions. The main challenge in learning
  from hyperedge events is that the number of possible hyperedges grows
  exponentially with the number of nodes in the network. This will make the
  computation of negative log-likelihood of the temporal point process expensive,
  as the calculation of survival function requires a summation over all possible
  hyperedges. In our work, we use noise contrastive estimation to learn the
  parameters of our model, and we have experimentally shown that our models
  perform better than previous state-of-the-art methods for interaction
  forecasting.
  </p>
  </div>
  </dd>
  <dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17944" title="Abstract">arXiv:2404.17944</a> [<a href="/pdf/2404.17944" title="Download PDF">pdf</a>, <a href="/ps/2404.17944" title="Download PostScript">ps</a>, <a href="/format/2404.17944" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mobile Edge Computing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ahmed%2C+S">Sohaib Ahmed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khalid%2C+H">Hassan Khalid</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hamza%2C+M">Muhammad Hamza</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Farhat%2C+D">Danyal Farhat</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages, 5 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>
  
  </div>
  <p class="mathjax">Mobile Edge Computing (MEC) has emerged as a solution to the high latency and
  suboptimal Quality of Experience (QoE) associated with Mobile Cloud Computing
  (MCC). By processing data near the source, MEC reduces the need to send
  information to distant data centers, resulting in faster response times and
  lower latency. This paper explores the differences between MEC and traditional
  cloud computing, emphasizing architecture, data flow, and resource allocation.
  Key technologies like Network Function Virtualization (NFV) and
  Software-Defined Networking (SDN) are discussed for their role in achieving
  scalability and flexibility. Additionally, security and privacy challenges are
  addressed, underscoring the need for robust frameworks. We conclude with an
  examination of various edge computing applications and suggest future research
  directions to enhance the effectiveness and adoption of MEC in the evolving
  technological landscape.
  </p>
  </div>
  </dd>
  <dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17946" title="Abstract">arXiv:2404.17946</a> [<a href="/pdf/2404.17946" title="Download PDF">pdf</a>, <a href="/ps/2404.17946" title="Download PostScript">ps</a>, <a href="/format/2404.17946" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Geometric Characteristic in Phaseless Operator and Structured Matrix  Recovery
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+G">Gao Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Song Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">In this paper, we first propose a simple and unified approach to stability of
  phaseless operator to both amplitude and intensity measurement, both complex
  and real cases on arbitrary geometric set, thus characterizing the robust
  performance of phase retrieval via empirical minimization method. The unified
  analysis involves the random embedding of concave lifting operator on tangent
  space. Similarly, we investigate structured matrix recovery problem through the
  robust injectivity of linear rank one measurement operator on arbitrary matrix
  set. The core of our analysis lies in bounding the empirical chaos process. We
  introduce Talagrand's <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-83-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-601" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.398em, 1000.963em, 1.414em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-602"><span class="msubsup" id="MathJax-Span-603"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.407em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-604" style="font-family: STIXGeneral-Italic;">γ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.398em;"><span class="texatom" id="MathJax-Span-605"><span class="mrow" id="MathJax-Span-606"><span class="mi" id="MathJax-Span-607" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">α</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.906em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-83">\gamma_{\alpha}</script> functionals to characterize the
  relationship between the required number of measurements and the geometric
  constraints. Additionally, adversarial noise is generated to illustrate the
  recovery bounds are sharp in the above situations.
  </p>
  </div>
  </dd>
  <dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17947" title="Abstract">arXiv:2404.17947</a> [<a href="/pdf/2404.17947" title="Download PDF">pdf</a>, <a href="/format/2404.17947" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bounding the Expected Robustness of Graph Neural Networks Subject to  Node Feature Attacks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Abbahaddou%2C+Y">Yassine Abbahaddou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ennadir%2C+S">Sofiane Ennadir</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lutzeyer%2C+J+F">Johannes F. Lutzeyer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vazirgiannis%2C+M">Michalis Vazirgiannis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bostr%C3%B6m%2C+H">Henrik Boström</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at ICLR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
  
  </div>
  <p class="mathjax">Graph Neural Networks (GNNs) have demonstrated state-of-the-art performance
  in various graph representation learning tasks. Recently, studies revealed
  their vulnerability to adversarial attacks. In this work, we theoretically
  define the concept of expected robustness in the context of attributed graphs
  and relate it to the classical definition of adversarial robustness in the
  graph representation learning literature. Our definition allows us to derive an
  upper bound of the expected robustness of Graph Convolutional Networks (GCNs)
  and Graph Isomorphism Networks subject to node feature attacks. Building on
  these findings, we connect the expected robustness of GNNs to the
  orthonormality of their weight matrices and consequently propose an
  attack-independent, more robust variant of the GCN, called the Graph
  Convolutional Orthonormal Robust Networks (GCORNs). We further introduce a
  probabilistic method to estimate the expected robustness, which allows us to
  evaluate the effectiveness of GCORN on several real-world datasets.
  Experimental experiments showed that GCORN outperforms available defense
  methods. Our code is publicly available at:
  \href{https://github.com/Sennadir/GCORN}{https://github.com/Sennadir/GCORN}.
  </p>
  </div>
  </dd>
  <dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17949" title="Abstract">arXiv:2404.17949</a> [<a href="/pdf/2404.17949" title="Download PDF">pdf</a>, <a href="/format/2404.17949" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Transfer Learning Enhanced Single-choice Decision for Multi-choice  Question Answering
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cui%2C+C">Chenhao Cui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yufan Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+S">Shuangzhi Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhoujun Li</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 1 figures.This article supersedes <a href="/abs/2011.03292">arXiv:2011.03292</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Multi-choice Machine Reading Comprehension (MMRC) aims to select the correct
  answer from a set of options based on a given passage and question. The
  existing methods employ the pre-trained language model as the encoder, share
  and transfer knowledge through fine-tuning.These methods mainly focus on the
  design of exquisite mechanisms to effectively capture the relationships among
  the triplet of passage, question and answers. It is non-trivial but ignored to
  transfer knowledge from other MRC tasks such as SQuAD due to task specific of
  MMRC.In this paper, we reconstruct multi-choice to single-choice by training a
  binary classification to distinguish whether a certain answer is correct. Then
  select the option with the highest confidence score as the final answer. Our
  proposed method gets rid of the multi-choice framework and can leverage
  resources of other tasks. We construct our model based on the ALBERT-xxlarge
  model and evaluate it on the RACE and DREAM datasets. Experimental results show
  that our model performs better than multi-choice methods. In addition, by
  transferring knowledge from other kinds of MRC tasks, our model achieves
  state-of-the-art results in both single and ensemble settings.
  </p>
  </div>
  </dd>
  <dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17951" title="Abstract">arXiv:2404.17951</a> [<a href="/pdf/2404.17951" title="Download PDF">pdf</a>, <a href="/format/2404.17951" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Cauchy-Schwarz Divergence Information Bottleneck for Regression
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+S">Shujian Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+X">Xi Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=L%C3%B8kse%2C+S">Sigurd Løkse</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jenssen%2C+R">Robert Jenssen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Principe%2C+J+C">Jose C. Principe</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> accepted by ICLR-24, project page: \url{<a href="https://github.com/SJYuCNEL/Cauchy-Schwarz-Information-Bottleneck">this https URL</a>}
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">The information bottleneck (IB) approach is popular to improve the
  generalization, robustness and explainability of deep neural networks.
  Essentially, it aims to find a minimum sufficient representation <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-84-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-608" style="width: 0.454em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.342em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.753em, 1000.342em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-609"><span class="texatom" id="MathJax-Span-610"><span class="mrow" id="MathJax-Span-611"><span class="mi" id="MathJax-Span-612" style="font-family: STIXGeneral; font-weight: bold;">t</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.906em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-84">\mathbf{t}</script>
  by striking a trade-off between a compression term <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-85-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-613" style="width: 2.939em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.374em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.318em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-614"><span class="mi" id="MathJax-Span-615" style="font-family: STIXGeneral-Italic;">I<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-616" style="font-family: STIXGeneral-Regular;">(</span><span class="texatom" id="MathJax-Span-617"><span class="mrow" id="MathJax-Span-618"><span class="mi" id="MathJax-Span-619" style="font-family: STIXGeneral; font-weight: bold;">x</span></span></span><span class="mo" id="MathJax-Span-620" style="font-family: STIXGeneral-Regular;">;</span><span class="texatom" id="MathJax-Span-621" style="padding-left: 0.172em;"><span class="mrow" id="MathJax-Span-622"><span class="mi" id="MathJax-Span-623" style="font-family: STIXGeneral; font-weight: bold;">t</span></span></span><span class="mo" id="MathJax-Span-624" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-85">I(\mathbf{x};\mathbf{t})</script>
  and a prediction term <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-86-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-625" style="width: 2.882em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.261em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-626"><span class="mi" id="MathJax-Span-627" style="font-family: STIXGeneral-Italic;">I<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-628" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-629" style="font-family: STIXGeneral-Italic;">y</span><span class="mo" id="MathJax-Span-630" style="font-family: STIXGeneral-Regular;">;</span><span class="texatom" id="MathJax-Span-631" style="padding-left: 0.172em;"><span class="mrow" id="MathJax-Span-632"><span class="mi" id="MathJax-Span-633" style="font-family: STIXGeneral; font-weight: bold;">t</span></span></span><span class="mo" id="MathJax-Span-634" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-86">I(y;\mathbf{t})</script>, where <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-87-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-635" style="width: 2.6em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.092em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.035em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-636"><span class="mi" id="MathJax-Span-637" style="font-family: STIXGeneral-Italic;">I<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-638" style="font-family: STIXGeneral-Regular;">(</span><span class="mo" id="MathJax-Span-639" style="font-family: STIXGeneral-Regular;">⋅</span><span class="mo" id="MathJax-Span-640" style="font-family: STIXGeneral-Regular;">;</span><span class="mo" id="MathJax-Span-641" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">⋅</span><span class="mo" id="MathJax-Span-642" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-87">I(\cdot;\cdot)</script> refers to the
  mutual information (MI). MI is for the IB for the most part expressed in terms
  of the Kullback-Leibler (KL) divergence, which in the regression case
  corresponds to prediction based on mean squared error (MSE) loss with Gaussian
  assumption and compression approximated by variational inference. In this
  paper, we study the IB principle for the regression problem and develop a new
  way to parameterize the IB with deep neural networks by exploiting favorable
  properties of the Cauchy-Schwarz (CS) divergence. By doing so, we move away
  from MSE-based regression and ease estimation by avoiding variational
  approximations or distributional assumptions. We investigate the improved
  generalization ability of our proposed CS-IB and demonstrate strong adversarial
  robustness guarantees. We demonstrate its superior performance on six
  real-world regression tasks over other popular deep IB approaches. We
  additionally observe that the solutions discovered by CS-IB always achieve the
  best trade-off between prediction accuracy and compression ratio in the
  information plane. The code is available at
  \url{https://github.com/SJYuCNEL/Cauchy-Schwarz-Information-Bottleneck}.
  </p>
  </div>
  </dd>
  <dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17954" title="Abstract">arXiv:2404.17954</a> [<a href="/pdf/2404.17954" title="Download PDF">pdf</a>, <a href="/format/2404.17954" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Parameterized Linear Time Transitive Closure
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kritikakis%2C+G">Giorgos Kritikakis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tollis%2C+I+G">Ioannis G Tollis</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2212.03945">arXiv:2212.03945</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  <p class="mathjax">Inquiries such as whether a task A depends on a task B, whether an author A
  has been influenced by a paper B, whether a certain protein is associated with
  a specific biological process or molecular function, or whether class A
  inherits from class B, are just a few examples of inquiries that can be modeled
  as reachability queries on a network (Directed Graph). Digital systems answer
  myriad such inquiries every day.
  <br>In this paper, we discuss the transitive closure problem. We focus on
  applicable solutions that enable us to answer queries fast, in constant time,
  and can serve in real-world applications. In contrast to the majority of
  research on this topic that revolves around the construction of a
  two-dimensional adjacency matrix, we present an approach that builds a
  reachability indexing scheme. This scheme enables us to answer queries in
  constant time and can be built in parameterized linear time. In addition, it
  captures a compressed data structure. Our approach and algorithms are validated
  by extensive experiments that shed light on the factors that play a key role in
  this problem. To stress the efficiency of this solution and demonstrate the
  potential to apply our approach to important problems, we use it algorithm to
  speed up Fulkerson's method for finding the width of a DAG. Our results
  challenge the prevailing belief, reiterated over the last thirty years,
  regarding the efficiency of this method.
  <br>Our approach is based on the concept of chain decomposition. Before we delve
  into its description, we introduce, analyze, and utilize a chain decomposition
  algorithm. Furthermore, we explore how chain decomposition can facilitate
  transitive closure solutions introducing a general purpose linear time
  reduction technique that removes a large subset of transitive edges given any
  chain decomposition.
  </p>
  </div>
  </dd>
  <dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17955" title="Abstract">arXiv:2404.17955</a> [<a href="/pdf/2404.17955" title="Download PDF">pdf</a>, <a href="/format/2404.17955" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Survey of Third-Party Library Security Research in Application  Software
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+J">Jia Zeng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+D">Dan Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yaling Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yangzhong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Weng%2C+F">Fangchen Weng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 21 pages, 3 figures, one table
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">In the current software development environment, third-party libraries play a
  crucial role. They provide developers with rich functionality and convenient
  solutions, speeding up the pace and efficiency of software development.
  However, with the widespread use of third-party libraries, associated security
  risks and potential vulnerabilities are increasingly apparent. Malicious
  attackers can exploit these vulnerabilities to infiltrate systems, execute
  unauthorized operations, or steal sensitive information, posing a severe threat
  to software security. Research on third-party libraries in software becomes
  paramount to address this growing security challenge. Numerous research
  findings exist regarding third-party libraries' usage, ecosystem, detection,
  and fortification defenses. Understanding the usage and ecosystem of
  third-party libraries helps developers comprehend the potential risks they
  bring and select trustworthy libraries. Third-party library detection tools aid
  developers in automatically discovering third-party libraries in software,
  facilitating their management. In addition to detection, fortification defenses
  are also indispensable. This article profoundly investigates and analyzes this
  literature, summarizing current research achievements and future development
  directions. It aims to provide practical and valuable insights for developers
  and researchers, jointly promoting the healthy development of software
  ecosystems and better-protecting software from security threats.
  </p>
  </div>
  </dd>
  <dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17958" title="Abstract">arXiv:2404.17958</a> [<a href="/pdf/2404.17958" title="Download PDF">pdf</a>, <a href="/format/2404.17958" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Continuous Linear Finite Element Method for Biharmonic Problems on  Surfaces
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Cai%2C+Y">Ying Cai</a>, 
  <a href="/search/math?searchtype=author&amp;query=Guo%2C+H">Hailong Guo</a>, 
  <a href="/search/math?searchtype=author&amp;query=Zhang%2C+Z">Zhimin Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">This paper presents an innovative continuous linear finite element approach
  to effectively solve biharmonic problems on surfaces. The key idea behind this
  method lies in the strategic utilization of a surface gradient recovery
  operator to compute the second-order surface derivative of a piecewise
  continuous linear function defined on the approximate surface, as conventional
  notions of second-order derivatives are not directly applicable in this
  context. By incorporating appropriate stabilizations, we rigorously establish
  the stability of the proposed formulation. Despite the presence of geometric
  error, we provide optimal error estimates in both the energy norm and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-88-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-643" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.076em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-644"><span class="msubsup" id="MathJax-Span-645"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-646" style="font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.624em;"><span class="mn" id="MathJax-Span-647" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-88">L^2</script>
  norm. Theoretical results are supported by numerical experiments.
  </p>
  </div>
  </dd>
  <dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17960" title="Abstract">arXiv:2404.17960</a> [<a href="/pdf/2404.17960" title="Download PDF">pdf</a>, <a href="/format/2404.17960" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PhishGuard: A Convolutional Neural Network Based Model for Detecting  Phishing URLs with Explainability Analysis
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Islam%2C+M+R">Md Robiul Islam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Islam%2C+M+M">Md Mahamodul Islam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Afrin%2C+M+S">Mst. Suraiya Afrin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Antara%2C+A">Anika Antara</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tabassum%2C+N">Nujhat Tabassum</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Amin%2C+A">Al Amin</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Cybersecurity is one of the global issues because of the extensive dependence
  on cyber systems of individuals, industries, and organizations. Among the cyber
  attacks, phishing is increasing tremendously and affecting the global economy.
  Therefore, this phenomenon highlights the vital need for enhancing user
  awareness and robust support at both individual and organizational levels.
  Phishing URL identification is the best way to address the problem. Various
  machine learning and deep learning methods have been proposed to automate the
  detection of phishing URLs. However, these approaches often need more
  convincing accuracy and rely on datasets consisting of limited samples.
  Furthermore, these black box intelligent models decision to detect suspicious
  URLs needs proper explanation to understand the features affecting the output.
  To address the issues, we propose a 1D Convolutional Neural Network (CNN) and
  trained the model with extensive features and a substantial amount of data. The
  proposed model outperforms existing works by attaining an accuracy of 99.85%.
  Additionally, our explainability analysis highlights certain features that
  significantly contribute to identifying the phishing URL.
  </p>
  </div>
  </dd>
  <dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17961" title="Abstract">arXiv:2404.17961</a> [<a href="/pdf/2404.17961" title="Download PDF">pdf</a>, <a href="/format/2404.17961" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Random Walk on Pixel Manifolds for Anomaly Segmentation of Complex  Driving Scenes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+Z">Zelong Zeng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tomite%2C+K">Kaname Tomite</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 23 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">In anomaly segmentation for complex driving scenes, state-of-the-art
  approaches utilize anomaly scoring functions to calculate anomaly scores. For
  these functions, accurately predicting the logits of inlier classes for each
  pixel is crucial for precisely inferring the anomaly score. However, in
  real-world driving scenarios, the diversity of scenes often results in
  distorted manifolds of pixel embeddings in embedding space. This effect is not
  conducive to directly using the pixel embeddings for the logit prediction
  during inference, a concern overlooked by existing methods. To address this
  problem, we propose a novel method called Random Walk on Pixel Manifolds
  (RWPM). RWPM utilizes random walks to reveal the intrinsic relationships among
  pixels to refine the pixel embeddings. The refined pixel embeddings alleviate
  the distortion of manifolds, improving the accuracy of anomaly scores. Our
  extensive experiments show that RWPM consistently improve the performance of
  the existing anomaly segmentation methods and achieve the best results. Code:
  \url{https://github.com/ZelongZeng/RWPM}.
  </p>
  </div>
  </dd>
  <dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17964" title="Abstract">arXiv:2404.17964</a> [<a href="/pdf/2404.17964" title="Download PDF">pdf</a>, <a href="/format/2404.17964" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Automating Zero-Shot Patch Porting for Hard Forks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+S">Shengyi Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">You Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhongxin Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+X">Xing Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xia%2C+X">Xin Xia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shanping Li</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by ISSTA 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Forking is a typical way of code reuse, which provides a simple way for
  developers to create a variant software (denoted as hard fork) by copying and
  modifying an existing codebase. Despite of the benefits, forking also leads to
  duplicate efforts in software maintenance. Developers need to port patches
  across the hard forks to address similar bugs or implement similar features.
  Due to the divergence between the source project and the hard fork, patch
  porting is complicated, which requires an adaption regarding different
  implementations of the same functionality. In this work, we take the first step
  to automate patch porting for hard forks under a zero-shot setting. We first
  conduct an empirical study of the patches ported from Vim to Neovim over the
  last ten years to investigate the necessities of patch porting and the
  potential flaws in the current practice. We then propose a large language model
  (LLM) based approach (namely PPatHF) to automatically port patches for hard
  forks on a function-wise basis. Specifically, PPatHF is composed of a reduction
  module and a porting module. Given the pre- and post-patch versions of a
  function from the reference project and the corresponding function from the
  target project, the reduction module first slims the input functions by
  removing code snippets less relevant to the patch. Then, the porting module
  leverages a LLM to apply the patch to the function from the target project. We
  evaluate PPatHF on 310 Neovim patches ported from Vim. The experimental results
  show that PPatHF outperforms the baselines significantly. Specifically, PPatHF
  can correctly port 131 (42.3%) patches and automate 57% of the manual edits
  required for the developer to port the patch.
  </p>
  </div>
  </dd>
  <dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17966" title="Abstract">arXiv:2404.17966</a> [<a href="/pdf/2404.17966" title="Download PDF">pdf</a>, <a href="/format/2404.17966" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Maximizing Patch Coverage for Testing of Highly-Configurable Software  without Exploding Build Times
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Y%C4%B1ld%C4%B1ran%2C+N+F">Necip Fazıl Yıldıran</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oh%2C+J">Jeho Oh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lawall%2C+J">Julia Lawall</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gazzillo%2C+P">Paul Gazzillo</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">The Linux kernel is highly-configurable, with a build system that takes a
  configuration file as input and automatically tailors the source code
  accordingly. Configurability, however, complicates testing, because different
  configuration options lead to the inclusion of different code fragments. With
  thousands of patches received per month, Linux kernel maintainers employ
  extensive automated continuous integration testing. To attempt patch coverage,
  i.e., taking all changed lines into account, current approaches either use
  configuration files that maximize total statement coverage or use multiple
  randomly-generated configuration files, both of which incur high build times
  without guaranteeing patch coverage. To achieve patch coverage without
  exploding build times, we propose krepair, which automatically repairs
  configuration files that are fast-building but have poor patch coverage to
  achieve high patch coverage with little effect on build times. krepair works by
  discovering a small set of changes to a configuration file that will ensure
  patch coverage, preserving most of the original configuration file's settings.
  Our evaluation shows that, when applied to configuration files with poor patch
  coverage on a statistically-significant sample of recent Linux kernel patches,
  krepair achieves nearly complete patch coverage, 98.5% on average, while
  changing less than 1.53% of the original default configuration file in 99% of
  patches, which keeps build times 10.5x faster than maximal configuration files.
  </p>
  </div>
  </dd>
  <dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17967" title="Abstract">arXiv:2404.17967</a> [<a href="/pdf/2404.17967" title="Download PDF">pdf</a>, <a href="/format/2404.17967" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SCorP: Statistics-Informed Dense Correspondence Prediction Directly from  Unsegmented Medical Images
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Iyer%2C+K">Krithika Iyer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Adams%2C+J">Jadie Adams</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Elhabian%2C+S+Y">Shireen Y. Elhabian</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Statistical shape modeling (SSM) is a powerful computational framework for
  quantifying and analyzing the geometric variability of anatomical structures,
  facilitating advancements in medical research, diagnostics, and treatment
  planning. Traditional methods for shape modeling from imaging data demand
  significant manual and computational resources. Additionally, these methods
  necessitate repeating the entire modeling pipeline to derive shape descriptors
  (e.g., surface-based point correspondences) for new data. While deep learning
  approaches have shown promise in streamlining the construction of SSMs on new
  data, they still rely on traditional techniques to supervise the training of
  the deep networks. Moreover, the predominant linearity assumption of
  traditional approaches restricts their efficacy, a limitation also inherited by
  deep learning models trained using optimized/established correspondences.
  Consequently, representing complex anatomies becomes challenging. To address
  these limitations, we introduce SCorP, a novel framework capable of predicting
  surface-based correspondences directly from unsegmented images. By leveraging
  the shape prior learned directly from surface meshes in an unsupervised manner,
  the proposed model eliminates the need for an optimized shape model for
  training supervision. The strong shape prior acts as a teacher and regularizes
  the feature learning of the student network to guide it in learning image-based
  features that are predictive of surface correspondences. The proposed model
  streamlines the training and inference phases by removing the supervision for
  the correspondence prediction task while alleviating the linearity assumption.
  </p>
  </div>
  </dd>
  <dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17968" title="Abstract">arXiv:2404.17968</a> [<a href="/pdf/2404.17968" title="Download PDF">pdf</a>, <a href="/format/2404.17968" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Usefulness of Emotional Prosody in Neural Machine Translation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Brazier%2C+C">Charles Brazier</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rouas%2C+J">Jean-Luc Rouas</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 5 pages, In Proceedings of the 11th International Conference on Speech Prosody (SP), Leiden, The Netherlands, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">Neural Machine Translation (NMT) is the task of translating a text from one
  language to another with the use of a trained neural network. Several existing
  works aim at incorporating external information into NMT models to improve or
  control predicted translations (e.g. sentiment, politeness, gender). In this
  work, we propose to improve translation quality by adding another external
  source of information: the automatically recognized emotion in the voice. This
  work is motivated by the assumption that each emotion is associated with a
  specific lexicon that can overlap between emotions. Our proposed method follows
  a two-stage procedure. At first, we select a state-of-the-art Speech Emotion
  Recognition (SER) model to predict dimensional emotion values from all input
  audio in the dataset. Then, we use these predicted emotions as source tokens
  added at the beginning of input texts to train our NMT model. We show that
  integrating emotion information, especially arousal, into NMT systems leads to
  better translations.
  </p>
  </div>
  </dd>
  <dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17970" title="Abstract">arXiv:2404.17970</a> [<a href="/pdf/2404.17970" title="Download PDF">pdf</a>, <a href="/format/2404.17970" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Privacy-Preserving Aggregation for Decentralized Learning with  Byzantine-Robustness
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ghavamipour%2C+A+R">Ali Reza Ghavamipour</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+B+Z+H">Benjamin Zi Hao Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ersoy%2C+O">Oguzhan Ersoy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Turkmen%2C+F">Fatih Turkmen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Decentralized machine learning (DL) has been receiving an increasing interest
  recently due to the elimination of a single point of failure, present in
  Federated learning setting. Yet, it is threatened by the looming threat of
  Byzantine clients who intentionally disrupt the learning process by
  broadcasting arbitrary model updates to other clients, seeking to degrade the
  performance of the global model. In response, robust aggregation schemes have
  emerged as promising solutions to defend against such Byzantine clients,
  thereby enhancing the robustness of Decentralized Learning. Defenses against
  Byzantine adversaries, however, typically require access to the updates of
  other clients, a counterproductive privacy trade-off that in turn increases the
  risk of inference attacks on those same model updates.
  <br>In this paper, we introduce SecureDL, a novel DL protocol designed to enhance
  the security and privacy of DL against Byzantine threats. SecureDL~facilitates
  a collaborative defense, while protecting the privacy of clients' model updates
  through secure multiparty computation. The protocol employs efficient
  computation of cosine similarity and normalization of updates to robustly
  detect and exclude model updates detrimental to model convergence. By using
  MNIST, Fashion-MNIST, SVHN and CIFAR-10 datasets, we evaluated SecureDL against
  various Byzantine attacks and compared its effectiveness with four existing
  defense mechanisms. Our experiments show that SecureDL is effective even in the
  case of attacks by the malicious majority (e.g., 80% Byzantine clients) while
  preserving high training accuracy.
  </p>
  </div>
  </dd>
  <dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17973" title="Abstract">arXiv:2404.17973</a> [<a href="/pdf/2404.17973" title="Download PDF">pdf</a>, <a href="/format/2404.17973" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Over-the-Air Fusion of Sparse Spatial Features for Integrated Sensing  and Edge AI over Broadband Channels
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiyan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lan%2C+Q">Qiao Lan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+K">Kaibin Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to IEEE for possible publication
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
  
  </div>
  <p class="mathjax">The 6G mobile networks are differentiated from 5G by two new usage scenarios
  - distributed sensing and edge AI. Their natural integration, termed integrated
  sensing and edge AI (ISEA), promised to create a platform for enabling
  environment perception to make intelligent decisions and take real-time
  actions. A basic operation in ISEA is for a fusion center to acquire and fuse
  features of spatial sensing data distributed at many agents. To overcome its
  communication bottleneck due to multiple access by numerous agents over hostile
  wireless channels, we propose a novel framework, called Spatial Over-the-Air
  Fusion (Spatial AirFusion), which exploits radio waveform superposition to
  aggregate spatially sparse features over the air. The technology is more
  sophisticated than conventional Over-the-Air Computing (AirComp) as it supports
  simultaneous aggregation over multiple voxels, which partition the 3D sensing
  region, and across multiple subcarriers. Its efficiency and robustness are
  derived from exploitation of both spatial feature sparsity and multiuser
  channel diversity to intelligently pair voxel-level aggregation tasks and
  subcarriers to maximize the minimum receive SNR among voxels under
  instantaneous power constraints. To optimally solve the mixed-integer
  Voxel-Carrier Pairing and Power Allocation (VoCa-PPA) problem, the proposed
  approach hinges on two useful results: (1) deriving the optimal power
  allocation as a closed-form function of voxel-carrier pairing and (2)
  discovering a useful property of VoCa-PPA that dramatically reduces the
  solution-space dimensionality. Both a low-complexity greedy algorithm and an
  optimal tree-search based approach are designed for VoCa-PPA. Extensive
  simulations using real datasets show that Spatial AirFusion achieves
  significant error reduction and accuracy improvement compared with conventional
  AirComp without awareness of spatial sparsity.
  </p>
  </div>
  </dd>
  <dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17974" title="Abstract">arXiv:2404.17974</a> [<a href="/pdf/2404.17974" title="Download PDF">pdf</a>, <a href="/format/2404.17974" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> HVOFusion: Incremental Mesh Reconstruction Using Hybrid Voxel Octree
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shaofan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Junbo Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jianke Zhu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Incremental scene reconstruction is essential to the navigation in robotics.
  Most of the conventional methods typically make use of either TSDF (truncated
  signed distance functions) volume or neural networks to implicitly represent
  the surface. Due to the voxel representation or involving with time-consuming
  sampling, they have difficulty in balancing speed, memory storage, and surface
  quality. In this paper, we propose a novel hybrid voxel-octree approach to
  effectively fuse octree with voxel structures so that we can take advantage of
  both implicit surface and explicit triangular mesh representation. Such sparse
  structure preserves triangular faces in the leaf nodes and produces partial
  meshes sequentially for incremental reconstruction. This storage scheme allows
  us to naturally optimize the mesh in explicit 3D space to achieve higher
  surface quality. We iteratively deform the mesh towards the target and recovers
  vertex colors by optimizing a shading model. Experimental results on several
  datasets show that our proposed approach is capable of quickly and accurately
  reconstructing a scene with realistic colors.
  </p>
  </div>
  </dd>
  <dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17975" title="Abstract">arXiv:2404.17975</a> [<a href="/pdf/2404.17975" title="Download PDF">pdf</a>, <a href="/ps/2404.17975" title="Download PostScript">ps</a>, <a href="/format/2404.17975" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Automating Customer Needs Analysis: A Comparative Study of Large  Language Models in the Travel Industry
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Barandoni%2C+S">Simone Barandoni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chiarello%2C+F">Filippo Chiarello</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cascone%2C+L">Lorenzo Cascone</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Marrale%2C+E">Emiliano Marrale</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Puccio%2C+S">Salvatore Puccio</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
  
  </div>
  <p class="mathjax">In the rapidly evolving landscape of Natural Language Processing (NLP), Large
  Language Models (LLMs) have emerged as powerful tools for many tasks, such as
  extracting valuable insights from vast amounts of textual data. In this study,
  we conduct a comparative analysis of LLMs for the extraction of travel customer
  needs from TripAdvisor posts. Leveraging a diverse range of models, including
  both open-source and proprietary ones such as GPT-4 and Gemini, we aim to
  elucidate their strengths and weaknesses in this specialized domain. Through an
  evaluation process involving metrics such as BERTScore, ROUGE, and BLEU, we
  assess the performance of each model in accurately identifying and summarizing
  customer needs. Our findings highlight the efficacy of opensource LLMs,
  particularly Mistral 7B, in achieving comparable performance to larger closed
  models while offering affordability and customization benefits. Additionally,
  we underscore the importance of considering factors such as model size,
  resource requirements, and performance metrics when selecting the most suitable
  LLM for customer needs analysis tasks. Overall, this study contributes valuable
  insights for businesses seeking to leverage advanced NLP techniques to enhance
  customer experience and drive operational efficiency in the travel industry.
  </p>
  </div>
  </dd>
  <dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17977" title="Abstract">arXiv:2404.17977</a> [<a href="/pdf/2404.17977" title="Download PDF">pdf</a>, <a href="/format/2404.17977" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Advancing Healthcare Automation: Multi-Agent Systems for Medical  Necessity Justification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pandey%2C+H">Himanshu Pandey</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Amod%2C+A">Akhil Amod</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shivang">Shivang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 5 pages, 4 figures. Work In Progress
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)
  
  </div>
  <p class="mathjax">This paper explores the application of Swarm-Structured Multi-Agent Systems
  (MAS) to establish medical necessity, a process that involves a systematic
  review of patient-specific medical structured and unstructured data against
  clinical guidelines. We addressed this complex task by decomposing it into
  smaller, more manageable sub-tasks. Each sub-task is handled by a specialized
  AI agent. We conduct a systematic study of the impact of various prompting
  strategies on these agents and benchmark different Large Language Models (LLMs)
  to determine their accuracy in completing these tasks. Additionally, we
  investigate how these agents can provide explainability, thereby enhancing
  trust and transparency within the system.
  </p>
  </div>
  </dd>
  <dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17978" title="Abstract">arXiv:2404.17978</a> [<a href="/pdf/2404.17978" title="Download PDF">pdf</a>, <a href="/format/2404.17978" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Method of Moments Embedding Constraint and its Application to  Semi-Supervised Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Majurski%2C+M">Michael Majurski</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Menon%2C+S">Sumeet Menon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Farvardin%2C+P">Parniyan Farvardin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chapman%2C+D">David Chapman</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Discriminative deep learning models with a linear+softmax final layer have a
  problem: the latent space only predicts the conditional probabilities <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-89-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-648" style="width: 3.503em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.826em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.769em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-649"><span class="mi" id="MathJax-Span-650" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-651" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-652" style="font-family: STIXGeneral-Italic;">Y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="texatom" id="MathJax-Span-653"><span class="mrow" id="MathJax-Span-654"><span class="mo" id="MathJax-Span-655" style="font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-656" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-657" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-89">p(Y|X)</script>
  but not the full joint distribution <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-90-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-658" style="width: 3.56em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.882em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.826em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-659"><span class="mi" id="MathJax-Span-660" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-661" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-662" style="font-family: STIXGeneral-Italic;">Y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-663" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-664" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-665" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-90">p(Y,X)</script>, which necessitates a generative
  approach. The conditional probability cannot detect outliers, causing outlier
  sensitivity in softmax networks. This exacerbates model over-confidence
  impacting many problems, such as hallucinations, confounding biases, and
  dependence on large datasets. To address this we introduce a novel embedding
  constraint based on the Method of Moments (MoM). We investigate the use of
  polynomial moments ranging from 1st through 4th order hyper-covariance
  matrices. Furthermore, we use this embedding constraint to train an
  Axis-Aligned Gaussian Mixture Model (AAGMM) final layer, which learns not only
  the conditional, but also the joint distribution of the latent space. We apply
  this method to the domain of semi-supervised image classification by extending
  FlexMatch with our technique. We find our MoM constraint with the AAGMM layer
  is able to match the reported FlexMatch accuracy, while also modeling the joint
  distribution, thereby reducing outlier sensitivity. We also present a
  preliminary outlier detection strategy based on Mahalanobis distance and
  discuss future improvements to this strategy. Code is available at:
  \url{https://github.com/mmajurski/ssl-gmm}
  </p>
  </div>
  </dd>
  <dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17980" title="Abstract">arXiv:2404.17980</a> [<a href="/pdf/2404.17980" title="Download PDF">pdf</a>, <a href="/format/2404.17980" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ALock: Asymmetric Lock Primitive for RDMA Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Baran%2C+A">Amanda Baran</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nelson-Slivon%2C+J">Jacob Nelson-Slivon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tseng%2C+L">Lewis Tseng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Palmieri%2C+R">Roberto Palmieri</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages, 6 figures, SPAA '24
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>
  
  </div>
  <p class="mathjax">Remote direct memory access (RDMA) networks are being rapidly adopted into
  industry for their high speed, low latency, and reduced CPU overheads compared
  to traditional kernel-based TCP/IP networks. RDMA enables threads to access
  remote memory without interacting with another process. However, atomicity
  between local accesses and remote accesses is not guaranteed by the technology,
  hence complicating synchronization significantly. The current solution is to
  require threads wanting to access local memory in an RDMA-accessible region to
  pass through the RDMA card using a mechanism known as loopback, but this can
  quickly degrade performance. In this paper, we introduce ALock, a novel locking
  primitive designed for RDMA-based systems. ALock allows programmers to
  synchronize local and remote accesses without using loopback or remote
  procedure calls (RPCs). We draw inspiration from the classic Peterson's
  algorithm to create a hierarchical design that includes embedded MCS locks for
  two cohorts, remote and local. To evaluate the ALock we implement a distributed
  lock table, measuring throughput and latency in various cluster configurations
  and workloads. In workloads with a majority of local operations, the ALock
  outperforms competitors up to 29x and achieves a latency up to 20x faster.
  </p>
  </div>
  </dd>
  <dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17983" title="Abstract">arXiv:2404.17983</a> [<a href="/pdf/2404.17983" title="Download PDF">pdf</a>, <a href="/format/2404.17983" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> TI-ASU: Toward Robust Automatic Speech Understanding through  Text-to-speech Imputation Against Missing Speech Modality
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+T">Tiantian Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+X">Xuan Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+R">Rahul Gupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Narayanan%2C+S+S">Shrikanth S. Narayanan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">Automatic Speech Understanding (ASU) aims at human-like speech
  interpretation, providing nuanced intent, emotion, sentiment, and content
  understanding from speech and language (text) content conveyed in speech.
  Typically, training a robust ASU model relies heavily on acquiring large-scale,
  high-quality speech and associated transcriptions. However, it is often
  challenging to collect or use speech data for training ASU due to concerns such
  as privacy. To approach this setting of enabling ASU when speech (audio)
  modality is missing, we propose TI-ASU, using a pre-trained text-to-speech
  model to impute the missing speech. We report extensive experiments evaluating
  TI-ASU on various missing scales, both multi- and single-modality settings, and
  the use of LLMs. Our findings show that TI-ASU yields substantial benefits to
  improve ASU in scenarios where even up to 95% of training speech is missing.
  Moreover, we show that TI-ASU is adaptive to dropout training, improving model
  robustness in addressing missing speech during inference.
  </p>
  </div>
  </dd>
  <dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17984" title="Abstract">arXiv:2404.17984</a> [<a href="/pdf/2404.17984" title="Download PDF">pdf</a>, <a href="/format/2404.17984" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Privacy-Preserving, Dropout-Resilient Aggregation in Decentralized  Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ghavamipour%2C+A+R">Ali Reza Ghavamipour</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+B+Z+H">Benjamin Zi Hao Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Turkmen%2C+F">Fatih Turkmen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Decentralized learning (DL) offers a novel paradigm in machine learning by
  distributing training across clients without central aggregation, enhancing
  scalability and efficiency. However, DL's peer-to-peer model raises challenges
  in protecting against inference attacks and privacy leaks. By forgoing central
  bottlenecks, DL demands privacy-preserving aggregation methods to protect data
  from 'honest but curious' clients and adversaries, maintaining network-wide
  privacy. Privacy-preserving DL faces the additional hurdle of client dropout,
  clients not submitting updates due to connectivity problems or unavailability,
  further complicating aggregation.
  <br>This work proposes three secret sharing-based dropout resilience approaches
  for privacy-preserving DL. Our study evaluates the efficiency, performance, and
  accuracy of these protocols through experiments on datasets such as MNIST,
  Fashion-MNIST, SVHN, and CIFAR-10. We compare our protocols with traditional
  secret-sharing solutions across scenarios, including those with up to 1000
  clients. Evaluations show that our protocols significantly outperform
  conventional methods, especially in scenarios with up to 30% of clients dropout
  and model sizes of up to <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-91-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-666" style="width: 1.81em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1001.471em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-667"><span class="msubsup" id="MathJax-Span-668"><span style="display: inline-block; position: relative; width: 1.414em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.963em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mn" id="MathJax-Span-669" style="font-family: STIXGeneral-Regular;">10</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.019em;"><span class="mn" id="MathJax-Span-670" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">6</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-91">10^6</script> parameters. Our approaches demonstrate markedly
  high efficiency with larger models, higher dropout rates, and extensive client
  networks, highlighting their effectiveness in enhancing decentralized learning
  systems' privacy and dropout robustness.
  </p>
  </div>
  </dd>
  <dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17985" title="Abstract">arXiv:2404.17985</a> [<a href="/pdf/2404.17985" title="Download PDF">pdf</a>, <a href="/format/2404.17985" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Detection of Conspiracy Theories Beyond Keyword Bias in German-Language  Telegram Using Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pustet%2C+M">Milena Pustet</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Steffen%2C+E">Elisabeth Steffen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mihaljevi%C4%87%2C+H">Helena Mihaljević</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the 8th Workshop on Online Abuse and Harms (WOAH), ACL 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)
  
  </div>
  <p class="mathjax">The automated detection of conspiracy theories online typically relies on
  supervised learning. However, creating respective training data requires
  expertise, time and mental resilience, given the often harmful content.
  Moreover, available datasets are predominantly in English and often
  keyword-based, introducing a token-level bias into the models. Our work
  addresses the task of detecting conspiracy theories in German Telegram
  messages. We compare the performance of supervised fine-tuning approaches using
  BERT-like models with prompt-based approaches using Llama2, GPT-3.5, and GPT-4
  which require little or no additional training data. We use a dataset of
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-92-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-671" style="width: 3.898em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.165em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.165em, 2.826em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-672"><span class="mo" id="MathJax-Span-673" style="font-family: STIXGeneral-Regular;">∼</span><span class="mspace" id="MathJax-Span-674" style="height: 0em; vertical-align: 0em; margin-left: -0.167em;"></span><span class="mspace" id="MathJax-Span-675" style="height: 0em; vertical-align: 0em; margin-left: -0.167em;"></span><span class="mn" id="MathJax-Span-676" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">4</span><span class="mo" id="MathJax-Span-677" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-678" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">000</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-92">\sim\!\! 4,000</script> messages collected during the COVID-19 pandemic, without the
  use of keyword filters.
  <br>Our findings demonstrate that both approaches can be leveraged effectively:
  For supervised fine-tuning, we report an F1 score of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-93-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-679" style="width: 2.431em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.979em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.922em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-680"><span class="mo" id="MathJax-Span-681" style="font-family: STIXGeneral-Regular;">∼</span><span class="mspace" id="MathJax-Span-682" style="height: 0em; vertical-align: 0em; margin-left: -0.167em;"></span><span class="mspace" id="MathJax-Span-683" style="height: 0em; vertical-align: 0em; margin-left: -0.167em;"></span><span class="mn" id="MathJax-Span-684" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">0.8</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-93">\sim\!\! 0.8</script> for the
  positive class, making our model comparable to recent models trained on
  keyword-focused English corpora. We demonstrate our model's adaptability to
  intra-domain temporal shifts, achieving F1 scores of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-94-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-685" style="width: 2.431em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.979em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.922em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-686"><span class="mo" id="MathJax-Span-687" style="font-family: STIXGeneral-Regular;">∼</span><span class="mspace" id="MathJax-Span-688" style="height: 0em; vertical-align: 0em; margin-left: -0.167em;"></span><span class="mspace" id="MathJax-Span-689" style="height: 0em; vertical-align: 0em; margin-left: -0.167em;"></span><span class="mn" id="MathJax-Span-690" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">0.7</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-94">\sim\!\! 0.7</script>. Among
  prompting variants, the best model is GPT-4, achieving an F1 score of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-95-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-691" style="width: 2.431em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.979em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.922em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-692"><span class="mo" id="MathJax-Span-693" style="font-family: STIXGeneral-Regular;">∼</span><span class="mspace" id="MathJax-Span-694" style="height: 0em; vertical-align: 0em; margin-left: -0.167em;"></span><span class="mspace" id="MathJax-Span-695" style="height: 0em; vertical-align: 0em; margin-left: -0.167em;"></span><span class="mn" id="MathJax-Span-696" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">0.8</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-95">\sim\!\!
  0.8</script> for the positive class in a zero-shot setting and equipped with a custom
  conspiracy theory definition.
  </p>
  </div>
  </dd>
  <dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17989" title="Abstract">arXiv:2404.17989</a> [<a href="/pdf/2404.17989" title="Download PDF">pdf</a>, <a href="/format/2404.17989" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> InfoSec.pptx: A Longitudinal Study of Speakers, Topics, and Sponsors at  Security Conferences in Academia and Industry
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Walter%2C+L">Lukas Walter</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sauerwein%2C+C">Clemens Sauerwein</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Woods%2C+D+W">Daniel W. Woods</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Code and data can be found in the repository: <a href="https://git.uibk.ac.at/csaw9252/master_thesis">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)
  
  </div>
  <p class="mathjax">Security conferences are important venues at which academics and
  practitioners share knowledge about new attacks and state-of-the-art defenses.
  Despite this, researchers have not studied who shares information and about
  which security topics. To address this, our study characterizes the speakers,
  sponsors, and topics presented at the most prestigious academic and industry
  conferences. We collect a longitudinal data set that contains 9,728 abstracts
  and 1,686 sponsors across 4 academic and 6 industry conferences. There is
  limited knowledge sharing between industry and academia. Conferences vary
  significantly in the equality of how talks/authorship is distributed across
  individuals. The topics of academic and industry abstracts display consistent
  coverage of techniques within the MITRE ATT&amp;CK framework. Top tier academic
  conferences, as well as DEFCON and Black Hat, inconsistently address the
  governance, response and recovery functions of the NIST Cybersecurity
  Framework. Commercial InfoSec and insurance conferences (RSA, Gartner, Advisen
  and NetDillgience) cover the framework more consistently. Prevention and
  detection remain the most common topic of talks, with no clear temporal trend.
  </p>
  </div>
  </dd>
  <dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17990" title="Abstract">arXiv:2404.17990</a> [<a href="/pdf/2404.17990" title="Download PDF">pdf</a>, <a href="/format/2404.17990" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> TabVFL: Improving Latent Representation in Vertical Federated Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rashad%2C+M">Mohamed Rashad</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zilong Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Decouchant%2C+J">Jeremie Decouchant</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L+Y">Lydia Y. Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
  
  </div>
  <p class="mathjax">Autoencoders are popular neural networks that are able to compress high
  dimensional data to extract relevant latent information. TabNet is a
  state-of-the-art neural network model designed for tabular data that utilizes
  an autoencoder architecture for training. Vertical Federated Learning (VFL) is
  an emerging distributed machine learning paradigm that allows multiple parties
  to train a model collaboratively on vertically partitioned data while
  maintaining data privacy. The existing design of training autoencoders in VFL
  is to train a separate autoencoder in each participant and aggregate the latent
  representation later. This design could potentially break important
  correlations between feature data of participating parties, as each autoencoder
  is trained on locally available features while disregarding the features of
  others. In addition, traditional autoencoders are not specifically designed for
  tabular data, which is ubiquitous in VFL settings. Moreover, the impact of
  client failures during training on the model robustness is under-researched in
  the VFL scene. In this paper, we propose TabVFL, a distributed framework
  designed to improve latent representation learning using the joint features of
  participants. The framework (i) preserves privacy by mitigating potential data
  leakage with the addition of a fully-connected layer, (ii) conserves feature
  correlations by learning one latent representation vector, and (iii) provides
  enhanced robustness against client failures during training phase. Extensive
  experiments on five classification datasets show that TabVFL can outperform the
  prior work design, with 26.12% of improvement on f1-score.
  </p>
  </div>
  </dd>
  <dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17991" title="Abstract">arXiv:2404.17991</a> [<a href="/pdf/2404.17991" title="Download PDF">pdf</a>, <a href="/format/2404.17991" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhancing Pre-Trained Generative Language Models with Question Attended  Span Extraction on Machine Reading Comprehension
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ai%2C+L">Lin Ai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hui%2C+Z">Zheng Hui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zizhou Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hirschberg%2C+J">Julia Hirschberg</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Machine Reading Comprehension (MRC) poses a significant challenge in the
  field of Natural Language Processing (NLP). While mainstream MRC methods
  predominantly leverage extractive strategies using encoder-only models such as
  BERT, generative approaches face the issue of out-of-control generation -- a
  critical problem where answers generated are often incorrect, irrelevant, or
  unfaithful to the source text. To address these limitations in generative
  models for MRC, we introduce the Question-Attended Span Extraction (QASE)
  module. Integrated during the fine-tuning phase of pre-trained generative
  language models (PLMs), QASE significantly enhances their performance, allowing
  them to surpass the extractive capabilities of advanced Large Language Models
  (LLMs) such as GPT-4. Notably, these gains in performance do not come with an
  increase in computational demands. The efficacy of the QASE module has been
  rigorously tested across various datasets, consistently achieving or even
  surpassing state-of-the-art (SOTA) results.
  </p>
  </div>
  </dd>
  <dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17993" title="Abstract">arXiv:2404.17993</a> [<a href="/pdf/2404.17993" title="Download PDF">pdf</a>, <a href="/format/2404.17993" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MinBackProp -- Backpropagating through Minimal Solvers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sungatullina%2C+D">Diana Sungatullina</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pajdla%2C+T">Tomas Pajdla</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">We present an approach to backpropagating through minimal problem solvers in
  end-to-end neural network training. Traditional methods relying on manually
  constructed formulas, finite differences, and autograd are laborious,
  approximate, and unstable for complex minimal problem solvers. We show that
  using the Implicit function theorem to calculate derivatives to backpropagate
  through the solution of a minimal problem solver is simple, fast, and stable.
  We compare our approach to (i) using the standard autograd on minimal problem
  solvers and relate it to existing backpropagation formulas through SVD-based
  and Eig-based solvers and (ii) implementing the backprop with an existing
  PyTorch Deep Declarative Networks (DDN) framework. We demonstrate our technique
  on a toy example of training outlier-rejection weights for 3D point
  registration and on a real application of training an outlier-rejection and
  RANSAC sampling network in image matching. Our method provides <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-96-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-697" style="width: 2.826em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.261em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.64em, 1002.205em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-698"><span class="mn" id="MathJax-Span-699" style="font-family: STIXGeneral-Regular;">100</span><span class="mi" id="MathJax-Span-700" style="font-family: STIXGeneral-Regular;">%</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-96">100\%</script>
  stability and is 10 times faster compared to autograd, which is unstable and
  slow, and compared to DDN, which is stable but also slow.
  </p>
  </div>
  </dd>
  <dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17996" title="Abstract">arXiv:2404.17996</a> [<a href="/pdf/2404.17996" title="Download PDF">pdf</a>, <a href="/format/2404.17996" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Variações do Problema de Distância de Rearranjos
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Alexandrino%2C+A+O">Alexsandro Oliveira Alexandrino</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> PhD Dissertation, in Portuguese, presented at the Institute of Computing - Unicamp in March 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Quantitative Methods (q-bio.QM)
  
  </div>
  <p class="mathjax">Considering a pair of genomes, the goal of rearrangement distance problems is
  to estimate how distant these genomes are from each other based on genome
  rearrangements. Seminal works in genome rearrangements assumed that both
  genomes being compared have the same set of genes (balanced genomes) and,
  furthermore, only the relative order of genes and their orientations, when they
  are known, are used in the mathematical representation of the genomes. In this
  case, the genomes are represented as permutations, originating the Sorting
  Permutations by Rearrangements problems. The main problems of Sorting
  Permutations by Rearrangements considered DCJs, reversals, transpositions, or
  the combination of both reversals and transpositions, and these problems have
  their complexity known. Besides these problems, other ones were studied
  involving the combination of transpositions with one or more of the following
  rearrangements: transreversals, revrevs, and reversals. Although there are
  approximation results for these problems, their complexity remained open. Some
  of the results of this thesis are the complexity proofs for these problems.
  Furthermore, we present a new 1.375-approximation algorithm, which has better
  time complexity, for the Sorting Permutations by Transpositions. When
  considering unbalanced genomes, it is necessary to use insertions and deletions
  to transform one genome into another. In this thesis, we studied Rearrangement
  Distance problems on unbalanced genomes considering only gene order and their
  orientations (when they are known), as well as Intergenic Rearrangement
  Distance problems, which incorporate the information regarding the size
  distribution of intergenic regions, besides the use of gene order and their
  orientations (when they are known). We present complexity proofs and
  approximation algorithms for problems that include reversals and
  transpositions.
  </p>
  </div>
  </dd>
  <dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17997" title="Abstract">arXiv:2404.17997</a> [<a href="/pdf/2404.17997" title="Download PDF">pdf</a>, <a href="/format/2404.17997" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Optimal Initialization of Batch Bayesian Optimization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+J">Jiuge Ren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sweet%2C+D">David Sweet</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 8 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">Field experiments and computer simulations are effective but time-consuming
  methods of measuring the quality of engineered systems at different settings.
  To reduce the total time required, experimenters may employ Bayesian
  optimization, which is parsimonious with measurements, and take measurements of
  multiple settings simultaneously, in a batch. In practice, experimenters use
  very few batches, thus, it is imperative that each batch be as informative as
  possible. Typically, the initial batch in a Batch Bayesian Optimization (BBO)
  is constructed from a quasi-random sample of settings values. We propose a
  batch-design acquisition function, Minimal Terminal Variance (MTV), that
  designs a batch by optimization rather than random sampling. MTV adapts a
  design criterion function from Design of Experiments, called I-Optimality,
  which minimizes the variance of the post-evaluation estimates of quality,
  integrated over the entire space of settings. MTV weights the integral by the
  probability that a setting is optimal, making it able to design not only an
  initial batch but all subsequent batches, as well. Applicability to both
  initialization and subsequent batches is novel among acquisition functions.
  Numerical experiments on test functions and simulators show that MTV compares
  favorably to other BBO methods.
  </p>
  </div>
  </dd>
  <dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17999" title="Abstract">arXiv:2404.17999</a> [<a href="/pdf/2404.17999" title="Download PDF">pdf</a>, <a href="/format/2404.17999" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Saeed%2C+N">Nadia Saeed</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 4 figures, Clinical NLP 2024 Workshop
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Accurate representation of medical information is crucial for patient safety,
  yet artificial intelligence (AI) systems, such as Large Language Models (LLMs),
  encounter challenges in error-free clinical text interpretation. This paper
  presents a novel approach submitted to the MEDIQA-CORR 2024 shared task (Ben
  Abacha et al., 2024a), focusing on the automatic correction of single-word
  errors in clinical notes. Unlike LLMs that rely on extensive generic data, our
  method emphasizes extracting contextually relevant information from available
  clinical text data. Leveraging an ensemble of extractive and abstractive
  question-answering approaches, we construct a supervised learning framework
  with domain-specific feature engineering. Our methodology incorporates domain
  expertise to enhance error correction accuracy. By integrating domain expertise
  and prioritizing meaningful information extraction, our approach underscores
  the significance of a human-centric strategy in adapting AI for healthcare.
  </p>
  </div>
  </dd>
  <dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18001" title="Abstract">arXiv:2404.18001</a> [<a href="/pdf/2404.18001" title="Download PDF">pdf</a>, <a href="/format/2404.18001" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LLMParser: An Exploratory Study on Using Large Language Models for Log  Parsing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zeyang Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+A+R">An Ran Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D+J">Dong Jae Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Tse-Hsun Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shaowei Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Logs are important in modern software development with runtime information.
  Log parsing is the first step in many log-based analyses, that involve
  extracting structured information from unstructured log data. Traditional log
  parsers face challenges in accurately parsing logs due to the diversity of log
  formats, which directly impacts the performance of downstream log-analysis
  tasks. In this paper, we explore the potential of using Large Language Models
  (LLMs) for log parsing and propose LLMParser, an LLM-based log parser based on
  generative LLMs and few-shot tuning. We leverage four LLMs, Flan-T5-small,
  Flan-T5-base, LLaMA-7B, and ChatGLM-6B in LLMParsers. Our evaluation of 16
  open-source systems shows that LLMParser achieves statistically significantly
  higher parsing accuracy than state-of-the-art parsers (a 96% average parsing
  accuracy). We further conduct a comprehensive empirical analysis on the effect
  of training size, model size, and pre-training LLM on log parsing accuracy. We
  find that smaller LLMs may be more effective than more complex LLMs; for
  instance where Flan-T5-base achieves comparable results as LLaMA-7B with a
  shorter inference time. We also find that using LLMs pre-trained using logs
  from other systems does not always improve parsing accuracy. While using
  pre-trained Flan-T5-base shows an improvement in accuracy, pre-trained LLaMA
  results in a decrease (decrease by almost 55% in group accuracy). In short, our
  study provides empirical evidence for using LLMs for log parsing and highlights
  the limitations and future research direction of LLM-based log parsers.
  </p>
  </div>
  </dd>
  <dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18002" title="Abstract">arXiv:2404.18002</a> [<a href="/pdf/2404.18002" title="Download PDF">pdf</a>, <a href="/format/2404.18002" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Privacy-Preserving Audio Classification Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chhaglani%2C+B">Bhawana Chhaglani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gummeson%2C+J">Jeremy Gummeson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shenoy%2C+P">Prashant Shenoy</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">Audio signals can reveal intimate details about a person's life, including
  their conversations, health status, emotions, location, and personal
  preferences. Unauthorized access or misuse of this information can have
  profound personal and social implications. In an era increasingly populated by
  devices capable of audio recording, safeguarding user privacy is a critical
  obligation. This work studies the ethical and privacy concerns in current audio
  classification systems. We discuss the challenges and research directions in
  designing privacy-preserving audio sensing systems. We propose
  privacy-preserving audio features that can be used to classify wide range of
  audio classes, while being privacy preserving.
  </p>
  </div>
  </dd>
  <dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18003" title="Abstract">arXiv:2404.18003</a> [<a href="/pdf/2404.18003" title="Download PDF">pdf</a>, <a href="/format/2404.18003" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Estimation of uncertainties in the density driven flow in fractured  porous media using MLMC
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Logashenko%2C+D">Dmitry Logashenko</a>, 
  <a href="/search/math?searchtype=author&amp;query=Litvinenko%2C+A">Alexander Litvinenko</a>, 
  <a href="/search/math?searchtype=author&amp;query=Tempone%2C+R">Raul Tempone</a>, 
  <a href="/search/math?searchtype=author&amp;query=Wittum%2C+G">Gabriel Wittum</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 25 pages, 4 tables, 7 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Computation (stat.CO)
  
  </div>
  <p class="mathjax">We use the Multi Level Monte Carlo method to estimate uncertainties in a
  Henry-like salt water intrusion problem with a fracture. The flow is induced by
  the variation of the density of the fluid phase, which depends on the mass
  fraction of salt. We assume that the fracture has a known fixed location but an
  uncertain aperture. Other input uncertainties are the porosity and permeability
  fields and the recharge. In our setting, porosity and permeability vary
  spatially and recharge is time-dependent. For each realisation of these
  uncertain parameters, the evolution of the mass fraction and pressure fields is
  modelled by a system of non-linear and time-dependent PDEs with a jump of the
  solution at the fracture. The uncertainties propagate into the distribution of
  the salt concentration, which is an important characteristic of the quality of
  water resources. We show that the multilevel Monte Carlo (MLMC) method is able
  to reduce the overall computational cost compared to classical Monte Carlo
  methods. This is achieved by balancing discretisation and statistical errors.
  Multiple scenarios are evaluated at different spatial and temporal mesh levels.
  The deterministic solver ug4 is run in parallel to calculate all stochastic
  scenarios.
  </p>
  </div>
  </dd>
  <dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18006" title="Abstract">arXiv:2404.18006</a> [<a href="/pdf/2404.18006" title="Download PDF">pdf</a>, <a href="/format/2404.18006" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FRAME: A Modular Framework for Autonomous Map-merging: Advancements in  the Field
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Stathoulopoulos%2C+N">Nikolaos Stathoulopoulos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lindqvist%2C+B">Björn Lindqvist</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Koval%2C+A">Anton Koval</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agha-mohammadi%2C+A">Ali-akbar Agha-mohammadi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nikolakopoulos%2C+G">George Nikolakopoulos</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 28 pages, 24 figures. Submitted to Field Robotics
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">In this article, a novel approach for merging 3D point cloud maps in the
  context of egocentric multi-robot exploration is presented. Unlike traditional
  methods, the proposed approach leverages state-of-the-art place recognition and
  learned descriptors to efficiently detect overlap between maps, eliminating the
  need for the time-consuming global feature extraction and feature matching
  process. The estimated overlapping regions are used to calculate a homogeneous
  rigid transform, which serves as an initial condition for the GICP point cloud
  registration algorithm to refine the alignment between the maps. The advantages
  of this approach include faster processing time, improved accuracy, and
  increased robustness in challenging environments. Furthermore, the
  effectiveness of the proposed framework is successfully demonstrated through
  multiple field missions of robot exploration in a variety of different
  underground environments.
  </p>
  </div>
  </dd>
  <dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18007" title="Abstract">arXiv:2404.18007</a> [<a href="/pdf/2404.18007" title="Download PDF">pdf</a>, <a href="/ps/2404.18007" title="Download PostScript">ps</a>, <a href="/format/2404.18007" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Formal Model to Prove Instantiation Termination for E-matching-Based  Axiomatisations (Extended Version)
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ge%2C+R">Rui Ge</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Garcia%2C+R">Ronald Garcia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Summers%2C+A+J">Alexander J. Summers</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> extended version of IJCAR 2024 publication
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  <p class="mathjax">SMT-based program analysis and verification often involve reasoning about
  program features that have been specified using quantifiers; incorporating
  quantifiers into SMT-based reasoning is, however, known to be challenging. If
  quantifier instantiation is not carefully controlled, then runtime and outcomes
  can be brittle and hard to predict. In particular, uncontrolled quantifier
  instantiation can lead to unexpected incompleteness and even non-termination.
  E-matching is the most widely-used approach for controlling quantifier
  instantiation, but when axiomatisations are complex, even experts cannot tell
  if their use of E-matching guarantees completeness or termination.
  <br>This paper presents a new formal model that facilitates the proof, once and
  for all, that giving a complex E-matching-based axiomatisation to an SMT
  solver, such as Z3 or cvc5, will not cause non-termination. Key to our
  technique is an operational semantics for solver behaviour that models how the
  E-matching rules common to most solvers are used to determine when quantifier
  instantiations are enabled, but abstracts over irrelevant details of individual
  solvers. We demonstrate the effectiveness of our technique by presenting a
  termination proof for a set theory axiomatisation adapted from those used in
  the Dafny and Viper verifiers.
  </p>
  </div>
  </dd>
  <dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18008" title="Abstract">arXiv:2404.18008</a> [<a href="/pdf/2404.18008" title="Download PDF">pdf</a>, <a href="/format/2404.18008" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Implicit Generative Prior for Bayesian Neural Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yijia Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)
  
  </div>
  <p class="mathjax">Predictive uncertainty quantification is crucial for reliable decision-making
  in various applied domains. Bayesian neural networks offer a powerful framework
  for this task. However, defining meaningful priors and ensuring computational
  efficiency remain significant challenges, especially for complex real-world
  applications. This paper addresses these challenges by proposing a novel neural
  adaptive empirical Bayes (NA-EB) framework. NA-EB leverages a class of implicit
  generative priors derived from low-dimensional distributions. This allows for
  efficient handling of complex data structures and effective capture of
  underlying relationships in real-world datasets. The proposed NA-EB framework
  combines variational inference with a gradient ascent algorithm. This enables
  simultaneous hyperparameter selection and approximation of the posterior
  distribution, leading to improved computational efficiency. We establish the
  theoretical foundation of the framework through posterior and classification
  consistency. We demonstrate the practical applications of our framework through
  extensive evaluations on a variety of tasks, including the two-spiral problem,
  regression, 10 UCI datasets, and image classification tasks on both MNIST and
  CIFAR-10 datasets. The results of our experiments highlight the superiority of
  our proposed framework over existing methods, such as sparse variational
  Bayesian and generative models, in terms of prediction accuracy and uncertainty
  quantification.
  </p>
  </div>
  </dd>
  <dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18012" title="Abstract">arXiv:2404.18012</a> [<a href="/pdf/2404.18012" title="Download PDF">pdf</a>, <a href="/ps/2404.18012" title="Download PostScript">ps</a>, <a href="/format/2404.18012" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Lessons Learned: The Evolution of an Undergraduate Robotics Course in  Computer Science
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Salas%2C+R+P">R. Pito Salas</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 11 pages, presented at Robotics in Education, 2024, in Koblenz, DE
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Seven years ago (2016), we began integrating Robotics into our Computer
  Science curriculum. This paper explores the mission, initial goals and
  objectives, specific choices we made along the way, and why and outcomes. Of
  course, we were not the first to do so. Our contribution in this paper is to
  describe a seven-year experience in the hope that others going down this road
  will benefit, perhaps avoiding some missteps and dead-ends. We offer our
  answers to many questions that anyone undertaking bootstrapping a new robotics
  program may have to deal with. At the end of the paper, we discuss a set of
  lessons learned, including striking the right balance between depth and breadth
  in syllabus design and material organization, the significance of utilizing
  physical robots and criteria for selecting a suitable robotics platform,
  insights into the scope and design of a robotics lab, the necessity of
  standardizing hardware and software configurations, along with implementation
  methods, and strategies for preparing students for the steep learning curve.
  </p>
  </div>
  </dd>
  <dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18013" title="Abstract">arXiv:2404.18013</a> [<a href="/pdf/2404.18013" title="Download PDF">pdf</a>, <a href="/format/2404.18013" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Impact of Dynamic Operating Envelopes on Distribution Network Hosting  Capacity for Electric Vehicles
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Fani%2C+H">Hossein Fani</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Hashmi%2C+M+U">Md Umar Hashmi</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Palacios-Garcia%2C+E+J">Emilio J. Palacios-Garcia</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Deconinck%2C+G">Geert Deconinck</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  <p class="mathjax">The examination of the maximum number of electric vehicles (EVs) that can be
  integrated into the distribution network (DN) without causing any operational
  incidents has become increasingly crucial as EV penetration rises. This issue
  can be addressed by utilizing dynamic operating envelopes (DOEs), which are
  generated based on the grid status. While DOEs improve the hosting capacity of
  the DN for EVs (EV-HC) by restricting the operational parameters of the
  network, they also alter the amount of energy needed for charging each EV,
  resulting in a decrease in the quality of service (QoS). This study proposes a
  network-aware hosting capacity framework for EVs (EV-NAHC) that i) aims to
  assess the effects of DOEs on active distribution networks, ii) introduces a
  novel definition for HC and calculates the EV-NAHC based on the aggregated QoS
  of all customers. A small-scale Belgian feeder is utilized to examine the
  proposed framework. The results show a substantial increase in the EV-NAHC with
  low, medium, and high-daily charging energy scenarios.
  </p>
  </div>
  </dd>
  <dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18016" title="Abstract">arXiv:2404.18016</a> [<a href="/pdf/2404.18016" title="Download PDF">pdf</a>, <a href="/format/2404.18016" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Reduced-order modeling of neutron transport separated in axial and  radial space by Proper Generalized Decomposition with applications to nuclear  reactor physics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Dominesey%2C+K+A">Kurt A. Dominesey</a>, 
  <a href="/search/math?searchtype=author&amp;query=Ji%2C+W">Wei Ji</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">In this article, we demonstrate the novel use of Proper Generalized
  Decomposition (PGD) to separate the axial and, optionally, polar dimensions of
  neutron transport. Doing so, the resulting Reduced-Order Models (ROMs) can
  exploit the fact that nuclear reactors tend to be tall, but geometrically
  simple, in the axial direction <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-97-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-701" style="width: 0.511em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.398em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.398em, 2.769em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-702"><span class="mi" id="MathJax-Span-703" style="font-family: STIXGeneral-Italic;">z</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.767em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-97">z</script>, and so the 3D neutron flux distribution
  often admits a low-rank "2D/1D" approximation. Through PGD, this approximation
  is computed by alternately solving 2D and 1D sub-models, like in existing 2D/1D
  models of reactor physics. However, the present methodology is more general in
  that the decomposition is arbitrary-rank, rather than rank-one, and no
  simplifying approximations of the transverse leakage are made. To begin, we
  derive two original models: that of axial PGD -- which separates only <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-98-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-704" style="width: 0.511em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.398em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.398em, 2.769em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-705"><span class="mi" id="MathJax-Span-706" style="font-family: STIXGeneral-Italic;">z</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.767em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-98">z</script> and
  the axial streaming direction <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-99-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-707" style="width: 7.06em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.705em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1005.592em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-708"><span class="mi" id="MathJax-Span-709" style="font-family: STIXGeneral-Italic;">ϑ</span><span class="mo" id="MathJax-Span-710" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="mo" id="MathJax-Span-711" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">{</span><span class="mo" id="MathJax-Span-712" style="font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-713" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-714" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-715" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">+</span><span class="mn" id="MathJax-Span-716" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-717" style="font-family: STIXGeneral-Regular;">}</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-99">\vartheta\in\{-1,+1\}</script> -- and axial-polar PGD --
  which separates both <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-100-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-718" style="width: 0.511em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.398em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.398em, 2.769em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-719"><span class="mi" id="MathJax-Span-720" style="font-family: STIXGeneral-Italic;">z</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.767em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-100">z</script> and polar angle <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-101-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-721" style="width: 0.737em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.567em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-722"><span class="mi" id="MathJax-Span-723" style="font-family: STIXGeneral-Italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.906em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-101">\mu</script> from the radial domain.
  Additionally, we grant that the energy dependence <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-102-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-724" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-725"><span class="mi" id="MathJax-Span-726" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-102">E</script> may be ascribed to either
  radial or axial modes, or both, bringing the total number of candidate 2D/1D
  ROMs to six. To assess performance, these PGD ROMs are applied to two few-group
  benchmarks characteristic of Light Water Reactors. Therein, we find both the
  axial and axial-polar ROMs are convergent and that the latter are often more
  economical than the former. Ultimately, given the popularity of 2D/1D methods
  in reactor physics, we expect a PGD ROM which achieves a similar effect, but
  perhaps with superior accuracy, a quicker runtime, and/or broader
  applicability, would be eminently useful, especially for full-core problems.
  </p>
  </div>
  </dd>
  <dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18020" title="Abstract">arXiv:2404.18020</a> [<a href="/pdf/2404.18020" title="Download PDF">pdf</a>, <a href="/format/2404.18020" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DM-Align: Leveraging the Power of Natural Language Instructions to Make  Changes to Images
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Trusca%2C+M+M">Maria Mihaela Trusca</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tuytelaars%2C+T">Tinne Tuytelaars</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Moens%2C+M">Marie-Francine Moens</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Text-based semantic image editing assumes the manipulation of an image using
  a natural language instruction. Although recent works are capable of generating
  creative and qualitative images, the problem is still mostly approached as a
  black box sensitive to generating unexpected outputs. Therefore, we propose a
  novel model to enhance the text-based control of an image editor by explicitly
  reasoning about which parts of the image to alter or preserve. It relies on
  word alignments between a description of the original source image and the
  instruction that reflects the needed updates, and the input image. The proposed
  Diffusion Masking with word Alignments (DM-Align) allows the editing of an
  image in a transparent and explainable way. It is evaluated on a subset of the
  Bison dataset and a self-defined dataset dubbed Dream. When comparing to
  state-of-the-art baselines, quantitative and qualitative results show that
  DM-Align has superior performance in image editing conditioned on language
  instructions, well preserves the background of the image and can better cope
  with long text instructions.
  </p>
  </div>
  </dd>
  <dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18021" title="Abstract">arXiv:2404.18021</a> [<a href="/pdf/2404.18021" title="Download PDF">pdf</a>, <a href="/format/2404.18021" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing  Experiments
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+K">Kaixuan Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qu%2C+Y">Yuanhao Qu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cousins%2C+H">Henry Cousins</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Johnson%2C+W+A">William A. Johnson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yin%2C+D">Di Yin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shah%2C+M">Mihir Shah</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+D">Denny Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Altman%2C+R">Russ Altman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M">Mengdi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cong%2C+L">Le Cong</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Quantitative Methods (q-bio.QM)
  
  </div>
  <p class="mathjax">The introduction of genome engineering technology has transformed biomedical
  research, making it possible to make precise changes to genetic information.
  However, creating an efficient gene-editing system requires a deep
  understanding of CRISPR technology, and the complex experimental systems under
  investigation. While Large Language Models (LLMs) have shown promise in various
  tasks, they often lack specific knowledge and struggle to accurately solve
  biological design problems. In this work, we introduce CRISPR-GPT, an LLM agent
  augmented with domain knowledge and external tools to automate and enhance the
  design process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages
  the reasoning ability of LLMs to facilitate the process of selecting CRISPR
  systems, designing guide RNAs, recommending cellular delivery methods, drafting
  protocols, and designing validation experiments to confirm editing outcomes. We
  showcase the potential of CRISPR-GPT for assisting non-expert researchers with
  gene-editing experiments from scratch and validate the agent's effectiveness in
  a real-world use case. Furthermore, we explore the ethical and regulatory
  considerations associated with automated gene-editing design, highlighting the
  need for responsible and transparent use of these tools. Our work aims to
  bridge the gap between beginner biological researchers and CRISPR genome
  engineering techniques, and demonstrate the potential of LLM agents in
  facilitating complex biological discovery tasks.
  </p>
  </div>
  </dd>
  <dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18023" title="Abstract">arXiv:2404.18023</a> [<a href="/pdf/2404.18023" title="Download PDF">pdf</a>, <a href="/format/2404.18023" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Tasking framework for Adaptive Speculative Parallel Mesh Generation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tsolakis%2C+C">Christos Tsolakis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Thomadakis%2C+P">Polykarpos Thomadakis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chrisochoides%2C+N">Nikos Chrisochoides</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> J Supercomput 78, 1-32 (2022)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>
  
  </div>
  <p class="mathjax">Handling the ever-increasing complexity of mesh generation codes along with
  the intricacies of newer hardware often results in codes that are both
  difficult to comprehend and maintain. Different facets of codes such as thread
  management and load balancing are often intertwined, resulting in efficient but
  highly complex software. In this work, we present a framework which aids in
  establishing a core principle, deemed separation of concerns, where
  functionality is separated from performance aspects of various mesh operations.
  In particular, thread management and scheduling decisions are elevated into a
  generic and reusable tasking framework. The results indicate that our approach
  can successfully abstract the load balancing aspects of two case studies, while
  providing access to a plethora of different execution back-ends. One would
  expect, this new flexibility to lead to some additional cost. However, for the
  configurations studied in this work, we observed up to 13% speedup for some
  meshing operations and up to 5.8% speedup over the entire application runtime
  compared to hand-optimized code. Moreover, we show that by using different task
  creation strategies, the overhead compared to straight-forward task execution
  models can be improved dramatically by as much as 1200% without compromises in
  portability and functionality.
  </p>
  </div>
  </dd>
  <dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18025" title="Abstract">arXiv:2404.18025</a> [<a href="/pdf/2404.18025" title="Download PDF">pdf</a>, <a href="/format/2404.18025" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Retrieval Robust to Object Motion Blur
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zou%2C+R">Rong Zou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pollefeys%2C+M">Marc Pollefeys</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rozumnyi%2C+D">Denys Rozumnyi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Moving objects are frequently seen in daily life and usually appear blurred
  in images due to their motion. While general object retrieval is a widely
  explored area in computer vision, it primarily focuses on sharp and static
  objects, and retrieval of motion-blurred objects in large image collections
  remains unexplored. We propose a method for object retrieval in images that are
  affected by motion blur. The proposed method learns a robust representation
  capable of matching blurred objects to their deblurred versions and vice versa.
  To evaluate our approach, we present the first large-scale datasets for blurred
  object retrieval, featuring images with objects exhibiting varying degrees of
  blur in various poses and scales. We conducted extensive experiments, showing
  that our method outperforms state-of-the-art retrieval methods on the new
  blur-retrieval datasets, which validates the effectiveness of the proposed
  approach.
  </p>
  </div>
  </dd>
  <dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18027" title="Abstract">arXiv:2404.18027</a> [<a href="/pdf/2404.18027" title="Download PDF">pdf</a>, <a href="/format/2404.18027" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Non-Spatial Hash Chemistry as a Minimalistic Open-Ended Evolutionary  System
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sayama%2C+H">Hiroki Sayama</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 6 figures, 1 table; accepted for publication in Proceedings of IEEE CEC 2024 (part of IEEE WCCI 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Discrete Mathematics (cs.DM); Populations and Evolution (q-bio.PE)
  
  </div>
  <p class="mathjax">There is an increasing level of interest in open-endedness in the recent
  literature of Artificial Life and Artificial Intelligence. We previously
  proposed the cardinality leap of possibility spaces as a promising mechanism to
  facilitate open-endedness in artificial evolutionary systems, and demonstrated
  its effectiveness using Hash Chemistry, an artificial chemistry model that used
  a hash function as a universal fitness evaluator. However, the spatial nature
  of Hash Chemistry came with extensive computational costs involved in its
  simulation, and the particle density limit imposed to prevent explosion of
  computational costs prevented unbounded growth in complexity of higher-order
  entities. To address these limitations, here we propose a simpler non-spatial
  variant of Hash Chemistry in which spatial proximity of particles are
  represented explicitly in the form of multisets. This model modification
  achieved a significant reduction of computational costs in simulating the
  model. Results of numerical simulations showed much more significant unbounded
  growth in both maximal and average sizes of replicating higher-order entities
  than the original model, demonstrating the effectiveness of this non-spatial
  model as a minimalistic example of open-ended evolutionary systems.
  </p>
  </div>
  </dd>
  <dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18028" title="Abstract">arXiv:2404.18028</a> [<a href="/pdf/2404.18028" title="Download PDF">pdf</a>, <a href="/format/2404.18028" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Reducing Dominating Sets in Graphs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Inza%2C+E+P">Ernesto Parra Inza</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Almira%2C+J+M+S">José María Sigarreta Almira</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vakhania%2C+N">Nodari Vakhania</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>
  
  </div>
  <p class="mathjax">A dominating set of a graph <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-103-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-727" style="width: 5.479em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.463em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1004.407em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-728"><span class="mi" id="MathJax-Span-729" style="font-family: STIXGeneral-Italic;">G</span><span class="mo" id="MathJax-Span-730" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mo" id="MathJax-Span-731" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">(</span><span class="mi" id="MathJax-Span-732" style="font-family: STIXGeneral-Italic;">V<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-733" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-734" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-735" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-103">G=(V,E)</script> is a subset of vertices <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-104-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-736" style="width: 3.165em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.543em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.543em, 2.826em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-737"><span class="mi" id="MathJax-Span-738" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-739" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">⊆</span><span class="mi" id="MathJax-Span-740" style="font-family: STIXGeneral-Italic; padding-left: 0.342em;">V<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-104">S\subseteq V</script>
  such that every vertex <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-105-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-741" style="width: 4.971em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.011em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.64em, 1004.011em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-742"><span class="mi" id="MathJax-Span-743" style="font-family: STIXGeneral-Italic;">v</span><span class="mo" id="MathJax-Span-744" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="mi" id="MathJax-Span-745" style="font-family: STIXGeneral-Italic; padding-left: 0.342em;">V<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-746" style="font-family: STIXVariants; padding-left: 0.229em;">∖</span><span class="mi" id="MathJax-Span-747" style="font-family: STIXGeneral-Italic; padding-left: 0.229em;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.323em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-105">v\in V\setminus S</script> has at least one neighbor in set
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-106-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-748" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-749"><span class="mi" id="MathJax-Span-750" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-106">S</script>. The corresponding optimization problem is known to be NP-hard. The best
  known polynomial time approximation algorithm for the problem separates the
  solution process in two stages applying first a fast greedy algorithm to obtain
  an initial dominating set, and then it uses an iterative procedure to reduce
  (purify) this dominating set. The purification stage turned out to be
  practically efficient. Here we further strengthen the purification stage
  presenting four new purification algorithms. All four purification procedures
  outperform the earlier purification procedure. The algorithms were tested for
  over 1300 benchmark problem instances. Compared to the known upper bounds, the
  obtained solutions were about 7 times better. Remarkably, for the 500 benchmark
  instances for which the optimum is known, the optimal solutions were obtained
  for 46.33\% of the tested instances, whereas the average error for the
  remaining instances was about 1.01.
  </p>
  </div>
  </dd>
  <dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18030" title="Abstract">arXiv:2404.18030</a> [<a href="/pdf/2404.18030" title="Download PDF">pdf</a>, <a href="/format/2404.18030" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Parallel Metric-based Anisotropic Mesh Adaptation using Speculative  Execution on Shared Memory
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tsolakis%2C+C">Christos Tsolakis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chrisochoides%2C+N">Nikos Chrisochoides</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>
  
  </div>
  <p class="mathjax">Efficient and robust anisotropic mesh adaptation is crucial for Computational
  Fluid Dynamics (CFD) simulations. The CFD Vision 2030 Study highlights the
  pressing need for this technology, particularly for simulations targeting
  supercomputers. This work applies a fine-grained speculative approach to
  anisotropic mesh operations. Our implementation exhibits more than 90% parallel
  efficiency on a multi-core node. Additionally, we evaluate our method within an
  adaptive pipeline for a spectrum of publicly available test-cases that includes
  both analytically derived and error-based fields. For all test-cases, our
  results are in accordance with published results in the literature. Support for
  CAD-based data is introduced, and its effectiveness is demonstrated on one of
  NASA's High-Lift prediction workshop cases.
  </p>
  </div>
  </dd>
  <dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18031" title="Abstract">arXiv:2404.18031</a> [<a href="/pdf/2404.18031" title="Download PDF">pdf</a>, <a href="/format/2404.18031" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quality Estimation with <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-107-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-751" style="width: 0.585em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.45em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1000.45em, 2.646em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-752"><span class="mi" id="MathJax-Span-753" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.947em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-107">k</script>-nearest Neighbors and Automatic Evaluation  for Model-specific Quality Estimation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dinh%2C+T+A">Tu Anh Dinh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Palzer%2C+T">Tobias Palzer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Niehues%2C+J">Jan Niehues</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to EAMT 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Providing quality scores along with Machine Translation (MT) output,
  so-called reference-free Quality Estimation (QE), is crucial to inform users
  about the reliability of the translation. We propose a model-specific,
  unsupervised QE approach, termed <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-108-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-754" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-755"><span class="mi" id="MathJax-Span-756" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-108">k</script>NN-QE, that extracts information from the
  MT model's training data using <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-109-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-757" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-758"><span class="mi" id="MathJax-Span-759" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-109">k</script>-nearest neighbors. Measuring the performance
  of model-specific QE is not straightforward, since they provide quality scores
  on their own MT output, thus cannot be evaluated using benchmark QE test sets
  containing human quality scores on premade MT output. Therefore, we propose an
  automatic evaluation method that uses quality scores from reference-based
  metrics as gold standard instead of human-generated ones. We are the first to
  conduct detailed analyses and conclude that this automatic method is
  sufficient, and the reference-based MetricX-23 is best for the task.
  </p>
  </div>
  </dd>
  <dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18032" title="Abstract">arXiv:2404.18032</a> [<a href="/pdf/2404.18032" title="Download PDF">pdf</a>, <a href="/ps/2404.18032" title="Download PostScript">ps</a>, <a href="/format/2404.18032" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Study of Clustering Techniques and Scheduling Algorithms with Fairness  for Cell-Free MIMO Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mashdour%2C+S">S. Mashdour</a>, 
  <a href="/search/cs?searchtype=author&amp;query=de+Lamare%2C+R+C">R. C. de Lamare</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages, 4 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
  
  </div>
  <p class="mathjax">In this work, we propose a clustering technique based on information rates
  for cell-free massive multiple-input multiple-output (MIMO) networks. Unlike
  existing clustering approaches that rely on the large scale fading coefficients
  of the channels and user-centric techniques, we develop an approach that is
  based on the information rates of cell-free massive MIMO networks. We also
  devise a resource allocation technique to incorporate the proposed clustering
  and schedule users with fairness. An analysis of the proposed clustering
  approach based on information rates is carried out along with an assessment of
  its benefits for scheduling. Numerical results show that the proposed
  techniques outperform existing approaches.
  </p>
  </div>
  </dd>
  <dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18033" title="Abstract">arXiv:2404.18033</a> [<a href="/pdf/2404.18033" title="Download PDF">pdf</a>, <a href="/format/2404.18033" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exposing Text-Image Inconsistency Using Diffusion Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+M">Mingzhen Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jia%2C+S">Shan Jia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhou Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ju%2C+Y">Yan Ju</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cai%2C+J">Jialing Cai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lyu%2C+S">Siwei Lyu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">In the battle against widespread online misinformation, a growing problem is
  text-image inconsistency, where images are misleadingly paired with texts with
  different intent or meaning. Existing classification-based methods for
  text-image inconsistency can identify contextual inconsistencies but fail to
  provide explainable justifications for their decisions that humans can
  understand. Although more nuanced, human evaluation is impractical at scale and
  susceptible to errors. To address these limitations, this study introduces
  D-TIIL (Diffusion-based Text-Image Inconsistency Localization), which employs
  text-to-image diffusion models to localize semantic inconsistencies in text and
  image pairs. These models, trained on large-scale datasets act as ``omniscient"
  agents that filter out irrelevant information and incorporate background
  knowledge to identify inconsistencies. In addition, D-TIIL uses text embeddings
  and modified image regions to visualize these inconsistencies. To evaluate
  D-TIIL's efficacy, we introduce a new TIIL dataset containing 14K consistent
  and inconsistent text-image pairs. Unlike existing datasets, TIIL enables
  assessment at the level of individual words and image regions and is carefully
  designed to represent various inconsistencies. D-TIIL offers a scalable and
  evidence-based approach to identifying and localizing text-image inconsistency,
  providing a robust framework for future research combating misinformation.
  </p>
  </div>
  </dd>
  <dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18037" title="Abstract">arXiv:2404.18037</a> [<a href="/pdf/2404.18037" title="Download PDF">pdf</a>, <a href="/format/2404.18037" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Comparison between a priori and a posteriori slope limiters for  high-order finite volume schemes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Palafoutas%2C+J">Jonathan Palafoutas</a>, 
  <a href="/search/math?searchtype=author&amp;query=Romero%2C+D+A+V">David A. Velasco Romero</a>, 
  <a href="/search/math?searchtype=author&amp;query=Teyssier%2C+R">Romain Teyssier</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">High-order finite volume and finite element methods offer impressive accuracy
  and cost efficiency when solving hyperbolic conservation laws with smooth
  solutions. However, if the solution contains discontinuities, these high-order
  methods can introduce unphysical oscillations and severe
  overshoots/undershoots. Slope limiters are an effective remedy, combating these
  oscillations by preserving monotonicity. Some limiters can even maintain a
  strict maximum principle in the numerical solution. They can be classified into
  one of two categories: \textit{a priori} and \textit{a posteriori} limiters.
  The former revises the high-order solution based only on data at the current
  time <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-110-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-760" style="width: 1.076em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.85em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.85em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-761"><span class="msubsup" id="MathJax-Span-762"><span style="display: inline-block; position: relative; width: 0.793em; height: 0px;"><span style="position: absolute; clip: rect(3.277em, 1000.285em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-763" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.342em;"><span class="mi" id="MathJax-Span-764" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-110">t^n</script>, while the latter involves computing a candidate solution at
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-111-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-765" style="width: 2.092em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.697em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.697em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-766"><span class="msubsup" id="MathJax-Span-767"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.277em, 1000.285em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-768" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.342em;"><span class="texatom" id="MathJax-Span-769"><span class="mrow" id="MathJax-Span-770"><span class="mi" id="MathJax-Span-771" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-772" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-773" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-111">t^{n+1}</script> and iteratively recomputing it until some conditions are satisfied.
  These two limiting paradigms are available for both finite volume and finite
  element methods.
  <br>In this work, we develop a methodology to compare \textit{a priori} and
  \textit{a posteriori} limiters for finite volume solvers at arbitrarily high
  order. We select the maximum principle preserving scheme presented in
  \cite{zhang2011maximum, zhang2010maximum} as our \textit{a priori} limited
  scheme. For \textit{a posteriori} limiting, we adopt the methodology presented
  in \cite{clain2011high} and search for so-called \textit{troubled cells} in the
  candidate solution. We revise them with a robust MUSCL fallback scheme. The
  linear advection equation is solved in both one and two dimensions and we
  compare variations of these limited schemes based on their ability to maintain
  a maximum principle, solution quality over long time integration and
  computational cost.
  <br>...
  </p>
  </div>
  </dd>
  <dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18039" title="Abstract">arXiv:2404.18039</a> [<a href="/pdf/2404.18039" title="Download PDF">pdf</a>, <a href="/format/2404.18039" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Implicit Update of the Moment Equations for a Multi-Species, Homogeneous  BGK Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Habbershaw%2C+E">Evan Habbershaw</a>, 
  <a href="/search/math?searchtype=author&amp;query=Hauck%2C+C+D">Cory D. Hauck</a>, 
  <a href="/search/math?searchtype=author&amp;query=Wise%2C+S+M">Steven M. Wise</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)
  
  </div>
  <p class="mathjax">A simple iterative approach for solving a set of implicit kinetic moment
  equations is proposed. This implicit solve is a key component in the IMEX
  discretization of the multi-species Bhatnagar-Gross-Krook (M-BGK) model with
  nontrivial collision frequencies depending on individual species temperatures.
  We prove that under mild time step restrictions, the iterative method generates
  a contraction mapping. Numerical simulations are provided to illustrate results
  of the IMEX scheme using the implicit moment solver.
  </p>
  </div>
  </dd>
  <dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18040" title="Abstract">arXiv:2404.18040</a> [<a href="/pdf/2404.18040" title="Download PDF">pdf</a>, <a href="/format/2404.18040" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Fashion Recommendation: Outfit Compatibility using GNN
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gulati%2C+S">Samaksh Gulati</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Numerous industries have benefited from the use of machine learning and
  fashion in industry is no exception. By gaining a better understanding of what
  makes a good outfit, companies can provide useful product recommendations to
  their users. In this project, we follow two existing approaches that employ
  graphs to represent outfits and use modified versions of the Graph neural
  network (GNN) frameworks. Both Node-wise Graph Neural Network (NGNN) and
  Hypergraph Neural Network aim to score a set of items according to the outfit
  compatibility of items. The data used is the Polyvore Dataset which consists of
  curated outfits with product images and text descriptions for each product in
  an outfit. We recreate the analysis on a subset of this data and compare the
  two existing models on their performance on two tasks Fill in the blank (FITB):
  finding an item that completes an outfit, and Compatibility prediction:
  estimating compatibility of different items grouped as an outfit. We can
  replicate the results directionally and find that HGNN does have a slightly
  better performance on both tasks. On top of replicating the results of the two
  papers we also tried to use embeddings generated from a vision transformer and
  witness enhanced prediction accuracy across the board
  </p>
  </div>
  </dd>
  <dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18042" title="Abstract">arXiv:2404.18042</a> [<a href="/pdf/2404.18042" title="Download PDF">pdf</a>, <a href="/format/2404.18042" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Pose-aware 3D Beamwidth Adaptation for Mobile Extended Reality
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Duru%2C+A">Alperen Duru</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mozaffari%2C+M">Mohammad Mozaffari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Afshang%2C+M">Mehrnaz Afshang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Ticao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khan%2C+T">Talha Khan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Humphreys%2C+T+E">Todd E. Humphreys</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Andrews%2C+J+G">Jeffrey G. Andrews</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted in the 2024 IEEE ICC
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">This paper presents a sensor-aided pose-aware beamwidth adaptation design for
  a conceptual extended reality (XR) Head-Mounted Display (HMD) equipped with a
  2D planar array. The beam is tracked and adapted on the user side by leveraging
  HMD orientation estimates. The beamwidth adaptation scheme is effected by
  selective deactivation of elements in the 2D antenna array, employing the
  angular estimation covariance matrix to overlap the beam with the estimation
  confidence interval. The proposed method utilizes the estimation correlations
  to adapt the beamwidth along the confidence interval of these estimates.
  Compared to a beamwidth adaptation without leveraging estimation correlations,
  the proposed method demonstrates the gain of leveraging estimation correlations
  by improving the coverage area for a given outage probability threshold by
  approximately 16%, or equivalently increasing the power efficiency up to 18%.
  </p>
  </div>
  </dd>
  <dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18043" title="Abstract">arXiv:2404.18043</a> [<a href="/pdf/2404.18043" title="Download PDF">pdf</a>, <a href="/ps/2404.18043" title="Download PostScript">ps</a>, <a href="/format/2404.18043" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Utilizing Large Language Models for Information Extraction from Real  Estate Transactions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yu Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+H">Haoxiang Gao</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Real estate sales contracts contain crucial information for property
  transactions, but manual extraction of data can be time-consuming and
  error-prone. This paper explores the application of large language models,
  specifically transformer-based architectures, for automated information
  extraction from real estate contracts. We discuss challenges, techniques, and
  future directions in leveraging these models to improve efficiency and accuracy
  in real estate contract analysis.
  </p>
  </div>
  </dd>
  <dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18047" title="Abstract">arXiv:2404.18047</a> [<a href="/pdf/2404.18047" title="Download PDF">pdf</a>, <a href="/format/2404.18047" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LIKO: LiDAR, Inertial, and Kinematic Odometry for Bipedal Robots
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Q">Qingrui Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Mingyuan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yongliang Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xuechao Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhangguo Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+L">Lianqiang Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fu%2C+Z">Zhenyuan Fu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jintao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chao Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuanxi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Q">Qiang Huang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">High-frequency and accurate state estimation is crucial for biped robots.
  This paper presents a tightly-coupled LiDAR-Inertial-Kinematic Odometry (LIKO)
  for biped robot state estimation based on an iterated extended Kalman filter.
  Beyond state estimation, the foot contact position is also modeled and
  estimated. This allows for both position and velocity updates from kinematic
  measurement. Additionally, the use of kinematic measurement results in an
  increased output state frequency of about 1kHz. This ensures temporal
  continuity of the estimated state and makes it practical for control purposes
  of biped robots. We also announce a biped robot dataset consisting of LiDAR,
  inertial measurement unit (IMU), joint encoders, force/torque (F/T) sensors,
  and motion capture ground truth to evaluate the proposed method. The dataset is
  collected during robot locomotion, and our approach reached the best
  quantitative result among other LIO-based methods and biped robot state
  estimation algorithms. The dataset and source code will be available at
  https://github.com/Mr-Zqr/LIKO.
  </p>
  </div>
  </dd>
  <dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18048" title="Abstract">arXiv:2404.18048</a> [<a href="/pdf/2404.18048" title="Download PDF">pdf</a>, <a href="/ps/2404.18048" title="Download PostScript">ps</a>, <a href="/format/2404.18048" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Scalable, Interpretable Distributed Protocol Verification by Inductive  Proof Slicing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Schultz%2C+W">William Schultz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ashton%2C+E">Edward Ashton</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Howard%2C+H">Heidi Howard</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tripakis%2C+S">Stavros Tripakis</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Logic in Computer Science (cs.LO)
  
  </div>
  <p class="mathjax">Many techniques for automated inference of inductive invariants for
  distributed protocols have been developed over the past several years, but
  their performance can still be unpredictable and their failure modes opaque for
  large-scale verification tasks. In this paper, we present inductive proof
  slicing, a new automated, compositional technique for inductive invariant
  inference that scales effectively to large distributed protocol verification
  tasks. Our technique is built on a core, novel data structure, the inductive
  proof graph, which explicitly represents the lemma and action dependencies of
  an inductive invariant and is built incrementally during the inference
  procedure, backwards from a target safety property. We present an invariant
  inference algorithm that integrates localized syntax-guided lemma synthesis
  routines at nodes of this graph, which are accelerated by computation of
  localized grammar and state variable slices. Additionally, in the case of
  failure to produce a complete inductive invariant, maintenance of this proof
  graph structure allows failures to be localized to small sub-components of this
  graph, enabling fine-grained failure diagnosis and repair by a user. We
  evaluate our technique on several complex distributed and concurrent protocols,
  including a large scale specification of the Raft consensus protocol, which is
  beyond the capabilities of modern distributed protocol verification tools, and
  also demonstrate how its interpretability features allow effective diagnosis
  and repair in cases of initial failure.
  </p>
  </div>
  </dd>
  <dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18053" title="Abstract">arXiv:2404.18053</a> [<a href="/pdf/2404.18053" title="Download PDF">pdf</a>, <a href="/ps/2404.18053" title="Download PostScript">ps</a>, <a href="/format/2404.18053" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Binary duadic codes and their related codes with a square-root-like  lower bound
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+T">Tingting Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Lanqiang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiuyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+S">Shixin Zhu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">Binary cyclic codes have been a hot topic for many years, and significant
  progress has been made in the study of this types of codes. As is well known,
  it is hard to construct infinite families of binary cyclic codes [n, n+1/2]
  with good minimum distance. In this paper, by using the BCH bound on cyclic
  codes, one of the open problems proposed by Liu et al. about binary cyclic
  codes (Finite Field Appl 91:102270, 2023) is settled. Specially, we present
  several families of binary duadic codes with length 2^m-1 and dimension
  2^(m-1), and the minimum distances have a square-root-like lower bound. As a
  by-product, the parameters of their dual codes and extended codes are provided,
  where the latter are self-dual and doubly-even.
  </p>
  </div>
  </dd>
  <dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18054" title="Abstract">arXiv:2404.18054</a> [<a href="/pdf/2404.18054" title="Download PDF">pdf</a>, <a href="/format/2404.18054" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mass-preserving Spatio-temporal adaptive PINN for Cahn-Hilliard  equations with strong nonlinearity and singularity
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Qiumei%2C+H">Huang Qiumei</a>, 
  <a href="/search/math?searchtype=author&amp;query=Jiaxuan%2C+M">Ma Jiaxuan</a>, 
  <a href="/search/math?searchtype=author&amp;query=Zhen%2C+X">Xu Zhen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">As one kind important phase field equations, Cahn-Hilliard equations contain
  spatial high order derivatives, strong nonlinearities, and even singularities.
  When using the physics informed neural network (PINN) to simulate the long time
  evolution, it is necessary to decompose the time domain to capture the
  transition of solutions in different time. Moreover, the baseline PINN can't
  maintain the mass conservation property for the equations. We propose a
  mass-preserving spatio-temporal adaptive PINN. This method adaptively dividing
  the time domain according to the rate of energy decrease, and solves the
  Cahn-Hilliard equation in each time step using an independent neural network.
  To improve the prediction accuracy, spatial adaptive sampling is employed in
  the subdomain to select points with large residual value and add them to the
  training samples. Additionally, a mass constraint is added to the loss function
  to compensate the mass degradation problem of the PINN method in solving the
  Cahn-Hilliard equations. The mass-preserving spatio-temporal adaptive PINN is
  employed to solve a series of numerical examples. These include the
  Cahn-Hilliard equations with different bulk potentials, the three dimensional
  Cahn-Hilliard equation with singularities, and the set of Cahn-Hilliard
  equations. The numerical results demonstrate the effectiveness of the proposed
  algorithm.
  </p>
  </div>
  </dd>
  <dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18057" title="Abstract">arXiv:2404.18057</a> [<a href="/pdf/2404.18057" title="Download PDF">pdf</a>, <a href="/format/2404.18057" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Efficient LLM Inference with Kcache
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+Q">Qiaozhi He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhihua Wu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Technical Report, 8 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Large Language Models(LLMs) have had a profound impact on AI applications,
  particularly in the domains of long-text comprehension and generation. KV Cache
  technology is one of the most widely used techniques in the industry. It
  ensures efficient sequence generation by caching previously computed KV states.
  However, it also introduces significant memory overhead. We discovered that KV
  Cache is not necessary and proposed a novel KCache technique to alleviate the
  memory bottleneck issue during the LLMs inference process. KCache can be used
  directly for inference without any training process, Our evaluations show that
  KCache improves the throughput of popular LLMs by 40% with the baseline, while
  keeping accuracy.
  </p>
  </div>
  </dd>
  <dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18060" title="Abstract">arXiv:2404.18060</a> [<a href="/pdf/2404.18060" title="Download PDF">pdf</a>, <a href="/format/2404.18060" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Prompt Customization for Continual Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dai%2C+Y">Yong Dai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hong%2C+X">Xiaopeng Hong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yabin Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zhiheng Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+D">Dongmei Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yaowei Wang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ACM MM
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Contemporary continual learning approaches typically select prompts from a
  pool, which function as supplementary inputs to a pre-trained model. However,
  this strategy is hindered by the inherent noise of its selection approach when
  handling increasing tasks. In response to these challenges, we reformulate the
  prompting approach for continual learning and propose the prompt customization
  (PC) method. PC mainly comprises a prompt generation module (PGM) and a prompt
  modulation module (PMM). In contrast to conventional methods that employ hard
  prompt selection, PGM assigns different coefficients to prompts from a
  fixed-sized pool of prompts and generates tailored prompts. Moreover, PMM
  further modulates the prompts by adaptively assigning weights according to the
  correlations between input data and corresponding prompts. We evaluate our
  method on four benchmark datasets for three diverse settings, including the
  class, domain, and task-agnostic incremental learning tasks. Experimental
  results demonstrate consistent improvement (by up to 16.2\%), yielded by the
  proposed method, over the state-of-the-art (SOTA) techniques.
  </p>
  </div>
  </dd>
  <dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18062" title="Abstract">arXiv:2404.18062</a> [<a href="/pdf/2404.18062" title="Download PDF">pdf</a>, <a href="/format/2404.18062" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Compressed Image Captioning using CNN-based Encoder-Decoder Framework
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ridoy%2C+M+A+R">Md Alif Rahman Ridoy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hasan%2C+M+M">M Mahmud Hasan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bhowmick%2C+S">Shovon Bhowmick</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">In today's world, image processing plays a crucial role across various
  fields, from scientific research to industrial applications. But one
  particularly exciting application is image captioning. The potential impact of
  effective image captioning is vast. It can significantly boost the accuracy of
  search engines, making it easier to find relevant information. Moreover, it can
  greatly enhance accessibility for visually impaired individuals, providing them
  with a more immersive experience of digital content. However, despite its
  promise, image captioning presents several challenges. One major hurdle is
  extracting meaningful visual information from images and transforming it into
  coherent language. This requires bridging the gap between the visual and
  linguistic domains, a task that demands sophisticated algorithms and models.
  Our project is focused on addressing these challenges by developing an
  automatic image captioning architecture that combines the strengths of
  convolutional neural networks (CNNs) and encoder-decoder models. The CNN model
  is used to extract the visual features from images, and later, with the help of
  the encoder-decoder framework, captions are generated. We also did a
  performance comparison where we delved into the realm of pre-trained CNN
  models, experimenting with multiple architectures to understand their
  performance variations. In our quest for optimization, we also explored the
  integration of frequency regularization techniques to compress the "AlexNet"
  and "EfficientNetB0" model. We aimed to see if this compressed model could
  maintain its effectiveness in generating image captions while being more
  resource-efficient.
  </p>
  </div>
  </dd>
  <dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18063" title="Abstract">arXiv:2404.18063</a> [<a href="/pdf/2404.18063" title="Download PDF">pdf</a>, <a href="/format/2404.18063" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Machine Learning Techniques for Data Reduction of CFD Applications
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Jaemoon Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jung%2C+K+S">Ki Sung Jung</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gong%2C+Q">Qian Gong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiao Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Klasky%2C+S">Scott Klasky</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jacqueline Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rangarajan%2C+A">Anand Rangarajan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ranka%2C+S">Sanjay Ranka</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 8 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Fluid Dynamics (physics.flu-dyn)
  
  </div>
  <p class="mathjax">We present an approach called guaranteed block autoencoder that leverages
  Tensor Correlations (GBATC) for reducing the spatiotemporal data generated by
  computational fluid dynamics (CFD) and other scientific applications. It uses a
  multidimensional block of tensors (spanning in space and time) for both input
  and output, capturing the spatiotemporal and interspecies relationship within a
  tensor. The tensor consists of species that represent different elements in a
  CFD simulation. To guarantee the error bound of the reconstructed data,
  principal component analysis (PCA) is applied to the residual between the
  original and reconstructed data. This yields a basis matrix, which is then used
  to project the residual of each instance. The resulting coefficients are
  retained to enable accurate reconstruction. Experimental results demonstrate
  that our approach can deliver two orders of magnitude in reduction while still
  keeping the errors of primary data under scientifically acceptable bounds.
  Compared to reduction-based approaches based on SZ, our method achieves a
  substantially higher compression ratio for a given error bound or a better
  error for a given compression ratio.
  </p>
  </div>
  </dd>
  <dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18065" title="Abstract">arXiv:2404.18065</a> [<a href="/pdf/2404.18065" title="Download PDF">pdf</a>, <a href="/format/2404.18065" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Grounded Compositional and Diverse Text-to-3D with Pretrained Multi-View  Diffusion Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaolong Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mo%2C+J">Jiawei Mo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Ying Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Parameshwara%2C+C">Chethan Parameshwara</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fei%2C+X">Xiaohan Fei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Swaminathan%2C+A">Ashwin Swaminathan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Taylor%2C+C">CJ Taylor</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tu%2C+Z">Zhuowen Tu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Favaro%2C+P">Paolo Favaro</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Soatto%2C+S">Stefano Soatto</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 10 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">In this paper, we propose an effective two-stage approach named
  Grounded-Dreamer to generate 3D assets that can accurately follow complex,
  compositional text prompts while achieving high fidelity by using a pre-trained
  multi-view diffusion model. Multi-view diffusion models, such as MVDream, have
  shown to generate high-fidelity 3D assets using score distillation sampling
  (SDS). However, applied naively, these methods often fail to comprehend
  compositional text prompts, and may often entirely omit certain subjects or
  parts. To address this issue, we first advocate leveraging text-guided 4-view
  images as the bottleneck in the text-to-3D pipeline. We then introduce an
  attention refocusing mechanism to encourage text-aligned 4-view image
  generation, without the necessity to re-train the multi-view diffusion model or
  craft a high-quality compositional 3D dataset. We further propose a hybrid
  optimization strategy to encourage synergy between the SDS loss and the sparse
  RGB reference images. Our method consistently outperforms previous
  state-of-the-art (SOTA) methods in generating compositional 3D assets,
  excelling in both quality and accuracy, and enabling diverse 3D from the same
  text prompt.
  </p>
  </div>
  </dd>
  <dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18066" title="Abstract">arXiv:2404.18066</a> [<a href="/pdf/2404.18066" title="Download PDF">pdf</a>, <a href="/format/2404.18066" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quantized Context Based LIF Neurons for Recurrent Spiking Neural  Networks in 45nm
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bezugam%2C+S+S">Sai Sukruth Bezugam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yihao Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yoo%2C+J">JaeBum Yoo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Strukov%2C+D">Dmitri Strukov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+B">Bongjin Kim</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 Pages, 7 Figures, 2 Tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)
  
  </div>
  <p class="mathjax">In this study, we propose the first hardware implementation of a
  context-based recurrent spiking neural network (RSNN) emphasizing on
  integrating dual information streams within the neocortical pyramidal neurons
  specifically Context- Dependent Leaky Integrate and Fire (CLIF) neuron models,
  essential element in RSNN. We present a quantized version of the CLIF neuron
  (qCLIF), developed through a hardware-software codesign approach utilizing the
  sparse activity of RSNN. Implemented in a 45nm technology node, the qCLIF is
  compact (900um^2) and achieves a high accuracy of 90% despite 8 bit
  quantization on DVS gesture classification dataset. Our analysis spans a
  network configuration from 10 to 200 qCLIF neurons, supporting up to 82k
  synapses within a 1.86 mm^2 footprint, demonstrating scalability and efficiency
  </p>
  </div>
  </dd>
  <dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18067" title="Abstract">arXiv:2404.18067</a> [<a href="/pdf/2404.18067" title="Download PDF">pdf</a>, <a href="/format/2404.18067" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Type Inference for Isabelle2Cpp
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+D">Dongchen Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fu%2C+C">Chenxi Fu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 22 pages, 4 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  <p class="mathjax">Isabelle2Cpp is a code generation framework that supports automatic
  generation of C++ code from Isabelle/HOL specifications. However, if some type
  information of Isabelle/HOL specification is missing, Isabelle2Cpp may not
  complete the code generation automatically. In order to solve this problem,
  this paper provides a type system for Isabelle2Cpp, which is used to perform
  type inference and type unification for expressions of the intermediate
  representation in Isabelle2Cpp. The system introduces new type inference rules
  and unification algorithms to enhance the Isabelle2Cpp framework. By
  incorporating the type system, the Isabelle2Cpp framework can provide more
  comprehensive type information for expression generation, which leads to more
  complete and accurate C++ code.
  </p>
  </div>
  </dd>
  <dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18069" title="Abstract">arXiv:2404.18069</a> [<a href="/pdf/2404.18069" title="Download PDF">pdf</a>, <a href="/format/2404.18069" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Local Discontinuous Galerkin method for fractional Korteweg-de Vries  equation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Dwivedi%2C+M">Mukul Dwivedi</a>, 
  <a href="/search/math?searchtype=author&amp;query=Sarkar%2C+T">Tanmay Sarkar</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">We propose a local discontinuous Galerkin (LDG) method for fractional
  Korteweg-de Vries equation involving the fractional Laplacian with exponent
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-112-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-774" style="width: 4.971em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.011em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.955em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-775"><span class="mi" id="MathJax-Span-776" style="font-family: STIXGeneral-Italic;">α</span><span class="mo" id="MathJax-Span-777" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="mo" id="MathJax-Span-778" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">(</span><span class="mn" id="MathJax-Span-779" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-780" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-781" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">2</span><span class="mo" id="MathJax-Span-782" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-112">\alpha\in (1,2)</script> in one and two space dimensions. By decomposing the
  fractional Laplacian into a first order derivative and a fractional integral,
  we prove <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-113-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-783" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.076em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-784"><span class="msubsup" id="MathJax-Span-785"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-786" style="font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.624em;"><span class="mn" id="MathJax-Span-787" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-113">L^2</script>-stability of the semi-discrete LDG scheme incorporating suitable
  interface and boundary fluxes. We analyze the error estimate by considering
  linear convection term and utilizing the estimate, we derive the error estimate
  for general nonlinear flux and demonstrate an order of convergence
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-114-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-788" style="width: 4.576em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.729em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(2.035em, 1003.673em, 3.39em, -999.997em); top: -3.046em; left: 0em;"><span class="mrow" id="MathJax-Span-789"><span class="texatom" id="MathJax-Span-790"><span class="mrow" id="MathJax-Span-791"><span class="mi" id="MathJax-Span-792" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-793" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-794"><span style="display: inline-block; position: relative; width: 2.318em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-795" style="font-family: STIXGeneral-Italic;">h</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-796"><span class="mrow" id="MathJax-Span-797"><span class="mi" id="MathJax-Span-798" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-799" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-800" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-801"><span class="mrow" id="MathJax-Span-802"><span class="mo" id="MathJax-Span-803" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-804" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-805" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 3.052em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-114">\mathcal{O}(h^{k+1/2})</script>. Moreover, the stability and error analysis have been
  extended to multiple space dimensional case. Additionally, we devise a fully
  discrete LDG scheme using the four-stage fourth-order Runge-Kutta method. We
  prove that the scheme is strongly stable under an appropriate time step
  constraint by establishing a \emph{three-step strong stability} estimate.
  Numerical illustrations are shown to demonstrate the efficiency of the scheme
  by obtaining an optimal order of convergence.
  </p>
  </div>
  </dd>
  <dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18071" title="Abstract">arXiv:2404.18071</a> [<a href="/pdf/2404.18071" title="Download PDF">pdf</a>, <a href="/ps/2404.18071" title="Download PostScript">ps</a>, <a href="/format/2404.18071" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Can Perplexity Predict Fine-Tuning Performance? An Investigation of  Tokenization Effects on Sequential Language Models for Nepali
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Luitel%2C+N">Nishant Luitel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bekoju%2C+N">Nirajan Bekoju</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sah%2C+A+K">Anand Kumar Sah</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shakya%2C+S">Subarna Shakya</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 11 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Recent language models use subwording mechanisms to handle
  Out-of-Vocabulary(OOV) words seen during test time and, their generation
  capacity is generally measured using perplexity, an intrinsic metric. It is
  known that increasing the subword granularity results in a decrease of
  perplexity value. However, the study of how subwording affects the
  understanding capacity of language models has been very few and only limited to
  a handful of languages. To reduce this gap we used 6 different tokenization
  schemes to pretrain relatively small language models in Nepali and used the
  representations learned to finetune on several downstream tasks. Although
  byte-level BPE algorithm has been used in recent models like GPT, RoBERTa we
  show that on average they are sub-optimal in comparison to algorithms such as
  SentencePiece in finetuning performances for Nepali. Additionally, similar
  recent studies have focused on the Bert-based language model. We, however,
  pretrain and finetune sequential transformer-based language models.
  </p>
  </div>
  </dd>
  <dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18072" title="Abstract">arXiv:2404.18072</a> [<a href="/pdf/2404.18072" title="Download PDF">pdf</a>, <a href="/ps/2404.18072" title="Download PostScript">ps</a>, <a href="/format/2404.18072" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Contextual Spelling Correction with Language Model for Low-resource  Setting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Luitel%2C+N">Nishant Luitel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bekoju%2C+N">Nirajan Bekoju</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sah%2C+A+K">Anand Kumar Sah</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shakya%2C+S">Subarna Shakya</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">The task of Spell Correction(SC) in low-resource languages presents a
  significant challenge due to the availability of only a limited corpus of data
  and no annotated spelling correction datasets. To tackle these challenges a
  small-scale word-based transformer LM is trained to provide the SC model with
  contextual understanding. Further, the probabilistic error rules are extracted
  from the corpus in an unsupervised way to model the tendency of error
  happening(error model). Then the combination of LM and error model is used to
  develop the SC model through the well-known noisy channel framework. The
  effectiveness of this approach is demonstrated through experiments on the
  Nepali language where there is access to just an unprocessed corpus of textual
  data.
  </p>
  </div>
  </dd>
  <dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18074" title="Abstract">arXiv:2404.18074</a> [<a href="/pdf/2404.18074" title="Download PDF">pdf</a>, <a href="/format/2404.18074" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MMAC-Copilot: Multi-modal Agent Collaboration Operating System Copilot
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+Z">Zirui Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yaohang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+M">Meng Fang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhenhao Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zecheng Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yuan Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> In processing
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)
  
  </div>
  <p class="mathjax">Autonomous virtual agents are often limited by their singular mode of
  interaction with real-world environments, restricting their versatility. To
  address this, we propose the Multi-Modal Agent Collaboration framework
  (MMAC-Copilot), a framework utilizes the collective expertise of diverse agents
  to enhance interaction ability with operating systems. The framework introduces
  a team collaboration chain, enabling each participating agent to contribute
  insights based on their specific domain knowledge, effectively reducing the
  hallucination associated with knowledge domain gaps. To evaluate the
  performance of MMAC-Copilot, we conducted experiments using both the GAIA
  benchmark and our newly introduced Visual Interaction Benchmark (VIBench).
  VIBench focuses on non-API-interactable applications across various domains,
  including 3D gaming, recreation, and office scenarios. MMAC-Copilot achieved
  exceptional performance on GAIA, with an average improvement of 6.8\% over
  existing leading systems. Furthermore, it demonstrated remarkable capability on
  VIBench, particularly in managing various methods of interaction within systems
  and applications. These results underscore MMAC-Copilot's potential in
  advancing the field of autonomous virtual agents through its innovative
  approach to agent collaboration.
  </p>
  </div>
  </dd>
  <dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18075" title="Abstract">arXiv:2404.18075</a> [<a href="/pdf/2404.18075" title="Download PDF">pdf</a>, <a href="/format/2404.18075" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Comparing E-bike and Conventional Bicycle Use Patterns in a Public Bike  Share System: A Case Study of Richmond, VA
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yifan Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sloate%2C+E">Elliott Sloate</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khadem%2C+N">Nashid Khadem</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chavis%2C+C">Celeste Chavis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Martinez%2C+V+F">Vanessa Frias Martinez</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Journal of Cycling and Micromobility Research (2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>
  
  </div>
  <p class="mathjax">The results show that pedelecs are generally associated with longer trip
  distances, shorter trip times, higher speeds, and lower rates of uphill
  elevation change. The origin-destination analysis considering the business,
  mixed use, residential, and other uses shows extremely similar trends, with a
  large number of trips staying within either business or residential locations
  or mixed use. The roadway use analysis shows that pedelecs are used farther
  outside of the city than bikes.
  </p>
  </div>
  </dd>
  <dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18077" title="Abstract">arXiv:2404.18077</a> [<a href="/pdf/2404.18077" title="Download PDF">pdf</a>, <a href="/format/2404.18077" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generative AI for Low-Carbon Artificial Intelligence of Things
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wen%2C+J">Jinbo Wen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruichen Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Niyato%2C+D">Dusit Niyato</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kang%2C+J">Jiawen Kang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Du%2C+H">Hongyang Du</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+Z">Zhu Han</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">By integrating Artificial Intelligence (AI) with the Internet of Things
  (IoT), Artificial Intelligence of Things (AIoT) has revolutionized many fields.
  However, AIoT is facing the challenges of energy consumption and carbon
  emissions due to the continuous advancement of mobile technology. Fortunately,
  Generative AI (GAI) holds immense potential to reduce carbon emissions of AIoT
  due to its excellent reasoning and generation capabilities. In this article, we
  explore the potential of GAI for carbon emissions reduction and propose a novel
  GAI-enabled solution for low-carbon AIoT. Specifically, we first study the main
  impacts that cause carbon emissions in AIoT, and then introduce GAI techniques
  and their relations to carbon emissions. We then explore the application
  prospects of GAI in low-carbon AIoT, focusing on how GAI can reduce carbon
  emissions of network components. Subsequently, we propose a Large Language
  Model (LLM)-enabled carbon emission optimization framework, in which we design
  pluggable LLM and Retrieval Augmented Generation (RAG) modules to generate more
  accurate and reliable optimization problems. Furthermore, we utilize Generative
  Diffusion Models (GDMs) to identify optimal strategies for carbon emission
  reduction. Simulation results demonstrate the effectiveness of the proposed
  framework. Finally, we insightfully provide open research directions for
  low-carbon AIoT.
  </p>
  </div>
  </dd>
  <dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18081" title="Abstract">arXiv:2404.18081</a> [<a href="/pdf/2404.18081" title="Download PDF">pdf</a>, <a href="/format/2404.18081" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ComposerX: Multi-Agent Symbolic Music Composition with LLMs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Deng%2C+Q">Qixin Deng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qikai Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+R">Ruibin Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yipeng Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xubo Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tian%2C+Z">Zeyue Tian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+J">Jiahao Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Ge Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+H">Hanfeng Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yizhi Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yinghao Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fu%2C+J">Jie Fu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+C">Chenghua Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Benetos%2C+E">Emmanouil Benetos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenwu Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xia%2C+G">Guangyu Xia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+W">Wei Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yike Guo</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">Music composition represents the creative side of humanity, and itself is a
  complex task that requires abilities to understand and generate information
  with long dependency and harmony constraints. While demonstrating impressive
  capabilities in STEM subjects, current LLMs easily fail in this task,
  generating ill-written music even when equipped with modern techniques like
  In-Context-Learning and Chain-of-Thoughts. To further explore and enhance LLMs'
  potential in music composition by leveraging their reasoning ability and the
  large knowledge base in music history and theory, we propose ComposerX, an
  agent-based symbolic music generation framework. We find that applying a
  multi-agent approach significantly improves the music composition quality of
  GPT-4. The results demonstrate that ComposerX is capable of producing coherent
  polyphonic music compositions with captivating melodies, while adhering to user
  instructions.
  </p>
  </div>
  </dd>
  <dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18082" title="Abstract">arXiv:2404.18082</a> [<a href="/pdf/2404.18082" title="Download PDF">pdf</a>, <a href="/ps/2404.18082" title="Download PostScript">ps</a>, <a href="/format/2404.18082" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Cyber Security in Containerization Platforms: A Comparative Study of  Security Challenges, Measures and Best Practices
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Adhikari%2C+S">Sohome Adhikari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Baidya%2C+S">Sabur Baidya</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>
  
  </div>
  <p class="mathjax">The paper reviews the comparative study of security measures, challenges, and
  best practices with a view to enhancing cyber safety in containerized
  platforms. This review is intended to give insight into the enhanced security
  posture of containerized environments, with a view to examining safety
  vulnerabilities in containerization platforms, exploring strategies for
  increasing containers isolation and assessing how encryption techniques play an
  important role in providing secure applications. The paper also provides
  practical guidance for organizations seeking to strengthen their cyber security
  defenses in the containerization area platforms.
  </p>
  </div>
  </dd>
  <dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18083" title="Abstract">arXiv:2404.18083</a> [<a href="/pdf/2404.18083" title="Download PDF">pdf</a>, <a href="/format/2404.18083" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Online,Target-Free LiDAR-Camera Extrinsic Calibration via Cross-Modal  Mask Matching
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhiwei Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yikang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qijun Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+R">Rui Fan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">LiDAR-camera extrinsic calibration (LCEC) is crucial for data fusion in
  intelligent vehicles. Offline, target-based approaches have long been the
  preferred choice in this field. However, they often demonstrate poor
  adaptability to real-world environments. This is largely because extrinsic
  parameters may change significantly due to moderate shocks or during extended
  operations in environments with vibrations. In contrast, online, target-free
  approaches provide greater adaptability yet typically lack robustness,
  primarily due to the challenges in cross-modal feature matching. Therefore, in
  this article, we unleash the full potential of large vision models (LVMs),
  which are emerging as a significant trend in the fields of computer vision and
  robotics, especially for embodied artificial intelligence, to achieve robust
  and accurate online, target-free LCEC across a variety of challenging
  scenarios. Our main contributions are threefold: we introduce a novel framework
  known as MIAS-LCEC, provide an open-source versatile calibration toolbox with
  an interactive visualization interface, and publish three real-world datasets
  captured from various indoor and outdoor environments. The cornerstone of our
  framework and toolbox is the cross-modal mask matching (C3M) algorithm,
  developed based on a state-of-the-art (SoTA) LVM and capable of generating
  sufficient and reliable matches. Extensive experiments conducted on these
  real-world datasets demonstrate the robustness of our approach and its superior
  performance compared to SoTA methods, particularly for the solid-state LiDARs
  with super-wide fields of view.
  </p>
  </div>
  </dd>
  <dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18084" title="Abstract">arXiv:2404.18084</a> [<a href="/pdf/2404.18084" title="Download PDF">pdf</a>, <a href="/format/2404.18084" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Age-minimal Multicast by Graph Attention Reinforcement Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yanning Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liao%2C+G">Guocheng Liao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+S">Shengbin Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+N">Ning Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Meng Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>
  
  </div>
  <p class="mathjax">Age of Information (AoI) is an emerging metric used to assess the timeliness
  of information, gaining research interest in real-time multicast applications
  such as video streaming and metaverse platforms. In this paper, we consider a
  dynamic multicast network with energy constraints, where our objective is to
  minimize the expected time-average AoI through energy-constrained multicast
  routing and scheduling. The inherent complexity of the problem, given the
  NP-hardness and intertwined scheduling and routing decisions, makes existing
  approaches inapplicable. To address these challenges, we decompose the original
  problem into two subtasks, each amenable to reinforcement learning (RL)
  methods. Subsequently, we propose an innovative framework based on graph
  attention networks (GATs) to effectively capture graph information with
  superior generalization capabilities. To validate our framework, we conduct
  experiments on three datasets including a real-world dataset called AS-733, and
  show that our proposed scheme reduces the energy consumption by <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-115-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-806" style="width: 3.165em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.543em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.64em, 1002.487em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-807"><span class="mn" id="MathJax-Span-808" style="font-family: STIXGeneral-Regular;">75.7</span><span class="mi" id="MathJax-Span-809" style="font-family: STIXGeneral-Regular;">%</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-115">75.7\%</script> while
  achieving a similar AoI compared to baselines.
  </p>
  </div>
  </dd>
  <dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18085" title="Abstract">arXiv:2404.18085</a> [<a href="/pdf/2404.18085" title="Download PDF">pdf</a>, <a href="/format/2404.18085" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CRE-LLM: A Domain-Specific Chinese Relation Extraction Framework with  Fine-tuned Large Language Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zhengpeng Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+H">Haoran Luo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> preprint
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Domain-Specific Chinese Relation Extraction (DSCRE) aims to extract relations
  between entities from domain-specific Chinese text. Despite the rapid
  development of PLMs in recent years, especially LLMs, DSCRE still faces three
  core challenges: complex network structure design, poor awareness, and high
  consumption of fine-tuning. Given the impressive performance of large language
  models (LLMs) in natural language processing, we propose a new framework called
  CRE-LLM. This framework is based on fine-tuning open-source LLMs, such as
  Llama-2, ChatGLM2, and Baichuan2. CRE-LLM enhances the logic-awareness and
  generative capabilities of the model by constructing an appropriate prompt and
  utilizing open-source LLMs for instruction-supervised fine-tuning. And then it
  directly extracts the relations of the given entities in the input textual
  data, which improving the CRE approach. To demonstrate the effectiveness of the
  proposed framework, we conducted extensive experiments on two domain-specific
  CRE datasets, FinRE and SanWen. The experimental results show that CRE-LLM is
  significantly superior and robust, achieving state-of-the-art (SOTA)
  performance on the FinRE dataset. This paper introduces a novel approach to
  domain-specific relation extraction (DSCRE) tasks that are semantically more
  complex by combining LLMs with triples. Our code is publicly available.
  </p>
  </div>
  </dd>
  <dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18088" title="Abstract">arXiv:2404.18088</a> [<a href="/pdf/2404.18088" title="Download PDF">pdf</a>, <a href="/ps/2404.18088" title="Download PostScript">ps</a>, <a href="/format/2404.18088" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On completely regular self-dual codes with covering radius <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-116-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-810" style="width: 2.914em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.332em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1002.287em, 2.87em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-811"><span class="texatom" id="MathJax-Span-812"><span class="mrow" id="MathJax-Span-813"><span class="mo" id="MathJax-Span-814" style="font-family: STIXGeneral-Regular;">ρ</span></span></span><span class="mo" id="MathJax-Span-815" style="font-family: STIXGeneral-Regular; padding-left: 0.316em;">=</span><span class="mn" id="MathJax-Span-816" style="font-family: STIXGeneral-Regular; padding-left: 0.316em;">2</span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.331em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.225em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-116">ρ=2</script>
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Borges%2C+J">J. Borges</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zinoviev%2C+D+V">D. V. Zinoviev</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zinoviev%2C+V+A">V. A. Zinoviev</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">We give a complete classification of completely regular self-dual codes with
  covering radius <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-117-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-817" style="width: 2.995em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.431em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.431em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-818"><span class="mi" id="MathJax-Span-819" style="font-family: STIXGeneral-Italic;">ρ</span><span class="mo" id="MathJax-Span-820" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mn" id="MathJax-Span-821" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-117">\rho = 2</script>. More precisely, we prove that there are two
  sporadic such codes, of length <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-118-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-822" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-823"><span class="mn" id="MathJax-Span-824" style="font-family: STIXGeneral-Regular;">8</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-118">8</script>, and an infinite family, of length <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-119-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-825" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-826"><span class="mn" id="MathJax-Span-827" style="font-family: STIXGeneral-Regular;">4</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-119">4</script>.
  <br>We provide a description of all such codes and give the intersection arrays
  for all of them.
  </p>
  </div>
  </dd>
  <dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18089" title="Abstract">arXiv:2404.18089</a> [<a href="/pdf/2404.18089" title="Download PDF">pdf</a>, <a href="/format/2404.18089" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ATR-Mapping: Asymmetric Topological Representation based Mapping  Framework for Multi-Robot Environment Exploration
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+J">Jiyu Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wei Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>
  
  </div>
  <p class="mathjax">In recent years, the widespread application of multi-robot systems in areas
  such as power inspection, autonomous vehicle fleets has made multi-robot
  technology a research hotspot in the field of robotics. This paper investigates
  multi-robot cooperative exploration in unknown environments, proposing a
  training framework and decision strategy based on multi-agent reinforcement
  learning. Specifically we propose a Asymmetric Topological Representation based
  mapping framework (ATR-Mapping), combining the advantages of methods based on
  raw grid maps and methods based on topology, the structural information from
  the raw grid maps is extracted and combined with a topological graph
  constructed based on geometric distance information for decision-making.
  Leveraging this topological graph representation, we employs a decision network
  based on topological graph matching to assign corresponding boundary points to
  each robot as long-term target points for decision-making. We conducts testing
  and application of the proposed algorithms in real world scenarios using the
  Gazebo and Gibson simulation environments. It validates that the proposed
  method, when compared to existing methods, achieves a certain degree of
  performance improvement.
  </p>
  </div>
  </dd>
  <dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18090" title="Abstract">arXiv:2404.18090</a> [<a href="/pdf/2404.18090" title="Download PDF">pdf</a>, <a href="/format/2404.18090" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Novel Classification of Attacks on Blockchain Layers: Vulnerabilities,  Attacks, Mitigations, and Research Directions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dwivedi%2C+K">Kaustubh Dwivedi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agrawal%2C+A">Ankit Agrawal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bhatia%2C+A">Ashutosh Bhatia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tiwari%2C+K">Kamlesh Tiwari</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>
  
  </div>
  <p class="mathjax">The widespread adoption of blockchain technology has amplified the spectrum
  of potential threats to its integrity and security. The ongoing quest to
  exploit vulnerabilities emphasizes how critical it is to expand on current
  research initiatives. Thus, using a methodology based on discrete blockchain
  layers, our survey study aims to broaden the existing body of knowledge by
  thoroughly discussing both new and known attack vectors inside the blockchain
  ecosystem. This survey proposes a novel classification of blockchain attacks
  and an in-depth investigation of blockchain data security. In particular, the
  paper provides a thorough discussion of the attack techniques and
  vulnerabilities that are specific to each tier, along with a detailed look at
  mitigating techniques. We reveal the deep dynamics of these security concerns
  by closely investigating the fundamental causes of attacks at various
  blockchain tiers. We clarify mitigation methods for known vulnerabilities and
  offer new information on recently developed attack vectors. We also discuss the
  implications of quantum computing in blockchain and the weaknesses in the
  current technology that can be exploited in the future. Our study advances the
  field of blockchain security and privacy research while also contributing to
  our understanding of blockchain vulnerabilities and attacks. This survey paper
  is a useful tool for readers who want to learn more about the intricacies of
  blockchain security. It also invites researchers to help strengthen blockchain
  privacy and security, paving the way for further developments in this dynamic
  and ever-evolving field.
  </p>
  </div>
  </dd>
  <dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18094" title="Abstract">arXiv:2404.18094</a> [<a href="/pdf/2404.18094" title="Download PDF">pdf</a>, <a href="/format/2404.18094" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> USAT: A Universal Speaker-Adaptive Text-to-Speech Approach
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenbin Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+Y">Yang Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jha%2C+S">Sanjay Jha</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages, 13 figures. Copyright has been transferred to IEEE
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> IEEE/ACM Transactions on Audio, Speech and Language Processing,
    2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">Conventional text-to-speech (TTS) research has predominantly focused on
  enhancing the quality of synthesized speech for speakers in the training
  dataset. The challenge of synthesizing lifelike speech for unseen,
  out-of-dataset speakers, especially those with limited reference data, remains
  a significant and unresolved problem. While zero-shot or few-shot
  speaker-adaptive TTS approaches have been explored, they have many limitations.
  Zero-shot approaches tend to suffer from insufficient generalization
  performance to reproduce the voice of speakers with heavy accents. While
  few-shot methods can reproduce highly varying accents, they bring a significant
  storage burden and the risk of overfitting and catastrophic forgetting. In
  addition, prior approaches only provide either zero-shot or few-shot
  adaptation, constraining their utility across varied real-world scenarios with
  different demands. Besides, most current evaluations of speaker-adaptive TTS
  are conducted only on datasets of native speakers, inadvertently neglecting a
  vast portion of non-native speakers with diverse accents. Our proposed
  framework unifies both zero-shot and few-shot speaker adaptation strategies,
  which we term as "instant" and "fine-grained" adaptations based on their
  merits. To alleviate the insufficient generalization performance observed in
  zero-shot speaker adaptation, we designed two innovative discriminators and
  introduced a memory mechanism for the speech decoder. To prevent catastrophic
  forgetting and reduce storage implications for few-shot speaker adaptation, we
  designed two adapters and a unique adaptation procedure.
  </p>
  </div>
  </dd>
  <dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18098" title="Abstract">arXiv:2404.18098</a> [<a href="/pdf/2404.18098" title="Download PDF">pdf</a>, <a href="/ps/2404.18098" title="Download PostScript">ps</a>, <a href="/format/2404.18098" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Parameterized Dynamic Logic -- Towards A Cyclic Logical Framework for  Program Verification via Operational Semantics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuanrui Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">Dynamic logic and its variations, because of their good expressive forms
  capturing program specifications clearly by isolating programs from logical
  formulas, have been used as a formalism in program reasoning for decades and
  have many applications in different areas. The program models of traditional
  dynamic logics are in explicit forms. With a clearly-defined syntactic
  structure, compositional verification is made possible, in which a deduction
  step transfers proving a program into proving its sub-programs. This
  structure-based reasoning forms the basis of many dynamic logics and popular
  Hoare-style logics. However, structural rules induce a major drawback that for
  different target programs, different rules have to be proposed to adapt
  different program structures. Moreover, there exist programs that does not
  support (or not entirely support) a structure-based reasoning. In this paper,
  we propose a parameterized `dynamic-logic-like' logic called DLp with general
  forms of program models and formulas, and propose a cyclic proof system for
  this logic. Program reasoning in DLp is directly based on symbolic executions
  of programs according to their operational semantics. This reduces the burden
  of designing a large set of rules when specializing a logic theory to a
  specific domain, and facilitates verifying programs without a suitable
  structure for direct reasoning. Without reasoning by dissolving program
  structures, DLp can cause an infinite proof structure. To solve this, we build
  a cyclic preproof structure for the proof system of DLp and prove its
  soundness. Case studies are analyzed to show how DLp works for reasoning about
  different types of programs.
  </p>
  </div>
  </dd>
  <dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18101" title="Abstract">arXiv:2404.18101</a> [<a href="/pdf/2404.18101" title="Download PDF">pdf</a>, <a href="/format/2404.18101" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Advancing Supervised Learning with the Wave Loss Function: A Robust and  Smooth Approach
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Akhtar%2C+M">Mushir Akhtar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tanveer%2C+M">M. Tanveer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Arshad%2C+M">Mohd. Arshad</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Loss function plays a vital role in supervised learning frameworks. The
  selection of the appropriate loss function holds the potential to have a
  substantial impact on the proficiency attained by the acquired model. The
  training of supervised learning algorithms inherently adheres to predetermined
  loss functions during the optimization process. In this paper, we present a
  novel contribution to the realm of supervised machine learning: an asymmetric
  loss function named wave loss. It exhibits robustness against outliers,
  insensitivity to noise, boundedness, and a crucial smoothness property.
  Theoretically, we establish that the proposed wave loss function manifests the
  essential characteristic of being classification-calibrated. Leveraging this
  breakthrough, we incorporate the proposed wave loss function into the least
  squares setting of support vector machines (SVM) and twin support vector
  machines (TSVM), resulting in two robust and smooth models termed Wave-SVM and
  Wave-TSVM, respectively. To address the optimization problem inherent in
  Wave-SVM, we utilize the adaptive moment estimation (Adam) algorithm. It is
  noteworthy that this paper marks the first instance of the Adam algorithm
  application to solve an SVM model. Further, we devise an iterative algorithm to
  solve the optimization problems of Wave-TSVM. To empirically showcase the
  effectiveness of the proposed Wave-SVM and Wave-TSVM, we evaluate them on
  benchmark UCI and KEEL datasets (with and without feature noise) from diverse
  domains. Moreover, to exemplify the applicability of Wave-SVM in the biomedical
  domain, we evaluate it on the Alzheimer Disease Neuroimaging Initiative (ADNI)
  dataset. The experimental outcomes unequivocally reveal the prowess of Wave-SVM
  and Wave-TSVM in achieving superior prediction accuracy against the baseline
  models.
  </p>
  </div>
  </dd>
  <dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18102" title="Abstract">arXiv:2404.18102</a> [<a href="/pdf/2404.18102" title="Download PDF">pdf</a>, <a href="/format/2404.18102" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quasi-interpolation projectors for Subdivision Surfaces
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Xu%2C+H">Hailun Xu</a>, 
  <a href="/search/math?searchtype=author&amp;query=Kang%2C+H">Hongmei Kang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">Subdivision surfaces are considered as an extension of splines to accommodate
  models with complex topologies, making them useful for addressing PDEs on
  models with complex topologies in isogeometric analysis. This has generated a
  lot of interest in the field of subdivision space approximation. The
  quasi-interpolation offers a highly efficient approach for spline
  approximation, eliminating the necessity of solving large linear systems of
  equations. Nevertheless, the lack of analytical expressions at extraordinary
  points on subdivision surfaces makes traditional techniques for creating
  B-spline quasi-interpolants inappropriate for subdivision spaces. To address
  this obstacle, this paper innovatively reframes the evaluation issue associated
  with subdivision surfaces as a correlation between subdivision matrices and
  limit points, offering a thorough method for quasi-interpolation specifically
  designed for subdivision surfaces. This developed quasi-interpolant, termed the
  subdivision space projection operator, accurately reproduces the subdivision
  space. We provide explicit quasi-interpolation formulas for various typical
  subdivision schemes. Numerical experiments demonstrate that the
  quasi-interpolants for Catmull-Clark and Loop subdivision exhibit third-order
  approximation in the (L_2) norm and second-order in the (L_\infty) norm.
  Furthermore, the modified Loop subdivision quasi-interpolant achieves optimal
  approximation rates in both the (L_2) and (L_\infty) norms.
  </p>
  </div>
  </dd>
  <dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18105" title="Abstract">arXiv:2404.18105</a> [<a href="/pdf/2404.18105" title="Download PDF">pdf</a>, <a href="/format/2404.18105" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Tightly-Coupled VLP/INS Integrated Navigation by Inclination Estimation  and Blockage Handling
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+X">Xiao Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+Y">Yuan Zhuang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiansheng Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huai%2C+J">Jianzhu Huai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+T">Tianming Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+D">Daquan Feng</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)
  
  </div>
  <p class="mathjax">Visible Light Positioning (VLP) has emerged as a promising technology capable
  of delivering indoor localization with high accuracy. In VLP systems that use
  Photodiodes (PDs) as light receivers, the Received Signal Strength (RSS) is
  affected by the incidence angle of light, making the inclination of PDs a
  critical parameter in the positioning model. Currently, most studies assume the
  inclination to be constant, limiting the applications and positioning accuracy.
  Additionally, light blockages may severely interfere with the RSS measurements
  but the literature has not explored blockage detection in real-world
  experiments. To address these problems, we propose a tightly coupled VLP/INS
  (Inertial Navigation System) integrated navigation system that uses graph
  optimization to account for varying PD inclinations and VLP blockages. We also
  discussed the possibility of simultaneously estimating the robot's pose and the
  locations of some unknown LEDs. Simulations and two groups of real-world
  experiments demonstrate the efficiency of our approach, achieving an average
  positioning accuracy of 10 cm during movement and inclination accuracy within 1
  degree despite inclination changes and blockages.
  </p>
  </div>
  </dd>
  <dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18106" title="Abstract">arXiv:2404.18106</a> [<a href="/pdf/2404.18106" title="Download PDF">pdf</a>, <a href="/format/2404.18106" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Semi-supervised Text-based Person Search
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+D">Daming Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yang Bai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+M">Min Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dou%2C+H">Hao Dou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+M">Mang Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Min Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Text-based person search (TBPS) aims to retrieve images of a specific person
  from a large image gallery based on a natural language description. Existing
  methods rely on massive annotated image-text data to achieve satisfactory
  performance in fully-supervised learning. It poses a significant challenge in
  practice, as acquiring person images from surveillance videos is relatively
  easy, while obtaining annotated texts is challenging. The paper undertakes a
  pioneering initiative to explore TBPS under the semi-supervised setting, where
  only a limited number of person images are annotated with textual descriptions
  while the majority of images lack annotations. We present a two-stage basic
  solution based on generation-then-retrieval for semi-supervised TBPS. The
  generation stage enriches annotated data by applying an image captioning model
  to generate pseudo-texts for unannotated images. Later, the retrieval stage
  performs fully-supervised retrieval learning using the augmented data.
  Significantly, considering the noise interference of the pseudo-texts on
  retrieval learning, we propose a noise-robust retrieval framework that enhances
  the ability of the retrieval model to handle noisy data. The framework
  integrates two key strategies: Hybrid Patch-Channel Masking (PC-Mask) to refine
  the model architecture, and Noise-Guided Progressive Training (NP-Train) to
  enhance the training process. PC-Mask performs masking on the input data at
  both the patch-level and the channel-level to prevent overfitting noisy
  supervision. NP-Train introduces a progressive training schedule based on the
  noise level of pseudo-texts to facilitate noise-robust learning. Extensive
  experiments on multiple TBPS benchmarks show that the proposed framework
  achieves promising performance under the semi-supervised setting.
  </p>
  </div>
  </dd>
  <dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18109" title="Abstract">arXiv:2404.18109</a> [<a href="/pdf/2404.18109" title="Download PDF">pdf</a>, <a href="/format/2404.18109" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Finding Beautiful and Happy Images for Mental Health and Well-being  Applications
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+R">Ruitao Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+C">Connor Qiu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+G">Guoping Qiu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">This paper explores how artificial intelligence (AI) technology can
  contribute to achieve progress on good health and well-being, one of the United
  Nations' 17 Sustainable Development Goals. It is estimated that one in ten of
  the global population lived with a mental disorder. Inspired by studies showing
  that engaging and viewing beautiful natural images can make people feel happier
  and less stressful, lead to higher emotional well-being, and can even have
  therapeutic values, we explore how AI can help to promote mental health by
  developing automatic algorithms for finding beautiful and happy images. We
  first construct a large image database consisting of nearly 20K very high
  resolution colour photographs of natural scenes where each image is labelled
  with beautifulness and happiness scores by about 10 observers. Statistics of
  the database shows that there is a good correlation between the beautifulness
  and happiness scores which provides anecdotal evidence to corroborate that
  engaging beautiful natural images can potentially benefit mental well-being.
  Building on this unique database, the very first of its kind, we have developed
  a deep learning based model for automatically predicting the beautifulness and
  happiness scores of natural images. Experimental results are presented to show
  that it is possible to develop AI algorithms to automatically assess an image's
  beautifulness and happiness values which can in turn be used to develop
  applications for promoting mental health and well-being.
  </p>
  </div>
  </dd>
  <dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18112" title="Abstract">arXiv:2404.18112</a> [<a href="/pdf/2404.18112" title="Download PDF">pdf</a>, <a href="/format/2404.18112" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Garbage Segmentation and Attribute Analysis by Robotic Dogs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+N">Nuo Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liao%2C+J">Jianfeng Liao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Meng%2C+Q">Qiwei Meng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+W">Wei Song</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
  
  </div>
  <p class="mathjax">Efficient waste management and recycling heavily rely on garbage exploration
  and identification. In this study, we propose GSA2Seg (Garbage Segmentation and
  Attribute Analysis), a novel visual approach that utilizes quadruped robotic
  dogs as autonomous agents to address waste management and recycling challenges
  in diverse indoor and outdoor environments. Equipped with advanced visual
  perception system, including visual sensors and instance segmentators, the
  robotic dogs adeptly navigate their surroundings, diligently searching for
  common garbage items. Inspired by open-vocabulary algorithms, we introduce an
  innovative method for object attribute analysis. By combining garbage
  segmentation and attribute analysis techniques, the robotic dogs accurately
  determine the state of the trash, including its position and placement
  properties. This information enhances the robotic arm's grasping capabilities,
  facilitating successful garbage retrieval. Additionally, we contribute an image
  dataset, named GSA2D, to support evaluation. Through extensive experiments on
  GSA2D, this paper provides a comprehensive analysis of GSA2Seg's effectiveness.
  Dataset available:
  \href{https://www.kaggle.com/datasets/hellob/gsa2d-2024}{https://www.kaggle.com/datasets/hellob/gsa2d-2024}.
  </p>
  </div>
  </dd>
  <dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18114" title="Abstract">arXiv:2404.18114</a> [<a href="/pdf/2404.18114" title="Download PDF">pdf</a>, <a href="/format/2404.18114" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Deep Boosting Learning: A Brand-new Cooperative Approach for Image-Text  Matching
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Diao%2C+H">Haiwen Diao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Ying Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+S">Shang Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ruan%2C+X">Xiang Ruan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+H">Huchuan Lu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages, 9 figures, Accepted by TIP2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)
  
  </div>
  <p class="mathjax">Image-text matching remains a challenging task due to heterogeneous semantic
  diversity across modalities and insufficient distance separability within
  triplets. Different from previous approaches focusing on enhancing multi-modal
  representations or exploiting cross-modal correspondence for more accurate
  retrieval, in this paper we aim to leverage the knowledge transfer between peer
  branches in a boosting manner to seek a more powerful matching model.
  Specifically, we propose a brand-new Deep Boosting Learning (DBL) algorithm,
  where an anchor branch is first trained to provide insights into the data
  properties, with a target branch gaining more advanced knowledge to develop
  optimal features and distance metrics. Concretely, an anchor branch initially
  learns the absolute or relative distance between positive and negative pairs,
  providing a foundational understanding of the particular network and data
  distribution. Building upon this knowledge, a target branch is concurrently
  tasked with more adaptive margin constraints to further enlarge the relative
  distance between matched and unmatched samples. Extensive experiments validate
  that our DBL can achieve impressive and consistent improvements based on
  various recent state-of-the-art models in the image-text matching field, and
  outperform related popular cooperative strategies, e.g., Conventional
  Distillation, Mutual Learning, and Contrastive Learning. Beyond the above, we
  confirm that DBL can be seamlessly integrated into their training scenarios and
  achieve superior performance under the same computational costs, demonstrating
  the flexibility and broad applicability of our proposed method. Our code is
  publicly available at: https://github.com/Paranioar/DBL.
  </p>
  </div>
  </dd>
  <dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18117" title="Abstract">arXiv:2404.18117</a> [<a href="/pdf/2404.18117" title="Download PDF">pdf</a>, <a href="/ps/2404.18117" title="Download PostScript">ps</a>, <a href="/format/2404.18117" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Basis-preserving Algorithm for Computing the Bezout Matrix of Newton  Polynomials
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jing Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+W">Wei Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Numerical Analysis (math.NA)
  
  </div>
  <p class="mathjax">This paper tackles the problem of constructing Bezout matrices for Newton
  polynomials in a basis-preserving approach that operates directly with the
  given Newton basis, thus avoiding the need for transformation from Newton basis
  to monomial basis. This approach significantly reduces the computational cost
  and also mitigates numerical instability caused by basis transformation. For
  this purpose, we investigate the internal structure of Bezout matrices in
  Newton basis and design a basis-preserving algorithm that generates the Bezout
  matrix in the specified basis used to formulate the input polynomials.
  Furthermore, we show an application of the proposed algorithm on constructing
  confederate resultant matrices for Newton polynomials. Experimental results
  demonstrate that the proposed methods perform superior to the
  basis-transformation-based ones.
  </p>
  </div>
  </dd>
  <dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18118" title="Abstract">arXiv:2404.18118</a> [<a href="/pdf/2404.18118" title="Download PDF">pdf</a>, <a href="/ps/2404.18118" title="Download PostScript">ps</a>, <a href="/format/2404.18118" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Finite-time Safety and Reach-avoid Verification of Stochastic  Discrete-time Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Xue%2C+B">Bai Xue</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  <p class="mathjax">This paper studies finite-time safety and reach-avoid verification for
  stochastic discrete-time dynamical systems. The aim is to ascertain lower and
  upper bounds of the probability that, within a predefined finite-time horizon,
  a system starting from an initial state in a safe set will either exit the safe
  set (safety verification) or reach a target set while remaining within the safe
  set until the first encounter with the target (reach-avoid verification). We
  introduce novel barrier-like sufficient conditions for characterizing these
  bounds, which either complement existing ones or fill gaps. Finally, we
  demonstrate the efficacy of these conditions on two examples.
  </p>
  </div>
  </dd>
  <dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18124" title="Abstract">arXiv:2404.18124</a> [<a href="/pdf/2404.18124" title="Download PDF">pdf</a>, <a href="/ps/2404.18124" title="Download PostScript">ps</a>, <a href="/format/2404.18124" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An Arbitrarily High-Order Fully Well-balanced Hybrid Finite  Element-Finite Volume Method for a One-dimensional Blood Flow Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Liu%2C+Y">Yongle Liu</a>, 
  <a href="/search/math?searchtype=author&amp;query=Barsukow%2C+W">Wasilij Barsukow</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">In this paper, we propose an arbitrarily high-order accurate fully
  well-balanced numerical method for the one-dimensional blood flow model. The
  developed method is based on a continuous representation of the solution and a
  natural combination of the conservative and primitive formulations of the
  studied PDEs. The degrees of freedom are defined as point values at cell
  interfaces and moments of the conservative variables inside the cell, drawing
  inspiration from the discontinuous Galerkin method. The well-balanced property,
  in the sense of an exact preservation of both the zero and non-zero velocity
  equilibria, is achieved by a well-balanced approximation of the source term in
  the conservative formulation and a well-balanced residual computation in the
  primitive formulation. To lowest (3rd) order this method reduces to the method
  developed in [Abgrall and Liu, A New Approach for Designing Well-Balanced
  Schemes for the Shallow Water Equations: A Combination of Conservative and
  Primitive Formulations, arXiv preprint, <a href="/abs/2304.07809">arXiv:2304.07809</a>]. Several numerical
  tests are shown to prove its well-balanced and high-order accuracy properties.
  </p>
  </div>
  </dd>
  <dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18125" title="Abstract">arXiv:2404.18125</a> [<a href="/pdf/2404.18125" title="Download PDF">pdf</a>, <a href="/format/2404.18125" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Large-Scale Empirical Study of COVID-19 Contact Tracing Mobile App  Reviews
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Parisa%2C+S+I">Sifat Ishmam Parisa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Anindya%2C+M+A+A">Md Awsaf Alam Anindya</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Iqbal%2C+A">Anindya Iqbal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Uddin%2C+G">Gias Uddin</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Since the beginning of 2020, the novel coronavirus has begun to sweep across
  the globe. Given the prevalence of smartphones everywhere, many countries
  across continents also developed COVID-19 contract tracing apps that users can
  install to get a warning of potential contacts with infected people. Unlike
  regular apps that undergo detailed requirement analysis, carefully designed
  development, rigorous testing, contact tracing apps were deployed after rapid
  development. Therefore such apps may not reach expectations for all end users.
  Users share their opinions and experience of the usage of the apps in the app
  store. This paper aims to understand the types of topics users discuss in the
  reviews of the COVID-19 contact tracing apps across the continents by analyzing
  the app reviews. We collected all the reviews of 35 COVID-19 contact tracing
  apps developed by 34 countries across the globe. We group the app reviews into
  the following geographical regions: Asia, Europe, North America, Latin America,
  Africa, Middle East, and Australasia (Australia and NZ). We run topic modeling
  on the app reviews of each region. We analyze the produced topics and their
  evolution over time by categorizing them into hierarchies and computing the
  ratings of reviews related to the topics. While privacy could be a concern with
  such apps, we only find privacy-related topics in Australasia, North America,
  and Middle East. Topics related to usability and performance of the apps are
  prevalent across all regions. Users frequently complained about the lack of
  features, user interface and the negative impact of such apps on their mobile
  batteries. Still, we also find that many users praised the apps because they
  helped them stay aware of the potential danger of getting infected. The finding
  of this study is expected to help app developers utilize their resources to
  address the reported issues in a prioritized way.
  </p>
  </div>
  </dd>
  <dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18126" title="Abstract">arXiv:2404.18126</a> [<a href="/pdf/2404.18126" title="Download PDF">pdf</a>, <a href="/format/2404.18126" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Testing <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-120-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-828" style="width: 1.391em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.122em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(0.181em, 1001.122em, 1.302em, -999.998em); top: -0.983em; left: 0em;"><span class="mrow" id="MathJax-Span-829"><span class="msubsup" id="MathJax-Span-830"><span style="display: inline-block; position: relative; width: 1.078em; height: 0px;"><span style="position: absolute; clip: rect(3.183em, 1000.674em, 4.124em, -999.998em); top: -3.985em; left: 0em;"><span class="mi" id="MathJax-Span-831" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.674em;"><span class="mi" id="MathJax-Span-832" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 0.988em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.275em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.114em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-120">C_k</script>-freeness in bounded-arboricity graphs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Eden%2C+T">Talya Eden</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Levi%2C+R">Reut Levi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ron%2C+D">Dana Ron</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  <p class="mathjax">We study the problem of testing <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-121-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-833" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-834"><span class="msubsup" id="MathJax-Span-835"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-836" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mi" id="MathJax-Span-837" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-121">C_k</script>-freeness (<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-122-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-838" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-839"><span class="mi" id="MathJax-Span-840" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-122">k</script>-cycle-freeness) for fixed
  constant <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-123-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-841" style="width: 2.882em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.261em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-842"><span class="mi" id="MathJax-Span-843" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-844" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">&gt;</span><span class="mn" id="MathJax-Span-845" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">3</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-123">k > 3</script> in graphs with bounded arboricity (but unbounded degrees). In
  particular, we are interested in one-sided error algorithms, so that they must
  detect a copy of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-124-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-846" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-847"><span class="msubsup" id="MathJax-Span-848"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-849" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mi" id="MathJax-Span-850" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-124">C_k</script> with high constant probability when the graph is
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-125-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-851" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-852"><span class="mi" id="MathJax-Span-853" style="font-family: STIXGeneral-Italic;">ϵ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-125">\epsilon</script>-far from <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-126-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-854" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-855"><span class="msubsup" id="MathJax-Span-856"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-857" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mi" id="MathJax-Span-858" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-126">C_k</script>-free. We next state our results for constant
  arboricity and constant <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-127-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-859" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-860"><span class="mi" id="MathJax-Span-861" style="font-family: STIXGeneral-Italic;">ϵ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-127">\epsilon</script> with a focus on the dependence on the number
  of graph vertices, <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-128-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-862" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-863"><span class="mi" id="MathJax-Span-864" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-128">n</script>. The query complexity of all our algorithms grows
  polynomially with <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-129-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-865" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.245em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-866"><span class="mn" id="MathJax-Span-867" style="font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-868"><span class="mrow" id="MathJax-Span-869"><span class="mo" id="MathJax-Span-870" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mi" id="MathJax-Span-871" style="font-family: STIXGeneral-Italic;">ϵ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-129">1/\epsilon</script>. (1) As opposed to the case of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-130-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-872" style="width: 2.882em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.261em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-873"><span class="mi" id="MathJax-Span-874" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-875" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mn" id="MathJax-Span-876" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">3</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-130">k=3</script>, where the
  complexity of testing <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-131-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-877" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-878"><span class="msubsup" id="MathJax-Span-879"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-880" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mn" id="MathJax-Span-881" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-131">C_3</script>-freeness grows with the arboricity of the graph but
  not with the size of the graph (Levi, ICALP 2021) this is no longer the case
  already for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-132-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-882" style="width: 2.882em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.318em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-883"><span class="mi" id="MathJax-Span-884" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-885" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mn" id="MathJax-Span-886" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">4</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-132">k=4</script>. We show that <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-133-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-887" style="width: 3.616em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.939em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1002.882em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-888"><span class="mi" id="MathJax-Span-889" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-890" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-891"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-892" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-893"><span class="mrow" id="MathJax-Span-894"><span class="mn" id="MathJax-Span-895" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-896"><span class="mrow" id="MathJax-Span-897"><span class="mo" id="MathJax-Span-898" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-899" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">4</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-900" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-133">\Omega(n^{1/4})</script> queries are necessary for
  testing <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-134-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-901" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-902"><span class="msubsup" id="MathJax-Span-903"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-904" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mn" id="MathJax-Span-905" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">4</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-134">C_4</script>-freeness, and that <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-135-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-906" style="width: 3.842em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.108em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.414em, 1003.052em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-907"><span class="texatom" id="MathJax-Span-908"><span class="mrow" id="MathJax-Span-909"><span class="munderover" id="MathJax-Span-910"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0.116em;"><span class="mi" id="MathJax-Span-911" style="font-family: STIXGeneral-Italic;">O</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.108em, 1000.963em, 3.56em, -999.997em); top: -4.232em; left: 0em;"><span class="mo" id="MathJax-Span-912" style=""><span style="font-family: STIXSizeTwoSym;">˜</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-913" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-914"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-915" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-916"><span class="mrow" id="MathJax-Span-917"><span class="mn" id="MathJax-Span-918" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-919"><span class="mrow" id="MathJax-Span-920"><span class="mo" id="MathJax-Span-921" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-922" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">4</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-923" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.531em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-135">\widetilde{O}(n^{1/4})</script> are sufficient. The
  same bounds hold for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-136-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-924" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-925"><span class="msubsup" id="MathJax-Span-926"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-927" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mn" id="MathJax-Span-928" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">5</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-136">C_5</script>. (2) For every fixed <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-137-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-929" style="width: 2.882em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.261em, 2.826em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-930"><span class="mi" id="MathJax-Span-931" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-932" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≥</span><span class="mn" id="MathJax-Span-933" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">6</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-137">k \geq 6</script>, any one-sided error
  algorithm for testing <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-138-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-934" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-935"><span class="msubsup" id="MathJax-Span-936"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-937" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mi" id="MathJax-Span-938" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-138">C_k</script>-freeness must perform <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-139-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-939" style="width: 3.616em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.939em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1002.882em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-940"><span class="mi" id="MathJax-Span-941" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-942" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-943"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-944" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-945"><span class="mrow" id="MathJax-Span-946"><span class="mn" id="MathJax-Span-947" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-948"><span class="mrow" id="MathJax-Span-949"><span class="mo" id="MathJax-Span-950" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-951" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-952" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-139">\Omega(n^{1/3})</script> queries.
  (3) For <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-140-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-953" style="width: 2.882em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.261em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-954"><span class="mi" id="MathJax-Span-955" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-956" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mn" id="MathJax-Span-957" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">6</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-140">k=6</script> we give a testing algorithm whose query complexity is
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-141-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-958" style="width: 3.842em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.108em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.414em, 1003.052em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-959"><span class="texatom" id="MathJax-Span-960"><span class="mrow" id="MathJax-Span-961"><span class="munderover" id="MathJax-Span-962"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0.116em;"><span class="mi" id="MathJax-Span-963" style="font-family: STIXGeneral-Italic;">O</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.108em, 1000.963em, 3.56em, -999.997em); top: -4.232em; left: 0em;"><span class="mo" id="MathJax-Span-964" style=""><span style="font-family: STIXSizeTwoSym;">˜</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-965" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-966"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-967" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-968"><span class="mrow" id="MathJax-Span-969"><span class="mn" id="MathJax-Span-970" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-971"><span class="mrow" id="MathJax-Span-972"><span class="mo" id="MathJax-Span-973" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-974" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-975" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.531em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-141">\widetilde{O}(n^{1/2})</script>. (4) For any fixed <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-142-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-976" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-977"><span class="mi" id="MathJax-Span-978" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-142">k</script>, the query complexity of
  testing <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-143-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-979" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-980"><span class="msubsup" id="MathJax-Span-981"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-982" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mi" id="MathJax-Span-983" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-143">C_k</script>-freeness is upper bounded by <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-144-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-984" style="width: 6.044em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.915em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1004.858em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-985"><span class="texatom" id="MathJax-Span-986"><span class="mrow" id="MathJax-Span-987"><span class="mi" id="MathJax-Span-988" style="font-family: STIXGeneral-Italic;">O</span></span></span><span class="mo" id="MathJax-Span-989" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-990"><span style="display: inline-block; position: relative; width: 3.503em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-991" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-992"><span class="mrow" id="MathJax-Span-993"><span class="mn" id="MathJax-Span-994" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-995" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-996" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-997"><span class="mrow" id="MathJax-Span-998"><span class="mo" id="MathJax-Span-999" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mo" id="MathJax-Span-1000" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">⌊</span><span class="mi" id="MathJax-Span-1001" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-1002"><span class="mrow" id="MathJax-Span-1003"><span class="mo" id="MathJax-Span-1004" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-1005" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-1006" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">⌋</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1007" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-144">{O}(n^{1-1/\lfloor k/2\rfloor})</script>.
  <br>Our <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-145-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1008" style="width: 3.616em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.939em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1002.882em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1009"><span class="mi" id="MathJax-Span-1010" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-1011" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1012"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1013" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-1014"><span class="mrow" id="MathJax-Span-1015"><span class="mn" id="MathJax-Span-1016" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-1017"><span class="mrow" id="MathJax-Span-1018"><span class="mo" id="MathJax-Span-1019" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-1020" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">4</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1021" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-145">\Omega(n^{1/4})</script> lower bound for testing <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-146-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1022" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1023"><span class="msubsup" id="MathJax-Span-1024"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1025" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mn" id="MathJax-Span-1026" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">4</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-146">C_4</script>-freeness in constant
  arboricity graphs provides a negative answer to an open problem posed by
  (Goldreich, 2021).
  </p>
  </div>
  </dd>
  <dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18130" title="Abstract">arXiv:2404.18130</a> [<a href="/pdf/2404.18130" title="Download PDF">pdf</a>, <a href="/format/2404.18130" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Logic Agent: Enhancing Validity with Logic Rule Invocation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Hanmeng Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Teng%2C+Z">Zhiyang Teng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chaoli Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yue Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
  
  </div>
  <p class="mathjax">Chain-of-Thought (CoT) prompting has emerged as a pivotal technique for
  augmenting the inferential capabilities of language models during reasoning
  tasks. Despite its advancements, CoT often grapples with challenges in
  validating reasoning validity and ensuring informativeness. Addressing these
  limitations, this paper introduces the Logic Agent (LA), an agent-based
  framework aimed at enhancing the validity of reasoning processes in Large
  Language Models (LLMs) through strategic logic rule invocation. Unlike
  conventional approaches, LA transforms LLMs into logic agents that dynamically
  apply propositional logic rules, initiating the reasoning process by converting
  natural language inputs into structured logic forms. The logic agent leverages
  a comprehensive set of predefined functions to systematically navigate the
  reasoning process. This methodology not only promotes the structured and
  coherent generation of reasoning constructs but also significantly improves
  their interpretability and logical coherence. Through extensive
  experimentation, we demonstrate LA's capacity to scale effectively across
  various model sizes, markedly improving the precision of complex reasoning
  across diverse tasks.
  </p>
  </div>
  </dd>
  <dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18132" title="Abstract">arXiv:2404.18132</a> [<a href="/pdf/2404.18132" title="Download PDF">pdf</a>, <a href="/format/2404.18132" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Allocating Mixed Goods with Customized Fairness and Indivisibility Ratio
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bo Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zihao Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shengxin Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zekai Wu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Appears in the 33rd International Joint Conference on Artificial Intelligence (IJCAI), 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>
  
  </div>
  <p class="mathjax">We consider the problem of fairly allocating a combination of divisible and
  indivisible goods. While fairness criteria like envy-freeness (EF) and
  proportionality (PROP) can always be achieved for divisible goods, only their
  relaxed versions, such as the ''up to one'' relaxations EF1 and PROP1, can be
  satisfied when the goods are indivisible. The ''up to one'' relaxations require
  the fairness conditions to be satisfied provided that one good can be
  completely eliminated or added in the comparison. In this work, we bridge the
  gap between the two extremes and propose ''up to a fraction'' relaxations for
  the allocation of mixed divisible and indivisible goods. The fraction is
  determined based on the proportion of indivisible goods, which we call the
  indivisibility ratio. The new concepts also introduce asymmetric conditions
  that are customized for individuals with varying indivisibility ratios. We
  provide both upper and lower bounds on the fractions of the modified item in
  order to satisfy the fairness criterion. Our results are tight up to a constant
  for EF and asymptotically tight for PROP.
  </p>
  </div>
  </dd>
  <dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18133" title="Abstract">arXiv:2404.18133</a> [<a href="/pdf/2404.18133" title="Download PDF">pdf</a>, <a href="/format/2404.18133" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Fair Division of Indivisible Goods with Comparison-Based Queries
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bu%2C+X">Xiaolin Bu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zihao Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shengxin Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+J">Jiaxin Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tao%2C+B">Biaoshuai Tao</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>
  
  </div>
  <p class="mathjax">We study the problem of fairly allocating <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-147-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1027" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1028"><span class="mi" id="MathJax-Span-1029" style="font-family: STIXGeneral-Italic;">m</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-147">m</script> indivisible goods to <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-148-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1030" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1031"><span class="mi" id="MathJax-Span-1032" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-148">n</script>
  agents, where agents may have different preferences over the goods. In the
  traditional setting, agents' valuations are provided as inputs to the
  algorithm. In this paper, we study a new comparison-based query model where the
  algorithm presents two bundles of goods to an agent and the agent responds by
  telling the algorithm which bundle she prefers. We investigate the query
  complexity for computing allocations with several fairness notions including
  proportionality up to one good (PROP1), envy-freeness up to one good (EF1), and
  maximin share (MMS). Our main result is an algorithm that computes an
  allocation satisfying both PROP1 and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-149-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1033" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1000.737em, 1.584em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1034"><span class="mfrac" id="MathJax-Span-1035"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.39em, 1000.285em, 4.181em, -999.997em); top: -4.401em; left: 50%; margin-left: -0.167em;"><span class="mn" id="MathJax-Span-1036" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.39em, 1000.342em, 4.181em, -999.997em); top: -3.611em; left: 50%; margin-left: -0.167em;"><span class="mn" id="MathJax-Span-1037" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.454em, 1.245em, -999.997em); top: -1.296em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.454em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.552em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.74em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-149">\frac12</script>-MMS within <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-150-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1038" style="width: 4.463em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.616em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.56em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1039"><span class="mi" id="MathJax-Span-1040" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1041" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1042" style="font-family: STIXGeneral-Regular;">log</span><span class="mo" id="MathJax-Span-1043"></span><span class="mi" id="MathJax-Span-1044" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">m</span><span class="mo" id="MathJax-Span-1045" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-150">O(\log m)</script> queries
  with a constant number of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-151-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1046" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1047"><span class="mi" id="MathJax-Span-1048" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-151">n</script> agents. For identical and additive valuation, we
  present an algorithm for computing an EF1 allocation within <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-152-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1049" style="width: 4.463em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.616em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.56em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1050"><span class="mi" id="MathJax-Span-1051" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1052" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1053" style="font-family: STIXGeneral-Regular;">log</span><span class="mo" id="MathJax-Span-1054"></span><span class="mi" id="MathJax-Span-1055" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">m</span><span class="mo" id="MathJax-Span-1056" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-152">O(\log m)</script> queries
  with a constant number of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-153-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1057" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1058"><span class="mi" id="MathJax-Span-1059" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-153">n</script> agents. To complement the positive results, we
  show that the lower bound of the query complexity for any of the three fairness
  notions is <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-154-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1060" style="width: 4.463em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.616em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.56em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1061"><span class="mi" id="MathJax-Span-1062" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-1063" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1064" style="font-family: STIXGeneral-Regular;">log</span><span class="mo" id="MathJax-Span-1065"></span><span class="mi" id="MathJax-Span-1066" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">m</span><span class="mo" id="MathJax-Span-1067" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-154">\Omega(\log m)</script> even with two agents.
  </p>
  </div>
  </dd>
  <dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18134" title="Abstract">arXiv:2404.18134</a> [<a href="/pdf/2404.18134" title="Download PDF">pdf</a>, <a href="/format/2404.18134" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhancing Fairness in Neural Networks Using FairVIC
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Barker%2C+C">Charmaine Barker</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bethell%2C+D">Daniel Bethell</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kazakov%2C+D">Dimitar Kazakov</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">Mitigating bias in automated decision-making systems, specifically deep
  learning models, is a critical challenge in achieving fairness. This complexity
  stems from factors such as nuanced definitions of fairness, unique biases in
  each dataset, and the trade-off between fairness and model accuracy. To address
  such issues, we introduce FairVIC, an innovative approach designed to enhance
  fairness in neural networks by addressing inherent biases at the training
  stage. FairVIC differs from traditional approaches that typically address
  biases at the data preprocessing stage. Instead, it integrates variance,
  invariance and covariance into the loss function to minimise the model's
  dependency on protected characteristics for making predictions, thus promoting
  fairness. Our experimentation and evaluation consists of training neural
  networks on three datasets known for their biases, comparing our results to
  state-of-the-art algorithms, evaluating on different sizes of model
  architectures, and carrying out sensitivity analysis to examine the
  fairness-accuracy trade-off. Through our implementation of FairVIC, we observed
  a significant improvement in fairness across all metrics tested, without
  compromising the model's accuracy to a detrimental extent. Our findings suggest
  that FairVIC presents a straightforward, out-of-the-box solution for the
  development of fairer deep learning models, thereby offering a generalisable
  solution applicable across many tasks and datasets.
  </p>
  </div>
  </dd>
  <dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18135" title="Abstract">arXiv:2404.18135</a> [<a href="/pdf/2404.18135" title="Download PDF">pdf</a>, <a href="/format/2404.18135" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Dexterous Grasp Transformer
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+G">Guo-Hao Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+Y">Yi-Lin Wei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+D">Dian Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiao-Ming Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+W">Wei-Shi Zheng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to CVPR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">In this work, we propose a novel discriminative framework for dexterous grasp
  generation, named Dexterous Grasp TRansformer (DGTR), capable of predicting a
  diverse set of feasible grasp poses by processing the object point cloud with
  only one forward pass. We formulate dexterous grasp generation as a set
  prediction task and design a transformer-based grasping model for it. However,
  we identify that this set prediction paradigm encounters several optimization
  challenges in the field of dexterous grasping and results in restricted
  performance. To address these issues, we propose progressive strategies for
  both the training and testing phases. First, the dynamic-static matching
  training (DSMT) strategy is presented to enhance the optimization stability
  during the training phase. Second, we introduce the adversarial-balanced
  test-time adaptation (AB-TTA) with a pair of adversarial losses to improve
  grasping quality during the testing phase. Experimental results on the
  DexGraspNet dataset demonstrate the capability of DGTR to predict dexterous
  grasp poses with both high quality and diversity. Notably, while keeping high
  quality, the diversity of grasp poses predicted by DGTR significantly
  outperforms previous works in multiple metrics without any data pre-processing.
  Codes are available at https://github.com/iSEE-Laboratory/DGTR .
  </p>
  </div>
  </dd>
  <dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18136" title="Abstract">arXiv:2404.18136</a> [<a href="/pdf/2404.18136" title="Download PDF">pdf</a>, <a href="/format/2404.18136" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SafePaint: Anti-forensic Image Inpainting with Domain Adaptation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+D">Dunyun Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liao%2C+X">Xin Liao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiaoshuai Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Shiwei Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)
  
  </div>
  <p class="mathjax">Existing image inpainting methods have achieved remarkable accomplishments in
  generating visually appealing results, often accompanied by a trend toward
  creating more intricate structural textures. However, while these models excel
  at creating more realistic image content, they often leave noticeable traces of
  tampering, posing a significant threat to security. In this work, we take the
  anti-forensic capabilities into consideration, firstly proposing an end-to-end
  training framework for anti-forensic image inpainting named SafePaint.
  Specifically, we innovatively formulated image inpainting as two major tasks:
  semantically plausible content completion and region-wise optimization. The
  former is similar to current inpainting methods that aim to restore the missing
  regions of corrupted images. The latter, through domain adaptation, endeavors
  to reconcile the discrepancies between the inpainted region and the unaltered
  area to achieve anti-forensic goals. Through comprehensive theoretical
  analysis, we validate the effectiveness of domain adaptation for anti-forensic
  performance. Furthermore, we meticulously crafted a region-wise separated
  attention (RWSA) module, which not only aligns with our objective of
  anti-forensics but also enhances the performance of the model. Extensive
  qualitative and quantitative evaluations show our approach achieves comparable
  results to existing image inpainting methods while offering anti-forensic
  capabilities not available in other methods.
  </p>
  </div>
  </dd>
  <dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18143" title="Abstract">arXiv:2404.18143</a> [<a href="/pdf/2404.18143" title="Download PDF">pdf</a>, <a href="/format/2404.18143" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Tracking Transforming Objects: A Benchmark
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">You Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuelong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liao%2C+Y">Yaxin Liao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+F">Fuliang Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+H">Hengzhou Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shuiwang Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Tracking transforming objects holds significant importance in various fields
  due to the dynamic nature of many real-world scenarios. By enabling systems
  accurately represent transforming objects over time, tracking transforming
  objects facilitates advancements in areas such as autonomous systems,
  human-computer interaction, and security applications. Moreover, understanding
  the behavior of transforming objects provides valuable insights into complex
  interactions or processes, contributing to the development of intelligent
  systems capable of robust and adaptive perception in dynamic environments.
  However, current research in the field mainly focuses on tracking generic
  objects. In this study, we bridge this gap by collecting a novel dedicated
  Dataset for Tracking Transforming Objects, called DTTO, which contains 100
  sequences, amounting to approximately 9.3K frames. We provide carefully
  hand-annotated bounding boxes for each frame within these sequences, making
  DTTO the pioneering benchmark dedicated to tracking transforming objects. We
  thoroughly evaluate 20 state-of-the-art trackers on the benchmark, aiming to
  comprehend the performance of existing methods and provide a comparison for
  future research on DTTO. With the release of DTTO, our goal is to facilitate
  further research and applications related to tracking transforming objects.
  </p>
  </div>
  </dd>
  <dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18144" title="Abstract">arXiv:2404.18144</a> [<a href="/pdf/2404.18144" title="Download PDF">pdf</a>, <a href="/format/2404.18144" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generative AI for Visualization: State of the Art and Future Directions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+Y">Yilin Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hao%2C+J">Jianing Hao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hou%2C+Y">Yihan Hou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+S">Shishi Xiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yuyu Luo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+W">Wei Zeng</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
  
  </div>
  <p class="mathjax">Generative AI (GenAI) has witnessed remarkable progress in recent years and
  demonstrated impressive performance in various generation tasks in different
  domains such as computer vision and computational design. Many researchers have
  attempted to integrate GenAI into visualization framework, leveraging the
  superior generative capacity for different operations. Concurrently, recent
  major breakthroughs in GenAI like diffusion model and large language model have
  also drastically increase the potential of GenAI4VIS. From a technical
  perspective, this paper looks back on previous visualization studies leveraging
  GenAI and discusses the challenges and opportunities for future research.
  Specifically, we cover the applications of different types of GenAI methods
  including sequence, tabular, spatial and graph generation techniques for
  different tasks of visualization which we summarize into four major stages:
  data enhancement, visual mapping generation, stylization and interaction. For
  each specific visualization sub-task, we illustrate the typical data and
  concrete GenAI algorithms, aiming to provide in-depth understanding of the
  state-of-the-art GenAI4VIS techniques and their limitations. Furthermore, based
  on the survey, we discuss three major aspects of challenges and research
  opportunities including evaluation, dataset, and the gap between end-to-end
  GenAI and generative algorithms. By summarizing different generation
  algorithms, their current applications and limitations, this paper endeavors to
  provide useful insights for future GenAI4VIS research.
  </p>
  </div>
  </dd>
  <dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18148" title="Abstract">arXiv:2404.18148</a> [<a href="/pdf/2404.18148" title="Download PDF">pdf</a>, <a href="/format/2404.18148" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Decentralized Peer Review in Open Science: A Mechanism Proposal
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Finke%2C+A">Andreas Finke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hensel%2C+T">Thomas Hensel</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, 1 figure
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computers and Society (cs.CY); General Economics (econ.GN)
  
  </div>
  <p class="mathjax">Peer review is a laborious, yet essential, part of academic publishing with
  crucial impact on the scientific endeavor. The current lack of incentives and
  transparency harms the credibility of this process. Researchers are neither
  rewarded for superior nor penalized for bad reviews. Additionally, confidential
  reports cause a loss of insights and make the review process vulnerable to
  scientific misconduct. We propose a community-owned and -governed system that
  1) remunerates reviewers for their efforts, 2) publishes the (anonymized)
  reports for scrutiny by the community, 3) tracks reputation of reviewers and 4)
  provides digital certificates. Automated by transparent smart-contract
  blockchain technology, the system aims to increase quality and speed of peer
  review while lowering the chance and impact of erroneous judgements.
  </p>
  </div>
  </dd>
  <dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18149" title="Abstract">arXiv:2404.18149</a> [<a href="/pdf/2404.18149" title="Download PDF">pdf</a>, <a href="/format/2404.18149" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Compressed Deepfake Video Detection Based on 3D Spatiotemporal  Trajectories
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zongmei Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liao%2C+X">Xin Liao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiaoshuai Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yanxiang Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)
  
  </div>
  <p class="mathjax">The misuse of deepfake technology by malicious actors poses a potential
  threat to nations, societies, and individuals. However, existing methods for
  detecting deepfakes primarily focus on uncompressed videos, such as noise
  characteristics, local textures, or frequency statistics. When applied to
  compressed videos, these methods experience a decrease in detection performance
  and are less suitable for real-world scenarios. In this paper, we propose a
  deepfake video detection method based on 3D spatiotemporal trajectories.
  Specifically, we utilize a robust 3D model to construct spatiotemporal motion
  features, integrating feature details from both 2D and 3D frames to mitigate
  the influence of large head rotation angles or insufficient lighting within
  frames. Furthermore, we separate facial expressions from head movements and
  design a sequential analysis method based on phase space motion trajectories to
  explore the feature differences between genuine and fake faces in deepfake
  videos. We conduct extensive experiments to validate the performance of our
  proposed method on several compressed deepfake benchmarks. The robustness of
  the well-designed features is verified by calculating the consistent
  distribution of facial landmarks before and after video compression.Our method
  yields satisfactory results and showcases its potential for practical
  applications.
  </p>
  </div>
  </dd>
  <dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18150" title="Abstract">arXiv:2404.18150</a> [<a href="/pdf/2404.18150" title="Download PDF">pdf</a>, <a href="/ps/2404.18150" title="Download PostScript">ps</a>, <a href="/format/2404.18150" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> RadSimReal: Bridging the Gap Between Synthetic and Real Data in Radar  Object Detection With Simulation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bialer%2C+O">Oded Bialer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Haitman%2C+Y">Yuval Haitman</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> CVPR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Object detection in radar imagery with neural networks shows great potential
  for improving autonomous driving. However, obtaining annotated datasets from
  real radar images, crucial for training these networks, is challenging,
  especially in scenarios with long-range detection and adverse weather and
  lighting conditions where radar performance excels. To address this challenge,
  we present RadSimReal, an innovative physical radar simulation capable of
  generating synthetic radar images with accompanying annotations for various
  radar types and environmental conditions, all without the need for real data
  collection. Remarkably, our findings demonstrate that training object detection
  models on RadSimReal data and subsequently evaluating them on real-world data
  produce performance levels comparable to models trained and tested on real data
  from the same dataset, and even achieves better performance when testing across
  different real datasets. RadSimReal offers advantages over other physical radar
  simulations that it does not necessitate knowledge of the radar design details,
  which are often not disclosed by radar suppliers, and has faster run-time. This
  innovative tool has the potential to advance the development of computer vision
  algorithms for radar-based autonomous driving applications.
  </p>
  </div>
  </dd>
  <dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18151" title="Abstract">arXiv:2404.18151</a> [<a href="/pdf/2404.18151" title="Download PDF">pdf</a>, <a href="/format/2404.18151" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Decidability of Graph Neural Networks via Logical Characterizations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Benedikt%2C+M">Michael Benedikt</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+C">Chia-Hsuan Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Motik%2C+B">Boris Motik</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tan%2C+T">Tony Tan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  <p class="mathjax">We present results concerning the expressiveness and decidability of a
  popular graph learning formalism, graph neural networks (GNNs), exploiting
  connections with logic. We use a family of recently-discovered decidable logics
  involving "Presburger quantifiers". We show how to use these logics to measure
  the expressiveness of classes of GNNs, in some cases getting exact
  correspondences between the expressiveness of logics and GNNs. We also employ
  the logics, and the techniques used to analyze them, to obtain decision
  procedures for verification problems over GNNs. We complement this with
  undecidability results for static analysis problems involving the logics, as
  well as for GNN verification problems.
  </p>
  </div>
  </dd>
  <dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18152" title="Abstract">arXiv:2404.18152</a> [<a href="/pdf/2404.18152" title="Download PDF">pdf</a>, <a href="/format/2404.18152" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Masked Attention as a Mechanism for Improving Interpretability of Vision  Transformers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Grisi%2C+C">Clément Grisi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Litjens%2C+G">Geert Litjens</a>, 
  <a href="/search/cs?searchtype=author&amp;query=van+der+Laak%2C+J">Jeroen van der Laak</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at MIDL 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
  
  </div>
  <p class="mathjax">Vision Transformers are at the heart of the current surge of interest in
  foundation models for histopathology. They process images by breaking them into
  smaller patches following a regular grid, regardless of their content. Yet, not
  all parts of an image are equally relevant for its understanding. This is
  particularly true in computational pathology where background is completely
  non-informative and may introduce artefacts that could mislead predictions. To
  address this issue, we propose a novel method that explicitly masks background
  in Vision Transformers' attention mechanism. This ensures tokens corresponding
  to background patches do not contribute to the final image representation,
  thereby improving model robustness and interpretability. We validate our
  approach using prostate cancer grading from whole-slide images as a case study.
  Our results demonstrate that it achieves comparable performance with plain
  self-attention while providing more accurate and clinically meaningful
  attention heatmaps.
  </p>
  </div>
  </dd>
  <dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18154" title="Abstract">arXiv:2404.18154</a> [<a href="/pdf/2404.18154" title="Download PDF">pdf</a>, <a href="/format/2404.18154" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Explaining vague language
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=%C3%89gr%C3%A9%2C+P">Paul Égré</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Spector%2C+B">Benjamin Spector</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Science and Game Theory (cs.GT); Information Theory (cs.IT)
  
  </div>
  <p class="mathjax">Why is language vague? Vagueness may be explained and rationalized if it can
  be shown that vague language is more useful to speaker and hearer than precise
  language. In a well-known paper, Lipman proposes a game-theoretic account of
  vagueness in terms of mixed strategy that leads to a puzzle: vagueness cannot
  be strictly better than precision at equilibrium. More recently, \'Egr\'e,
  Spector, Mortier and Verheyen have put forward a Bayesian account of vagueness
  establishing that using vague words can be strictly more informative than using
  precise words. This paper proposes to compare both results and to explain why
  they are not in contradiction. Lipman's definition of vagueness relies
  exclusively on a property of signaling strategies, without making any
  assumptions about the lexicon, whereas \'Egr\'e et al.'s involves a layer of
  semantic content. We argue that the semantic account of vagueness is needed,
  and more adequate and explanatory of vagueness.
  </p>
  </div>
  </dd>
  <dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18155" title="Abstract">arXiv:2404.18155</a> [<a href="/pdf/2404.18155" title="Download PDF">pdf</a>, <a href="/format/2404.18155" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ShapeMoiré: Channel-Wise Shape-Guided Network for Image Demoiréing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+J">Jinming Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shen%2C+S">Sicheng Shen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Q">Qiu Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yin%2C+Y">Yifang Yin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yangyan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zimmermann%2C+R">Roger Zimmermann</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Photographing optoelectronic displays often introduces unwanted moir\'e
  patterns due to analog signal interference between the pixel grids of the
  display and the camera sensor arrays. This work identifies two problems that
  are largely ignored by existing image demoir\'eing approaches: 1) moir\'e
  patterns vary across different channels (RGB); 2) repetitive patterns are
  constantly observed. However, employing conventional convolutional (CNN) layers
  cannot address these problems. Instead, this paper presents the use of our
  recently proposed Shape concept. It was originally employed to model consistent
  features from fragmented regions, particularly when identical or similar
  objects coexist in an RGB-D image. Interestingly, we find that the Shape
  information effectively captures the moir\'e patterns in artifact images.
  Motivated by this discovery, we propose a ShapeMoir\'e method to aid in image
  demoir\'eing. Beyond modeling shape features at the patch-level, we further
  extend this to the global image-level and design a novel Shape-Architecture.
  Consequently, our proposed method, equipped with both ShapeConv and
  Shape-Architecture, can be seamlessly integrated into existing approaches
  without introducing additional parameters or computation overhead during
  inference. We conduct extensive experiments on four widely used datasets, and
  the results demonstrate that our ShapeMoir\'e achieves state-of-the-art
  performance, particularly in terms of the PSNR metric. We then apply our method
  across four popular architectures to showcase its generalization capabilities.
  Moreover, our ShapeMoir\'e is robust and viable under real-world demoir\'eing
  scenarios involving smartphone photographs.
  </p>
  </div>
  </dd>
  <dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18156" title="Abstract">arXiv:2404.18156</a> [<a href="/pdf/2404.18156" title="Download PDF">pdf</a>, <a href="/format/2404.18156" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Event-based Video Frame Interpolation with Edge Guided Motion Refinement
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuhan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yongjian Deng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+B">Bochen Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Youfu Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhen Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Video frame interpolation, the process of synthesizing intermediate frames
  between sequential video frames, has made remarkable progress with the use of
  event cameras. These sensors, with microsecond-level temporal resolution, fill
  information gaps between frames by providing precise motion cues. However,
  contemporary Event-Based Video Frame Interpolation (E-VFI) techniques often
  neglect the fact that event data primarily supply high-confidence features at
  scene edges during multi-modal feature fusion, thereby diminishing the role of
  event signals in optical flow (OF) estimation and warping refinement. To
  address this overlooked aspect, we introduce an end-to-end E-VFI learning
  method (referred to as EGMR) to efficiently utilize edge features from event
  signals for motion flow and warping enhancement. Our method incorporates an
  Edge Guided Attentive (EGA) module, which rectifies estimated video motion
  through attentive aggregation based on the local correlation of multi-modal
  features in a coarse-to-fine strategy. Moreover, given that event data can
  provide accurate visual references at scene edges between consecutive frames,
  we introduce a learned visibility map derived from event data to adaptively
  mitigate the occlusion problem in the warping refinement process. Extensive
  experiments on both synthetic and real datasets show the effectiveness of the
  proposed approach, demonstrating its potential for higher quality video frame
  interpolation.
  </p>
  </div>
  </dd>
  <dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18159" title="Abstract">arXiv:2404.18159</a> [<a href="/pdf/2404.18159" title="Download PDF">pdf</a>, <a href="/format/2404.18159" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Evaluating ROCKET and Catch22 features for calf behaviour classification  from accelerometer data using Machine Learning models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dissanayakea%2C+O">Oshana Dissanayakea</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McPhersonc%2C+S+E">Sarah E. McPhersonc</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Allyndree%2C+J">Joseph Allyndree</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kennedy%2C+E">Emer Kennedy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cunningham%2C+P">Padraig Cunningham</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Riaboff%2C+L">Lucile Riaboff</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 45 pages, 8 figures, 11 tables (3 in the Appendix), Journal paper
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)
  
  </div>
  <p class="mathjax">Monitoring calf behaviour continuously would be beneficial to identify
  routine practices (e.g., weaning, dehorning, etc.) that impact calf welfare in
  dairy farms. In that regard, accelerometer data collected from neck collars can
  be used along with Machine Learning models to classify calf behaviour
  automatically. Hand-crafted features are commonly used in Machine Learning
  models, while ROCKET and Catch22 features are specifically designed for
  time-series classification problems in related fields. This study aims to
  compare the performance of ROCKET and Catch22 features to Hand-Crafted
  features. 30 Irish Holstein Friesian and Jersey pre-weaned calves were
  monitored using accelerometer sensors allowing for 27.4 hours of annotated
  behaviors. Additional time-series were computed from the raw X, Y and Z-axis
  and split into 3-second time windows. ROCKET, Catch22 and Hand-Crafted features
  were calculated for each time window, and the dataset was then split into the
  train, validation and test sets. Each set of features was used to train three
  Machine Learning models (Random Forest, eXtreme Gradient Boosting, and
  RidgeClassifierCV) to classify six behaviours indicative of pre-weaned calf
  welfare (drinking milk, grooming, lying, running, walking and other). Models
  were tuned with the validation set, and the performance of each feature-model
  combination was evaluated with the test set. The best performance across the
  three models was obtained with ROCKET [average balanced accuracy +/- standard
  deviation] (0.70 +/- 0.07), followed by Catch22 (0.69 +/- 0.05), surpassing
  Hand-Crafted (0.65 +/- 0.034). The best balanced accuracy (0.77) was obtained
  with ROCKET and RidgeClassifierCV, followed by Catch22 and Random Forest
  (0.73). Thus, tailoring these approaches for specific behaviours and contexts
  will be crucial in advancing precision livestock farming and enhancing animal
  welfare on a larger scale.
  </p>
  </div>
  </dd>
  <dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18161" title="Abstract">arXiv:2404.18161</a> [<a href="/pdf/2404.18161" title="Download PDF">pdf</a>, <a href="/format/2404.18161" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> IMEX-Reg: Implicit-Explicit Regularization in the Function Space for  Continual Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bhat%2C+P">Prashant Bhat</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Renjith%2C+B">Bharath Renjith</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Arani%2C+E">Elahe Arani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zonooz%2C+B">Bahram Zonooz</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Published in Transactions on Machine Learning Research
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Continual learning (CL) remains one of the long-standing challenges for deep
  neural networks due to catastrophic forgetting of previously acquired
  knowledge. Although rehearsal-based approaches have been fairly successful in
  mitigating catastrophic forgetting, they suffer from overfitting on buffered
  samples and prior information loss, hindering generalization under low-buffer
  regimes. Inspired by how humans learn using strong inductive biases, we propose
  IMEX-Reg to improve the generalization performance of experience rehearsal in
  CL under low buffer regimes. Specifically, we employ a two-pronged
  implicit-explicit regularization approach using contrastive representation
  learning (CRL) and consistency regularization. To further leverage the global
  relationship between representations learned using CRL, we propose a
  regularization strategy to guide the classifier toward the activation
  correlations in the unit hypersphere of the CRL. Our results show that IMEX-Reg
  significantly improves generalization performance and outperforms
  rehearsal-based approaches in several CL scenarios. It is also robust to
  natural and adversarial corruptions with less task-recency bias. Additionally,
  we provide theoretical insights to support our design decisions further.
  </p>
  </div>
  </dd>
  <dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18162" title="Abstract">arXiv:2404.18162</a> [<a href="/pdf/2404.18162" title="Download PDF">pdf</a>, <a href="/format/2404.18162" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> fMRI Exploration of Visual Quality Assessment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yiming Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+Y">Ying Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Min%2C+X">Xiongkuo Min</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yan Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+G">Guangtao Zhai</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Neurons and Cognition (q-bio.NC)
  
  </div>
  <p class="mathjax">Despite significant strides in visual quality assessment, the neural
  mechanisms underlying visual quality perception remain insufficiently explored.
  This study employed fMRI to examine brain activity during image quality
  assessment and identify differences in human processing of images with varying
  quality. Fourteen healthy participants underwent tasks assessing both image
  quality and content classification while undergoing functional MRI scans. The
  collected behavioral data was statistically analyzed, and univariate and
  functional connectivity analyses were conducted on the imaging data. The
  findings revealed that quality assessment is a more complex task than content
  classification, involving enhanced activation in high-level cognitive brain
  regions for fine-grained visual analysis. Moreover, the research showed the
  brain's adaptability to different visual inputs, adopting different strategies
  depending on the input's quality. In response to high-quality images, the brain
  primarily uses specialized visual areas for precise analysis, whereas with
  low-quality images, it recruits additional resources including higher-order
  visual cortices and related cognitive and attentional networks to decode and
  recognize complex, ambiguous signals effectively. This study pioneers the
  intersection of neuroscience and image quality research, providing empirical
  evidence through fMRI linking image quality to neural processing. It
  contributes novel insights into the human visual system's response to diverse
  image qualities, thereby paving the way for advancements in objective image
  quality assessment algorithms.
  </p>
  </div>
  </dd>
  <dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18166" title="Abstract">arXiv:2404.18166</a> [<a href="/pdf/2404.18166" title="Download PDF">pdf</a>, <a href="/format/2404.18166" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Behavior-Contextualized Item Preference Modeling for Multi-Behavior  Recommendation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+M">Mingshi Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+F">Fan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jing Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+F">Fuming Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Z">Zhiyong Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+Y">Yahong Han</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This paper has been accepted by SIGIR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">In recommender systems, multi-behavior methods have demonstrated their
  effectiveness in mitigating issues like data sparsity, a common challenge in
  traditional single-behavior recommendation approaches. These methods typically
  infer user preferences from various auxiliary behaviors and apply them to the
  target behavior for recommendations. However, this direct transfer can
  introduce noise to the target behavior in recommendation, due to variations in
  user attention across different behaviors. To address this issue, this paper
  introduces a novel approach, Behavior-Contextualized Item Preference Modeling
  (BCIPM), for multi-behavior recommendation. Our proposed
  Behavior-Contextualized Item Preference Network discerns and learns users'
  specific item preferences within each behavior. It then considers only those
  preferences relevant to the target behavior for final recommendations,
  significantly reducing noise from auxiliary behaviors. These auxiliary
  behaviors are utilized solely for training the network parameters, thereby
  refining the learning process without compromising the accuracy of the target
  behavior recommendations. To further enhance the effectiveness of BCIPM, we
  adopt a strategy of pre-training the initial embeddings. This step is crucial
  for enriching the item-aware preferences, particularly in scenarios where data
  related to the target behavior is sparse. Comprehensive experiments conducted
  on four real-world datasets demonstrate BCIPM's superior performance compared
  to several leading state-of-the-art models, validating the robustness and
  efficiency of our proposed approach.
  </p>
  </div>
  </dd>
  <dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18170" title="Abstract">arXiv:2404.18170</a> [<a href="/pdf/2404.18170" title="Download PDF">pdf</a>, <a href="/format/2404.18170" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bridging Worlds: Achieving Language Interoperability between Julia and  Python in Scientific Computing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Osborne%2C+I">Ianna Osborne</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pivarski%2C+J">Jim Pivarski</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ling%2C+J">Jerry Ling</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 1 figure, ACAT2024 workshop
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Data Analysis, Statistics and Probability (physics.data-an)
  
  </div>
  <p class="mathjax">In the realm of scientific computing, both Julia and Python have established
  themselves as powerful tools. Within the context of High Energy Physics (HEP)
  data analysis, Python has been traditionally favored, yet there exists a
  compelling case for migrating legacy software to Julia. This article focuses on
  language interoperability, specifically exploring how Awkward Array data
  structures can bridge the gap between Julia and Python. The talk offers
  insights into key considerations such as memory management, data buffer copies,
  and dependency handling. It delves into the performance enhancements achieved
  by invoking Julia from Python and vice versa, particularly for intensive
  array-oriented calculations involving large-scale, though not excessively
  dimensional, arrays of HEP data. The advantages and challenges inherent in
  achieving interoperability between Julia and Python in the domain of scientific
  computing are discussed.
  </p>
  </div>
  </dd>
  <dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18174" title="Abstract">arXiv:2404.18174</a> [<a href="/pdf/2404.18174" title="Download PDF">pdf</a>, <a href="/format/2404.18174" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mamba-FETrack: Frame-Event Tracking via State Space Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Ju Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shiao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuai Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhe Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+B">Bo Jiang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> In Peer Review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">RGB-Event based tracking is an emerging research topic, focusing on how to
  effectively integrate heterogeneous multi-modal data (synchronized exposure
  video frames and asynchronous pulse Event stream). Existing works typically
  employ Transformer based networks to handle these modalities and achieve decent
  accuracy through input-level or feature-level fusion on multiple datasets.
  However, these trackers require significant memory consumption and
  computational complexity due to the use of self-attention mechanism. This paper
  proposes a novel RGB-Event tracking framework, Mamba-FETrack, based on the
  State Space Model (SSM) to achieve high-performance tracking while effectively
  reducing computational costs and realizing more efficient tracking.
  Specifically, we adopt two modality-specific Mamba backbone networks to extract
  the features of RGB frames and Event streams. Then, we also propose to boost
  the interactive learning between the RGB and Event features using the Mamba
  network. The fused features will be fed into the tracking head for target
  object localization. Extensive experiments on FELT and FE108 datasets fully
  validated the efficiency and effectiveness of our proposed tracker.
  Specifically, our Mamba-based tracker achieves 43.5/55.6 on the SR/PR metric,
  while the ViT-S based tracker (OSTrack) obtains 40.0/50.9. The GPU memory cost
  of ours and ViT-S based tracker is 13.98GB and 15.44GB, which decreased about
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-155-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1068" style="width: 2.543em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.035em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.64em, 1001.979em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1069"><span class="mn" id="MathJax-Span-1070" style="font-family: STIXGeneral-Regular;">9.5</span><span class="mi" id="MathJax-Span-1071" style="font-family: STIXGeneral-Regular;">%</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-155">9.5\%</script>. The FLOPs and parameters of ours/ViT-S based OSTrack are 59GB/1076GB
  and 7MB/60MB, which decreased about <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-156-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1072" style="width: 3.165em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.543em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.64em, 1002.487em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1073"><span class="mn" id="MathJax-Span-1074" style="font-family: STIXGeneral-Regular;">94.5</span><span class="mi" id="MathJax-Span-1075" style="font-family: STIXGeneral-Regular;">%</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-156">94.5\%</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-157-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1076" style="width: 3.165em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.543em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.64em, 1002.487em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1077"><span class="mn" id="MathJax-Span-1078" style="font-family: STIXGeneral-Regular;">88.3</span><span class="mi" id="MathJax-Span-1079" style="font-family: STIXGeneral-Regular;">%</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-157">88.3\%</script>, respectively. We
  hope this work can bring some new insights to the tracking field and greatly
  promote the application of the Mamba architecture in tracking. The source code
  of this work will be released on
  \url{https://github.com/Event-AHU/Mamba_FETrack}.
  </p>
  </div>
  </dd>
  <dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18176" title="Abstract">arXiv:2404.18176</a> [<a href="/pdf/2404.18176" title="Download PDF">pdf</a>, <a href="/format/2404.18176" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Auto-Optimized Maximum Torque Per Ampere Control of IPMSM Using Dual  Control for Exploration and Exploitation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Zuo%2C+Y">Yuefei Zuo</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Yu%2C+Y">Yalei Yu</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Yang%2C+J">Jun Yang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Chen%2C+W">Wen-Hua Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  <p class="mathjax">In this paper, a maximum torque per ampere (MTPA) control strategy for the
  interior permanent magnet synchronous motor (IPMSM) using dual control for
  exploration and exploitation (DCEE). In the proposed method, the permanent
  magnet flux and the difference between the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-158-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1080" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1081"><span class="mi" id="MathJax-Span-1082" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-158">d</script>- and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-159-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1083" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1084"><span class="mi" id="MathJax-Span-1085" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-159">q</script>-axis inductance are
  identified by multiple estimators using the recursive least square method. The
  initial values of the estimated parameters in different estimators are
  different. By using multiple estimators, exploration of the operational
  environment to reduce knowledge uncertainty can be realized. Compared to those
  MTPA control strategies based on the extremum-seeking method, the proposed
  method has better dynamic performance when speed or load varies. The
  effectiveness of the proposed method is verified by simulations.
  </p>
  </div>
  </dd>
  <dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18180" title="Abstract">arXiv:2404.18180</a> [<a href="/pdf/2404.18180" title="Download PDF">pdf</a>, <a href="/format/2404.18180" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> EkoHate: Abusive Language and Hate Speech Detection for Code-switched  Political Discussions on Nigerian Twitter
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ilevbare%2C+C+E">Comfort Eseohen Ilevbare</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Alabi%2C+J+O">Jesujoba O. Alabi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Adelani%2C+D+I">David Ifeoluwa Adelani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bakare%2C+F+D">Firdous Damilola Bakare</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Abiola%2C+O+B">Oluwatoyin Bunmi Abiola</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Adeyemo%2C+O+A">Oluwaseyi Adesina Adeyemo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> AfricaNLP workshop @ ICLR2024 and WOAH @ NAACL2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Nigerians have a notable online presence and actively discuss political and
  topical matters. This was particularly evident throughout the 2023 general
  election, where Twitter was used for campaigning, fact-checking and
  verification, and even positive and negative discourse. However, little or none
  has been done in the detection of abusive language and hate speech in Nigeria.
  In this paper, we curated code-switched Twitter data directed at three
  musketeers of the governorship election on the most populous and economically
  vibrant state in Nigeria; Lagos state, with the view to detect offensive speech
  in political discussions. We developed EkoHate -- an abusive language and hate
  speech dataset for political discussions between the three candidates and their
  followers using a binary (normal vs offensive) and fine-grained four-label
  annotation scheme. We analysed our dataset and provided an empirical evaluation
  of state-of-the-art methods across both supervised and cross-lingual transfer
  learning settings. In the supervised setting, our evaluation results in both
  binary and four-label annotation schemes show that we can achieve 95.1 and 70.3
  F1 points respectively. Furthermore, we show that our dataset adequately
  transfers very well to three publicly available offensive datasets (OLID,
  HateUS2020, and FountaHate), generalizing to political discussions in other
  regions like the US.
  </p>
  </div>
  </dd>
  <dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18181" title="Abstract">arXiv:2404.18181</a> [<a href="/pdf/2404.18181" title="Download PDF">pdf</a>, <a href="/format/2404.18181" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning to Move Objects with Fluid Streams in a Differentiable  Simulation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Freivalds%2C+K">Karlis Freivalds</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Leja%2C+L">Laura Leja</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Teikmanis%2C+O">Oskars Teikmanis</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 7 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">We introduce a method for manipulating objects in three-dimensional space
  using controlled fluid streams. To achieve this, we train a neural network
  controller in a differentiable simulation and evaluate it in a simulated
  environment consisting of an 8x8 grid of vertical emitters. By carrying out
  various horizontal displacement tasks such as moving objects to specific
  positions while reacting to external perturbations, we demonstrate that a
  controller, trained with a limited number of iterations, can generalise to
  longer episodes and learn the complex dynamics of fluid-solid interactions.
  Importantly, our approach requires only the observation of the manipulated
  object's state, paving the way for the development of physical systems that
  enable contactless manipulation of objects using air streams.
  </p>
  </div>
  </dd>
  <dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18185" title="Abstract">arXiv:2404.18185</a> [<a href="/pdf/2404.18185" title="Download PDF">pdf</a>, <a href="/format/2404.18185" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Ranked List Truncation for Large Language Model-based Re-Ranking
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Meng%2C+C">Chuan Meng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Arabzadeh%2C+N">Negar Arabzadeh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Askari%2C+A">Arian Askari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aliannejadi%2C+M">Mohammad Aliannejadi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=de+Rijke%2C+M">Maarten de Rijke</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted for publication as a long paper at SIGIR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">We study ranked list truncation (RLT) from a novel "retrieve-then-re-rank"
  perspective, where we optimize re-ranking by truncating the retrieved list
  (i.e., trim re-ranking candidates). RLT is crucial for re-ranking as it can
  improve re-ranking efficiency by sending variable-length candidate lists to a
  re-ranker on a per-query basis. It also has the potential to improve re-ranking
  effectiveness. Despite its importance, there is limited research into applying
  RLT methods to this new perspective. To address this research gap, we reproduce
  existing RLT methods in the context of re-ranking, especially newly emerged
  large language model (LLM)-based re-ranking. In particular, we examine to what
  extent established findings on RLT for retrieval are generalizable to the
  "retrieve-then-re-rank" setup from three perspectives: (i) assessing RLT
  methods in the context of LLM-based re-ranking with lexical first-stage
  retrieval, (ii) investigating the impact of different types of first-stage
  retrievers on RLT methods, and (iii) investigating the impact of different
  types of re-rankers on RLT methods. We perform experiments on the TREC 2019 and
  2020 deep learning tracks, investigating 8 RLT methods for pipelines involving
  3 retrievers and 2 re-rankers. We reach new insights into RLT methods in the
  context of re-ranking.
  </p>
  </div>
  </dd>
  <dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18186" title="Abstract">arXiv:2404.18186</a> [<a href="/pdf/2404.18186" title="Download PDF">pdf</a>, <a href="/format/2404.18186" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Static Application Security Testing (SAST) Tools for Smart Contracts:  How Far Are We?
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+K">Kaixuan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+Y">Yue Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Sen Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Han Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+K">Kairan Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+M">Ming Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Haijun Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yixiang Chen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> to appear at FSE 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">In recent years, the importance of smart contract security has been
  heightened by the increasing number of attacks against them. To address this
  issue, a multitude of static application security testing (SAST) tools have
  been proposed for detecting vulnerabilities in smart contracts. However,
  objectively comparing these tools to determine their effectiveness remains
  challenging. Existing studies often fall short due to the taxonomies and
  benchmarks only covering a coarse and potentially outdated set of vulnerability
  types, which leads to evaluations that are not entirely comprehensive and may
  display bias.
  <br>In this paper, we fill this gap by proposing an up-to-date and fine-grained
  taxonomy that includes 45 unique vulnerability types for smart contracts.
  Taking it as a baseline, we develop an extensive benchmark that covers 40
  distinct types and includes a diverse range of code characteristics,
  vulnerability patterns, and application scenarios. Based on them, we evaluated
  8 SAST tools using this benchmark, which comprises 788 smart contract files and
  10,394 vulnerabilities. Our results reveal that the existing SAST tools fail to
  detect around 50% of vulnerabilities in our benchmark and suffer from high
  false positives, with precision not surpassing 10%. We also discover that by
  combining the results of multiple tools, the false negative rate can be reduced
  effectively, at the expense of flagging 36.77 percentage points more functions.
  Nevertheless, many vulnerabilities, especially those beyond Access Control and
  Reentrancy vulnerabilities, remain undetected. We finally highlight the
  valuable insights from our study, hoping to provide guidance on tool
  development, enhancement, evaluation, and selection for developers,
  researchers, and practitioners.
  </p>
  </div>
  </dd>
  <dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18187" title="Abstract">arXiv:2404.18187</a> [<a href="/pdf/2404.18187" title="Download PDF">pdf</a>, <a href="/format/2404.18187" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Joint Spectrum Partitioning and Power Allocation for Energy Efficient  Semi-Integrated Sensing and Communications
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Abouelmaati%2C+A+M">Ammar Mohamed Abouelmaati</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aboagye%2C+S">Sylvester Aboagye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tabassum%2C+H">Hina Tabassum</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted in IEEE Communications Letters
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)
  
  </div>
  <p class="mathjax">With spectrum resources becoming congested and the emergence of
  sensing-enabled wireless applications, conventional resource allocation methods
  need a revamp to support communications-only, sensing-only, and integrated
  sensing and communication (ISaC) services together. In this letter, we propose
  two joint spectrum partitioning (SP) and power allocation (PA) schemes to
  maximize the aggregate sensing and communication performance as well as
  corresponding energy efficiency (EE) of a semi-ISaC system that supports all
  three services in a unified manner. The proposed framework captures the
  priority of the distinct services, impact of target clutters, power budget and
  bandwidth constraints, and sensing and communication quality-of-service (QoS)
  requirements. We reveal that the former problem is jointly convex and the
  latter is a non-convex problem that can be solved optimally by exploiting
  fractional and parametric programming techniques. Numerical results verify the
  effectiveness of proposed schemes and extract novel insights related to the
  impact of the priority and QoS requirements of distinct services on the
  performance of semi-ISaC networks.
  </p>
  </div>
  </dd>
  <dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18190" title="Abstract">arXiv:2404.18190</a> [<a href="/pdf/2404.18190" title="Download PDF">pdf</a>, <a href="/format/2404.18190" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Naive Bayes Classifiers and One-hot Encoding of Categorical Variables
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Williams%2C+C+K+I">Christopher K. I. Williams</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 3 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">This paper investigates the consequences of encoding a <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-160-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1086" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1087"><span class="mi" id="MathJax-Span-1088" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-160">K</script>-valued categorical
  variable incorrectly as <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-161-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1089" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1090"><span class="mi" id="MathJax-Span-1091" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-161">K</script> bits via one-hot encoding, when using a Na\"{\i}ve
  Bayes classifier. This gives rise to a product-of-Bernoullis (PoB) assumption,
  rather than the correct categorical Na\"{\i}ve Bayes classifier. The
  differences between the two classifiers are analysed mathematically and
  experimentally. In our experiments using probability vectors drawn from a
  Dirichlet distribution, the two classifiers are found to agree on the maximum a
  posteriori class label for most cases, although the posterior probabilities are
  usually greater for the PoB case.
  </p>
  </div>
  </dd>
  <dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18191" title="Abstract">arXiv:2404.18191</a> [<a href="/pdf/2404.18191" title="Download PDF">pdf</a>, <a href="/format/2404.18191" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring the Robustness of In-Context Learning with Noisy Labels
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+C">Chen Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+X">Xinzhi Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wen%2C+H">Haodong Wen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jinsong Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yue%2C+G">Guanzhang Yue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yihao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zeming Wei</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICLR 2024 Workshop on Reliable and Responsible Foundation Models
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Optimization and Control (math.OC)
  
  </div>
  <p class="mathjax">Recently, the mysterious In-Context Learning (ICL) ability exhibited by
  Transformer architectures, especially in large language models (LLMs), has
  sparked significant research interest. However, the resilience of Transformers'
  in-context learning capabilities in the presence of noisy samples, prevalent in
  both training corpora and prompt demonstrations, remains underexplored. In this
  paper, inspired by prior research that studies ICL ability using simple
  function classes, we take a closer look at this problem by investigating the
  robustness of Transformers against noisy labels. Specifically, we first conduct
  a thorough evaluation and analysis of the robustness of Transformers against
  noisy labels during in-context learning and show that they exhibit notable
  resilience against diverse types of noise in demonstration labels. Furthermore,
  we delve deeper into this problem by exploring whether introducing noise into
  the training set, akin to a form of data augmentation, enhances such robustness
  during inference, and find that such noise can indeed improve the robustness of
  ICL. Overall, our fruitful analysis and findings provide a comprehensive
  understanding of the resilience of Transformer models against label noises
  during ICL and provide valuable insights into the research on Transformers in
  natural language processing. Our code is available at
  https://github.com/InezYu0928/in-context-learning.
  </p>
  </div>
  </dd>
  <dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18192" title="Abstract">arXiv:2404.18192</a> [<a href="/pdf/2404.18192" title="Download PDF">pdf</a>, <a href="/format/2404.18192" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Block-Map-Based Localization in Large-Scale Environment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yixiao Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Zhou Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yongliang Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yunlong Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiangyu Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hao Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+G">Guyue Zhou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 4 figures, 4 tables, published to ICRA 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Accurate localization is an essential technology for the flexible navigation
  of robots in large-scale environments. Both SLAM-based and map-based
  localization will increase the computing load due to the increase in map size,
  which will affect downstream tasks such as robot navigation and services. To
  this end, we propose a localization system based on Block Maps (BMs) to reduce
  the computational load caused by maintaining large-scale maps. Firstly, we
  introduce a method for generating block maps and the corresponding switching
  strategies, ensuring that the robot can estimate the state in large-scale
  environments by loading local map information. Secondly, global localization
  according to Branch-and-Bound Search (BBS) in the 3D map is introduced to
  provide the initial pose. Finally, a graph-based optimization method is adopted
  with a dynamic sliding window that determines what factors are being
  marginalized whether a robot is exposed to a BM or switching to another one,
  which maintains the accuracy and efficiency of pose tracking. Comparison
  experiments are performed on publicly available large-scale datasets. Results
  show that the proposed method can track the robot pose even though the map
  scale reaches more than 6 kilometers, while efficient and accurate localization
  is still guaranteed on NCLT and M2DGR.
  </p>
  </div>
  </dd>
  <dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18196" title="Abstract">arXiv:2404.18196</a> [<a href="/pdf/2404.18196" title="Download PDF">pdf</a>, <a href="/format/2404.18196" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Intent-based User Interfaces: Charting the Design Space of  Intent-AI Interactions Across Task Types
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+Z">Zijian Ding</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">Technological advances continue to redefine the dynamics of human-machine
  interactions, particularly in task execution. This proposal responds to the
  advancements in Generative AI by outlining a research plan that probes
  intent-AI interaction across a diverse set of tasks: fixed-scope content
  curation task, atomic creative tasks, and complex and interdependent tasks.
  This exploration aims to inform and contribute to the development of
  Intent-based User Interface (IUI). The study is structured in three phases:
  examining fixed-scope tasks through news headline generation, exploring atomic
  creative tasks via analogy generation, and delving into complex tasks through
  exploratory visual data analysis. Future work will focus on improving IUIs to
  better provide suggestions to encourage experienced users to express broad and
  exploratory intents, and detailed and structured guidance for novice users to
  iterate on analysis intents for high quality outputs.
  </p>
  </div>
  </dd>
  <dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18199" title="Abstract">arXiv:2404.18199</a> [<a href="/pdf/2404.18199" title="Download PDF">pdf</a>, <a href="/format/2404.18199" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Rethinking Attention Gated with Hybrid Dual Pyramid Transformer-CNN for  Generalized Segmentation in Medical Imaging
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Bougourzi%2C+F">Fares Bougourzi</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Dornaika%2C+F">Fadi Dornaika</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Taleb-Ahmed%2C+A">Abdelmalik Taleb-Ahmed</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Hoang%2C+V+T">Vinh Truong Hoang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Inspired by the success of Transformers in Computer vision, Transformers have
  been widely investigated for medical imaging segmentation. However, most of
  Transformer architecture are using the recent transformer architectures as
  encoder or as parallel encoder with the CNN encoder. In this paper, we
  introduce a novel hybrid CNN-Transformer segmentation architecture
  (PAG-TransYnet) designed for efficiently building a strong CNN-Transformer
  encoder. Our approach exploits attention gates within a Dual Pyramid hybrid
  encoder. The contributions of this methodology can be summarized into three key
  aspects: (i) the utilization of Pyramid input for highlighting the prominent
  features at different scales, (ii) the incorporation of a PVT transformer to
  capture long-range dependencies across various resolutions, and (iii) the
  implementation of a Dual-Attention Gate mechanism for effectively fusing
  prominent features from both CNN and Transformer branches. Through
  comprehensive evaluation across different segmentation tasks including:
  abdominal multi-organs segmentation, infection segmentation (Covid-19 and Bone
  Metastasis), microscopic tissues segmentation (Gland and Nucleus). The proposed
  approach demonstrates state-of-the-art performance and exhibits remarkable
  generalization capabilities. This research represents a significant advancement
  towards addressing the pressing need for efficient and adaptable segmentation
  solutions in medical imaging applications.
  </p>
  </div>
  </dd>
  <dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18201" title="Abstract">arXiv:2404.18201</a> [<a href="/pdf/2404.18201" title="Download PDF">pdf</a>, <a href="/format/2404.18201" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> What Foundation Models can Bring for Robot Learning in Manipulation : A  Survey
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Dingzhe Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jin%2C+Y">Yixiang Jin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=A%2C+Y">Yong A</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Hongze Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+J">Jun Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hao%2C+X">Xiaoshuai Hao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hao%2C+P">Peng Hao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Huaping Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+F">Fuchun Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+B">Bin Fang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">The realization of universal robots is an ultimate goal of researchers.
  However, a key hurdle in achieving this goal lies in the robots' ability to
  manipulate objects in their unstructured surrounding environments according to
  different tasks. The learning-based approach is considered an effective way to
  address generalization. The impressive performance of foundation models in the
  fields of computer vision and natural language suggests the potential of
  embedding foundation models into manipulation tasks as a viable path toward
  achieving general manipulation capability. However, we believe achieving
  general manipulation capability requires an overarching framework akin to auto
  driving. This framework should encompass multiple functional modules, with
  different foundation models assuming distinct roles in facilitating general
  manipulation capability. This survey focuses on the contributions of foundation
  models to robot learning for manipulation. We propose a comprehensive framework
  and detail how foundation models can address challenges in each module of the
  framework. What's more, we examine current approaches, outline challenges,
  suggest future research directions, and identify potential risks associated
  with integrating foundation models into this domain.
  </p>
  </div>
  </dd>
  <dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18202" title="Abstract">arXiv:2404.18202</a> [<a href="/pdf/2404.18202" title="Download PDF">pdf</a>, <a href="/format/2404.18202" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> WorldGPT: Empowering LLM as Multimodal World Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ge%2C+Z">Zhiqi Ge</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+H">Hongzhe Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+M">Mingze Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Juncheng Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+G">Guoming Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+S">Siliang Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+Y">Yueting Zhuang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multimedia (cs.MM)
  
  </div>
  <p class="mathjax">World models are progressively being employed across diverse fields,
  extending from basic environment simulation to complex scenario construction.
  However, existing models are mainly trained on domain-specific states and
  actions, and confined to single-modality state representations. In this paper,
  We introduce WorldGPT, a generalist world model built upon Multimodal Large
  Language Model (MLLM). WorldGPT acquires an understanding of world dynamics
  through analyzing millions of videos across various domains. To further enhance
  WorldGPT's capability in specialized scenarios and long-term tasks, we have
  integrated it with a novel cognitive architecture that combines memory
  offloading, knowledge retrieval, and context reflection. As for evaluation, we
  build WorldNet, a multimodal state transition prediction benchmark encompassing
  varied real-life scenarios. Conducting evaluations on WorldNet directly
  demonstrates WorldGPT's capability to accurately model state transition
  patterns, affirming its effectiveness in understanding and predicting the
  dynamics of complex scenarios. We further explore WorldGPT's emerging potential
  in serving as a world simulator, helping multimodal agents generalize to
  unfamiliar domains through efficiently synthesising multimodal instruction
  instances which are proved to be as reliable as authentic data for fine-tuning
  purposes. The project is available on
  \url{https://github.com/DCDmllm/WorldGPT}.
  </p>
  </div>
  </dd>
  <dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18203" title="Abstract">arXiv:2404.18203</a> [<a href="/pdf/2404.18203" title="Download PDF">pdf</a>, <a href="/format/2404.18203" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LMM-PCQA: Assisting Point Cloud Quality Assessment with LMM
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zicheng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Haoning Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yingjie Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chunyi Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+W">Wei Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C">Chaofeng Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Min%2C+X">Xiongkuo Min</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaohong Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+W">Weisi Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+G">Guangtao Zhai</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Although large multi-modality models (LMMs) have seen extensive exploration
  and application in various quality assessment studies, their integration into
  Point Cloud Quality Assessment (PCQA) remains unexplored. Given LMMs'
  exceptional performance and robustness in low-level vision and quality
  assessment tasks, this study aims to investigate the feasibility of imparting
  PCQA knowledge to LMMs through text supervision. To achieve this, we transform
  quality labels into textual descriptions during the fine-tuning phase, enabling
  LMMs to derive quality rating logits from 2D projections of point clouds. To
  compensate for the loss of perception in the 3D domain, structural features are
  extracted as well. These quality logits and structural features are then
  combined and regressed into quality scores. Our experimental results affirm the
  effectiveness of our approach, showcasing a novel integration of LMMs into PCQA
  that enhances model understanding and assessment accuracy. We hope our
  contributions can inspire subsequent investigations into the fusion of LMMs
  with PCQA, fostering advancements in 3D visual quality analysis and beyond.
  </p>
  </div>
  </dd>
  <dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18205" title="Abstract">arXiv:2404.18205</a> [<a href="/pdf/2404.18205" title="Download PDF">pdf</a>, <a href="/ps/2404.18205" title="Download PostScript">ps</a>, <a href="/format/2404.18205" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LEGO-like Small-Model Constructions for Åqvist's Logics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rozplokhas%2C+D">Dmitry Rozplokhas</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  <p class="mathjax">{\AA}qvist's logics (E, F, F+(CM), and G) are among the best-known systems in
  the long tradition of preference-based approaches for modeling conditional
  obligation. While the general semantics of preference models align well with
  philosophical intuitions, more constructive characterizations are needed to
  assess computational complexity and facilitate automated deduction. Existing
  small model constructions from conditional logics (due to Friedman and Halpern)
  are applicable only to F+(CM) and G, while recently developed proof-theoretic
  characterizations leave unresolved the exact complexity of theoremhood in logic
  F. In this paper, we introduce alternative small model constructions, obtained
  uniformly for all four {\AA}qvist's logics. Our constructions propose
  alternative semantical characterizations and imply co-NP-completeness of
  theoremhood. Furthermore, they can be naturally encoded in classical
  propositional logic for automated deduction.
  </p>
  </div>
  </dd>
  <dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18206" title="Abstract">arXiv:2404.18206</a> [<a href="/pdf/2404.18206" title="Download PDF">pdf</a>, <a href="/format/2404.18206" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhancing Action Recognition from Low-Quality Skeleton Data via  Part-Level Knowledge Distillation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Cuiwei Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Youzhi Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Du%2C+C">Chong Du</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhaokui Li</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> published in Signal Processing 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Skeleton-based action recognition is vital for comprehending human-centric
  videos and has applications in diverse domains. One of the challenges of
  skeleton-based action recognition is dealing with low-quality data, such as
  skeletons that have missing or inaccurate joints. This paper addresses the
  issue of enhancing action recognition using low-quality skeletons through a
  general knowledge distillation framework. The proposed framework employs a
  teacher-student model setup, where a teacher model trained on high-quality
  skeletons guides the learning of a student model that handles low-quality
  skeletons. To bridge the gap between heterogeneous high-quality and lowquality
  skeletons, we present a novel part-based skeleton matching strategy, which
  exploits shared body parts to facilitate local action pattern learning. An
  action-specific part matrix is developed to emphasize critical parts for
  different actions, enabling the student model to distill discriminative
  part-level knowledge. A novel part-level multi-sample contrastive loss achieves
  knowledge transfer from multiple high-quality skeletons to low-quality ones,
  which enables the proposed knowledge distillation framework to include training
  low-quality skeletons that lack corresponding high-quality matches.
  Comprehensive experiments conducted on the NTU-RGB+D, Penn Action, and SYSU 3D
  HOI datasets demonstrate the effectiveness of the proposed knowledge
  distillation framework.
  </p>
  </div>
  </dd>
  <dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18208" title="Abstract">arXiv:2404.18208</a> [<a href="/pdf/2404.18208" title="Download PDF">pdf</a>, <a href="/format/2404.18208" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ROS 2 on a Chip, Achieving Brain-Like Speeds and Efficiency in Robotic  Networking
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mayoral-Vilches%2C+V">Víctor Mayoral-Vilches</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Reina-Mu%C3%B1oz%2C+J+M">Juan Manuel Reina-Muñoz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Crespo-%C3%81lvarez%2C+M">Martiño Crespo-Álvarez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mayoral-Vilches%2C+D">David Mayoral-Vilches</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">The Robot Operating System (ROS) pubsub model played a pivotal role in
  developing sophisticated robotic applications. However, the complexities and
  real-time demands of modern robotics necessitate more efficient communication
  solutions that are deterministic and isochronous. This article introduces a
  groundbreaking approach: embedding ROS 2 message-passing infrastructure
  directly onto a specialized hardware chip, significantly enhancing speed and
  efficiency in robotic communications. Our FPGA prototypes of the chip design
  can send or receive packages in less than 2.5 microseconds, accelerating
  networking communications by more than 62x on average and improving energy
  consumption by more than 500x when compared to traditional ROS 2 software
  implementations on modern CPUs. Additionally, it dramatically reduces maximum
  latency in ROS 2 networking communication by more than 30,000x. In situations
  of peak latency, our design guarantees an isochronous response within 11
  microseconds, a stark improvement over the potential hundreds of milliseconds
  reported by modern CPU systems under similar conditions.
  </p>
  </div>
  </dd>
  <dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18209" title="Abstract">arXiv:2404.18209</a> [<a href="/pdf/2404.18209" title="Download PDF">pdf</a>, <a href="/format/2404.18209" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> 4DBInfer: A 4D Benchmarking Toolbox for Graph-Centric Predictive  Modeling on Relational DBs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M">Minjie Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gan%2C+Q">Quan Gan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wipf%2C+D">David Wipf</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cai%2C+Z">Zhenkun Cai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+N">Ning Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+J">Jianheng Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yanlin Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zizhao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mao%2C+Z">Zunyao Mao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+Y">Yakun Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanbo Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jiahang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Han Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+G">Guang Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qin%2C+X">Xiao Qin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lei%2C+C">Chuan Lei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Muhan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weinan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Faloutsos%2C+C">Christos Faloutsos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zheng Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Under review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)
  
  </div>
  <p class="mathjax">Although RDBs store vast amounts of rich, informative data spread across
  interconnected tables, the progress of predictive machine learning models as
  applied to such tasks arguably falls well behind advances in other domains such
  as computer vision or natural language processing. This deficit stems, at least
  in part, from the lack of established/public RDB benchmarks as needed for
  training and evaluation purposes. As a result, related model development thus
  far often defaults to tabular approaches trained on ubiquitous single-table
  benchmarks, or on the relational side, graph-based alternatives such as GNNs
  applied to a completely different set of graph datasets devoid of tabular
  characteristics. To more precisely target RDBs lying at the nexus of these two
  complementary regimes, we explore a broad class of baseline models predicated
  on: (i) converting multi-table datasets into graphs using various strategies
  equipped with efficient subsampling, while preserving tabular characteristics;
  and (ii) trainable models with well-matched inductive biases that output
  predictions based on these input subgraphs. Then, to address the dearth of
  suitable public benchmarks and reduce siloed comparisons, we assemble a diverse
  collection of (i) large-scale RDB datasets and (ii) coincident predictive
  tasks. From a delivery standpoint, we operationalize the above four dimensions
  (4D) of exploration within a unified, scalable open-source toolbox called
  4DBInfer. We conclude by presenting evaluations using 4DBInfer, the results of
  which highlight the importance of considering each such dimension in the design
  of RDB predictive models, as well as the limitations of more naive approaches
  such as simply joining adjacent tables. Our source code is released at
  https://github.com/awslabs/multi-table-benchmark .
  </p>
  </div>
  </dd>
  <dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18210" title="Abstract">arXiv:2404.18210</a> [<a href="/pdf/2404.18210" title="Download PDF">pdf</a>, <a href="/format/2404.18210" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Decentralized Synthesis of Passivity-Based Distributed Controllers for  DC Microgrids
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Najafirad%2C+M+J">Mohammad Javad Najafirad</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Welikala%2C+S">Shirantha Welikala</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  <p class="mathjax">Microgrids (MGs) provide a promising solution for exploiting renewable energy
  resources (RESs). Most of the existing papers on DC MGs focused on controller
  design. However, in this paper, we proposed a co-design passivity-based control
  (PBC) that designs the controller and communication topology simultaneously. In
  addition, the plug-and-play feature is maintained without compromising the
  stability and re-designing of the remaining controllers. To this end, the local
  controller for distributed generators (DGs) and lines are obtained using
  smaller decentralized LMI problems, and then the global controller is
  formulated using the passivity indices of the local controller to restore
  voltages to the reference value.
  </p>
  </div>
  </dd>
  <dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18211" title="Abstract">arXiv:2404.18211</a> [<a href="/pdf/2404.18211" title="Download PDF">pdf</a>, <a href="/format/2404.18211" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A survey of dynamic graph neural networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+Y">Yanping Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yi%2C+L">Lu Yi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zhewei Wei</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)
  
  </div>
  <p class="mathjax">Graph neural networks (GNNs) have emerged as a powerful tool for effectively
  mining and learning from graph-structured data, with applications spanning
  numerous domains. However, most research focuses on static graphs, neglecting
  the dynamic nature of real-world networks where topologies and attributes
  evolve over time. By integrating sequence modeling modules into traditional GNN
  architectures, dynamic GNNs aim to bridge this gap, capturing the inherent
  temporal dependencies of dynamic graphs for a more authentic depiction of
  complex networks. This paper provides a comprehensive review of the fundamental
  concepts, key techniques, and state-of-the-art dynamic GNN models. We present
  the mainstream dynamic GNN models in detail and categorize models based on how
  temporal information is incorporated. We also discuss large-scale dynamic GNNs
  and pre-training techniques. Although dynamic GNNs have shown superior
  performance, challenges remain in scalability, handling heterogeneous
  information, and lack of diverse graph datasets. The paper also discusses
  possible future directions, such as adaptive and memory-enhanced models,
  inductive learning, and theoretical analysis.
  </p>
  </div>
  </dd>
  <dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18212" title="Abstract">arXiv:2404.18212</a> [<a href="/pdf/2404.18212" title="Download PDF">pdf</a>, <a href="/format/2404.18212" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Paint by Inpaint: Learning to Add Image Objects by Removing Them First
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wasserman%2C+N">Navve Wasserman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rotstein%2C+N">Noam Rotstein</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ganz%2C+R">Roy Ganz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kimmel%2C+R">Ron Kimmel</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Image editing has advanced significantly with the introduction of
  text-conditioned diffusion models. Despite this progress, seamlessly adding
  objects to images based on textual instructions without requiring user-provided
  input masks remains a challenge. We address this by leveraging the insight that
  removing objects (Inpaint) is significantly simpler than its inverse process of
  adding them (Paint), attributed to the utilization of segmentation mask
  datasets alongside inpainting models that inpaint within these masks.
  Capitalizing on this realization, by implementing an automated and extensive
  pipeline, we curate a filtered large-scale image dataset containing pairs of
  images and their corresponding object-removed versions. Using these pairs, we
  train a diffusion model to inverse the inpainting process, effectively adding
  objects into images. Unlike other editing datasets, ours features natural
  target images instead of synthetic ones; moreover, it maintains consistency
  between source and target by construction. Additionally, we utilize a large
  Vision-Language Model to provide detailed descriptions of the removed objects
  and a Large Language Model to convert these descriptions into diverse,
  natural-language instructions. We show that the trained model surpasses
  existing ones both qualitatively and quantitatively, and release the
  large-scale dataset alongside the trained models for the community.
  </p>
  </div>
  </dd>
  <dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18213" title="Abstract">arXiv:2404.18213</a> [<a href="/pdf/2404.18213" title="Download PDF">pdf</a>, <a href="/format/2404.18213" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> S<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-162-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1092" style="width: 0.629em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.495em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(0.002em, 1000.495em, 1.122em, -999.998em); top: -0.983em; left: 0em;"><span class="mrow" id="MathJax-Span-1093"><span class="msubsup" id="MathJax-Span-1094"><span style="display: inline-block; position: relative; width: 0.45em; height: 0px;"><span style="position: absolute; clip: rect(3.855em, 1000.002em, 4.124em, -999.998em); top: -3.985em; left: 0em;"><span class="mi" id="MathJax-Span-1095"></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -4.344em; left: 0em;"><span class="mn" id="MathJax-Span-1096" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 0.988em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.169em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-162">^2</script>Mamba: A Spatial-spectral State Space Model for Hyperspectral Image  Classification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+G">Guanchun Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiangrong Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+Z">Zelin Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianyang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jia%2C+X">Xiuping Jia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiao%2C+L">Licheng Jiao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages, 9 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Land cover analysis using hyperspectral images (HSI) remains an open problem
  due to their low spatial resolution and complex spectral information. Recent
  studies are primarily dedicated to designing Transformer-based architectures
  for spatial-spectral long-range dependencies modeling, which is computationally
  expensive with quadratic complexity. Selective structured state space model
  (Mamba), which is efficient for modeling long-range dependencies with linear
  complexity, has recently shown promising progress. However, its potential in
  hyperspectral image processing that requires handling numerous spectral bands
  has not yet been explored. In this paper, we innovatively propose S<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-163-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1097" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1000.511em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1098"><span class="msubsup" id="MathJax-Span-1099"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px;"><span style="position: absolute; clip: rect(3.842em, 1000.003em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1100"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0em;"><span class="mn" id="MathJax-Span-1101" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-163">^2</script>Mamba, a
  spatial-spectral state space model for hyperspectral image classification, to
  excavate spatial-spectral contextual features, resulting in more efficient and
  accurate land cover analysis. In S<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-164-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1102" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1000.511em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1103"><span class="msubsup" id="MathJax-Span-1104"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px;"><span style="position: absolute; clip: rect(3.842em, 1000.003em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1105"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0em;"><span class="mn" id="MathJax-Span-1106" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-164">^2</script>Mamba, two selective structured state
  space models through different dimensions are designed for feature extraction,
  one for spatial, and the other for spectral, along with a spatial-spectral
  mixture gate for optimal fusion. More specifically, S<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-165-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1107" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1000.511em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1108"><span class="msubsup" id="MathJax-Span-1109"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px;"><span style="position: absolute; clip: rect(3.842em, 1000.003em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1110"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0em;"><span class="mn" id="MathJax-Span-1111" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-165">^2</script>Mamba first captures
  spatial contextual relations by interacting each pixel with its adjacent
  through a Patch Cross Scanning module and then explores semantic information
  from continuous spectral bands through a Bi-directional Spectral Scanning
  module. Considering the distinct expertise of the two attributes in homogenous
  and complicated texture scenes, we realize the Spatial-spectral Mixture Gate by
  a group of learnable matrices, allowing for the adaptive incorporation of
  representations learned across different dimensions. Extensive experiments
  conducted on HSI classification benchmarks demonstrate the superiority and
  prospect of S<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-166-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1112" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1000.511em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1113"><span class="msubsup" id="MathJax-Span-1114"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px;"><span style="position: absolute; clip: rect(3.842em, 1000.003em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1115"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0em;"><span class="mn" id="MathJax-Span-1116" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-166">^2</script>Mamba. The code will be available at:
  https://github.com/PURE-melo/S2Mamba.
  </p>
  </div>
  </dd>
  <dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18214" title="Abstract">arXiv:2404.18214</a> [<a href="/pdf/2404.18214" title="Download PDF">pdf</a>, <a href="/format/2404.18214" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Contrastive Learning Method for Sequential Recommendation based on  Multi-Intention Disentanglement
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+Z">Zeyu Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+Y">Yuzhi Xiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+T">Tao Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huo%2C+X">Xuanrong Huo</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
  
  </div>
  <p class="mathjax">Sequential recommendation is one of the important branches of recommender
  system, aiming to achieve personalized recommended items for the future through
  the analysis and prediction of users' ordered historical interactive behaviors.
  However, along with the growth of the user volume and the increasingly rich
  behavioral information, how to understand and disentangle the user's
  interactive multi-intention effectively also poses challenges to behavior
  prediction and sequential recommendation. In light of these challenges, we
  propose a Contrastive Learning sequential recommendation method based on
  Multi-Intention Disentanglement (MIDCL). In our work, intentions are recognized
  as dynamic and diverse, and user behaviors are often driven by current
  multi-intentions, which means that the model needs to not only mine the most
  relevant implicit intention for each user, but also impair the influence from
  irrelevant intentions. Therefore, we choose Variational Auto-Encoder (VAE) to
  realize the disentanglement of users' multi-intentions, and propose two types
  of contrastive learning paradigms for finding the most relevant user's
  interactive intention, and maximizing the mutual information of positive sample
  pairs, respectively. Experimental results show that MIDCL not only has
  significant superiority over most existing baseline methods, but also brings a
  more interpretable case to the research about intention-based prediction and
  recommendation.
  </p>
  </div>
  </dd>
  <dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18216" title="Abstract">arXiv:2404.18216</a> [<a href="/pdf/2404.18216" title="Download PDF">pdf</a>, <a href="/format/2404.18216" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> L3Cube-MahaNews: News-based Short Text and Long Document Classification  Datasets in Marathi
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mittal%2C+S">Saloni Mittal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Magdum%2C+V">Vidula Magdum</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dhekane%2C+O">Omkar Dhekane</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hiwarkhedkar%2C+S">Sharayu Hiwarkhedkar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Joshi%2C+R">Raviraj Joshi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at SPELLL 2023
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">The availability of text or topic classification datasets in the low-resource
  Marathi language is limited, typically consisting of fewer than 4 target
  labels, with some achieving nearly perfect accuracy. In this work, we introduce
  L3Cube-MahaNews, a Marathi text classification corpus that focuses on News
  headlines and articles. This corpus stands out as the largest supervised
  Marathi Corpus, containing over 1.05L records classified into a diverse range
  of 12 categories. To accommodate different document lengths, MahaNews comprises
  three supervised datasets specifically designed for short text, long documents,
  and medium paragraphs. The consistent labeling across these datasets
  facilitates document length-based analysis. We provide detailed data statistics
  and baseline results on these datasets using state-of-the-art pre-trained BERT
  models. We conduct a comparative analysis between monolingual and multilingual
  BERT models, including MahaBERT, IndicBERT, and MuRIL. The monolingual MahaBERT
  model outperforms all others on every dataset. These resources also serve as
  Marathi topic classification datasets or models and are publicly available at
  https://github.com/l3cube-pune/MarathiNLP .
  </p>
  </div>
  </dd>
  <dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18221" title="Abstract">arXiv:2404.18221</a> [<a href="/pdf/2404.18221" title="Download PDF">pdf</a>, <a href="/format/2404.18221" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Automatically designing robot swarms in environments populated by other  robots: an experiment in robot shepherding
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ramos%2C+D+G">David Garzón Ramos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Birattari%2C+M">Mauro Birattari</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 2024 IEEE International Conference on Robotics and Automation (ICRA)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Automatic design is a promising approach to realizing robot swarms. Given a
  mission to be performed by the swarm, an automatic method produces the required
  control software for the individual robots. Automatic design has concentrated
  on missions that a swarm can execute independently, interacting only with a
  static environment and without the involvement of other active entities. In
  this paper, we investigate the design of robot swarms that perform their
  mission by interacting with other robots that populate their environment. We
  frame our research within robot shepherding: the problem of using a small group
  of robots, the shepherds, to coordinate a relatively larger group, the sheep.
  In our study, the group of shepherds is the swarm that is automatically
  designed, and the sheep are pre-programmed robots that populate its
  environment. We use automatic modular design and neuroevolution to produce the
  control software for the swarm of shepherds to coordinate the sheep. We show
  that automatic design can leverage mission-specific interaction strategies to
  enable an effective coordination between the two groups.
  </p>
  </div>
  </dd>
  <dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18223" title="Abstract">arXiv:2404.18223</a> [<a href="/pdf/2404.18223" title="Download PDF">pdf</a>, <a href="/format/2404.18223" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On the suitability of single-edge notch tension (SENT) testing for  assessing hydrogen-assisted cracking susceptibility
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cupertino-Malheiros%2C+L">L. Cupertino-Malheiros</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mandal%2C+T+K">T.K. Mandal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Thebault%2C+F">F. Thebault</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mart%C3%ADnez-Pa%C3%B1eda%2C+E">E. Martínez-Pañeda</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Materials Science (cond-mat.mtrl-sci); Applied Physics (physics.app-ph); Chemical Physics (physics.chem-ph)
  
  </div>
  <p class="mathjax">Combined experiments and computational modelling are used to increase
  understanding of the suitability of the Single-Edge Notch Tension (SENT) test
  for assessing hydrogen embrittlement susceptibility. The SENT tests were
  designed to provide the mode I threshold stress intensity factor
  (<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-167-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1117" style="width: 1.697em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.358em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.358em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1118"><span class="msubsup" id="MathJax-Span-1119"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1120" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="texatom" id="MathJax-Span-1121"><span class="mrow" id="MathJax-Span-1122"><span class="mtext" id="MathJax-Span-1123" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">th</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-167">K_{\text{th}}</script>) for hydrogen-assisted cracking of a C110 steel in two
  corrosive environments. These were accompanied by hydrogen permeation
  experiments to relate the environments to the absorbed hydrogen concentrations.
  A coupled phase-field-based deformation-diffusion-fracture model is then
  employed to simulate the SENT tests, predicting <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-168-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1124" style="width: 1.697em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.358em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.358em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1125"><span class="msubsup" id="MathJax-Span-1126"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1127" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="texatom" id="MathJax-Span-1128"><span class="mrow" id="MathJax-Span-1129"><span class="mtext" id="MathJax-Span-1130" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">th</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-168">K_{\text{th}}</script> in good
  agreement with the experimental results and providing insights into the
  hydrogen absorption-diffusion-cracking interactions. The suitability of SENT
  testing and its optimal characteristics (e.g., test duration) are discussed in
  terms of the various simultaneous active time-dependent phenomena, triaxiality
  dependencies, and regimes of hydrogen embrittlement susceptibility.
  </p>
  </div>
  </dd>
  <dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18225" title="Abstract">arXiv:2404.18225</a> [<a href="/pdf/2404.18225" title="Download PDF">pdf</a>, <a href="/format/2404.18225" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quadruped robot traversing 3D complex environments with limited  perception
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Y">Yi Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Hang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+G">Guoping Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+L">Linqi Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Houde Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+B">Bin Liang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 8 figures,submitted to iros2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Traversing 3-D complex environments has always been a significant challenge
  for legged locomotion. Existing methods typically rely on external sensors such
  as vision and lidar to preemptively react to obstacles by acquiring
  environmental information. However, in scenarios like nighttime or dense
  forests, external sensors often fail to function properly, necessitating robots
  to rely on proprioceptive sensors to perceive diverse obstacles in the
  environment and respond promptly. This task is undeniably challenging. Our
  research finds that methods based on collision detection can enhance a robot's
  perception of environmental obstacles. In this work, we propose an end-to-end
  learning-based quadruped robot motion controller that relies solely on
  proprioceptive sensing. This controller can accurately detect, localize, and
  agilely respond to collisions in unknown and complex 3D environments, thereby
  improving the robot's traversability in complex environments. We demonstrate in
  both simulation and real-world experiments that our method enables quadruped
  robots to successfully traverse challenging obstacles in various complex
  environments.
  </p>
  </div>
  </dd>
  <dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18228" title="Abstract">arXiv:2404.18228</a> [<a href="/pdf/2404.18228" title="Download PDF">pdf</a>, <a href="/format/2404.18228" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> TextGram: Towards a better domain-adaptive pretraining
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hiwarkhedkar%2C+S">Sharayu Hiwarkhedkar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mittal%2C+S">Saloni Mittal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Magdum%2C+V">Vidula Magdum</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dhekane%2C+O">Omkar Dhekane</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Joshi%2C+R">Raviraj Joshi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kale%2C+G">Geetanjali Kale</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ladkat%2C+A">Arnav Ladkat</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at SPELLL 2023
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">For green AI, it is crucial to measure and reduce the carbon footprint
  emitted during the training of large language models. In NLP, performing
  pre-training on Transformer models requires significant computational
  resources. This pre-training involves using a large amount of text data to gain
  prior knowledge for performing downstream tasks. Thus, it is important that we
  select the correct data in the form of domain-specific data from this vast
  corpus to achieve optimum results aligned with our domain-specific tasks. While
  training on large unsupervised data is expensive, it can be optimized by
  performing a data selection step before pretraining. Selecting important data
  reduces the space overhead and the substantial amount of time required to
  pre-train the model while maintaining constant accuracy. We investigate the
  existing selection strategies and propose our own domain-adaptive data
  selection method - TextGram - that effectively selects essential data from
  large corpora. We compare and evaluate the results of finetuned models for text
  classification task with and without data selection. We show that the proposed
  strategy works better compared to other selection methods.
  </p>
  </div>
  </dd>
  <dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18231" title="Abstract">arXiv:2404.18231</a> [<a href="/pdf/2404.18231" title="Download PDF">pdf</a>, <a href="/format/2404.18231" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> From Persona to Personalization: A Survey on Role-Playing Language  Agents
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiangjie Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xintao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+R">Rui Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+S">Siyu Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yikai Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+W">Wei Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+J">Jian Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shuang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+R">Ruihan Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+T">Tinghui Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+A">Aili Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+N">Nianqi Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Lida Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+C">Caiyu Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+S">Siye Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+S">Scott Ren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fu%2C+Z">Ziquan Fu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+Y">Yanghua Xiao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Preprint
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Recent advancements in large language models (LLMs) have significantly
  boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI
  systems designed to simulate assigned personas. By harnessing multiple advanced
  abilities of LLMs, including in-context learning, instruction following, and
  social intelligence, RPLAs achieve a remarkable sense of human likeness and
  vivid role-playing performance. RPLAs can mimic a wide range of personas,
  ranging from historical figures and fictional characters to real-life
  individuals. Consequently, they have catalyzed numerous AI applications, such
  as emotional companions, interactive video games, personalized assistants and
  copilots, and digital clones. In this paper, we conduct a comprehensive survey
  of this field, illustrating the evolution and recent progress in RPLAs
  integrating with cutting-edge LLM technologies. We categorize personas into
  three types: 1) Demographic Persona, which leverages statistical stereotypes;
  2) Character Persona, focused on well-established figures; and 3)
  Individualized Persona, customized through ongoing user interactions for
  personalized services. We begin by presenting a comprehensive overview of
  current methodologies for RPLAs, followed by the details for each persona type,
  covering corresponding data sourcing, agent construction, and evaluation.
  Afterward, we discuss the fundamental risks, existing limitations, and future
  prospects of RPLAs. Additionally, we provide a brief review of RPLAs in AI
  applications, which reflects practical user demands that shape and drive RPLA
  research. Through this work, we aim to establish a clear taxonomy of RPLA
  research and applications, and facilitate future research in this critical and
  ever-evolving field, and pave the way for a future where humans and RPLAs
  coexist in harmony.
  </p>
  </div>
  </dd>
  <dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18235" title="Abstract">arXiv:2404.18235</a> [<a href="/pdf/2404.18235" title="Download PDF">pdf</a>, <a href="/format/2404.18235" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Flood Data Analysis on SpaceNet 8 Using Apache Sedona
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yanbing Bai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zihao Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Jinze Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ju%2C+R">Rui-Yang Ju</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+B">Bin Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mas%2C+E">Erick Mas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Koshimura%2C+S">Shunichi Koshimura</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">With the escalating frequency of floods posing persistent threats to human
  life and property, satellite remote sensing has emerged as an indispensable
  tool for monitoring flood hazards. SpaceNet8 offers a unique opportunity to
  leverage cutting-edge artificial intelligence technologies to assess these
  hazards. A significant contribution of this research is its application of
  Apache Sedona, an advanced platform specifically designed for the efficient and
  distributed processing of large-scale geospatial data. This platform aims to
  enhance the efficiency of error analysis, a critical aspect of improving flood
  damage detection accuracy. Based on Apache Sedona, we introduce a novel
  approach that addresses the challenges associated with inaccuracies in flood
  damage detection. This approach involves the retrieval of cases from historical
  flood events, the adaptation of these cases to current scenarios, and the
  revision of the model based on clustering algorithms to refine its performance.
  Through the replication of both the SpaceNet8 baseline and its top-performing
  models, we embark on a comprehensive error analysis. This analysis reveals
  several main sources of inaccuracies. To address these issues, we employ data
  visual interpretation and histogram equalization techniques, resulting in
  significant improvements in model metrics. After these enhancements, our
  indicators show a notable improvement, with precision up by 5%, F1 score by
  2.6%, and IoU by 4.5%. This work highlights the importance of advanced
  geospatial data processing tools, such as Apache Sedona. By improving the
  accuracy and efficiency of flood detection, this research contributes to
  safeguarding public safety and strengthening infrastructure resilience in
  flood-prone areas, making it a valuable addition to the field of remote sensing
  and disaster management.
  </p>
  </div>
  </dd>
  <dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18239" title="Abstract">arXiv:2404.18239</a> [<a href="/pdf/2404.18239" title="Download PDF">pdf</a>, <a href="/format/2404.18239" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SOUL: Unlocking the Power of Second-Order Optimization for LLM  Unlearning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jia%2C+J">Jinghan Jia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yihua Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yimeng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiancheng Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Runwal%2C+B">Bharat Runwal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Diffenderfer%2C+J">James Diffenderfer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kailkhura%2C+B">Bhavya Kailkhura</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Sijia Liu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
  
  </div>
  <p class="mathjax">Large Language Models (LLMs) have highlighted the necessity of effective
  unlearning mechanisms to comply with data regulations and ethical AI practices.
  LLM unlearning aims at removing undesired data influences and associated model
  capabilities without compromising utility out of the scope of unlearning. While
  interest in studying LLM unlearning is growing,the impact of the optimizer
  choice for LLM unlearning remains under-explored. In this work, we shed light
  on the significance of optimizer selection in LLM unlearning for the first
  time, establishing a clear connection between {second-order optimization} and
  influence unlearning (a classical approach using influence functions to update
  the model for data influence removal). This insight propels us to develop a
  second-order unlearning framework, termed SOUL, built upon the second-order
  clipped stochastic optimization (Sophia)-based LLM training method. SOUL
  extends the static, one-shot model update using influence unlearning to a
  dynamic, iterative unlearning process. Our extensive experiments show that SOUL
  consistently outperforms conventional first-order methods across various
  unlearning tasks, models, and metrics, suggesting the promise of second-order
  optimization in providing a scalable and easily implementable solution for LLM
  unlearning.
  </p>
  </div>
  </dd>
  <dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18243" title="Abstract">arXiv:2404.18243</a> [<a href="/pdf/2404.18243" title="Download PDF">pdf</a>, <a href="/format/2404.18243" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LEGENT: Open Platform for Embodied Agents
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Z">Zhili Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhitong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Jinyi Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+S">Shengding Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+A">An Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tu%2C+Y">Yuge Tu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+P">Pengkai Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+L">Lei Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiyuan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+M">Maosong Sun</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Demo Paper
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Despite advancements in Large Language Models (LLMs) and Large Multimodal
  Models (LMMs), their integration into language-grounded, human-like embodied
  agents remains incomplete, hindering complex real-life task performance in
  physical environments. Existing integrations often feature limited open
  sourcing, challenging collective progress in this field. We introduce LEGENT,
  an open, scalable platform for developing embodied agents using LLMs and LMMs.
  LEGENT offers a dual approach: a rich, interactive 3D environment with
  communicable and actionable agents, paired with a user-friendly interface, and
  a sophisticated data generation pipeline utilizing advanced algorithms to
  exploit supervision from simulated worlds at scale. In our experiments, an
  embryonic vision-language-action model trained on LEGENT-generated data
  surpasses GPT-4V in embodied tasks, showcasing promising generalization
  capabilities.
  </p>
  </div>
  </dd>
  <dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18245" title="Abstract">arXiv:2404.18245</a> [<a href="/pdf/2404.18245" title="Download PDF">pdf</a>, <a href="/format/2404.18245" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FAD-SAR: A Novel Fishing Activity Detection System via Synthetic  Aperture Radar Images Based on Deep Learning Method
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yanbing Bai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ju%2C+R">Rui-Yang Ju</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Siao Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zihao Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Jinze Yu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Illegal, unreported, and unregulated (IUU) fishing seriously affects various
  aspects of human life. However, current methods for detecting and monitoring
  IUU activities at sea have limitations. While Synthetic Aperture Radar (SAR)
  can complement existing vessel detection systems, extracting useful information
  from SAR images using traditional methods, especially for IUU fishing
  identification, poses challenges. This paper proposes a deep learning-based
  system for detecting fishing activities. We implemented this system on the
  xView3 dataset using six classical object detection models: Faster R-CNN,
  Cascade R-CNN, SSD, RetinaNet, FSAF, and FCOS. We applied improvement methods
  to enhance the performance of the Faster R-CNN model. Specifically, training
  the Faster R-CNN model using Online Hard Example Mining (OHEM) strategy
  improved the Avg-F1 value from 0.212 to 0.216, representing a 1.96%
  improvement.
  </p>
  </div>
  </dd>
  <dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18246" title="Abstract">arXiv:2404.18246</a> [<a href="/pdf/2404.18246" title="Download PDF">pdf</a>, <a href="/format/2404.18246" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> AdaFSNet: Time Series Classification Based on Convolutional Network with  a Adaptive and Effective Kernel Size Configuration
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Haoxiao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+B">Bo Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jianhua Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xu Cheng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by IJCNN 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Time series classification is one of the most critical and challenging
  problems in data mining, existing widely in various fields and holding
  significant research importance. Despite extensive research and notable
  achievements with successful real-world applications, addressing the challenge
  of capturing the appropriate receptive field (RF) size from one-dimensional or
  multi-dimensional time series of varying lengths remains a persistent issue,
  which greatly impacts performance and varies considerably across different
  datasets. In this paper, we propose an Adaptive and Effective Full-Scope
  Convolutional Neural Network (AdaFSNet) to enhance the accuracy of time series
  classification. This network includes two Dense Blocks. Particularly, it can
  dynamically choose a range of kernel sizes that effectively encompass the
  optimal RF size for various datasets by incorporating multiple prime numbers
  corresponding to the time series length. We also design a TargetDrop block,
  which can reduce redundancy while extracting a more effective RF. To assess the
  effectiveness of the AdaFSNet network, comprehensive experiments were conducted
  using the UCR and UEA datasets, which include one-dimensional and
  multi-dimensional time series data, respectively. Our model surpassed baseline
  models in terms of classification accuracy, underscoring the AdaFSNet network's
  efficiency and effectiveness in handling time series classification tasks.
  </p>
  </div>
  </dd>
  <dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18249" title="Abstract">arXiv:2404.18249</a> [<a href="/pdf/2404.18249" title="Download PDF">pdf</a>, <a href="/format/2404.18249" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Tenspiler: A Verified Lifting-Based Compiler for Tensor Operations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+J">Jie Qiu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cai%2C+C">Colin Cai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bhatia%2C+S">Sahil Bhatia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hasabnis%2C+N">Niranjan Hasabnis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Seshia%2C+S+A">Sanjit A. Seshia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheung%2C+A">Alvin Cheung</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>
  
  </div>
  <p class="mathjax">Tensor processing infrastructures such as deep learning frameworks and
  specialized hardware accelerators have revolutionized how computationally
  intensive code from domains such as deep learning and image processing is
  executed and optimized. These infrastructures provide powerful and expressive
  abstractions while ensuring high performance. However, to utilize them, code
  must be written specifically using the APIs / ISAs of such software frameworks
  or hardware accelerators. Importantly, given the fast pace of innovation in
  these domains, code written today quickly becomes legacy as new frameworks and
  accelerators are developed, and migrating such legacy code manually is a
  considerable effort.
  <br>To enable developers in leveraging such DSLs while preserving their current
  programming paradigm, we introduce Tenspiler, a verified lifting-based compiler
  that uses program synthesis to translate sequential programs written in
  general-purpose programming languages (e.g., C++ or Python code) into tensor
  operations. Central to Tenspiler is our carefully crafted yet simple
  intermediate language, named TensIR, that expresses tensor operations. TensIR
  enables efficient lifting, verification, and code generation.
  <br>Currently, Tenspiler already supports \textbf{six} DSLs, spanning a broad
  spectrum of software and hardware environments. Furthermore, we show that new
  backends can be easily supported by Tenspiler by adding simple pattern-matching
  rules for TensIR. Using 10 real-world code benchmark suites, our experimental
  evaluation shows that by translating code to be executed on \textbf{6}
  different software frameworks and hardware devices, Tenspiler offers on average
  105<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-169-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1131" style="width: 0.85em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.866em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1132"><span class="mo" id="MathJax-Span-1133" style="font-family: STIXGeneral-Regular;">×</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.837em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-169">\times</script> kernel and 9.65<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-170-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1134" style="width: 0.85em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.866em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1135"><span class="mo" id="MathJax-Span-1136" style="font-family: STIXGeneral-Regular;">×</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.837em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-170">\times</script> end-to-end execution time improvement over
  the fully-optimized sequential implementation of the same benchmarks.
  </p>
  </div>
  </dd>
  <dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18251" title="Abstract">arXiv:2404.18251</a> [<a href="/pdf/2404.18251" title="Download PDF">pdf</a>, <a href="/format/2404.18251" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Machine Learning for Blockchain Data Analysis: Progress and  Opportunities
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Azad%2C+P">Poupak Azad</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Akcora%2C+C+G">Cuneyt Gurcan Akcora</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khan%2C+A">Arijit Khan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Blockchain technology has rapidly emerged to mainstream attention, while its
  publicly accessible, heterogeneous, massive-volume, and temporal data are
  reminiscent of the complex dynamics encountered during the last decade of big
  data. Unlike any prior data source, blockchain datasets encompass multiple
  layers of interactions across real-world entities, e.g., human users,
  autonomous programs, and smart contracts. Furthermore, blockchain's integration
  with cryptocurrencies has introduced financial aspects of unprecedented scale
  and complexity such as decentralized finance, stablecoins, non-fungible tokens,
  and central bank digital currencies. These unique characteristics present both
  opportunities and challenges for machine learning on blockchain data.
  <br>On one hand, we examine the state-of-the-art solutions, applications, and
  future directions associated with leveraging machine learning for blockchain
  data analysis critical for the improvement of blockchain technology such as
  e-crime detection and trends prediction. On the other hand, we shed light on
  the pivotal role of blockchain by providing vast datasets and tools that can
  catalyze the growth of the evolving machine learning ecosystem. This paper
  serves as a comprehensive resource for researchers, practitioners, and
  policymakers, offering a roadmap for navigating this dynamic and transformative
  field.
  </p>
  </div>
  </dd>
  <dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18252" title="Abstract">arXiv:2404.18252</a> [<a href="/pdf/2404.18252" title="Download PDF">pdf</a>, <a href="/format/2404.18252" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Fisher Information Improved Training-Free Conditional Diffusion Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+K">Kaiyu Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lai%2C+H">Hanjiang Lai</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Recently, the diffusion model with the training-free methods has succeeded in
  conditional image generation tasks. However, there is an efficiency problem
  because it requires calculating the gradient with high computational cost, and
  previous methods make strong assumptions to solve it, sacrificing
  generalization. In this work, we propose the Fisher information guided
  diffusion model (FIGD). Concretely, we introduce the Fisher information to
  estimate the gradient without making any additional assumptions to reduce
  computation cost. Meanwhile, we demonstrate that the Fisher information ensures
  the generalization of FIGD and provides new insights for training-free methods
  based on the information theory. The experimental results demonstrate that FIGD
  could achieve different conditional generations more quickly while maintaining
  high quality.
  </p>
  </div>
  </dd>
  <dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18253" title="Abstract">arXiv:2404.18253</a> [<a href="/pdf/2404.18253" title="Download PDF">pdf</a>, <a href="/format/2404.18253" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Efficient Remote Sensing with Harmonized Transfer Learning and Modality  Alignment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+T">Tengjun Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by the Twelfth International Conference on Learning Representations (ICLR) Workshop
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">With the rise of Visual and Language Pretraining (VLP), an increasing number
  of downstream tasks are adopting the paradigm of pretraining followed by
  fine-tuning. Although this paradigm has demonstrated potential in various
  multimodal downstream tasks, its implementation in the remote sensing domain
  encounters some obstacles. Specifically, the tendency for same-modality
  embeddings to cluster together impedes efficient transfer learning. To tackle
  this issue, we review the aim of multimodal transfer learning for downstream
  tasks from a unified perspective, and rethink the optimization process based on
  three distinct objectives. We propose "Harmonized Transfer Learning and
  Modality Alignment (HarMA)", a method that simultaneously satisfies task
  constraints, modality alignment, and single-modality uniform alignment, while
  minimizing training overhead through parameter-efficient fine-tuning.
  Remarkably, without the need for external data for training, HarMA achieves
  state-of-the-art performance in two popular multimodal retrieval tasks in the
  field of remote sensing. Our experiments reveal that HarMA achieves competitive
  and even superior performance to fully fine-tuned models with only minimal
  adjustable parameters. Due to its simplicity, HarMA can be integrated into
  almost all existing multimodal pretraining models. We hope this method can
  facilitate the efficient application of large models to a wide range of
  downstream tasks while significantly reducing the resource consumption. Code is
  available at https://github.com/seekerhuang/HarMA.
  </p>
  </div>
  </dd>
  <dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18254" title="Abstract">arXiv:2404.18254</a> [<a href="/pdf/2404.18254" title="Download PDF">pdf</a>, <a href="/format/2404.18254" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Robust Resource Sharing in Network Slicing via Hypothesis Testing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nikolaidis%2C+P">Panagiotis Nikolaidis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Baras%2C+J">John Baras</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>
  
  </div>
  <p class="mathjax">In network slicing, the network operator needs to satisfy the service level
  agreements of multiple slices at the same time and on the same physical
  infrastructure. To do so with reduced provisioned resources, the operator may
  consider resource sharing mechanisms. However, each slice then becomes
  susceptible to traffic surges in other slices which degrades performance
  isolation. To maintain both high efficiency and high isolation, we propose the
  introduction of hypothesis testing in resource sharing. Our approach comprises
  two phases. In the trial phase, the operator obtains a stochastic model for
  each slice that describes its normal behavior, provisions resources and then
  signs the service level agreements. In the regular phase, whenever there is
  resource contention, hypothesis testing is conducted to check which slices
  follow their normal behavior. Slices that fail the test are excluded from
  resource sharing to protect the well-behaved ones. We test our approach on a
  mobile traffic dataset. Results show that our approach fortifies the service
  level agreements against unexpected traffic patterns and achieves high
  efficiency via resource sharing. Overall, our approach provides an appealing
  tradeoff between efficiency and isolation.
  </p>
  </div>
  </dd>
  <dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18255" title="Abstract">arXiv:2404.18255</a> [<a href="/pdf/2404.18255" title="Download PDF">pdf</a>, <a href="/format/2404.18255" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PatentGPT: A Large Language Model for Intellectual Property
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bai%2C+Z">Zilong Bai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruiji Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Linqing Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cai%2C+Q">Qijun Cai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yuan Zhong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+C+W+Y">Cong Wang Yan Fang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+J">Jie Fang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jing Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Weikuan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+L">Lizhi Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+H+H+T">Haoran Hua Tian Qiu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chaochao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+C">Cheng Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+J">Jianping Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yixin Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+Y+X+M">Yubin Xia Meng Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Haowen Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+P">Peng Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+L">Licong Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bian%2C+F">Fu Bian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gu%2C+X">Xiaolong Gu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L+Z+W">Lisha Zhang Weilei Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tu%2C+C">Changyang Tu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 19 pages, 9 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">In recent years, large language models have attracted significant attention
  due to their exceptional performance across a multitude of natural language
  process tasks, and have been widely applied in various fields. However, the
  application of large language models in the Intellectual Property (IP) space is
  challenging due to the strong need for specialized knowledge, privacy
  protection, processing of extremely long text in this field. In this technical
  report, we present for the first time a low-cost, standardized procedure for
  training IP-oriented LLMs, meeting the unique requirements of the IP domain.
  Using this standard process, we have trained the PatentGPT series models based
  on open-source pretrained models. By evaluating them on the open-source
  IP-oriented benchmark MOZIP, our domain-specific LLMs outperforms GPT-4,
  indicating the effectiveness of the proposed training procedure and the
  expertise of the PatentGPT models in the IP demain. What is impressive is that
  our model significantly outperformed GPT-4 on the 2019 China Patent Agent
  Qualification Examination by achieving a score of 65, reaching the level of
  human experts. Additionally, the PatentGPT model, which utilizes the SMoE
  architecture, achieves performance comparable to that of GPT-4 in the IP domain
  and demonstrates a better cost-performance ratio on long-text tasks,
  potentially serving as an alternative to GPT-4 within the IP domain.
  </p>
  </div>
  </dd>
  <dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18257" title="Abstract">arXiv:2404.18257</a> [<a href="/pdf/2404.18257" title="Download PDF">pdf</a>, <a href="/format/2404.18257" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mapping 'when'-clauses in Latin American and Caribbean languages: an  experiment in subtoken-based typology
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pedrazzini%2C+N">Nilo Pedrazzini</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 6 figures. To be published in the 2024 Proceedings of the Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)
  
  </div>
  <p class="mathjax">Languages can encode temporal subordination lexically, via subordinating
  conjunctions, and morphologically, by marking the relation on the predicate.
  Systematic cross-linguistic variation among the former can be studied using
  well-established token-based typological approaches to token-aligned parallel
  corpora. Variation among different morphological means is instead much harder
  to tackle and therefore more poorly understood, despite being predominant in
  several language groups. This paper explores variation in the expression of
  generic temporal subordination ('when'-clauses) among the languages of Latin
  America and the Caribbean, where morphological marking is particularly common.
  It presents probabilistic semantic maps computed on the basis of the languages
  of the region, thus avoiding bias towards the many world's languages that
  exclusively use lexified connectors, incorporating associations between
  character <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-171-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1137" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1138"><span class="mi" id="MathJax-Span-1139" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-171">n</script>-grams and English <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-172-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1140" style="width: 2.656em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.148em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.148em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1141"><span class="mi" id="MathJax-Span-1142" style="font-family: STIXGeneral-Italic;">w</span><span class="mi" id="MathJax-Span-1143" style="font-family: STIXGeneral-Italic;">h</span><span class="mi" id="MathJax-Span-1144" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-1145" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-172">when</script>. The approach allows capturing
  morphological clause-linkage devices in addition to lexified connectors, paving
  the way for larger-scale, strategy-agnostic analyses of typological variation
  in temporal subordination.
  </p>
  </div>
  </dd>
  <dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18260" title="Abstract">arXiv:2404.18260</a> [<a href="/pdf/2404.18260" title="Download PDF">pdf</a>, <a href="/format/2404.18260" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Align, Minimize and Diversify: A Source-Free Unsupervised Domain  Adaptation Method for Handwritten Text Recognition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Alfaro-Contreras%2C+M">María Alfaro-Contreras</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Calvo-Zaragoza%2C+J">Jorge Calvo-Zaragoza</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to ECCV 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">This paper serves to introduce the Align, Minimize and Diversify (AMD)
  method, a Source-Free Unsupervised Domain Adaptation approach for Handwritten
  Text Recognition (HTR). This framework decouples the adaptation process from
  the source data, thus not only sidestepping the resource-intensive retraining
  process but also making it possible to leverage the wealth of pre-trained
  knowledge encoded in modern Deep Learning architectures. Our method explicitly
  eliminates the need to revisit the source data during adaptation by
  incorporating three distinct regularization terms: the Align term, which
  reduces the feature distribution discrepancy between source and target data,
  ensuring the transferability of the pre-trained representation; the Minimize
  term, which encourages the model to make assertive predictions, pushing the
  outputs towards one-hot-like distributions in order to minimize prediction
  uncertainty, and finally, the Diversify term, which safeguards against the
  degeneracy in predictions by promoting varied and distinctive sequences
  throughout the target data, preventing informational collapse. Experimental
  results from several benchmarks demonstrated the effectiveness and robustness
  of AMD, showing it to be competitive and often outperforming DA methods in HTR.
  </p>
  </div>
  </dd>
  <dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18262" title="Abstract">arXiv:2404.18262</a> [<a href="/pdf/2404.18262" title="Download PDF">pdf</a>, <a href="/format/2404.18262" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generating Situated Reflection Triggers about Alternative Solution  Paths: A Case Study of Generative AI for Computer-Supported Collaborative  Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Naik%2C+A">Atharva Naik</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yin%2C+J+R">Jessica Ruhan Yin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kamath%2C+A">Anusha Kamath</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Q">Qianou Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+S+T">Sherry Tongshuang Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Murray%2C+C">Charles Murray</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bogart%2C+C">Christopher Bogart</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sakr%2C+M">Majd Sakr</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rose%2C+C+P">Carolyn P. Rose</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  <p class="mathjax">An advantage of Large Language Models (LLMs) is their contextualization
  capability - providing different responses based on student inputs like
  solution strategy or prior discussion, to potentially better engage students
  than standard feedback. We present a design and evaluation of a
  proof-of-concept LLM application to offer students dynamic and contextualized
  feedback. Specifically, we augment an Online Programming Exercise bot for a
  college-level Cloud Computing course with ChatGPT, which offers students
  contextualized reflection triggers during a collaborative query optimization
  task in database design. We demonstrate that LLMs can be used to generate
  highly situated reflection triggers that incorporate details of the
  collaborative discussion happening in context. We discuss in depth the
  exploration of the design space of the triggers and their correspondence with
  the learning objectives as well as the impact on student learning in a pilot
  study with 34 students.
  </p>
  </div>
  </dd>
  <dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18264" title="Abstract">arXiv:2404.18264</a> [<a href="/pdf/2404.18264" title="Download PDF">pdf</a>, <a href="/format/2404.18264" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Modeling Orthographic Variation Improves NLP Performance for Nigerian  Pidgin
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+P">Pin-Jie Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Scholman%2C+M">Merel Scholman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Saeed%2C+M">Muhammed Saeed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Demberg%2C+V">Vera Demberg</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024 Main Conference
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Nigerian Pidgin is an English-derived contact language and is traditionally
  an oral language, spoken by approximately 100 million people. No orthographic
  standard has yet been adopted, and thus the few available Pidgin datasets that
  exist are characterised by noise in the form of orthographic variations. This
  contributes to under-performance of models in critical NLP tasks. The current
  work is the first to describe various types of orthographic variations commonly
  found in Nigerian Pidgin texts, and model this orthographic variation. The
  variations identified in the dataset form the basis of a phonetic-theoretic
  framework for word editing, which is used to generate orthographic variations
  to augment training data. We test the effect of this data augmentation on two
  critical NLP tasks: machine translation and sentiment analysis. The proposed
  variation generation framework augments the training data with new orthographic
  variants which are relevant for the test set but did not occur in the training
  set originally. Our results demonstrate the positive effect of augmenting the
  training data with a combination of real texts from other corpora as well as
  synthesized orthographic variation, resulting in performance improvements of
  2.1 points in sentiment analysis and 1.4 BLEU points in translation to English.
  </p>
  </div>
  </dd>
  <dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18267" title="Abstract">arXiv:2404.18267</a> [<a href="/pdf/2404.18267" title="Download PDF">pdf</a>, <a href="/format/2404.18267" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LINOCS: Lookahead Inference of Networked Operators for Continuous  Stability
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Mudrik%2C+N">Noga Mudrik</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Yezerets%2C+E">Eva Yezerets</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Chen%2C+Y">Yenho Chen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Rozell%2C+C">Christopher Rozell</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Charles%2C+A">Adam Charles</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> under review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)
  
  </div>
  <p class="mathjax">Identifying latent interactions within complex systems is key to unlocking
  deeper insights into their operational dynamics, including how their elements
  affect each other and contribute to the overall system behavior. For instance,
  in neuroscience, discovering neuron-to-neuron interactions is essential for
  understanding brain function; in ecology, recognizing the interactions among
  populations is key for understanding complex ecosystems. Such systems, often
  modeled as dynamical systems, typically exhibit noisy high-dimensional and
  non-stationary temporal behavior that renders their identification challenging.
  Existing dynamical system identification methods often yield operators that
  accurately capture short-term behavior but fail to predict long-term trends,
  suggesting an incomplete capture of the underlying process. Methods that
  consider extended forecasts (e.g., recurrent neural networks) lack explicit
  representations of element-wise interactions and require substantial training
  data, thereby failing to capture interpretable network operators. Here we
  introduce Lookahead-driven Inference of Networked Operators for Continuous
  Stability (LINOCS), a robust learning procedure for identifying hidden
  dynamical interactions in noisy time-series data. LINOCS integrates several
  multi-step predictions with adaptive weights during training to recover
  dynamical operators that can yield accurate long-term predictions. We
  demonstrate LINOCS' ability to recover the ground truth dynamical operators
  underlying synthetic time-series data for multiple dynamical systems models
  (including linear, piece-wise linear, time-changing linear systems'
  decomposition, and regularized linear time-varying systems) as well as its
  capability to produce meaningful operators with robust reconstructions through
  various real-world examples.
  </p>
  </div>
  </dd>
  <dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18270" title="Abstract">arXiv:2404.18270</a> [<a href="/pdf/2404.18270" title="Download PDF">pdf</a>, <a href="/format/2404.18270" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Pragmatic Formal Verification of Sequential Error Detection and  Correction Codes (ECCs) used in Safety-Critical Design
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+A">Aman Kumar</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Published in DVCon U.S. 2023
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)
  
  </div>
  <p class="mathjax">Error Detection and Correction Codes (ECCs) are often used in digital designs
  to protect data integrity. Especially in safety-critical systems such as
  automotive electronics, ECCs are widely used and the verification of such
  complex logic becomes more critical considering the ISO 26262 safety standards.
  Exhaustive verification of ECC using formal methods has been a challenge given
  the high number of data bits to protect. As an example, for an ECC of 128 data
  bits with a possibility to detect up to four-bit errors, the combination of bit
  errors is given by 128C1 + 128C2 + 128C3 + 128C4 = 1.1 * 10^7. This vast
  analysis space often leads to bounded proof results. Moreover, the complexity
  and state-space increase further if the ECC has sequential encoding and
  decoding stages. To overcome such problems and sign-off the design with
  confidence within reasonable proof time, we present a pragmatic formal
  verification approach of complex ECC cores with several complexity reduction
  techniques and know-how that were learnt during the course of verification. We
  discuss using the linearity of the syndrome generator as a helper assertion,
  using the abstract model as glue logic to compare the RTL with the sequential
  version of the circuit, k-induction-based model checking and using mathematical
  relations captured as properties to simplify the verification in order to get
  an unbounded proof result within 24 hours of proof runtime.
  </p>
  </div>
  </dd>
  <dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18271" title="Abstract">arXiv:2404.18271</a> [<a href="/pdf/2404.18271" title="Download PDF">pdf</a>, <a href="/format/2404.18271" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Parameter-Efficient Tuning Large Language Models for Graph  Representation Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qi Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+D">Da Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+X">Xiang Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shichang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jin%2C+B">Bowen Jin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yizhou Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Karypis%2C+G">George Karypis</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Text-rich graphs, which exhibit rich textual information on nodes and edges,
  are prevalent across a wide range of real-world business applications. Large
  Language Models (LLMs) have demonstrated remarkable abilities in understanding
  text, which also introduced the potential for more expressive modeling in
  text-rich graphs. Despite these capabilities, efficiently applying LLMs to
  representation learning on graphs presents significant challenges. Recently,
  parameter-efficient fine-tuning methods for LLMs have enabled efficient new
  task generalization with minimal time and memory consumption. Inspired by this,
  we introduce Graph-aware Parameter-Efficient Fine-Tuning - GPEFT, a novel
  approach for efficient graph representation learning with LLMs on text-rich
  graphs. Specifically, we utilize a graph neural network (GNN) to encode
  structural information from neighboring nodes into a graph prompt. This prompt
  is then inserted at the beginning of the text sequence. To improve the quality
  of graph prompts, we pre-trained the GNN to assist the frozen LLM in predicting
  the next token in the node text. Compared with existing joint GNN and LMs, our
  method directly generate the node embeddings from large language models with an
  affordable fine-tuning cost. We validate our approach through comprehensive
  experiments conducted on 8 different text-rich graphs, observing an average
  improvement of 2% in hit@1 and Mean Reciprocal Rank (MRR) in link prediction
  evaluations. Our results demonstrate the efficacy and efficiency of our model,
  showing that it can be smoothly integrated with various large language models,
  including OPT, LLaMA and Falcon.
  </p>
  </div>
  </dd>
  <dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18273" title="Abstract">arXiv:2404.18273</a> [<a href="/pdf/2404.18273" title="Download PDF">pdf</a>, <a href="/format/2404.18273" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Kernel Corrector LSTM
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tuna%2C+R">Rodrigo Tuna</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Baghoussi%2C+Y">Yassine Baghoussi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Soares%2C+C">Carlos Soares</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mendes-Moreira%2C+J">João Mendes-Moreira</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages, 4 figures, IDA 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Forecasting methods are affected by data quality issues in two ways: 1. they
  are hard to predict, and 2. they may affect the model negatively when it is
  updated with new data. The latter issue is usually addressed by pre-processing
  the data to remove those issues. An alternative approach has recently been
  proposed, Corrector LSTM (cLSTM), which is a Read \&amp; Write Machine Learning
  (RW-ML) algorithm that changes the data while learning to improve its
  predictions. Despite promising results being reported, cLSTM is computationally
  expensive, as it uses a meta-learner to monitor the hidden states of the LSTM.
  We propose a new RW-ML algorithm, Kernel Corrector LSTM (KcLSTM), that replaces
  the meta-learner of cLSTM with a simpler method: Kernel Smoothing. We
  empirically evaluate the forecasting accuracy and the training time of the new
  algorithm and compare it with cLSTM and LSTM. Results indicate that it is able
  to decrease the training time while maintaining a competitive forecasting
  accuracy.
  </p>
  </div>
  </dd>
  <dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18276" title="Abstract">arXiv:2404.18276</a> [<a href="/pdf/2404.18276" title="Download PDF">pdf</a>, <a href="/ps/2404.18276" title="Download PostScript">ps</a>, <a href="/format/2404.18276" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bias Neutralization Framework: Measuring Fairness in Large Language  Models with Bias Intelligence Quotient (BiQ)
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Narayan%2C+M">Malur Narayan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pasmore%2C+J">John Pasmore</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sampaio%2C+E">Elton Sampaio</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Raghavan%2C+V">Vijay Raghavan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Waters%2C+G">Gabriella Waters</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 41 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">The burgeoning influence of Large Language Models (LLMs) in shaping public
  discourse and decision-making underscores the imperative to address inherent
  biases within these AI systems. In the wake of AI's expansive integration
  across sectors, addressing racial bias in LLMs has never been more critical.
  This paper introduces a novel framework called Comprehensive Bias
  Neutralization Framework (CBNF) which embodies an innovative approach to
  quantifying and mitigating biases within LLMs. Our framework combines the Large
  Language Model Bias Index (LLMBI) [Oketunji, A., Anas, M., Saina, D., (2023)]
  and Bias removaL with No Demographics (BLIND) [Orgad, H., Belinkov, Y. (2023)]
  methodologies to create a new metric called Bias Intelligence Quotient
  (BiQ)which detects, measures, and mitigates racial bias in LLMs without
  reliance on demographic annotations.
  <br>By introducing a new metric called BiQ that enhances LLMBI with additional
  fairness metrics, CBNF offers a multi-dimensional metric for bias assessment,
  underscoring the necessity of a nuanced approach to fairness in AI [Mehrabi et
  al., 2021]. This paper presents a detailed analysis of Latimer AI (a language
  model incrementally trained on black history and culture) in comparison to
  ChatGPT 3.5, illustrating Latimer AI's efficacy in detecting racial, cultural,
  and gender biases through targeted training and refined bias mitigation
  strategies [Latimer &amp; Bender, 2023].
  </p>
  </div>
  </dd>
  <dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18279" title="Abstract">arXiv:2404.18279</a> [<a href="/pdf/2404.18279" title="Download PDF">pdf</a>, <a href="/format/2404.18279" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Out-of-distribution Detection in Medical Image Analysis: A survey
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hong%2C+Z">Zesheng Hong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yue%2C+Y">Yubiao Yue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yubin Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+H">Huanjie Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yuanmei Luo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M+H">Mini Han Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Weidong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Jialong Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiaoqi Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhenzhang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+S">Sihong Xie</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 23 pages, 3 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Computer-aided diagnostics has benefited from the development of deep
  learning-based computer vision techniques in these years. Traditional
  supervised deep learning methods assume that the test sample is drawn from the
  identical distribution as the training data. However, it is possible to
  encounter out-of-distribution samples in real-world clinical scenarios, which
  may cause silent failure in deep learning-based medical image analysis tasks.
  Recently, research has explored various out-of-distribution (OOD) detection
  situations and techniques to enable a trustworthy medical AI system. In this
  survey, we systematically review the recent advances in OOD detection in
  medical image analysis. We first explore several factors that may cause a
  distributional shift when using a deep-learning-based model in clinic
  scenarios, with three different types of distributional shift well defined on
  top of these factors. Then a framework is suggested to categorize and feature
  existing solutions, while the previous studies are reviewed based on the
  methodology taxonomy. Our discussion also includes evaluation protocols and
  metrics, as well as the challenge and a research direction lack of exploration.
  </p>
  </div>
  </dd>
  <dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18280" title="Abstract">arXiv:2404.18280</a> [<a href="/pdf/2404.18280" title="Download PDF">pdf</a>, <a href="/ps/2404.18280" title="Download PostScript">ps</a>, <a href="/format/2404.18280" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Tracy, Traces, and Transducers: Computable Counterexamples and  Explanations for HyperLTL Model-Checking
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Winter%2C+S">Sarah Winter</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zimmermann%2C+M">Martin Zimmermann</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)
  
  </div>
  <p class="mathjax">HyperLTL model-checking enables the automated verification of
  information-flow properties for security-critical systems. However, it only
  provides a binary answer. Here, we introduce two paradigms to compute
  counterexamples and explanations for HyperLTL model-checking, thereby
  considerably increasing its usefulness. Both paradigms are based on the maxim
  ``counterexamples/explanations are Skolem functions for the existentially
  quantified trace variables''.
  <br>Our first paradigm is complete (everything can be explained), but restricted
  to ultimately periodic system traces. The second paradigm works with (Turing
  machine) computable Skolem functions and is therefore much more general, but
  also shown incomplete (not everything can computably be explained). Finally, we
  prove that it is decidable whether a given finite transition system and a
  formula have computable Skolem functions witnessing that the system satisfies
  the formula. Our algorithm also computes transducers implementing computable
  Skolem functions, if they exist.
  </p>
  </div>
  </dd>
  <dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18282" title="Abstract">arXiv:2404.18282</a> [<a href="/pdf/2404.18282" title="Download PDF">pdf</a>, <a href="/format/2404.18282" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Monitoring Real-Time Systems under Parametric Delay
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fr%C3%A4nzle%2C+M">Martin Fränzle</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Grosen%2C+T+M">Thomas M. Grosen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Larsen%2C+K+G">Kim G. Larsen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zimmermann%2C+M">Martin Zimmermann</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>
  
  </div>
  <p class="mathjax">Online monitoring of embedded real-time systems can be achieved by reduction
  of an adequate property language, like Metric Interval Temporal Logic, to timed
  automata and symbolic execution of the resulting automata on the trace observed
  from the system. This direct construction however only is faithful if
  observation of the trace is immediate in the sense that the monitor can assign
  exact time stamps to the actions it observes, which is rarely true in practice
  due to the substantial and fluctuating parametric delays introduced by the
  circuitry connecting the observed system to its monitoring device. We present a
  purely zone-based online monitoring procedure and its implementation which
  handle such parametric delays exactly without recurrence to costly verification
  procedures for parametric timed automata.
  </p>
  </div>
  </dd>
  <dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18284" title="Abstract">arXiv:2404.18284</a> [<a href="/pdf/2404.18284" title="Download PDF">pdf</a>, <a href="/format/2404.18284" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> S3-SLAM: Sparse Tri-plane Encoding for Neural Implicit SLAM
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhiyao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yunzhou Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yanmin Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+B">Bin Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xingshuo Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tian%2C+R">Rui Tian</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">With the emergence of Neural Radiance Fields (NeRF), neural implicit
  representations have gained widespread applications across various domains,
  including simultaneous localization and mapping. However, current neural
  implicit SLAM faces a challenging trade-off problem between performance and the
  number of parameters. To address this problem, we propose sparse tri-plane
  encoding, which efficiently achieves scene reconstruction at resolutions up to
  512 using only 2~4% of the commonly used tri-plane parameters (reduced from
  100MB to 2~4MB). On this basis, we design S3-SLAM to achieve rapid and
  high-quality tracking and mapping through sparsifying plane parameters and
  integrating orthogonal features of tri-plane. Furthermore, we develop
  hierarchical bundle adjustment to achieve globally consistent geometric
  structures and reconstruct high-resolution appearance. Experimental results
  demonstrate that our approach achieves competitive tracking and scene
  reconstruction with minimal parameters on three datasets. Source code will soon
  be available.
  </p>
  </div>
  </dd>
  <dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18286" title="Abstract">arXiv:2404.18286</a> [<a href="/pdf/2404.18286" title="Download PDF">pdf</a>, <a href="/format/2404.18286" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Comparing LLM prompting with Cross-lingual transfer performance on  Indigenous and Low-resource Brazilian Languages
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Adelani%2C+D+I">David Ifeoluwa Adelani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Do%C4%9Fru%C3%B6z%2C+A+S">A. Seza Doğruöz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Coneglian%2C+A">André Coneglian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ojha%2C+A+K">Atul Kr. Ojha</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the Americas NLP Workshop at NAACL 2024 (<a href="https://turing.iimas.unam.mx/americasnlp/2024_workshop.html">this https URL</a>)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Large Language Models are transforming NLP for a variety of tasks. However,
  how LLMs perform NLP tasks for low-resource languages (LRLs) is less explored.
  In line with the goals of the AmeicasNLP workshop, we focus on 12 LRLs from
  Brazil, 2 LRLs from Africa and 2 high-resource languages (HRLs) (e.g., English
  and Brazilian Portuguese). Our results indicate that the LLMs perform worse for
  the part of speech (POS) labeling of LRLs in comparison to HRLs. We explain the
  reasons behind this failure and provide an error analyses through examples
  observed in our data set.
  </p>
  </div>
  </dd>
  <dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18287" title="Abstract">arXiv:2404.18287</a> [<a href="/pdf/2404.18287" title="Download PDF">pdf</a>, <a href="/format/2404.18287" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Joint Energy and Latency Optimization in Federated Learning over  Cell-Free Massive MIMO Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mahmoudi%2C+A">Afsaneh Mahmoudi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zaher%2C+M">Mahmoud Zaher</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bj%C3%B6rnson%2C+E">Emil Björnson</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)
  
  </div>
  <p class="mathjax">Federated learning (FL) is a distributed learning paradigm wherein users
  exchange FL models with a server instead of raw datasets, thereby preserving
  data privacy and reducing communication overhead. However, the increased number
  of FL users may hinder completing large-scale FL over wireless networks due to
  high imposed latency. Cell-free massive multiple-input
  multiple-output~(CFmMIMO) is a promising architecture for implementing FL
  because it serves many users on the same time/frequency resources. While
  CFmMIMO enhances energy efficiency through spatial multiplexing and
  collaborative beamforming, it remains crucial to meticulously allocate uplink
  transmission powers to the FL users. In this paper, we propose an uplink power
  allocation scheme in FL over CFmMIMO by considering the effect of each user's
  power on the energy and latency of other users to jointly minimize the users'
  uplink energy and the latency of FL training. The proposed solution algorithm
  is based on the coordinate gradient descent method. Numerical results show that
  our proposed method outperforms the well-known max-sum rate by increasing up
  to~<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-173-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1146" style="width: 1.245em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.963em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1147"><span class="mn" id="MathJax-Span-1148" style="font-family: STIXGeneral-Regular;">27</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-173">27</script>\% and max-min energy efficiency of the Dinkelbach method by increasing
  up to~<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-174-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1149" style="width: 1.245em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.906em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1150"><span class="mn" id="MathJax-Span-1151" style="font-family: STIXGeneral-Regular;">21</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-174">21</script>\% in terms of test accuracy while having limited uplink energy and
  latency budget for FL over CFmMIMO.
  </p>
  </div>
  </dd>
  <dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18291" title="Abstract">arXiv:2404.18291</a> [<a href="/pdf/2404.18291" title="Download PDF">pdf</a>, <a href="/format/2404.18291" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Panoptic Segmentation and Labelling of Lumbar Spine Vertebrae using  Modified Attention Unet
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pal%2C+R">Rikathi Pal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Saha%2C+P">Priya Saha</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ghoshal%2C+S">Somoballi Ghoshal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chakrabarti%2C+A">Amlan Chakrabarti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sur-Kolay%2C+S">Susmita Sur-Kolay</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 10 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Segmentation and labeling of vertebrae in MRI images of the spine are
  critical for the diagnosis of illnesses and abnormalities. These steps are
  indispensable as MRI technology provides detailed information about the tissue
  structure of the spine. Both supervised and unsupervised segmentation methods
  exist, yet acquiring sufficient data remains challenging for achieving high
  accuracy. In this study, we propose an enhancing approach based on modified
  attention U-Net architecture for panoptic segmentation of 3D sliced MRI data of
  the lumbar spine. Our method achieves an impressive accuracy of 99.5\% by
  incorporating novel masking logic, thus significantly advancing the
  state-of-the-art in vertebral segmentation and labeling. This contributes to
  more precise and reliable diagnosis and treatment planning.
  </p>
  </div>
  </dd>
  <dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18296" title="Abstract">arXiv:2404.18296</a> [<a href="/pdf/2404.18296" title="Download PDF">pdf</a>, <a href="/ps/2404.18296" title="Download PostScript">ps</a>, <a href="/format/2404.18296" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Using Deep Q-Learning to Dynamically Toggle between Push/Pull Actions in  Computational Trust Mechanisms
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lygizou%2C+Z">Zoi Lygizou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kalles%2C+D">Dimitris Kalles</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)
  
  </div>
  <p class="mathjax">Recent work on decentralized computational trust models for open Multi Agent
  Systems has resulted in the development of CA, a biologically inspired model
  which focuses on the trustee's perspective. This new model addresses a serious
  unresolved problem in existing trust and reputation models, namely the
  inability to handle constantly changing behaviors and agents' continuous entry
  and exit from the system. In previous work, we compared CA to FIRE, a
  well-known trust and reputation model, and found that CA is superior when the
  trustor population changes, whereas FIRE is more resilient to the trustee
  population changes. Thus, in this paper, we investigate how the trustors can
  detect the presence of several dynamic factors in their environment and then
  decide which trust model to employ in order to maximize utility. We frame this
  problem as a machine learning problem in a partially observable environment,
  where the presence of several dynamic factors is not known to the trustor and
  we describe how an adaptable trustor can rely on a few measurable features so
  as to assess the current state of the environment and then use Deep Q Learning
  (DQN), in a single-agent Reinforcement Learning setting, to learn how to adapt
  to a changing environment. We ran a series of simulation experiments to compare
  the performance of the adaptable trustor with the performance of trustors using
  only one model (FIRE or CA) and we show that an adaptable agent is indeed
  capable of learning when to use each model and, thus, perform consistently in
  dynamic environments.
  </p>
  </div>
  </dd>
  <dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18300" title="Abstract">arXiv:2404.18300</a> [<a href="/pdf/2404.18300" title="Download PDF">pdf</a>, <a href="/format/2404.18300" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> VoroTO: Multiscale Topology Optimization of Voronoi Structures using  Surrogate Neural Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Padhy%2C+R+K">Rahul Kumar Padhy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Suresh%2C+K">Krishnan Suresh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chandrasekhar%2C+A">Aaditya Chandrasekhar</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to Engineering with Computers
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)
  
  </div>
  <p class="mathjax">Cellular structures found in nature exhibit remarkable properties such as
  high strength, high energy absorption, excellent thermal/acoustic insulation,
  and fluid transfusion. Many of these structures are Voronoi-like; therefore
  researchers have proposed Voronoi multi-scale designs for a wide variety of
  engineering applications. However, designing such structures can be
  computationally prohibitive due to the multi-scale nature of the underlying
  analysis and optimization. In this work, we propose the use of a neural network
  (NN) to carry out efficient topology optimization (TO) of multi-scale Voronoi
  structures. The NN is first trained using Voronoi parameters (cell site
  locations, thickness, orientation, and anisotropy) to predict the homogenized
  constitutive properties. This network is then integrated into a conventional TO
  framework to minimize structural compliance subject to a volume constraint.
  Special considerations are given for ensuring positive definiteness of the
  constitutive matrix and promoting macroscale connectivity. Several numerical
  examples are provided to showcase the proposed method.
  </p>
  </div>
  </dd>
  <dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18301" title="Abstract">arXiv:2404.18301</a> [<a href="/pdf/2404.18301" title="Download PDF">pdf</a>, <a href="/format/2404.18301" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Finding Understanding and Support: Navigating Online Communities to  Share and Connect at the intersection of Abuse and Foster Care Experiences
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ammari%2C+T">Tawfiq Ammari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ahn%2C+E">Eunhye Ahn</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lakhankar%2C+A">Astha Lakhankar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Joyce Lee</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">Many children in foster care experience trauma that is rooted in unstable
  family relationships. Other members of the foster care system like foster
  parents and social workers face secondary trauma. Drawing on 10 years of Reddit
  data, we used a mixed methods approach to analyze how different members of the
  foster care system find support and similar experiences at the intersection of
  two Reddit communities - foster care, and abuse. Users who cross this boundary
  focus on trauma experiences specific to different roles in foster care. While
  representing a small number of users, boundary crossing users contribute
  heavily to both communities, and, compared to matching users, receive higher
  scores and more replies. We explore the roles boundary crossing users have both
  in the online community and in the context of foster care. Finally, we present
  design recommendations that would support trauma survivors find communities
  more suited to their personal experiences.
  </p>
  </div>
  </dd>
  <dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18304" title="Abstract">arXiv:2404.18304</a> [<a href="/pdf/2404.18304" title="Download PDF">pdf</a>, <a href="/format/2404.18304" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Retrieval-Oriented Knowledge for Click-Through Rate Prediction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Huanshuo Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+B">Bo Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+M">Menghui Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J">Jianghao Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qin%2C+J">Jiarui Qin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yang Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+R">Ruiming Tang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Click-through rate (CTR) prediction plays an important role in personalized
  recommendations. Recently, sample-level retrieval-based models (e.g., RIM) have
  achieved remarkable performance by retrieving and aggregating relevant samples.
  However, their inefficiency at the inference stage makes them impractical for
  industrial applications. To overcome this issue, this paper proposes a
  universal plug-and-play Retrieval-Oriented Knowledge (ROK) framework.
  Specifically, a knowledge base, consisting of a retrieval-oriented embedding
  layer and a knowledge encoder, is designed to preserve and imitate the
  retrieved &amp; aggregated representations in a decomposition-reconstruction
  paradigm. Knowledge distillation and contrastive learning methods are utilized
  to optimize the knowledge base, and the learned retrieval-enhanced
  representations can be integrated with arbitrary CTR models in both
  instance-wise and feature-wise manners. Extensive experiments on three
  large-scale datasets show that ROK achieves competitive performance with the
  retrieval-based CTR models while reserving superior inference efficiency and
  model compatibility.
  </p>
  </div>
  </dd>
  <dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18305" title="Abstract">arXiv:2404.18305</a> [<a href="/pdf/2404.18305" title="Download PDF">pdf</a>, <a href="/format/2404.18305" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Data-Driven Dynamic State Estimation of Photovoltaic Systems via Sparse  Regression Unscented Kalman Filter
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jamalinia%2C+E">Elham Jamalinia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhongtian Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khazaei%2C+J">Javad Khazaei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Blum%2C+R+S">Rick S. Blum</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  <p class="mathjax">Dynamic state estimation (DSE) is vital in modern power systems with numerous
  inverter-based distributed energy resources including solar and wind, ensuring
  real-time accuracy for tracking system variables and optimizing grid stability.
  This paper proposes a data-driven DSE approach designed for photovoltaic (PV)
  energy conversion systems (single stage and two stage) that are subjected to
  both process and measurement noise. The proposed framework follows a two-phase
  methodology encompassing ``data-driven model identification" and
  ``state-estimation." In the initial model identification phase, state feedback
  is gathered to elucidate the dynamics of the photovoltaic systems using
  nonlinear sparse regression technique. Following the identification of the PV
  dynamics, the nonlinear data-driven model will be utilized to estimate the
  dynamics of the PV system for monitoring and protection purposes. To account
  for incomplete measurements, inherent uncertainties, and noise, we employ an
  ``unscented Kalman filter," which facilitates state estimation by processing
  the noisy output data. Ultimately, the paper substantiates the efficacy of the
  proposed sparse regression-based unscented Kalman filter through simulation
  results, providing a comparative analysis with a physics-based DSE.
  </p>
  </div>
  </dd>
  <dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18308" title="Abstract">arXiv:2404.18308</a> [<a href="/pdf/2404.18308" title="Download PDF">pdf</a>, <a href="/ps/2404.18308" title="Download PostScript">ps</a>, <a href="/format/2404.18308" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Near-Term Enforcement of AI Chip Export Controls Using A Minimal  Firmware-Based Design for Offline Licensing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Petrie%2C+J">James Petrie</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)
  
  </div>
  <p class="mathjax">Offline licensing is a technical mechanism for compute governance that could
  be used to prevent unregulated training of potentially dangerous frontier AI
  models. The mechanism works by disabling AI chips unless they have an
  up-to-date license from a regulator. In this report, we present a technical
  design for a minimal version of offline licensing that could be delivered via a
  firmware update. Existing AI chips could potentially support offline licensing
  within a year if they have the following (relatively common) hardware security
  features: firmware verification, firmware rollback protection, and secure
  non-volatile memory. Public documentation suggests that NVIDIA's H100 AI chip
  already has these security features. Without additional hardware modifications,
  the system is susceptible to physical hardware attacks. However, these attacks
  might require expensive equipment and could be difficult to reliably apply to
  thousands of AI chips. A firmware-based offline licensing design shares the
  same legal requirements and license approval mechanism as a hardware-based
  solution. Implementing a firmware-based solution now could accelerate the
  eventual deployment of a more secure hardware-based solution in the future. For
  AI chip manufacturers, implementing this security mechanism might allow chips
  to be sold to customers that would otherwise be prohibited by export
  restrictions. For governments, it may be important to be able to prevent unsafe
  or malicious actors from training frontier AI models in the next few years.
  Based on this initial analysis, firmware-based offline licensing could
  partially solve urgent security and trade problems and is technically feasible
  for AI chips that have common hardware security features.
  </p>
  </div>
  </dd>
  <dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18310" title="Abstract">arXiv:2404.18310</a> [<a href="/pdf/2404.18310" title="Download PDF">pdf</a>, <a href="/ps/2404.18310" title="Download PostScript">ps</a>, <a href="/format/2404.18310" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multiport Network Modeling for Reconfigurable Intelligent Surfaces:  Numerical Validation with a Full-Wave PEEC Simulator
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pettanice%2C+G">Giuseppe Pettanice</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jeong%2C+S">Sumin Jeong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Valentini%2C+R">Roberto Valentini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Di+Marco%2C+P">Piergiuseppe Di Marco</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Santucci%2C+F">Fortunato Santucci</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Romano%2C+D">Daniele Romano</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Antonini%2C+G">Giulio Antonini</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">Reconfigurable Intelligent Surface (RIS) modeling and optimization are a
  crucial steps in developing the next generation of wireless communications. To
  this aim, the availability of accurate electromagnetic (EM) models is of
  paramount important for the design of RIS-assisted communication links. In this
  work, we validate a widely-used analytical multiport network for RISs by means
  of a well-established full-wave numerical method based on the Partial Elements
  Equivalent Circuit (PEEC) approach. Numerical results show good agreement
  between the two methods, thus demonstrating i) the considered multiport network
  model being effective and ii) the PEEC method being appropriate for EM modeling
  of RIS-assisted wireless links.
  </p>
  </div>
  </dd>
  <dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18311" title="Abstract">arXiv:2404.18311</a> [<a href="/pdf/2404.18311" title="Download PDF">pdf</a>, <a href="/ps/2404.18311" title="Download PostScript">ps</a>, <a href="/format/2404.18311" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Trends and Challenges of Real-time Learning in Large Language Models: A  Critical Review
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jovanovic%2C+M">Mladjan Jovanovic</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Voss%2C+P">Peter Voss</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  <p class="mathjax">Real-time learning concerns the ability of learning systems to acquire
  knowledge over time, enabling their adaptation and generalization to novel
  tasks. It is a critical ability for intelligent, real-world systems, especially
  when data may be insufficient or difficult to obtain. This review provides a
  comprehensive analysis of real-time learning in Large Language Models. It
  synthesizes the state-of-the-art real-time learning paradigms, including
  continual learning, meta-learning, parameter-efficient learning, and
  mixture-of-experts learning. We demonstrate their utility for real-time
  learning by describing specific achievements from these related topics and
  their critical factors. Finally, the paper highlights current problems and
  challenges for future research in the field. By consolidating the latest
  relevant research developments, this review offers a comprehensive
  understanding of real-time learning and its implications for designing and
  developing LLM-based learning systems addressing real-world problems.
  </p>
  </div>
  </dd>
  <dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18312" title="Abstract">arXiv:2404.18312</a> [<a href="/pdf/2404.18312" title="Download PDF">pdf</a>, <a href="/format/2404.18312" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Application of Iterative LQR on a Mobile Robot With Simple Dynamics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Aaqaoui%2C+A">Ayoub Aaqaoui</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Mohammed%2C+Y+M+E">Yousif Mohammed Elsheikh Mohammed</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  <p class="mathjax">The aim in this paper is to apply the iLQR, iterative Linear Quadratic
  Regulator, to control the movement of a mobile robot following an already
  defined trajectory. This control strategy has proven its utility for nonlinear
  systems. As follows up, this work intends to concertize this statement and to
  evaluate the extent to which the performance is comparatively improved against
  the ordinary, non-iterative LQR. The method is applied to a differential robot
  with non-holonomic constraints. The mathematical equations, resulting
  description and the implementation of this method are explicitly explained, and
  the simulation studies are conducted in the Matlab and Simulink environment.
  </p>
  </div>
  </dd>
  <dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18313" title="Abstract">arXiv:2404.18313</a> [<a href="/pdf/2404.18313" title="Download PDF">pdf</a>, <a href="/format/2404.18313" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-Link Operation and Wireless Digital Twin to Support Enhanced  Roaming in Next-Gen Wi-Fi
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Scanzio%2C+S">Stefano Scanzio</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rosani%2C+M">Matteo Rosani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Formis%2C+G">Gabriele Formis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cavalcanti%2C+D">Dave Cavalcanti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Frascolla%2C+V">Valerio Frascolla</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Marchetto%2C+G">Guido Marchetto</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cena%2C+G">Gianluca Cena</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> preprint, 4 pages
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> 20th IEEE International Conference on Factory Communication
    Systems (WFCS 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>
  
  </div>
  <p class="mathjax">The next generation of Wi-Fi is meant to achieve ultra-high reliability for
  wireless communication. Several approaches are available to this extent, some
  of which are being considered for inclusion in standards specifications,
  including coordination of access points to reduce interference.
  <br>In this paper, we propose a centralized architecture based on digital twins,
  called WiTwin, with the aim of supporting wireless stations in selecting the
  optimal association according to a set of parameters. Unlike prior works, we
  assume that Wi-Fi 7 features like multi-link operation (MLO) are available.
  Moreover, one of the main goals of this architecture is to preserve
  communication quality in the presence of mobility, by helping stations to
  perform reassociation at the right time and in the best way.
  </p>
  </div>
  </dd>
  <dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18314" title="Abstract">arXiv:2404.18314</a> [<a href="/pdf/2404.18314" title="Download PDF">pdf</a>, <a href="/format/2404.18314" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DIRESA, a distance-preserving nonlinear dimension reduction technique  based on regularized autoencoders
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=De+Paepe%2C+G">Geert De Paepe</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Cruz%2C+L">Lesley De Cruz</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 16 pages, 10 figures, 4 tables; 7 pages of Supporting Information
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chaotic Dynamics (nlin.CD); Atmospheric and Oceanic Physics (physics.ao-ph)
  
  </div>
  <p class="mathjax">In meteorology, finding similar weather patterns or analogs in historical
  datasets can be useful for data assimilation, forecasting, and postprocessing.
  In climate science, analogs in historical and climate projection data are used
  for attribution and impact studies. However, most of the time, those large
  weather and climate datasets are nearline. They must be downloaded, which takes
  a lot of bandwidth and disk space, before the computationally expensive search
  can be executed. We propose a dimension reduction technique based on
  autoencoder (AE) neural networks to compress those datasets and perform the
  search in an interpretable, compressed latent space. A distance-regularized
  Siamese twin autoencoder (DIRESA) architecture is designed to preserve distance
  in latent space while capturing the nonlinearities in the datasets. Using
  conceptual climate models of different complexities, we show that the latent
  components thus obtained provide physical insight into the dominant modes of
  variability in the system. Compressing datasets with DIRESA reduces the online
  storage and keeps the latent components uncorrelated, while the distance
  (ordering) preservation and reconstruction fidelity robustly outperform
  Principal Component Analysis (PCA) and other dimension reduction techniques
  such as UMAP or variational autoencoders.
  </p>
  </div>
  </dd>
  <dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18315" title="Abstract">arXiv:2404.18315</a> [<a href="/pdf/2404.18315" title="Download PDF">pdf</a>, <a href="/ps/2404.18315" title="Download PostScript">ps</a>, <a href="/format/2404.18315" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Design and Optimization of Reconfigurable Intelligent Surfaces Using the  PEEC Method
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pettanice%2C+G">Giuseppe Pettanice</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Valentini%2C+R">Roberto Valentini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jeong%2C+S">Sumin Jeong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Di+Marco%2C+P">Piergiuseppe Di Marco</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Santucci%2C+F">Fortunato Santucci</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Romano%2C+D">Daniele Romano</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Antonini%2C+G">Giulio Antonini</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">The design and optimization of Reconfigurable Intelligent Surfaces (RISs) are
  key challenges for future wireless communication systems. RISs are devices that
  can manipulate electromagnetic (EM) waves in a programmable way, thus enhancing
  the performance and efficiency of wireless links. To achieve this goal, it is
  essential to have reliable EM models that can capture the behavior of RISs in
  different scenarios. This work demonstrates that the Partial Elements
  Equivalent Circuit (PEEC) method is a powerful tool for EM analysis of
  RIS-aided wireless links. It might also be integrated with optimization
  algorithms in order to optimize wireless communication networks.
  </p>
  </div>
  </dd>
  <dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18316" title="Abstract">arXiv:2404.18316</a> [<a href="/pdf/2404.18316" title="Download PDF">pdf</a>, <a href="/format/2404.18316" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Position paper: Do not explain (vision models) without context
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tomaszewska%2C+P">Paulina Tomaszewska</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Biecek%2C+P">Przemysław Biecek</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Does the stethoscope in the picture make the adjacent person a doctor or a
  patient? This, of course, depends on the contextual relationship of the two
  objects. If it is obvious, why don not explanation methods for vision models
  use contextual information? In this paper, we (1) review the most popular
  methods of explaining computer vision models by pointing out that they do not
  take into account context information, (2) provide examples of real-world use
  cases where spatial context plays a significant role, (3) propose new research
  directions that may lead to better use of context information in explaining
  computer vision models, (4) argue that a change in approach to explanations is
  needed from 'where' to 'how'.
  </p>
  </div>
  </dd>
  <dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18319" title="Abstract">arXiv:2404.18319</a> [<a href="/pdf/2404.18319" title="Download PDF">pdf</a>, <a href="/format/2404.18319" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> User Welfare Optimization in Recommender Systems with Competing Content  Creators
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yao%2C+F">Fan Yao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liao%2C+Y">Yiming Liao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+M">Mingzhe Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chuanhao Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yan Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">James Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qifan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Haifeng Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hongning Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">Driven by the new economic opportunities created by the creator economy, an
  increasing number of content creators rely on and compete for revenue generated
  from online content recommendation platforms. This burgeoning competition
  reshapes the dynamics of content distribution and profoundly impacts long-term
  user welfare on the platform. However, the absence of a comprehensive picture
  of global user preference distribution often traps the competition, especially
  the creators, in states that yield sub-optimal user welfare. To encourage
  creators to best serve a broad user population with relevant content, it
  becomes the platform's responsibility to leverage its information advantage
  regarding user preference distribution to accurately signal creators.
  <br>In this study, we perform system-side user welfare optimization under a
  competitive game setting among content creators. We propose an algorithmic
  solution for the platform, which dynamically computes a sequence of weights for
  each user based on their satisfaction of the recommended content. These weights
  are then utilized to design mechanisms that adjust the recommendation policy or
  the post-recommendation rewards, thereby influencing creators' content
  production strategies. To validate the effectiveness of our proposed method, we
  report our findings from a series of experiments, including: 1. a
  proof-of-concept negative example illustrating how creators' strategies
  converge towards sub-optimal states without platform intervention; 2. offline
  experiments employing our proposed intervention mechanisms on diverse datasets;
  and 3. results from a three-week online experiment conducted on a leading
  short-video recommendation platform.
  </p>
  </div>
  </dd>
  <dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18321" title="Abstract">arXiv:2404.18321</a> [<a href="/pdf/2404.18321" title="Download PDF">pdf</a>, <a href="/format/2404.18321" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Riemannian Optimization for Active Mapping with Robot Teams
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Asgharivaskasi%2C+A">Arash Asgharivaskasi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Girke%2C+F">Fritz Girke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Atanasov%2C+N">Nikolay Atanasov</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Autonomous exploration of unknown environments using a team of mobile robots
  demands distributed perception and planning strategies to enable efficient and
  scalable performance. Ideally, each robot should update its map and plan its
  motion not only relying on its own observations, but also considering the
  observations of its peers. Centralized solutions to multi-robot coordination
  are susceptible to central node failure and require a sophisticated
  communication infrastructure for reliable operation. Current decentralized
  active mapping methods consider simplistic robot models with linear-Gaussian
  observations and Euclidean robot states. In this work, we present a distributed
  multi-robot mapping and planning method, called Riemannian Optimization for
  Active Mapping (ROAM). We formulate an optimization problem over a graph with
  node variables belonging to a Riemannian manifold and a consensus constraint
  requiring feasible solutions to agree on the node variables. We develop a
  distributed Riemannian optimization algorithm that relies only on one-hop
  communication to solve the problem with consensus and optimality guarantees. We
  show that multi-robot active mapping can be achieved via two applications of
  our distributed Riemannian optimization over different manifolds: distributed
  estimation of a 3-D semantic map and distributed planning of SE(3) trajectories
  that minimize map uncertainty. We demonstrate the performance of ROAM in
  simulation and real-world experiments using a team of robots with RGB-D
  cameras.
  </p>
  </div>
  </dd>
  <dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18322" title="Abstract">arXiv:2404.18322</a> [<a href="/pdf/2404.18322" title="Download PDF">pdf</a>, <a href="/format/2404.18322" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> BlockLLM: Multi-tenant Finer-grained Serving for Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jiamin Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+L">Le Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Hong Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Akella%2C+A">Aditya Akella</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>
  
  </div>
  <p class="mathjax">The growing demand for Large Language Models (LLMs) across diverse
  applications has prompted a paradigm shift in the design of deep learning
  serving systems. Deploying LLMs, especially in multi-tenant environments,
  presents considerable challenges due to their high computational and memory
  demands. We present BlockLLM, a serving system that exploits the potential of
  sharing components among fine-tuned LLM models to offer an efficient and
  flexible solution for LLM workloads. BlockLLM partitions the models into
  finer-grained blocks to enable the reuse of model components and independent
  provisioning to improve the computation efficiency. BlockLLM consists of an
  offline block zoo, for storing the blocks, and an online system to serve the
  requests through chains of blocks. It offers multi-fold flexibility: (1)
  Adaptive assembly of block chains on-the-fly is achieved with the help of
  equivalence evaluation among blocks in the zoo. (2) We enable per-block batch
  size and configure best-effort KV cache coordination at individual block level.
  (3) We adopt speculative execution and locality-aware block placement to
  mitigate the communication costs from dynamic block resource allocation. Our
  evaluation demonstrates that BlockLLM reduces memory and storage footprints and
  improves computation efficiency, outperforming existing serving approach in
  95\%ile latency and GPU utilization by 33.5\% and 20.1\%, respectively.
  </p>
  </div>
  </dd>
  <dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18326" title="Abstract">arXiv:2404.18326</a> [<a href="/pdf/2404.18326" title="Download PDF">pdf</a>, <a href="/format/2404.18326" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SAFE-RL: Saliency-Aware Counterfactual Explainer for Deep Reinforcement  Learning Policies
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Samadi%2C+A">Amir Samadi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Koufos%2C+K">Konstantinos Koufos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Debattista%2C+K">Kurt Debattista</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dianati%2C+M">Mehrdad Dianati</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">While Deep Reinforcement Learning (DRL) has emerged as a promising solution
  for intricate control tasks, the lack of explainability of the learned policies
  impedes its uptake in safety-critical applications, such as automated driving
  systems (ADS). Counterfactual (CF) explanations have recently gained prominence
  for their ability to interpret black-box Deep Learning (DL) models. CF examples
  are associated with minimal changes in the input, resulting in a complementary
  output by the DL model. Finding such alternations, particularly for
  high-dimensional visual inputs, poses significant challenges. Besides, the
  temporal dependency introduced by the reliance of the DRL agent action on a
  history of past state observations further complicates the generation of CF
  examples. To address these challenges, we propose using a saliency map to
  identify the most influential input pixels across the sequence of past observed
  states by the agent. Then, we feed this map to a deep generative model,
  enabling the generation of plausible CFs with constrained modifications centred
  on the salient regions. We evaluate the effectiveness of our framework in
  diverse domains, including ADS, Atari Pong, Pacman and space-invaders games,
  using traditional performance metrics such as validity, proximity and sparsity.
  Experimental results demonstrate that this framework generates more informative
  and plausible CFs than the state-of-the-art for a wide range of environments
  and DRL agents. In order to foster research in this area, we have made our
  datasets and codes publicly available at
  https://github.com/Amir-Samadi/SAFE-RL.
  </p>
  </div>
  </dd>
  <dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18327" title="Abstract">arXiv:2404.18327</a> [<a href="/pdf/2404.18327" title="Download PDF">pdf</a>, <a href="/format/2404.18327" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MultiMAE-DER: Multimodal Masked Autoencoder for Dynamic Emotion  Recognition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xiang%2C+P">Peihao Xiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+C">Chaohao Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+K">Kaida Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bai%2C+O">Ou Bai</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by ICPRS 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">This paper presents a novel approach to processing multimodal data for
  dynamic emotion recognition, named as the Multimodal Masked Autoencoder for
  Dynamic Emotion Recognition (MultiMAE-DER). The MultiMAE-DER leverages the
  closely correlated representation information within spatiotemporal sequences
  across visual and audio modalities. By utilizing a pre-trained masked
  autoencoder model, the MultiMAEDER is accomplished through simple,
  straightforward finetuning. The performance of the MultiMAE-DER is enhanced by
  optimizing six fusion strategies for multimodal input sequences. These
  strategies address dynamic feature correlations within cross-domain data across
  spatial, temporal, and spatiotemporal sequences. In comparison to
  state-of-the-art multimodal supervised learning models for dynamic emotion
  recognition, MultiMAE-DER enhances the weighted average recall (WAR) by 4.41%
  on the RAVDESS dataset and by 2.06% on the CREMAD. Furthermore, when compared
  with the state-of-the-art model of multimodal self-supervised learning,
  MultiMAE-DER achieves a 1.86% higher WAR on the IEMOCAP dataset.
  </p>
  </div>
  </dd>
  <dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18328" title="Abstract">arXiv:2404.18328</a> [<a href="/pdf/2404.18328" title="Download PDF">pdf</a>, <a href="/ps/2404.18328" title="Download PostScript">ps</a>, <a href="/format/2404.18328" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-stage Attack Detection and Prediction Using Graph Neural Networks:  An IoT Feasibility Study
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Friji%2C+H">Hamdi Friji</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mavromatis%2C+I">Ioannis Mavromatis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sanchez-Mompo%2C+A">Adrian Sanchez-Mompo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Carnelli%2C+P">Pietro Carnelli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Olivereau%2C+A">Alexis Olivereau</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khan%2C+A">Aftab Khan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">With the ever-increasing reliance on digital networks for various aspects of
  modern life, ensuring their security has become a critical challenge. Intrusion
  Detection Systems play a crucial role in ensuring network security, actively
  identifying and mitigating malicious behaviours. However, the relentless
  advancement of cyber-threats has rendered traditional/classical approaches
  insufficient in addressing the sophistication and complexity of attacks. This
  paper proposes a novel 3-stage intrusion detection system inspired by a
  simplified version of the Lockheed Martin cyber kill chain to detect advanced
  multi-step attacks. The proposed approach consists of three models, each
  responsible for detecting a group of attacks with common characteristics. The
  detection outcome of the first two stages is used to conduct a feasibility
  study on the possibility of predicting attacks in the third stage. Using the
  ToN IoT dataset, we achieved an average of 94% F1-Score among different stages,
  outperforming the benchmark approaches based on Random-forest model. Finally,
  we comment on the feasibility of this approach to be integrated in a real-world
  system and propose various possible future work.
  </p>
  </div>
  </dd>
  <dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18331" title="Abstract">arXiv:2404.18331</a> [<a href="/pdf/2404.18331" title="Download PDF">pdf</a>, <a href="/format/2404.18331" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-Robot Object SLAM using Distributed Variational Inference
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+H">Hanwen Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shreedharan%2C+S">Sriram Shreedharan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Atanasov%2C+N">Nikolay Atanasov</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Multi-robot simultaneous localization and mapping (SLAM) enables a robot team
  to achieve coordinated tasks relying on a common map. However, centralized
  processing of robot observations is undesirable because it creates a single
  point of failure and requires pre-existing infrastructure and significant
  multi-hop communication throughput. This paper formulates multi-robot object
  SLAM as a variational inference problem over a communication graph. We impose a
  consensus constraint on the objects maintained by different nodes to ensure
  agreement on a common map. To solve the problem, we develop a distributed
  mirror descent algorithm with a regularization term enforcing consensus. Using
  Gaussian distributions in the algorithm, we derive a distributed multi-state
  constraint Kalman filter (MSCKF) for multi-robot object SLAM. Experiments on
  real and simulated data show that our method improves the trajectory and object
  estimates, compared to individual-robot SLAM, while achieving better scaling to
  large robot teams, compared to centralized multi-robot SLAM. Code is available
  at https://github.com/intrepidChw/distributed_msckf.
  </p>
  </div>
  </dd>
  <dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18337" title="Abstract">arXiv:2404.18337</a> [<a href="/pdf/2404.18337" title="Download PDF">pdf</a>, <a href="/ps/2404.18337" title="Download PostScript">ps</a>, <a href="/format/2404.18337" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Additive Spanner Lower Bounds with Optimal Inner Graph Structure
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bodwin%2C+G">Greg Bodwin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hoppenworth%2C+G">Gary Hoppenworth</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Williams%2C+V+V">Virginia Vassilevska Williams</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wein%2C+N">Nicole Wein</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zixuan Xu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICALP 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  <p class="mathjax">We construct <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-175-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1152" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1153"><span class="mi" id="MathJax-Span-1154" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-175">n</script>-node graphs on which any <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-176-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1155" style="width: 2.374em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.922em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.866em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1156"><span class="mi" id="MathJax-Span-1157" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1158" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1159" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-1160" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-176">O(n)</script>-size spanner has additive
  error at least <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-177-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1161" style="width: 4.858em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.955em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1003.898em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1162"><span class="mo" id="MathJax-Span-1163" style="font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-1164" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-1165" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1166"><span style="display: inline-block; position: relative; width: 1.81em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1167" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-1168"><span class="mrow" id="MathJax-Span-1169"><span class="mn" id="MathJax-Span-1170" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span class="texatom" id="MathJax-Span-1171"><span class="mrow" id="MathJax-Span-1172"><span class="mo" id="MathJax-Span-1173" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-1174" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">17</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1175" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-177">+\Omega(n^{3/17})</script>, improving on the previous best lower bound
  of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-178-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1176" style="width: 3.616em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.939em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1002.882em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1177"><span class="mi" id="MathJax-Span-1178" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-1179" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1180"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1181" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-1182"><span class="mrow" id="MathJax-Span-1183"><span class="mn" id="MathJax-Span-1184" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-1185"><span class="mrow" id="MathJax-Span-1186"><span class="mo" id="MathJax-Span-1187" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-1188" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">7</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1189" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-178">\Omega(n^{1/7})</script> [Bodwin-Hoppenworth FOCS '22]. Our construction completes
  the first two steps of a particular three-step research program, introduced in
  prior work and overviewed here, aimed at producing tight bounds for the problem
  by aligning aspects of the upper and lower bound constructions. More
  specifically, we develop techniques that enable the use of inner graphs in the
  lower bound framework whose technical properties are provably tight with the
  corresponding assumptions made in the upper bounds. As an additional
  application of our techniques, we improve the corresponding lower bound for
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-179-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1190" style="width: 2.374em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.922em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.866em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1191"><span class="mi" id="MathJax-Span-1192" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1193" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1194" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-1195" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-179">O(n)</script>-size additive emulators to <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-180-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1196" style="width: 4.858em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.955em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1003.898em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1197"><span class="mo" id="MathJax-Span-1198" style="font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-1199" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-1200" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1201"><span style="display: inline-block; position: relative; width: 1.81em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1202" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-1203"><span class="mrow" id="MathJax-Span-1204"><span class="mn" id="MathJax-Span-1205" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-1206"><span class="mrow" id="MathJax-Span-1207"><span class="mo" id="MathJax-Span-1208" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-1209" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">14</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1210" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-180">+\Omega(n^{1/14})</script>.
  </p>
  </div>
  </dd>
  <dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18338" title="Abstract">arXiv:2404.18338</a> [<a href="/pdf/2404.18338" title="Download PDF">pdf</a>, <a href="/format/2404.18338" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An extension of the box method discrete fracture model (Box-DFM) to  include low-permeable barriers with minimal additional degrees of freedom
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Xu%2C+Z">Ziyao Xu</a>, 
  <a href="/search/math?searchtype=author&amp;query=Gl%C3%A4ser%2C+D">Dennis Gläser</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">The box method discrete fracture model (Box-DFM) is an important finite
  volume-based discrete fracture model (DFM) to simulate flows in fractured
  porous media. In this paper, we investigate a simple but effective extension of
  the box method discrete fracture model to include low-permeable barriers. The
  method remains identical to the traditional Box-DFM [41, 48] in the absence of
  barriers. The inclusion of barriers requires only minimal additional degrees of
  freedom to accommodate pressure discontinuities and necessitates minor
  modifications to the original coding framework of the Box-DFM. We use extensive
  numerical tests on published benchmark problems and comparison with existing
  finite volume DFMs to demonstrate the validity and performance of the method.
  </p>
  </div>
  </dd>
  <dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18343" title="Abstract">arXiv:2404.18343</a> [<a href="/pdf/2404.18343" title="Download PDF">pdf</a>, <a href="/format/2404.18343" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> G-Refine: A General Quality Refiner for Text-to-Image Generation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chunyi Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Haoning Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hao%2C+H">Hongkun Hao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zicheng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kou%2C+T">Tengchaun Kou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C">Chaofeng Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bai%2C+L">Lei Bai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaohong Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+W">Weisi Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+G">Guangtao Zhai</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">With the evolution of Text-to-Image (T2I) models, the quality defects of
  AI-Generated Images (AIGIs) pose a significant barrier to their widespread
  adoption. In terms of both perception and alignment, existing models cannot
  always guarantee high-quality results. To mitigate this limitation, we
  introduce G-Refine, a general image quality refiner designed to enhance
  low-quality images without compromising the integrity of high-quality ones. The
  model is composed of three interconnected modules: a perception quality
  indicator, an alignment quality indicator, and a general quality enhancement
  module. Based on the mechanisms of the Human Visual System (HVS) and syntax
  trees, the first two indicators can respectively identify the perception and
  alignment deficiencies, and the last module can apply targeted quality
  enhancement accordingly. Extensive experimentation reveals that when compared
  to alternative optimization methods, AIGIs after G-Refine outperform in 10+
  quality metrics across 4 databases. This improvement significantly contributes
  to the practical application of contemporary T2I models, paving the way for
  their broader adoption. The code will be released on
  https://github.com/Q-Future/Q-Refine.
  </p>
  </div>
  </dd>
  <dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18348" title="Abstract">arXiv:2404.18348</a> [<a href="/pdf/2404.18348" title="Download PDF">pdf</a>, <a href="/ps/2404.18348" title="Download PostScript">ps</a>, <a href="/format/2404.18348" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bilinear optimal control for the Stokes-Brinkman equations: a priori and  a posteriori error analyses
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Allendes%2C+A">Alejandro Allendes</a>, 
  <a href="/search/math?searchtype=author&amp;query=Campa%C3%B1a%2C+G">Gilberto Campaña</a>, 
  <a href="/search/math?searchtype=author&amp;query=Otarola%2C+E">Enrique Otarola</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)
  
  </div>
  <p class="mathjax">We analyze a bilinear optimal control problem for the Stokes--Brinkman
  equations: the control variable enters the state equations as a coefficient. In
  two- and three-dimensional Lipschitz domains, we perform a complete continuous
  analysis that includes the existence of solutions and first- and second-order
  optimality conditions. We also develop two finite element methods that differ
  fundamentally in whether the admissible control set is discretized or not. For
  each of the proposed methods, we perform a convergence analysis and derive a
  priori error estimates; the latter under the assumption that the domain is
  convex. Finally, assuming that the domain is Lipschitz, we develop an a
  posteriori error estimator for each discretization scheme and obtain a global
  reliability bound.
  </p>
  </div>
  </dd>
  <dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18350" title="Abstract">arXiv:2404.18350</a> [<a href="/pdf/2404.18350" title="Download PDF">pdf</a>, <a href="/format/2404.18350" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> L-DIT: A dApp for Live Detectability, Identifiability and Trackability  for ASOs on the Behavioral Dynamics Blockchain
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chowdhury%2C+A">Anirban Chowdhury</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Latif%2C+Y">Yasir Latif</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aksenov%2C+I">Ivan Aksenov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jah%2C+M+K">Moriba K. Jah</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bagchi%2C+S">Samya Bagchi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM)
  
  </div>
  <p class="mathjax">As the number of Anthropogenic Space Objects (ASOs) grows, there is an urgent
  need to ensure space safety, security, and sustainability (S3) for long-term
  space use. Currently, no globally effective method can quantify the safety,
  security, and Sustainability of all ASOs in orbit. Existing methods such as the
  Space Sustainability Rating (SSR) rely on volunteering private information to
  provide sustainability ratings. However, the need for such sensitive data might
  prove to be a barrier to adoption for space entities. For effective comparison
  of ASOs, the rating mechanism should apply to all ASOs, even retroactively, so
  that the sustainability of a single ASO can be assessed holistically. Lastly,
  geopolitical boundaries and alignments play a crucial and limiting role in a
  volunteered rating system, limiting the space safety, security, and
  sustainability. This work presents a Live Detectability, Identifiability, and
  Trackability (L-DIT) score through a distributed app (dApp) built on top of the
  Behavioral Dynamics blockchain (BDB). The BDB chain is a space situational
  awareness (SSA) chain that provides verified and cross-checked ASO data from
  multiple sources. This unique combination of consensus-based information from
  BDB and permissionless access to data allows the DIT scoring method presented
  here to be applied to all ASOs. While the underlying BDB chain collects,
  filters, and validates SSA data from various open (and closed if available)
  sources, the L-DIT dApp consumes the data from the chain to provide L-DIT score
  that can contribute towards an operator's, manufacturer's, or owner's
  sustainability practices. Our dApp provides data for all ASOs, allowing their
  sustainability score to be compared against other ASOs, regardless of
  geopolitical alignments, providing business value to entities such as space
  insurance providers and enabling compliance validation and enforcement.
  </p>
  </div>
  </dd>
  <dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18352" title="Abstract">arXiv:2404.18352</a> [<a href="/pdf/2404.18352" title="Download PDF">pdf</a>, <a href="/format/2404.18352" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Post-hoc and manifold explanations analysis of facial expression data  based on deep learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+Y">Yang Xiao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 19PAGES
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">The complex information processing system of humans generates a lot of
  objective and subjective evaluations, making the exploration of human cognitive
  products of great cutting-edge theoretical value. In recent years, deep
  learning technologies, which are inspired by biological brain mechanisms, have
  made significant strides in the application of psychological or cognitive
  scientific research, particularly in the memorization and recognition of facial
  data. This paper investigates through experimental research how neural networks
  process and store facial expression data and associate these data with a range
  of psychological attributes produced by humans. Researchers utilized deep
  learning model VGG16, demonstrating that neural networks can learn and
  reproduce key features of facial data, thereby storing image memories.
  Moreover, the experimental results reveal the potential of deep learning models
  in understanding human emotions and cognitive processes and establish a
  manifold visualization interpretation of cognitive products or psychological
  attributes from a non-Euclidean space perspective, offering new insights into
  enhancing the explainability of AI. This study not only advances the
  application of AI technology in the field of psychology but also provides a new
  psychological theoretical understanding the information processing of the AI.
  The code is available in here: https://github.com/NKUShaw/Psychoinformatics.
  </p>
  </div>
  </dd>
  <dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18353" title="Abstract">arXiv:2404.18353</a> [<a href="/pdf/2404.18353" title="Download PDF">pdf</a>, <a href="/format/2404.18353" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling  Vulnerabilities in Code Generated by Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tihanyi%2C+N">Norbert Tihanyi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bisztray%2C+T">Tamas Bisztray</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ferrag%2C+M+A">Mohamed Amine Ferrag</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jain%2C+R">Ridhi Jain</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cordeiro%2C+L+C">Lucas C. Cordeiro</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL)
  
  </div>
  <p class="mathjax">This study provides a comparative analysis of state-of-the-art large language
  models (LLMs), analyzing how likely they generate vulnerabilities when writing
  simple C programs using a neutral zero-shot prompt. We address a significant
  gap in the literature concerning the security properties of code produced by
  these models without specific directives. N. Tihanyi et al. introduced the
  FormAI dataset at PROMISE '23, containing 112,000 GPT-3.5-generated C programs,
  with over 51.24% identified as vulnerable. We expand that work by introducing
  the FormAI-v2 dataset comprising 265,000 compilable C programs generated using
  various LLMs, including robust models such as Google's GEMINI-pro, OpenAI's
  GPT-4, and TII's 180 billion-parameter Falcon, to Meta's specialized 13
  billion-parameter CodeLLama2 and various other compact models. Each program in
  the dataset is labelled based on the vulnerabilities detected in its source
  code through formal verification using the Efficient SMT-based Context-Bounded
  Model Checker (ESBMC). This technique eliminates false positives by delivering
  a counterexample and ensures the exclusion of false negatives by completing the
  verification process. Our study reveals that at least 63.47% of the generated
  programs are vulnerable. The differences between the models are minor, as they
  all display similar coding errors with slight variations. Our research
  highlights that while LLMs offer promising capabilities for code generation,
  deploying their output in a production environment requires risk assessment and
  validation.
  </p>
  </div>
  </dd>
  <dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18355" title="Abstract">arXiv:2404.18355</a> [<a href="/pdf/2404.18355" title="Download PDF">pdf</a>, <a href="/format/2404.18355" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Pièces de viole des Cinq Livres and their statistical signatures: the  musical work of Marin Marais and Jordi Savall
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lugo%2C+I">Igor Lugo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Alatriste-Contreras%2C+M+G">Martha G. Alatriste-Contreras</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Applications (stat.AP)
  
  </div>
  <p class="mathjax">This study analyzes the spectrum of audio signals related to the work of
  "Pi\`eces de viole des Cinq Livres" based on the collaborative work between
  Marin Marais and Jordi Savall for the underlying musical information. In
  particular, we explore the identification of possible statistical signatures
  related to this musical work. Based on the complex systems approach, we compute
  the spectrum of audio signals, analyze and identify their best-fit statistical
  distributions, and plot their relative frequencies using the scientific pitch
  notation. Findings suggest that the collection of frequency components related
  to the spectrum of each of the books that form this audio work show highly
  skewed and associated statistical distributions. Therefore, the most frequent
  statistical distribution that best describes the collection of these audio data
  and may be associated with a singular statistical signature is the exponential.
  </p>
  </div>
  </dd>
  <dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18356" title="Abstract">arXiv:2404.18356</a> [<a href="/pdf/2404.18356" title="Download PDF">pdf</a>, <a href="/format/2404.18356" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FEDQ-Trust: Efficient Data-Driven Trust Prediction for Mobile Edge-Based  IoT Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bai%2C+J">Jiahui Bai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+H">Hai Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bouguettaya%2C+A">Athman Bouguettaya</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, 6 figures, submitted to IEEE Transactions on Services Computing
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>
  
  </div>
  <p class="mathjax">We introduce FEDQ-Trust, an innovative data-driven trust prediction approach
  designed for mobile edge-based Internet of Things (IoT) environments. The
  decentralized nature of mobile edge environments introduces challenges due to
  variations in data distribution, impacting the accuracy and training efficiency
  of existing distributed data-driven trust prediction models. FEDQ-Trust
  effectively tackles the statistical heterogeneity challenges by integrating
  Federated Expectation-Maximization with Deep Q Networks. Federated
  Expectation-Maximization's robust handling of statistical heterogeneity
  significantly enhances trust prediction accuracy. Meanwhile, Deep Q Networks
  streamlines the model training process, efficiently reducing the number of
  training clients while maintaining model performance. We conducted a suite of
  experiments within simulated MEC-based IoT settings by leveraging two
  real-world IoT datasets. The experimental results demonstrate that our model
  achieved a significant convergence time reduction of 97% to 99% while ensuring
  a notable improvement of 8% to 14% in accuracy compared to state-of-the-art
  models.
  </p>
  </div>
  </dd>
  <dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18357" title="Abstract">arXiv:2404.18357</a> [<a href="/pdf/2404.18357" title="Download PDF">pdf</a>, <a href="/format/2404.18357" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Display in the Air: Balancing Distraction and Workload in AR Glasses  Interfaces for Driving Navigation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+X">Xiangyang He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+K">Keyuan Zhou</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">Augmented Reality (AR) navigation via Head-Mounted Displays (HMDs),
  particularly AR glasses, is revolutionizing the driving experience by
  integrating real-time routing information into the driver's field of view.
  Despite the potential of AR glasses, the question of how to display navigation
  information on the interface of these devices remains a valuable yet relatively
  unexplored research area. This study employs a mixed-method approach involving
  32 participants, combining qualitative feedback from semi-structured interviews
  with quantitative data from usability questionnaires in both simulated and
  real-world scenarios. Highlighting the necessity of real-world testing, the
  research evaluates the impact of five icon placements on the efficiency and
  effectiveness of information perception in both environments. The experiment
  results indicate a preference for non-central icon placements, especially
  bottom-center in real world, which mostly balances distraction and workload for
  the driver. Moreover, these findings contribute to the formulation of four
  specific design implications for augmented reality interfaces and systems. This
  research advances the understanding of AR glasses in driving assistance and
  sets the stage for further developments in this emerging technology field.
  </p>
  </div>
  </dd>
  <dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18359" title="Abstract">arXiv:2404.18359</a> [<a href="/pdf/2404.18359" title="Download PDF">pdf</a>, <a href="/format/2404.18359" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of  Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Wei Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+R">Ren Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+J">Jiang Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gu%2C+C">Chenya Gu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+J">Jiahui Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Len%2C+J">Jinyang Len</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Songyang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+H">Hang Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+D">Dahua Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+C">Conghui He</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">In the burgeoning field of large language models (LLMs), the assessment of
  fundamental knowledge remains a critical challenge, particularly for models
  tailored to Chinese language and culture. This paper introduces FoundaBench, a
  pioneering benchmark designed to rigorously evaluate the fundamental knowledge
  capabilities of Chinese LLMs. FoundaBench encompasses a diverse array of 3354
  multiple-choice questions across common sense and K-12 educational subjects,
  meticulously curated to reflect the breadth and depth of everyday and academic
  knowledge. We present an extensive evaluation of 12 state-of-the-art LLMs using
  FoundaBench, employing both traditional assessment methods and our CircularEval
  protocol to mitigate potential biases in model responses. Our results highlight
  the superior performance of models pre-trained on Chinese corpora, and reveal a
  significant disparity between models' reasoning and memory recall capabilities.
  The insights gleaned from FoundaBench evaluations set a new standard for
  understanding the fundamental knowledge of LLMs, providing a robust framework
  for future advancements in the field.
  </p>
  </div>
  </dd>
  <dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18361" title="Abstract">arXiv:2404.18361</a> [<a href="/pdf/2404.18361" title="Download PDF">pdf</a>, <a href="/format/2404.18361" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Improving Multi-Instance GPU Efficiency via Sub-Entry Sharing TLB Design
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bingyao Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yueqi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Tianyu Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Eeckhout%2C+L">Lieven Eeckhout</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jun Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jaleel%2C+A">Aamer Jaleel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+X">Xulong Tang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR)
  
  </div>
  <p class="mathjax">NVIDIA's Multi-Instance GPU (MIG) technology enables partitioning GPU
  computing power and memory into separate hardware instances, providing complete
  isolation including compute resources, caches, and memory. However, prior work
  identifies that MIG does not extend to partitioning the last-level TLB (i.e.,
  L3 TLB), which remains shared among all instances. To enhance TLB reach, NVIDIA
  GPUs reorganized the TLB structure with 16 sub-entries in each L3 TLB entry
  that have a one-to-one mapping to the address translations for 16 pages of size
  64KB located within the same 1MB aligned range. Our comprehensive investigation
  of address translation efficiency in MIG identifies two main issues caused by
  L3 TLB sharing interference: (i) it results in performance degradation for
  co-running applications, and (ii) TLB sub-entries are not fully utilized before
  eviction. Based on this observation, we propose STAR to improve the utilization
  of TLB sub-entries through dynamic sharing of TLB entries across multiple base
  addresses. STAR evaluates TLB entries based on their sub-entry utilization to
  optimize address translation storage, dynamically adjusting between a shared
  and non-shared status to cater to current demand. We show that STAR improves
  overall performance by an average of 30.2% across various multi-tenant
  workloads.
  </p>
  </div>
  </dd>
  <dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18362" title="Abstract">arXiv:2404.18362</a> [<a href="/pdf/2404.18362" title="Download PDF">pdf</a>, <a href="/format/2404.18362" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Physics-informed Convolutional Neural Network for Microgrid Economic  Dispatch
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Ge%2C+X">Xiaoyu Ge</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Khazaei%2C+J">Javad Khazaei</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">The variability of renewable energy generation and the unpredictability of
  electricity demand create a need for real-time economic dispatch (ED) of assets
  in microgrids. However, solving numerical optimization problems in real-time
  can be incredibly challenging. This study proposes using a convolutional neural
  network (CNN) based on deep learning to address these challenges. Compared to
  traditional methods, CNN is more efficient, delivers more dependable results,
  and has a shorter response time when dealing with uncertainties. While CNN has
  shown promising results, it does not extract explainable knowledge from the
  data. To address this limitation, a physics-inspired CNN model is developed by
  incorporating constraints of the ED problem into the CNN training to ensure
  that the model follows physical laws while fitting the data. The proposed
  method can significantly accelerate real-time economic dispatch of microgrids
  without compromising the accuracy of numerical optimization techniques. The
  effectiveness of the proposed data-driven approach for optimal allocation of
  microgrid resources in real-time is verified through a comprehensive comparison
  with conventional numerical optimization approaches.
  </p>
  </div>
  </dd>
  <dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18363" title="Abstract">arXiv:2404.18363</a> [<a href="/pdf/2404.18363" title="Download PDF">pdf</a>, <a href="/format/2404.18363" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Reactive Composition of UAV Delivery Services in Urban Environments
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+W">Woojin Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shahzaad%2C+B">Babar Shahzaad</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Alkouz%2C+B">Balsam Alkouz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bouguettaya%2C+A">Athman Bouguettaya</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, 18 figures. This is an accepted paper and it is going to appear in IEEE Transactions on Intelligent Transportation Systems (T-ITS)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
  
  </div>
  <p class="mathjax">We propose a novel failure-aware reactive UAV delivery service composition
  framework. A skyway network infrastructure is presented for the effective
  provisioning of services in urban areas. We present a formal drone delivery
  service model and a system architecture for reactive drone delivery services.
  We develop radius-based, cell density-based, and two-phased algorithms to
  reduce the search space and perform reactive service compositions when a
  service failure occurs. We conduct a set of experiments with a real drone
  dataset to demonstrate the effectiveness of our proposed approach.
  </p>
  </div>
  </dd>
  <dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18365" title="Abstract">arXiv:2404.18365</a> [<a href="/pdf/2404.18365" title="Download PDF">pdf</a>, <a href="/format/2404.18365" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> "What Keeps People Secure is That They Met The Security Team":  Deconstructing Drivers And Goals of Organizational Security Awareness
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hielscher%2C+J">Jonas Hielscher</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Parkin%2C+S">Simon Parkin</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>
  
  </div>
  <p class="mathjax">Security awareness campaigns in organizations now collectively cost billions
  of dollars annually. There is increasing focus on ensuring certain security
  behaviors among employees. On the surface, this would imply a user-centered
  view of security in organizations. Despite this, the basis of what security
  awareness managers do and what decides this are unclear. We conducted n=15
  semi-structured interviews with full-time security awareness managers, with
  experience across various national and international companies in European
  countries, with thousands of employees. Through thematic analysis, we identify
  that success in awareness management is fragile while having the potential to
  improve; there are a range of restrictions, and mismatched drivers and goals
  for security awareness, affecting how it is structured, delivered, measured,
  and improved. We find that security awareness as a practice is underspecified,
  and split between messaging around secure behaviors and connecting to
  employees, with a lack of recognition for the measures that awareness managers
  regard as important. We discuss ways forward, including alternative indicators
  of success, and security usability advocacy for employees.
  </p>
  </div>
  </dd>
  <dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18371" title="Abstract">arXiv:2404.18371</a> [<a href="/pdf/2404.18371" title="Download PDF">pdf</a>, <a href="/format/2404.18371" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> QANA: LLM-based Question Generation and Network Analysis for Zero-shot  Key Point Analysis and Beyond
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fukuma%2C+T">Tomoki Fukuma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Noda%2C+K">Koki Noda</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hoso%2C+T+U+K">Toshihide Ubukata Kousuke Hoso</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ichikawa%2C+Y">Yoshiharu Ichikawa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kambe%2C+K">Kyosuke Kambe</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Masubuch%2C+Y">Yu Masubuch</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Toriumi%2C+F">Fujio Toriumi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Under review as a conference paper at COLM 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">The proliferation of social media has led to information overload and
  increased interest in opinion mining. We propose "Question-Answering Network
  Analysis" (QANA), a novel opinion mining framework that utilizes Large Language
  Models (LLMs) to generate questions from users' comments, constructs a
  bipartite graph based on the comments' answerability to the questions, and
  applies centrality measures to examine the importance of opinions. We
  investigate the impact of question generation styles, LLM selections, and the
  choice of embedding model on the quality of the constructed QA networks by
  comparing them with annotated Key Point Analysis datasets. QANA achieves
  comparable performance to previous state-of-the-art supervised models in a
  zero-shot manner for Key Point Matching task, also reducing the computational
  cost from quadratic to linear. For Key Point Generation, questions with high
  PageRank or degree centrality align well with manually annotated key points.
  Notably, QANA enables analysts to assess the importance of key points from
  various aspects according to their selection of centrality measure. QANA's
  primary contribution lies in its flexibility to extract key points from a wide
  range of perspectives, which enhances the quality and impartiality of opinion
  mining.
  </p>
  </div>
  </dd>
  <dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18373" title="Abstract">arXiv:2404.18373</a> [<a href="/pdf/2404.18373" title="Download PDF">pdf</a>, <a href="/format/2404.18373" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> 6G comprehensive intelligence: network operations and optimization based  on Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Long%2C+S">Sifan Long</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+F">Fengxiao Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yangfan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tan%2C+T">Tiao Tan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jin%2C+Z">Zhengjie Jin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+M">Ming Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kato%2C+N">Nei Kato</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 5 figures, 15 preferences
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>
  
  </div>
  <p class="mathjax">The sixth generation mobile communication standard (6G) can promote the
  development of Industrial Internet and Internet of Things (IoT). To achieve
  comprehensive intelligent development of the network and provide customers with
  higher quality personalized services. This paper proposes a network performance
  optimization and intelligent operation network architecture based on Large
  Language Model (LLM), aiming to build a comprehensive intelligent 6G network
  system. The Large Language Model, with more parameters and stronger learning
  ability, can more accurately capture patterns and features in data, which can
  achieve more accurate content output and high intelligence and provide strong
  support for related research such as network data security, privacy protection,
  and health assessment. This paper also presents the design framework of a
  network health assessment system based on LLM and focuses on its potential
  application value, through the case of network health management system, it is
  fully demonstrated that the 6G intelligent network system based on LLM has
  important practical significance for the comprehensive realization of
  intelligence.
  </p>
  </div>
  </dd>
  <dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18374" title="Abstract">arXiv:2404.18374</a> [<a href="/pdf/2404.18374" title="Download PDF">pdf</a>, <a href="/format/2404.18374" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Trajectory Optimization for Adaptive Informative Path Planning with  Multimodal Sensing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ott%2C+J">Joshua Ott</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Balaban%2C+E">Edward Balaban</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kochenderfer%2C+M">Mykel Kochenderfer</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> IEEE International Conference on Control, Decision and Information Technologies
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">We consider the problem of an autonomous agent equipped with multiple
  sensors, each with different sensing precision and energy costs. The agent's
  goal is to explore the environment and gather information subject to its
  resource constraints in unknown, partially observable environments. The
  challenge lies in reasoning about the effects of sensing and movement while
  respecting the agent's resource and dynamic constraints. We formulate the
  problem as a trajectory optimization problem and solve it using a
  projection-based trajectory optimization approach where the objective is to
  reduce the variance of the Gaussian process world belief. Our approach
  outperforms previous approaches in long horizon trajectories by achieving an
  overall variance reduction of up to 85% and reducing the root-mean square error
  in the environment belief by 50%. This approach was developed in support of
  rover path planning for the NASA VIPER Mission.
  </p>
  </div>
  </dd>
  <dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18375" title="Abstract">arXiv:2404.18375</a> [<a href="/pdf/2404.18375" title="Download PDF">pdf</a>, <a href="/format/2404.18375" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Field Notes on Deploying Research Robots in Public Spaces
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bu%2C+F">Fanjun Bu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bremers%2C+A">Alexandra Bremers</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Colley%2C+M">Mark Colley</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ju%2C+W">Wendy Ju</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> CHI LBW 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Human-robot interaction requires to be studied in the wild. In the summers of
  2022 and 2023, we deployed two trash barrel service robots through the
  wizard-of-oz protocol in public spaces to study human-robot interactions in
  urban settings. We deployed the robots at two different public plazas in
  downtown Manhattan and Brooklyn for a collective of 20 hours of field time. To
  date, relatively few long-term human-robot interaction studies have been
  conducted in shared public spaces. To support researchers aiming to fill this
  gap, we would like to share some of our insights and learned lessons that would
  benefit both researchers and practitioners on how to deploy robots in public
  spaces. We share best practices and lessons learned with the HRI research
  community to encourage more in-the-wild research of robots in public spaces and
  call for the community to share their lessons learned to a GitHub repository.
  </p>
  </div>
  </dd>
  <dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18381" title="Abstract">arXiv:2404.18381</a> [<a href="/pdf/2404.18381" title="Download PDF">pdf</a>, <a href="/format/2404.18381" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Object Registration in Neural Fields
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hall%2C+D">David Hall</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hausler%2C+S">Stephen Hausler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mahendren%2C+S">Sutharsan Mahendren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Moghadam%2C+P">Peyman Moghadam</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to ICRA 2024 RoboNeRF workshop. 5 pages, 10 figures. arXiv admin note: substantial text overlap with <a href="/abs/2402.09722">arXiv:2402.09722</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Neural fields provide a continuous scene representation of 3D geometry and
  appearance in a way which has great promise for robotics applications. One
  functionality that unlocks unique use-cases for neural fields in robotics is
  object 6-DoF registration. In this paper, we provide an expanded analysis of
  the recent Reg-NF neural field registration method and its use-cases within a
  robotics context. We showcase the scenario of determining the 6-DoF pose of
  known objects within a scene using scene and object neural field models. We
  show how this may be used to better represent objects within imperfectly
  modelled scenes and generate new scenes by substituting object neural field
  models into the scene.
  </p>
  </div>
  </dd>
  <dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18383" title="Abstract">arXiv:2404.18383</a> [<a href="/pdf/2404.18383" title="Download PDF">pdf</a>, <a href="/format/2404.18383" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Framework for Learning and Reusing Robotic Skills
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hertel%2C+B">Brendan Hertel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tran%2C+N">Nhu Tran</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Elkoudi%2C+M">Meriem Elkoudi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Azadeh%2C+R">Reza Azadeh</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 4 pages, 4 figures. Accepted for publication as work-in-progress paper at Ubiquitous Robots (UR) 2024. Code available here: <a href="https://github.com/brenhertel/Probabilistic-Segmentation">this https URL</a> and here: <a href="https://github.com/brenhertel/Elastic-Clustering">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">In this paper, we present our work in progress towards creating a library of
  motion primitives. This library facilitates easier and more intuitive learning
  and reusing of robotic skills. Users can teach robots complex skills through
  Learning from Demonstration, which is automatically segmented into primitives
  and stored in clusters of similar skills. We propose a novel multimodal
  segmentation method as well as a novel trajectory clustering method. Then, when
  needed for reuse, we transform primitives into new environments using
  trajectory editing. We present simulated results for our framework with
  demonstrations taken on real-world robots.
  </p>
  </div>
  </dd>
  <dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18384" title="Abstract">arXiv:2404.18384</a> [<a href="/pdf/2404.18384" title="Download PDF">pdf</a>, <a href="/format/2404.18384" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring the Limits of Fine-grained LLM-based Physics Inference via  Premise Removal Interventions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Meadows%2C+J">Jordan Meadows</a>, 
  <a href="/search/cs?searchtype=author&amp;query=James%2C+T">Tamsin James</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Freitas%2C+A">Andre Freitas</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Language models can hallucinate when performing complex and detailed
  mathematical reasoning. Physics provides a rich domain for assessing
  mathematical reasoning capabilities where physical context imbues the use of
  symbols which needs to satisfy complex semantics (\textit{e.g.,} units,
  tensorial order), leading to instances where inference may be algebraically
  coherent, yet unphysical. In this work, we assess the ability of Language
  Models (LMs) to perform fine-grained mathematical and physical reasoning using
  a curated dataset encompassing multiple notations and Physics subdomains. We
  improve zero-shot scores using synthetic in-context examples, and demonstrate
  non-linear degradation of derivation quality with perturbation strength via the
  progressive omission of supporting premises. We find that the models'
  mathematical reasoning is not physics-informed in this setting, where physical
  context is predominantly ignored in favour of reverse-engineering solutions.
  </p>
  </div>
  </dd>
  <dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18385" title="Abstract">arXiv:2404.18385</a> [<a href="/pdf/2404.18385" title="Download PDF">pdf</a>, <a href="/format/2404.18385" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Equivalence: An analysis of artists' roles with Image Generative AI from  Conceptual Art perspective through an interactive installation design  practice
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yixuan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Baciu%2C+D+C">Dan C. Baciu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Novak%2C+M">Marcos Novak</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Legrady%2C+G">George Legrady</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Over the past year, the emergence of advanced text-to-image Generative AI
  models has significantly impacted the art world, challenging traditional
  notions of creativity and the role of artists. This study explores how artists
  interact with these technologies, using a 5P model (Purpose, People, Process,
  Product, and Press) based on Rhodes' creativity framework to compare the
  artistic processes behind Conceptual Art and Image Generative AI. To exemplify
  this framework, a practical case study titled "Equivalence", a multi-screen
  interactive installation that converts users' speech input into continuously
  evolving paintings developed based on Stable Diffusion and NLP algorithms, was
  developed. Through comprehensive analysis and the case study, this work aims to
  broaden our understanding of artists' roles and foster a deeper appreciation
  for the creative aspects inherent in artwork created with Image Generative AI.
  </p>
  </div>
  </dd>
  <dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18386" title="Abstract">arXiv:2404.18386</a> [<a href="/pdf/2404.18386" title="Download PDF">pdf</a>, <a href="/format/2404.18386" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Network Intent Decomposition and Optimization for Energy-Aware Radio  Access Network
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yijun Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yexing Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Dong Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xiaoxue Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+C">Chungang Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>
  
  </div>
  <p class="mathjax">With recent advancements in the sixth generation (6G) communication
  technologies, more vertical industries have encountered diverse network
  services. How to reduce energy consumption is critical to meet the expectation
  of the quality of diverse network services. In particular, the number of base
  stations in 6G is huge with coupled adjustable network parameters. However, the
  problem is complex with multiple network objectives and parameters. Network
  intents are difficult to map to individual network elements and require
  enhanced automation capabilities. In this paper, we present a network intent
  decomposition and optimization mechanism in an energy-aware radio access
  network scenario. By characterizing the intent ontology with a standard
  template, we present a generic network intent representation framework. Then we
  propose a novel intent modeling method using Knowledge Acquisition in automated
  Specification language, which can model the network ontology. To clarify the
  number and types of network objectives and energy-saving operations, we develop
  a Softgoal Interdependency Graph-based network intent decomposition model, and
  thus, a network intent decomposition algorithm is presented. Simulation results
  demonstrate that the proposed algorithm outperforms without conflict analysis
  in intent decomposition time. Moreover, we design a deep Q-network-assisted
  intent optimization scheme to validate the performance gain.
  </p>
  </div>
  </dd>
  <dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18388" title="Abstract">arXiv:2404.18388</a> [<a href="/pdf/2404.18388" title="Download PDF">pdf</a>, <a href="/format/2404.18388" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SPECIAL: Synopsis Assisted Secure Collaborative Analytics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chenghong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+L">Lina Qiu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bater%2C+J">Johes Bater</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yukui Luo</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Databases (cs.DB)
  
  </div>
  <p class="mathjax">Secure collaborative analytics (SCA) enable the processing of analytical SQL
  queries across multiple owners' data, even when direct data sharing is not
  feasible. Although essential for strong privacy, the large overhead from
  data-oblivious primitives in traditional SCA has hindered its practical
  adoption. Recent SCA variants that permit controlled leakages under
  differential privacy (DP) show a better balance between privacy and efficiency.
  However, they still face significant challenges, such as potentially unbounded
  privacy loss, suboptimal query planning, and lossy processing. To address these
  challenges, we introduce SPECIAL, the first SCA system that simultaneously
  ensures bounded privacy loss, advanced query planning, and lossless processing.
  SPECIAL employs a novel synopsis-assisted secure processing model, where a
  one-time privacy cost is spent to acquire private synopses (table statistics)
  from owner data. These synopses then allow SPECIAL to estimate (compaction)
  sizes for secure operations (e.g., filter, join) and index encrypted data
  without extra privacy loss. Crucially, these estimates and indexes can be
  prepared before runtime, thereby facilitating efficient query planning and
  accurate cost estimations. Moreover, by using one-sided noise mechanisms and
  private upper bound techniques, SPECIAL ensures strict lossless processing for
  complex queries (e.g., multi-join). Through a comprehensive benchmark, we show
  that SPECIAL significantly outperforms cutting-edge SCAs, with up to 80X faster
  query times and over 900X smaller memory for complex queries. Moreover, it also
  achieves up to an 89X reduction in privacy loss under continual processing.
  </p>
  </div>
  </dd>
  <dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18390" title="Abstract">arXiv:2404.18390</a> [<a href="/pdf/2404.18390" title="Download PDF">pdf</a>, <a href="/format/2404.18390" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Critical grid method: An extensible Smoothed Particle Hydrodynamics  fluid general interpolation method for Fluid-Structure Interaction surface  coupling based on preCICE
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Long%2C+S">Sifan Long</a>, 
  <a href="/search/math?searchtype=author&amp;query=Guo%2C+X">Xiaowei Guo</a>, 
  <a href="/search/math?searchtype=author&amp;query=Fan%2C+X">Xiaokang Fan</a>, 
  <a href="/search/math?searchtype=author&amp;query=Yang%2C+C">Canqun Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">Solving Fluid-Structure Interaction (FSI) problems using traditional methods
  is a big challenge in the field of numerical simulation. As a powerful
  multi-physical field coupled library, preCICE has a bright application prospect
  for solving FSI, which supports many open/closed source software and commercial
  CFD solvers to solve FSI problems in the form of a black box. However, this
  library currently only supports mesh-based coupling schemes. This paper
  proposes a critical grid (mesh) as an intermediate medium for the particle
  method to connect a bidirectional coupling tool named preCICE. The particle and
  critical mesh are used to interpolate the displacement and force so that the
  pure Lagrangian Smoothed Particle Hydrodynamic (SPH) method can also solve the
  FSI problem. This method is called the particle mesh coupling (PMC) method,
  which theoretically solves the mesh mismatch problem based on the particle
  method to connect preCICE. In addition, we conduct experiments to verify the
  performance of the PMC method, in which the fluid and the structure is
  discretized by SPH and the Finite Element Method (FEM), respectively. The
  results show that the PMC method given in this paper is effective for solving
  FSI problems. Finally, our source code for the SPH fluid adapter is open-source
  and available on GitHub for further developing preCICE compatibility with more
  meshless methods.
  </p>
  </div>
  </dd>
  <dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18392" title="Abstract">arXiv:2404.18392</a> [<a href="/pdf/2404.18392" title="Download PDF">pdf</a>, <a href="/format/2404.18392" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Dflow, a Python framework for constructing cloud-native AI-for-Science  workflows
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xinzijian Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+Y">Yanbo Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuoyuan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+J">Jiahao Fan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chengqian Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+J">Jinzhe Zeng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shan%2C+Y">Yifan Shan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yannan Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Wei-Hong Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yun-Pei Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuzhi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wen%2C+T">Tongqi Wen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=York%2C+D+M">Darrin M. York</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+Z">Zhicheng Zhong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+H">Hang Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+J">Jun Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Linfeng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Han Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>
  
  </div>
  <p class="mathjax">In the AI-for-science era, scientific computing scenarios such as concurrent
  learning and high-throughput computing demand a new generation of
  infrastructure that supports scalable computing resources and automated
  workflow management on both cloud and high-performance supercomputers. Here we
  introduce Dflow, an open-source Python toolkit designed for scientists to
  construct workflows with simple programming interfaces. It enables complex
  process control and task scheduling across a distributed, heterogeneous
  infrastructure, leveraging containers and Kubernetes for flexibility. Dflow is
  highly observable and can scale to thousands of concurrent nodes per workflow,
  enhancing the efficiency of complex scientific computing tasks. The basic unit
  in Dflow, known as an Operation (OP), is reusable and independent of the
  underlying infrastructure or context. Dozens of workflow projects have been
  developed based on Dflow, spanning a wide range of projects. We anticipate that
  the reusability of Dflow and its components will encourage more scientists to
  publish their workflows and OP components. These components, in turn, can be
  adapted and reused in various contexts, fostering greater collaboration and
  innovation in the scientific community.
  </p>
  </div>
  </dd>
  <dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18394" title="Abstract">arXiv:2404.18394</a> [<a href="/pdf/2404.18394" title="Download PDF">pdf</a>, <a href="/format/2404.18394" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Reconstructing Satellites in 3D from Amateur Telescope Images
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chang%2C+Z">Zhiming Chang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+B">Boyang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xia%2C+Y">Yifei Xia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+Y">Youming Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+B">Boxin Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+H">He Sun</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">This paper proposes a framework for the 3D reconstruction of satellites in
  low-Earth orbit, utilizing videos captured by small amateur telescopes. The
  video data obtained from these telescopes differ significantly from data for
  standard 3D reconstruction tasks, characterized by intense motion blur,
  atmospheric turbulence, pervasive background light pollution, extended focal
  length and constrained observational perspectives. To address these challenges,
  our approach begins with a comprehensive pre-processing workflow that
  encompasses deep learning-based image restoration, feature point extraction and
  camera pose initialization. We proceed with the application of an improved 3D
  Gaussian splatting algorithm for reconstructing the 3D model. Our technique
  supports simultaneous 3D Gaussian training and pose estimation, enabling the
  robust generation of intricate 3D point clouds from sparse, noisy data. The
  procedure is further bolstered by a post-editing phase designed to eliminate
  noise points inconsistent with our prior knowledge of a satellite's geometric
  constraints. We validate our approach using both synthetic datasets and actual
  observations of China's Space Station, showcasing its significant advantages
  over existing methods in reconstructing 3D space objects from ground-based
  observations.
  </p>
  </div>
  </dd>
  <dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18395" title="Abstract">arXiv:2404.18395</a> [<a href="/pdf/2404.18395" title="Download PDF">pdf</a>, <a href="/format/2404.18395" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mesh-based Photorealistic and Real-time 3D Mapping for Robust Visual  Perception of Autonomous Underwater Vehicle
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Jungwoo Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cho%2C+Y">Younggun Cho</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 15 figures, IEEE ICRA Workshop on Field Robotics 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">This paper proposes a photorealistic real-time dense 3D mapping system that
  utilizes a learning-based image enhancement method and mesh-based map
  representation. Due to the characteristics of the underwater environment, where
  problems such as hazing and low contrast occur, it is hard to apply
  conventional simultaneous localization and mapping (SLAM) methods. Furthermore,
  for sensitive tasks like inspecting cracks, photorealistic mapping is very
  important. However, the behavior of Autonomous Underwater Vehicle (AUV) is
  computationally constrained. In this paper, we utilize a neural network-based
  image enhancement method to improve pose estimation and mapping quality and
  apply a sliding window-based mesh expansion method to enable lightweight, fast,
  and photorealistic mapping. To validate our results, we utilize real-world and
  indoor synthetic datasets. We performed qualitative validation with the
  real-world dataset and quantitative validation by modeling images from the
  indoor synthetic dataset as underwater scenes.
  </p>
  </div>
  </dd>
  <dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18396" title="Abstract">arXiv:2404.18396</a> [<a href="/pdf/2404.18396" title="Download PDF">pdf</a>, <a href="/format/2404.18396" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DRAM-Profiler: An Experimental DRAM RowHammer Vulnerability Profiling  Mechanism
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+R">Ranyang Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J+T">Jacqueline T. Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kochar%2C+N">Nakul Kochar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ahmed%2C+S">Sabbir Ahmed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rakin%2C+A+S">Adnan Siraj Rakin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Angizi%2C+S">Shaahin Angizi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages, 6 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)
  
  </div>
  <p class="mathjax">RowHammer stands out as a prominent example, potentially the pioneering one,
  showcasing how a failure mechanism at the circuit level can give rise to a
  significant and pervasive security vulnerability within systems. Prior research
  has approached RowHammer attacks within a static threat model framework.
  Nonetheless, it warrants consideration within a more nuanced and dynamic model.
  This paper presents a low-overhead DRAM RowHammer vulnerability profiling
  technique termed DRAM-Profiler, which utilizes innovative test vectors for
  categorizing memory cells into distinct security levels. The proposed test
  vectors intentionally weaken the spatial correlation between the aggressors and
  victim rows before an attack for evaluation, thus aiding designers in
  mitigating RowHammer vulnerabilities in the mapping phase. While there has been
  no previous research showcasing the impact of such profiling to our knowledge,
  our study methodically assesses 128 commercial DDR4 DRAM products. The results
  uncover the significant variability among chips from different manufacturers in
  the type and quantity of RowHammer attacks that can be exploited by
  adversaries.
  </p>
  </div>
  </dd>
  <dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18397" title="Abstract">arXiv:2404.18397</a> [<a href="/pdf/2404.18397" title="Download PDF">pdf</a>, <a href="/format/2404.18397" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ViOCRVQA: Novel Benchmark Dataset and Vision Reader for Visual Question  Answering by Understanding Vietnamese Text in Images
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pham%2C+H+Q">Huy Quang Pham</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+T+K">Thang Kien-Bao Nguyen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Van+Nguyen%2C+Q">Quan Van Nguyen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tran%2C+D+Q">Dan Quang Tran</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+N+H">Nghia Hieu Nguyen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Van+Nguyen%2C+K">Kiet Van Nguyen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+N+L">Ngan Luu-Thuy Nguyen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Optical Character Recognition - Visual Question Answering (OCR-VQA) is the
  task of answering text information contained in images that have just been
  significantly developed in the English language in recent years. However, there
  are limited studies of this task in low-resource languages such as Vietnamese.
  To this end, we introduce a novel dataset, ViOCRVQA (Vietnamese Optical
  Character Recognition - Visual Question Answering dataset), consisting of
  28,000+ images and 120,000+ question-answer pairs. In this dataset, all the
  images contain text and questions about the information relevant to the text in
  the images. We deploy ideas from state-of-the-art methods proposed for English
  to conduct experiments on our dataset, revealing the challenges and
  difficulties inherent in a Vietnamese dataset. Furthermore, we introduce a
  novel approach, called VisionReader, which achieved 0.4116 in EM and 0.6990 in
  the F1-score on the test set. Through the results, we found that the OCR system
  plays a very important role in VQA models on the ViOCRVQA dataset. In addition,
  the objects in the image also play a role in improving model performance. We
  open access to our dataset at link (https://github.com/qhnhynmm/ViOCRVQA.git)
  for further research in OCR-VQA task in Vietnamese.
  </p>
  </div>
  </dd>
  <dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18398" title="Abstract">arXiv:2404.18398</a> [<a href="/pdf/2404.18398" title="Download PDF">pdf</a>, <a href="/format/2404.18398" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MM-TTS: A Unified Framework for Multimodal, Prompt-Induced Emotional  Text-to-Speech Synthesis
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+J">Jun-Yan He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+X">Xiaojiang Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hauptmann%2C+A+G">Alexander G. Hauptmann</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM)
  
  </div>
  <p class="mathjax">Emotional Text-to-Speech (E-TTS) synthesis has gained significant attention
  in recent years due to its potential to enhance human-computer interaction.
  However, current E-TTS approaches often struggle to capture the complexity of
  human emotions, primarily relying on oversimplified emotional labels or
  single-modality inputs. To address these limitations, we propose the Multimodal
  Emotional Text-to-Speech System (MM-TTS), a unified framework that leverages
  emotional cues from multiple modalities to generate highly expressive and
  emotionally resonant speech. MM-TTS consists of two key components: (1) the
  Emotion Prompt Alignment Module (EP-Align), which employs contrastive learning
  to align emotional features across text, audio, and visual modalities, ensuring
  a coherent fusion of multimodal information; and (2) the Emotion
  Embedding-Induced TTS (EMI-TTS), which integrates the aligned emotional
  embeddings with state-of-the-art TTS models to synthesize speech that
  accurately reflects the intended emotions. Extensive evaluations across diverse
  datasets demonstrate the superior performance of MM-TTS compared to traditional
  E-TTS models. Objective metrics, including Word Error Rate (WER) and Character
  Error Rate (CER), show significant improvements on ESD dataset, with MM-TTS
  achieving scores of 7.35% and 3.07%, respectively. Subjective assessments
  further validate that MM-TTS generates speech with emotional fidelity and
  naturalness comparable to human speech. Our code and pre-trained models are
  publicly available at https://anonymous.4open.science/r/MMTTS-D214
  </p>
  </div>
  </dd>
  <dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18399" title="Abstract">arXiv:2404.18399</a> [<a href="/pdf/2404.18399" title="Download PDF">pdf</a>, <a href="/format/2404.18399" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Semantic Line Combination Detector
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ko%2C+J">Jinwon Ko</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jin%2C+D">Dongkwon Jin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+C">Chang-Su Kim</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">A novel algorithm, called semantic line combination detector (SLCD), to find
  an optimal combination of semantic lines is proposed in this paper. It
  processes all lines in each line combination at once to assess the overall
  harmony of the lines. First, we generate various line combinations from
  reliable lines. Second, we estimate the score of each line combination and
  determine the best one. Experimental results demonstrate that the proposed SLCD
  outperforms existing semantic line detectors on various datasets. Moreover, it
  is shown that SLCD can be applied effectively to three vision tasks of
  vanishing point detection, symmetry axis detection, and composition-based image
  retrieval. Our codes are available at https://github.com/Jinwon-Ko/SLCD.
  </p>
  </div>
  </dd>
  <dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18400" title="Abstract">arXiv:2404.18400</a> [<a href="/pdf/2404.18400" title="Download PDF">pdf</a>, <a href="/format/2404.18400" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LLM-SR: Scientific Equation Discovery via Programming with Large  Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shojaee%2C+P">Parshin Shojaee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Meidani%2C+K">Kazem Meidani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+S">Shashank Gupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Farimani%2C+A+B">Amir Barati Farimani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Reddy%2C+C+K">Chandan K Reddy</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)
  
  </div>
  <p class="mathjax">Mathematical equations have been unreasonably effective in describing complex
  natural phenomena across various scientific disciplines. However, discovering
  such insightful equations from data presents significant challenges due to the
  necessity of navigating extremely high-dimensional combinatorial and nonlinear
  hypothesis spaces. Traditional methods of equation discovery largely focus on
  extracting equations from data alone, often neglecting the rich domain-specific
  prior knowledge that scientists typically depend on. To bridge this gap, we
  introduce LLM-SR, a novel approach that leverages the extensive scientific
  knowledge and robust code generation capabilities of Large Language Models
  (LLMs) to discover scientific equations from data in an efficient manner.
  Specifically, LLM-SR treats equations as programs with mathematical operators
  and combines LLMs' scientific priors with evolutionary search over equation
  programs. The LLM iteratively proposes new equation skeletons, drawing from its
  physical understanding, which are then optimized against data to estimate
  skeleton parameters. We demonstrate LLM-SR's effectiveness across three diverse
  scientific domains, where it discovers physically accurate equations that
  provide significantly better fits to in-domain and out-of-domain data compared
  to the well-established equation discovery baselines
  </p>
  </div>
  </dd>
  <dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18401" title="Abstract">arXiv:2404.18401</a> [<a href="/pdf/2404.18401" title="Download PDF">pdf</a>, <a href="/ps/2404.18401" title="Download PostScript">ps</a>, <a href="/format/2404.18401" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Spectral-Spatial Mamba for Hyperspectral Image Classification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+L">Lingbo Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yushi Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+X">Xin He</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Recently, deep learning models have achieved excellent performance in
  hyperspectral image (HSI) classification. Among the many deep models,
  Transformer has gradually attracted interest for its excellence in modeling the
  long-range dependencies of spatial-spectral features in HSI. However,
  Transformer has the problem of quadratic computational complexity due to the
  self-attention mechanism, which is heavier than other models and thus has
  limited adoption in HSI processing. Fortunately, the recently emerging state
  space model-based Mamba shows great computational efficiency while achieving
  the modeling power of Transformers. Therefore, in this paper, we make a
  preliminary attempt to apply the Mamba to HSI classification, leading to the
  proposed spectral-spatial Mamba (SS-Mamba). Specifically, the proposed SS-Mamba
  mainly consists of spectral-spatial token generation module and several stacked
  spectral-spatial Mamba blocks. Firstly, the token generation module converts
  any given HSI cube to spatial and spectral tokens as sequences. And then these
  tokens are sent to stacked spectral-spatial mamba blocks (SS-MB). Each SS-MB
  block consists of two basic mamba blocks and a spectral-spatial feature
  enhancement module. The spatial and spectral tokens are processed separately by
  the two basic mamba blocks, respectively. Besides, the feature enhancement
  module modulates spatial and spectral tokens using HSI sample's center region
  information. In this way, the spectral and spatial tokens cooperate with each
  other and achieve information fusion within each block. The experimental
  results conducted on widely used HSI datasets reveal that the proposed model
  achieves competitive results compared with the state-of-the-art methods. The
  Mamba-based method opens a new window for HSI classification.
  </p>
  </div>
  </dd>
  <dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18405" title="Abstract">arXiv:2404.18405</a> [<a href="/pdf/2404.18405" title="Download PDF">pdf</a>, <a href="/ps/2404.18405" title="Download PostScript">ps</a>, <a href="/format/2404.18405" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Understanding and Shaping Human-Technology Assemblages in the Age of  Generative AI
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Andres%2C+J">Josh Andres</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Danta%2C+C">Chris Danta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bianchi%2C+A">Andrea Bianchi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hong%2C+S">Sungyeon Hong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuying Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sandoval%2C+E+B">Eduardo B. Sandoval</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Martin%2C+C">Charles Martin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cooper%2C+N">Ned Cooper</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">Generative AI capabilities are rapidly transforming how we perceive, interact
  with, and relate to machines. This one-day workshop invites HCI researchers,
  designers, and practitioners to imaginatively inhabit and explore the possible
  futures that might emerge from humans combining generative AI capabilities into
  everyday technologies at massive scale. Workshop participants will craft
  stories, visualisations, and prototypes through scenario-based design to
  investigate these possible futures, resulting in the production of an
  open-annotated scenario library and a journal or interactions article to
  disseminate the findings. We aim to gather the DIS community knowledge to
  explore, understand and shape the relations this new interaction paradigm is
  forging between humans, their technologies and the environment in safe,
  sustainable, enriching, and responsible ways.
  </p>
  </div>
  </dd>
  <dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18406" title="Abstract">arXiv:2404.18406</a> [<a href="/pdf/2404.18406" title="Download PDF">pdf</a>, <a href="/ps/2404.18406" title="Download PostScript">ps</a>, <a href="/format/2404.18406" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Movable Antenna-Enhanced Wireless Powered Mobile Edge Computing Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+P">Pengcheng Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yuxuan Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lyu%2C+B">Bin Lyu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhen Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jamalipour%2C+A">Abbas Jamalipour</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages, 10 figures. Submitted for possible publication
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
  
  </div>
  <p class="mathjax">In this paper, we propose a movable antenna (MA) enhanced scheme for wireless
  powered mobile edge computing (WP-MEC) system, where the hybrid access point
  (HAP) equipped with multiple MAs first emits wireless energy to charge wireless
  devices (WDs), and then receives the offloaded tasks from the WDs for edge
  computing. The MAs deployed at the HAP enhance the spatial degrees of freedom
  (DoFs) by flexibly adjusting the positions of MAs within an available region,
  thereby improving the efficiency of both downlink wireless energy transfer
  (WPT) and uplink task offloading. To balance the performance enhancement
  against the implementation intricacy, we further propose three types of MA
  positioning configurations, i.e., dynamic MA positioning, semi-dynamic MA
  positioning, and static MA positioning. In addition, the non-linear power
  conversion of energy harvesting (EH) circuits at the WDs and the finite
  computing capability at the edge server are taken into account. Our objective
  is to maximize the sum computational rate (SCR) by jointly optimizing the time
  allocation, positions of MAs, energy beamforming matrix, receive combing
  vectors, and offloading strategies of WDs. To solve the non-convex problems,
  efficient alternating optimization (AO) frameworks are proposed. Moreover, we
  propose a hybrid algorithm of particle swarm optimization with variable local
  search (PSO-VLS) to solve the sub-problem of MA positioning. Numerical results
  validate the superiority of exploiting MAs over the fixed-position antennas
  (FPAs) for enhancing the SCR performance of WP-MEC systems.
  </p>
  </div>
  </dd>
  <dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18407" title="Abstract">arXiv:2404.18407</a> [<a href="/pdf/2404.18407" title="Download PDF">pdf</a>, <a href="/format/2404.18407" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ICMarks: A Robust Watermarking Framework for Integrated Circuit Physical  Design IP Protection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruisi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rajarathnam%2C+R+S">Rachel Selina Rajarathnam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+D+Z">David Z. Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Koushanfar%2C+F">Farinaz Koushanfar</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)
  
  </div>
  <p class="mathjax">Physical design watermarking on contemporary integrated circuit (IC) layout
  encodes signatures without considering the dense connections and design
  constraints, which could lead to performance degradation on the watermarked
  products. This paper presents ICMarks, a quality-preserving and robust
  watermarking framework for modern IC physical design. ICMarks embeds unique
  watermark signatures during the physical design's placement stage, thereby
  authenticating the IC layout ownership. ICMarks's novelty lies in (i)
  strategically identifying a region of cells to watermark with minimal impact on
  the layout performance and (ii) a two-level watermarking framework for
  augmented robustness toward potential removal and forging attacks. Extensive
  evaluations on benchmarks of different design objectives and sizes validate
  that ICMarks incurs no wirelength and timing metrics degradation, while
  successfully proving ownership. Furthermore, we demonstrate ICMarks is robust
  against two major watermarking attack categories, namely, watermark removal and
  forging attacks; even if the adversaries have prior knowledge of the
  watermarking schemes, the signatures cannot be removed without significantly
  undermining the layout quality.
  </p>
  </div>
  </dd>
  <dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18409" title="Abstract">arXiv:2404.18409</a> [<a href="/pdf/2404.18409" title="Download PDF">pdf</a>, <a href="/format/2404.18409" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PKU-AIGIQA-4K: A Perceptual Quality Assessment Database for Both  Text-to-Image and Image-to-Image AI-Generated Images
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+J">Jiquan Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+F">Fanyi Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jihe Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+X">Xinyan Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Che%2C+J">Jinming Che</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J">Jinlong Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+X">Xixin Cao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages. arXiv admin note: substantial text overlap with <a href="/abs/2311.15556">arXiv:2311.15556</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">In recent years, image generation technology has rapidly advanced, resulting
  in the creation of a vast array of AI-generated images (AIGIs). However, the
  quality of these AIGIs is highly inconsistent, with low-quality AIGIs severely
  impairing the visual experience of users. Due to the widespread application of
  AIGIs, the AI-generated image quality assessment (AIGIQA), aimed at evaluating
  the quality of AIGIs from the perspective of human perception, has garnered
  increasing interest among scholars. Nonetheless, current research has not yet
  fully explored this field. We have observed that existing databases are limited
  to images generated from single scenario settings. Databases such as AGIQA-1K,
  AGIQA-3K, and AIGCIQA2023, for example, only include images generated by
  text-to-image generative models. This oversight highlights a critical gap in
  the current research landscape, underscoring the need for dedicated databases
  catering to image-to-image scenarios, as well as more comprehensive databases
  that encompass a broader range of AI-generated image scenarios. Addressing
  these issues, we have established a large scale perceptual quality assessment
  database for both text-to-image and image-to-image AIGIs, named PKU-AIGIQA-4K.
  We then conduct a well-organized subjective experiment to collect quality
  labels for AIGIs and perform a comprehensive analysis of the PKU-AIGIQA-4K
  database. Regarding the use of image prompts during the training process, we
  propose three image quality assessment (IQA) methods based on pre-trained
  models that include a no-reference method NR-AIGCIQA, a full-reference method
  FR-AIGCIQA, and a partial-reference method PR-AIGCIQA. Finally, leveraging the
  PKU-AIGIQA-4K database, we conduct extensive benchmark experiments and compare
  the performance of the proposed methods and the current IQA methods.
  </p>
  </div>
  </dd>
  <dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18410" title="Abstract">arXiv:2404.18410</a> [<a href="/pdf/2404.18410" title="Download PDF">pdf</a>, <a href="/format/2404.18410" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mixture-of-Instructions: Comprehensive Alignment of a Large Language  Model through the Mixture of Diverse System Prompting Instructions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+B">Bowen Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+S">Shaoyu Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+K">Kai Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+L">Lulu Hu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">With the proliferation of large language models (LLMs), the comprehensive
  alignment of such models across multiple tasks has emerged as a critical area
  of research. Existing alignment methodologies primarily address single task,
  such as multi-turn dialogue, coding, mathematical problem-solving, and tool
  usage. However, AI-driven products that leverage language models usually
  necessitate a fusion of these abilities to function effectively in real-world
  scenarios. Moreover, the considerable computational resources required for
  proper alignment of LLMs underscore the need for a more robust, efficient, and
  encompassing approach to multi-task alignment, ensuring improved generative
  performance. In response to these challenges, we introduce a novel technique
  termed Mixture-of-Instructions (MoI), which employs a strategy of instruction
  concatenation combined with diverse system prompts to boost the alignment
  efficiency of language models. We have also compiled a diverse set of seven
  benchmark datasets to rigorously evaluate the alignment efficacy of the
  MoI-enhanced language model. Our methodology was applied to the open-source
  Qwen-7B-chat model, culminating in the development of Qwen-SFT-MoI. This
  enhanced model demonstrates significant advancements in generative capabilities
  across coding, mathematics, and tool use tasks.
  </p>
  </div>
  </dd>
  <dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18411" title="Abstract">arXiv:2404.18411</a> [<a href="/pdf/2404.18411" title="Download PDF">pdf</a>, <a href="/format/2404.18411" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-modal Perception Dataset of In-water Objects for Autonomous  Surface Vehicles
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jeong%2C+M">Mingi Jeong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chadda%2C+A">Arihant Chadda</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+Z">Ziang Ren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+L">Luyang Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Haowen Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Roznere%2C+M">Monika Roznere</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+A">Aiwei Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yitao Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Achong%2C+S">Sabriel Achong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lensgraf%2C+S">Samuel Lensgraf</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+A+Q">Alberto Quattrini Li</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the IEEE ICRA Workshop on Field Robotics 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">This paper introduces the first publicly accessible multi-modal perception
  dataset for autonomous maritime navigation, focusing on in-water obstacles
  within the aquatic environment to enhance situational awareness for Autonomous
  Surface Vehicles (ASVs). This dataset, consisting of diverse objects
  encountered under varying environmental conditions, aims to bridge the research
  gap in marine robotics by providing a multi-modal, annotated, and ego-centric
  perception dataset, for object detection and classification. We also show the
  applicability of the proposed dataset's framework using deep learning-based
  open-source perception algorithms that have shown success. We expect that our
  dataset will contribute to development of the marine autonomy pipeline and
  marine (field) robotics. Please note this is a work-in-progress paper about our
  on-going research that we plan to release in full via future publication.
  </p>
  </div>
  </dd>
  <dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18413" title="Abstract">arXiv:2404.18413</a> [<a href="/pdf/2404.18413" title="Download PDF">pdf</a>, <a href="/format/2404.18413" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> 3AM: An Ambiguity-Aware Multi-Modal Machine Translation Dataset
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+X">Xinyu Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xuebo Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wong%2C+D+F">Derek F. Wong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rao%2C+J">Jun Rao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bei Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+L">Liang Ding</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chao%2C+L+S">Lidia S. Chao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tao%2C+D">Dacheng Tao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Min Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Multimodal machine translation (MMT) is a challenging task that seeks to
  improve translation quality by incorporating visual information. However,
  recent studies have indicated that the visual information provided by existing
  MMT datasets is insufficient, causing models to disregard it and overestimate
  their capabilities. This issue presents a significant obstacle to the
  development of MMT research. This paper presents a novel solution to this issue
  by introducing 3AM, an ambiguity-aware MMT dataset comprising 26,000 parallel
  sentence pairs in English and Chinese, each with corresponding images. Our
  dataset is specifically designed to include more ambiguity and a greater
  variety of both captions and images than other MMT datasets. We utilize a word
  sense disambiguation model to select ambiguous data from vision-and-language
  datasets, resulting in a more challenging dataset. We further benchmark several
  state-of-the-art MMT models on our proposed dataset. Experimental results show
  that MMT models trained on our dataset exhibit a greater ability to exploit
  visual information than those trained on other MMT datasets. Our work provides
  a valuable resource for researchers in the field of multimodal learning and
  encourages further exploration in this area. The data, code and scripts are
  freely available at https://github.com/MaxyLee/3AM.
  </p>
  </div>
  </dd>
  <dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18414" title="Abstract">arXiv:2404.18414</a> [<a href="/pdf/2404.18414" title="Download PDF">pdf</a>, <a href="/format/2404.18414" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning a Sparse Neural Network using IHT
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Damadi%2C+S">Saeed Damadi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zolfaghari%2C+S">Soroush Zolfaghari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rezaie%2C+M">Mahdi Rezaie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shen%2C+J">Jinglai Shen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">The core of a good model is in its ability to focus only on important
  information that reflects the basic patterns and consistencies, thus pulling
  out a clear, noise-free signal from the dataset. This necessitates using a
  simplified model defined by fewer parameters. The importance of theoretical
  foundations becomes clear in this context, as this paper relies on established
  results from the domain of advanced sparse optimization, particularly those
  addressing nonlinear differentiable functions. The need for such theoretical
  foundations is further highlighted by the trend that as computational power for
  training NNs increases, so does the complexity of the models in terms of a
  higher number of parameters. In practical scenarios, these large models are
  often simplified to more manageable versions with fewer parameters.
  <br>Understanding why these simplified models with less number of parameters
  remain effective raises a crucial question. Understanding why these simplified
  models with fewer parameters remain effective raises an important question.
  This leads to the broader question of whether there is a theoretical framework
  that can clearly explain these empirical observations. Recent developments,
  such as establishing necessary conditions for the convergence of iterative hard
  thresholding (IHT) to a sparse local minimum (a sparse method analogous to
  gradient descent) are promising. The remarkable capacity of the IHT algorithm
  to accurately identify and learn the locations of nonzero parameters
  underscores its practical effectiveness and utility.
  <br>This paper aims to investigate whether the theoretical prerequisites for such
  convergence are applicable in the realm of neural network (NN) training by
  providing justification for all the necessary conditions for convergence. Then,
  these conditions are validated by experiments on a single-layer NN, using the
  IRIS dataset as a testbed.
  </p>
  </div>
  </dd>
  <dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18416" title="Abstract">arXiv:2404.18416</a> [<a href="/pdf/2404.18416" title="Download PDF">pdf</a>, <a href="/format/2404.18416" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Capabilities of Gemini Models in Medicine
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Saab%2C+K">Khaled Saab</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tu%2C+T">Tao Tu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Weng%2C+W">Wei-Hung Weng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tanno%2C+R">Ryutaro Tanno</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stutz%2C+D">David Stutz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wulczyn%2C+E">Ellery Wulczyn</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+F">Fan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Strother%2C+T">Tim Strother</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Park%2C+C">Chunjong Park</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vedadi%2C+E">Elahe Vedadi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chaves%2C+J+Z">Juanma Zambrano Chaves</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+S">Szu-Yeu Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schaekermann%2C+M">Mike Schaekermann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kamath%2C+A">Aishwarya Kamath</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Y">Yong Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Barrett%2C+D+G+T">David G.T. Barrett</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheung%2C+C">Cathy Cheung</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mustafa%2C+B">Basil Mustafa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Palepu%2C+A">Anil Palepu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McDuff%2C+D">Daniel McDuff</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hou%2C+L">Le Hou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Golany%2C+T">Tomer Golany</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+L">Luyang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Alayrac%2C+J">Jean-baptiste Alayrac</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Houlsby%2C+N">Neil Houlsby</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tomasev%2C+N">Nenad Tomasev</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Freyberg%2C+J">Jan Freyberg</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lau%2C+C">Charles Lau</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kemp%2C+J">Jonas Kemp</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lai%2C+J">Jeremy Lai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Azizi%2C+S">Shekoofeh Azizi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kanada%2C+K">Kimberly Kanada</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Man%2C+S">SiWai Man</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kulkarni%2C+K">Kavita Kulkarni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+R">Ruoxi Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shakeri%2C+S">Siamak Shakeri</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+L">Luheng He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Caine%2C+B">Ben Caine</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Webson%2C+A">Albert Webson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Latysheva%2C+N">Natasha Latysheva</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Johnson%2C+M">Melvin Johnson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mansfield%2C+P">Philip Mansfield</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+J">Jian Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rivlin%2C+E">Ehud Rivlin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Anderson%2C+J">Jesper Anderson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Green%2C+B">Bradley Green</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wong%2C+R">Renee Wong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Krause%2C+J">Jonathan Krause</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shlens%2C+J">Jonathon Shlens</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dominowska%2C+E">Ewa Dominowska</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Eslami%2C+S+M+A">S. M. Ali Eslami</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cui%2C+C">Claire Cui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vinyals%2C+O">Oriol Vinyals</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kavukcuoglu%2C+K">Koray Kavukcuoglu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Manyika%2C+J">James Manyika</a>,  et al. (11 additional authors not shown)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Excellence in a wide variety of medical applications poses considerable
  challenges for AI, requiring advanced reasoning, access to up-to-date medical
  knowledge and understanding of complex multimodal data. Gemini models, with
  strong general capabilities in multimodal and long-context reasoning, offer
  exciting possibilities in medicine. Building on these core strengths of Gemini,
  we introduce Med-Gemini, a family of highly capable multimodal models that are
  specialized in medicine with the ability to seamlessly use web search, and that
  can be efficiently tailored to novel modalities using custom encoders. We
  evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art
  (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every
  benchmark where a direct comparison is viable, often by a wide margin. On the
  popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves
  SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search
  strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU
  (health &amp; medicine), Med-Gemini improves over GPT-4V by an average relative
  margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context
  capabilities through SoTA performance on a needle-in-a-haystack retrieval task
  from long de-identified health records and medical video question answering,
  surpassing prior bespoke methods using only in-context learning. Finally,
  Med-Gemini's performance suggests real-world utility by surpassing human
  experts on tasks such as medical text summarization, alongside demonstrations
  of promising potential for multimodal medical dialogue, medical research and
  education. Taken together, our results offer compelling evidence for
  Med-Gemini's potential, although further rigorous evaluation will be crucial
  before real-world deployment in this safety-critical domain.
  </p>
  </div>
  </dd>
  <dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18417" title="Abstract">arXiv:2404.18417</a> [<a href="/pdf/2404.18417" title="Download PDF">pdf</a>, <a href="/format/2404.18417" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Domain Reasoning in TopKAT
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Cheng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=de+Amorim%2C+A+A">Arthur Azevedo de Amorim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gaboardi%2C+M">Marco Gaboardi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> A version of this article is accepted at ICALP 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)
  
  </div>
  <p class="mathjax">TopKAT is the algebraic theory of Kleene algebra with tests (KAT) extended
  with a top element. Compared to KAT, one pleasant feature of TopKAT is that, in
  relational models, the top element allows us to express the domain and codomain
  of a relation. This enables several applications in program logics, such as
  proving under-approximate specifications or reachability properties of
  imperative programs. However, while TopKAT inherits many pleasant features of
  KATs, such as having a decidable equational theory, it is incomplete with
  respect to relational models. In other words, there are properties that hold
  true of all relational TopKATs but cannot be proved with the axioms of TopKAT.
  This issue is potentially worrisome for program-logic applications, in which
  relational models play a key role.
  <br>In this paper, we further investigate the completeness properties of TopKAT
  with respect to relational models. We show that TopKAT is complete with respect
  to (co)domain comparison of KAT terms, but incomplete when comparing the
  (co)domain of arbitrary TopKAT terms. Since the encoding of under-approximate
  specifications in TopKAT hinges on this type of formula, the aforementioned
  incompleteness results have a limited impact when using TopKAT to reason about
  such specifications.
  </p>
  </div>
  </dd>
  <dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18418" title="Abstract">arXiv:2404.18418</a> [<a href="/pdf/2404.18418" title="Download PDF">pdf</a>, <a href="/format/2404.18418" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Decomposition Model Assisted Energy-Saving Design in Radio Access  Network
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xiaoxue Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yijun Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yexing Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Dong Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+C">Chungang Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)
  
  </div>
  <p class="mathjax">The continuous emergence of novel services and massive connections involve
  huge energy consumption towards ultra-dense radio access networks. Moreover,
  there exist much more number of controllable parameters that can be adjusted to
  reduce the energy consumption from a network-wide perspective. However, a
  network-level energy-saving intent usually contains multiple network objectives
  and constraints. Therefore, it is critical to decompose a network-level
  energy-saving intent into multiple levels of configurated operations from a
  top-down refinement perspective. In this work, we utilize a softgoal
  interdependency graph decomposition model to assist energy-saving scheme
  design. Meanwhile, we propose an energy-saving approach based on deep
  Q-network, which achieve a better trade-off among the energy consumption, the
  throughput, and the first packet delay. In addition, we illustrate how the
  decomposition model can assist in making energy-saving decisions. Evaluation
  results demonstrate the performance gain of the proposed scheme in accelerating
  the model training process.
  </p>
  </div>
  </dd>
  <dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18419" title="Abstract">arXiv:2404.18419</a> [<a href="/pdf/2404.18419" title="Download PDF">pdf</a>, <a href="/ps/2404.18419" title="Download PostScript">ps</a>, <a href="/format/2404.18419" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Research on Intelligent Aided Diagnosis System of Medical Image Based on  Computer Deep Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+J">Jiajie Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+L">Linxiao Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gong%2C+Y">Yulu Gong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhou Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+S">Shuyao He</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">This paper combines Struts and Hibernate two architectures together, using
  DAO (Data Access Object) to store and access data. Then a set of dual-mode
  humidity medical image library suitable for deep network is established, and a
  dual-mode medical image assisted diagnosis method based on the image is
  proposed. Through the test of various feature extraction methods, the optimal
  operating characteristic under curve product (AUROC) is 0.9985, the recall rate
  is 0.9814, and the accuracy is 0.9833. This method can be applied to clinical
  diagnosis, and it is a practical method. Any outpatient doctor can register
  quickly through the system, or log in to the platform to upload the image to
  obtain more accurate images. Through the system, each outpatient physician can
  quickly register or log in to the platform for image uploading, thus obtaining
  more accurate images. The segmentation of images can guide doctors in clinical
  departments. Then the image is analyzed to determine the location and nature of
  the tumor, so as to make targeted treatment.
  </p>
  </div>
  </dd>
  <dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18423" title="Abstract">arXiv:2404.18423</a> [<a href="/pdf/2404.18423" title="Download PDF">pdf</a>, <a href="/format/2404.18423" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Unsupervised Dynamics Prediction with Object-Centric Kinematics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+Y">Yeon-Ji Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Choi%2C+S">Suhyung Choi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">Jaein Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">Jin-Hwa Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+B">Byoung-Tak Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages, 6 figures, 4 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Human perception involves discerning complex multi-object scenes into
  time-static object appearance (\ie, size, shape, color) and time-varying object
  motion (\ie, location, velocity, acceleration). This innate ability to
  unconsciously understand the environment is the motivation behind the success
  of dynamics modeling. Object-centric representations have emerged as a
  promising tool for dynamics prediction, yet they primarily focus on the
  objects' appearance, often overlooking other crucial attributes. In this paper,
  we propose Object-Centric Kinematics (OCK), a framework for dynamics prediction
  leveraging object-centric representations. Our model utilizes a novel component
  named object kinematics, which comprises low-level structured states of
  objects' position, velocity, and acceleration. The object kinematics are
  obtained via either implicit or explicit approaches, enabling comprehensive
  spatiotemporal object reasoning, and integrated through various transformer
  mechanisms, facilitating effective object-centric dynamics modeling. Our model
  demonstrates superior performance when handling objects and backgrounds in
  complex scenes characterized by a wide range of object attributes and dynamic
  movements. Moreover, our model demonstrates generalization capabilities across
  diverse synthetic environments, highlighting its potential for broad
  applicability in vision-related tasks.
  </p>
  </div>
  </dd>
  <dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18424" title="Abstract">arXiv:2404.18424</a> [<a href="/pdf/2404.18424" title="Download PDF">pdf</a>, <a href="/format/2404.18424" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PromptReps: Prompting Large Language Models to Generate Dense and Sparse  Representations for Zero-Shot Document Retrieval
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+S">Shengyao Zhuang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+X">Xueguang Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Koopman%2C+B">Bevan Koopman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J">Jimmy Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zuccon%2C+G">Guido Zuccon</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">The current use of large language models (LLMs) for zero-shot document
  ranking follows one of two ways: 1) prompt-based re-ranking methods, which
  require no further training but are feasible for only re-ranking a handful of
  candidate documents due to the associated computational costs; and 2)
  unsupervised contrastive trained dense retrieval methods, which can retrieve
  relevant documents from the entire corpus but require a large amount of paired
  text data for contrastive training. In this paper, we propose PromptReps, which
  combines the advantages of both categories: no need for training and the
  ability to retrieve from the whole corpus. Our method only requires prompts to
  guide an LLM to generate query and document representations for effective
  document retrieval. Specifically, we prompt the LLMs to represent a given text
  using a single word, and then use the last token's hidden states and the
  corresponding logits associated to the prediction of the next token to
  construct a hybrid document retrieval system. The retrieval system harnesses
  both dense text embedding and sparse bag-of-words representations given by the
  LLM. Our experimental evaluation on the BEIR zero-shot document retrieval
  datasets illustrates that this simple prompt-based LLM retrieval method can
  achieve a similar or higher retrieval effectiveness than state-of-the-art LLM
  embedding methods that are trained with large amounts of unsupervised data,
  especially when using a larger LLM.
  </p>
  </div>
  </dd>
  <dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18426" title="Abstract">arXiv:2404.18426</a> [<a href="/pdf/2404.18426" title="Download PDF">pdf</a>, <a href="/format/2404.18426" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Efficient Meta-Learning Enabled Lightweight Multiscale Few-Shot Object  Detection in Remote Sensing Images
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Guan%2C+W">Wenbin Guan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zijiu Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiaohong Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Liqiong Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+F">Feng Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+X">Xiaohai He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Honggang Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Presently, the task of few-shot object detection (FSOD) in remote sensing
  images (RSIs) has become a focal point of attention. Numerous few-shot
  detectors, particularly those based on two-stage detectors, face challenges
  when dealing with the multiscale complexities inherent in RSIs. Moreover, these
  detectors present impractical characteristics in real-world applications,
  mainly due to their unwieldy model parameters when handling large amount of
  data. In contrast, we recognize the advantages of one-stage detectors,
  including high detection speed and a global receptive field. Consequently, we
  choose the YOLOv7 one-stage detector as a baseline and subject it to a novel
  meta-learning training framework. This transformation allows the detector to
  adeptly address FSOD tasks while capitalizing on its inherent advantage of
  lightweight. Additionally, we thoroughly investigate the samples generated by
  the meta-learning strategy and introduce a novel meta-sampling approach to
  retain samples produced by our designed meta-detection head. Coupled with our
  devised meta-cross loss, we deliberately utilize ``negative samples" that are
  often overlooked to extract valuable knowledge from them. This approach serves
  to enhance detection accuracy and efficiently refine the overall meta-learning
  strategy. To validate the effectiveness of our proposed detector, we conducted
  performance comparisons with current state-of-the-art detectors using the DIOR
  and NWPU VHR-10.v2 datasets, yielding satisfactory results.
  </p>
  </div>
  </dd>
  <dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18428" title="Abstract">arXiv:2404.18428</a> [<a href="/pdf/2404.18428" title="Download PDF">pdf</a>, <a href="/format/2404.18428" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Geospatial Big Data: Survey and Challenges
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+J">Jiayang Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gan%2C+W">Wensheng Gan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chao%2C+H">Han-Chieh Chao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+P+S">Philip S. Yu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> IEEE JSTARS. 14 pages, 5 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>
  
  </div>
  <p class="mathjax">In recent years, geospatial big data (GBD) has obtained attention across
  various disciplines, categorized into big earth observation data and big human
  behavior data. Identifying geospatial patterns from GBD has been a vital
  research focus in the fields of urban management and environmental
  sustainability. This paper reviews the evolution of GBD mining and its
  integration with advanced artificial intelligence (AI) techniques. GBD consists
  of data generated by satellites, sensors, mobile devices, and geographical
  information systems, and we categorize geospatial data based on different
  perspectives. We outline the process of GBD mining and demonstrate how it can
  be incorporated into a unified framework. Additionally, we explore new
  technologies like large language models (LLM), the Metaverse, and knowledge
  graphs, and how they could make GBD even more useful. We also share examples of
  GBD helping with city management and protecting the environment. Finally, we
  discuss the real challenges that come up when working with GBD, such as issues
  with data retrieval and security. Our goal is to give readers a clear view of
  where GBD mining stands today and where it might go next.
  </p>
  </div>
  </dd>
  <dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18433" title="Abstract">arXiv:2404.18433</a> [<a href="/pdf/2404.18433" title="Download PDF">pdf</a>, <a href="/format/2404.18433" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ShadowMaskFormer: Mask Augmented Patch Embeddings for Shadow Removal
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuohao Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+G">Guoyang Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+G">Guannan Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhichao Lu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Transformer recently emerged as the de facto model for computer vision tasks
  and has also been successfully applied to shadow removal. However, these
  existing methods heavily rely on intricate modifications to the attention
  mechanisms within the transformer blocks while using a generic patch embedding.
  As a result, it often leads to complex architectural designs requiring
  additional computation resources. In this work, we aim to explore the efficacy
  of incorporating shadow information within the early processing stage.
  Accordingly, we propose a transformer-based framework with a novel patch
  embedding that is tailored for shadow removal, dubbed ShadowMaskFormer.
  Specifically, we present a simple and effective mask-augmented patch embedding
  to integrate shadow information and promote the model's emphasis on acquiring
  knowledge for shadow regions. Extensive experiments conducted on the ISTD,
  ISTD+, and SRD benchmark datasets demonstrate the efficacy of our method
  against state-of-the-art approaches while using fewer model parameters.
  </p>
  </div>
  </dd>
  <dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18434" title="Abstract">arXiv:2404.18434</a> [<a href="/pdf/2404.18434" title="Download PDF">pdf</a>, <a href="/ps/2404.18434" title="Download PostScript">ps</a>, <a href="/format/2404.18434" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The augmented codes of a family of linear codes with locality 2
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Heng%2C+Z">Ziling Heng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+K">Keqing Cao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 25 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">In this paper, we first generalize the class of linear codes by Ding and Ding
  (IEEE TIT, 61(11), pp. 5835-5842, 2015). Then we mainly study the augmented
  codes of this generalized class of linear codes. For one thing, we use Gaussian
  sums to determine the parameters and weight distributions of the augmented
  codes in some cases. It is shown that the augmented codes are self-orthogonal
  and have only a few nonzero weights. For another thing, the locality of the
  augmented codes is proved to be 2, which indicates the augmented codes are
  useful in distributed storage. Besides, the augmented codes are projective as
  the minimum distance of their duals is proved to be 3. In particular, we obtain
  several (almost) optimal linear codes and locally recoverable codes.
  </p>
  </div>
  </dd>
  <dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18436" title="Abstract">arXiv:2404.18436</a> [<a href="/pdf/2404.18436" title="Download PDF">pdf</a>, <a href="/format/2404.18436" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Three-Dimension Collision-Free Trajectory Planning of UAVs Based on  ADS-B Information in Low-Altitude Urban Airspace
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Dong%2C+C">Chao Dong</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+Y">Yifan Zhang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Jia%2C+Z">Ziye Jia</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Liao%2C+Y">Yiyang Liao</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+L">Lei Zhang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wu%2C+Q">Qihui Wu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  <p class="mathjax">The environment of low-altitude urban airspace is complex and variable due to
  numerous obstacles, non-cooperative aircrafts, and birds. Unmanned aerial
  vehicles (UAVs) leveraging environmental information to achieve three-dimension
  collision-free trajectory planning is the prerequisite to ensure airspace
  security. However, the timely information of surrounding situation is difficult
  to acquire by UAVs, which further brings security risks. As a mature technology
  leveraged in traditional civil aviation, the automatic dependent
  surveillance-broadcast (ADS-B) realizes continuous surveillance of the
  information of aircrafts. Consequently, we leverage ADS-B for surveillance and
  information broadcasting, and divide the aerial airspace into multiple
  sub-airspaces to improve flight safety in UAV trajectory planning. In detail,
  we propose the secure sub-airspaces planning (SSP) algorithm and particle swarm
  optimization rapidly-exploring random trees (PSO-RRT) algorithm for the UAV
  trajectory planning in law-altitude airspace. The performance of the proposed
  algorithm is verified by simulations and the results show that SSP reduces both
  the maximum number of UAVs in the sub-airspace and the length of the
  trajectory, and PSO-RRT reduces the cost of UAV trajectory in the sub-airspace.
  </p>
  </div>
  </dd>
  <dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18437" title="Abstract">arXiv:2404.18437</a> [<a href="/pdf/2404.18437" title="Download PDF">pdf</a>, <a href="/ps/2404.18437" title="Download PostScript">ps</a>, <a href="/format/2404.18437" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A family of self-orthogonal divisible codes with locality 2
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Heng%2C+Z">Ziling Heng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+M">Mengjie Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ming%2C+Y">Yang Ming</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 25 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">Linear codes are widely studied due to their applications in communication,
  cryptography, quantum codes, distributed storage and many other fields. In this
  paper, we use the trace and norm functions over finite fields to construct a
  family of linear codes. The weight distributions of the codes are determined in
  three cases via Gaussian sums. The codes are shown to be self-orthogonal
  divisible codes with only three, four or five nonzero weights in these cases.
  In particular, we prove that this family of linear codes has locality 2.
  Several optimal or almost optimal linear codes and locally recoverable codes
  are derived. In particular, an infinite family of distance-optimal binary
  linear codes with respect to the sphere-packing bound is obtained. The
  self-orthogonal codes derived in this paper can be used to construct lattices
  and have nice application in distributed storage.
  </p>
  </div>
  </dd>
  <dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18438" title="Abstract">arXiv:2404.18438</a> [<a href="/pdf/2404.18438" title="Download PDF">pdf</a>, <a href="/ps/2404.18438" title="Download PostScript">ps</a>, <a href="/format/2404.18438" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Two classes of constacyclic codes with a square-root-like lower bound
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Tingfang Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhonghua Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+C">Conghui Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+C">Cunsheng Ding</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">Constacyclic codes over finite fields are an important class of linear codes
  as they contain distance-optimal codes and linear codes with best known
  parameters. They are interesting in theory and practice, as they have the
  constacyclic structure. In this paper, an infinite class of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-181-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1211" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1212"><span class="mi" id="MathJax-Span-1213" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-181">q</script>-ary negacyclic
  codes of length <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-182-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1214" style="width: 5.141em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.181em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1004.181em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1215"><span class="mo" id="MathJax-Span-1216" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1217"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.511em, 4.407em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1218" style="font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="mi" id="MathJax-Span-1219" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">m</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1220" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">−</span><span class="mn" id="MathJax-Span-1221" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">1</span><span class="mo" id="MathJax-Span-1222" style="font-family: STIXGeneral-Regular;">)</span><span class="texatom" id="MathJax-Span-1223"><span class="mrow" id="MathJax-Span-1224"><span class="mo" id="MathJax-Span-1225" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mn" id="MathJax-Span-1226" style="font-family: STIXGeneral-Regular;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-182">(q^m-1)/2</script> and an infinite class of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-183-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1227" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1228"><span class="mi" id="MathJax-Span-1229" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-183">q</script>-ary constacyclic codes
  of length <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-184-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1230" style="width: 8.02em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.496em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1006.439em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1231"><span class="mo" id="MathJax-Span-1232" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1233"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.511em, 4.407em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1234" style="font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="mi" id="MathJax-Span-1235" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">m</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1236" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">−</span><span class="mn" id="MathJax-Span-1237" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">1</span><span class="mo" id="MathJax-Span-1238" style="font-family: STIXGeneral-Regular;">)</span><span class="texatom" id="MathJax-Span-1239"><span class="mrow" id="MathJax-Span-1240"><span class="mo" id="MathJax-Span-1241" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mo" id="MathJax-Span-1242" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1243" style="font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-1244" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">−</span><span class="mn" id="MathJax-Span-1245" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">1</span><span class="mo" id="MathJax-Span-1246" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-184">(q^m-1)/(q-1)</script> are constructed and analyzed. As a by-product, two
  infinite classes of ternary negacyclic self-dual codes with a square-root-like
  lower bound on their minimum distances are presented.
  </p>
  </div>
  </dd>
  <dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18439" title="Abstract">arXiv:2404.18439</a> [<a href="/pdf/2404.18439" title="Download PDF">pdf</a>, <a href="/format/2404.18439" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-185-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1247" style="width: 0.629em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.495em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.929em, 1000.495em, 2.646em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-1248"><span class="texatom" id="MathJax-Span-1249"><span class="mrow" id="MathJax-Span-1250"><span class="mo" id="MathJax-Span-1251" style="font-family: STIXGeneral-Regular;">ν</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.725em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-185">ν</script>-DBA: Neural Implicit Dense Bundle Adjustment Enables Image-Only  Driving Scene Reconstruction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mao%2C+Y">Yunxuan Mao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shen%2C+B">Bingqi Shen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yifei Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+K">Kai Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+R">Rong Xiong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liao%2C+Y">Yiyi Liao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yue Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
  
  </div>
  <p class="mathjax">The joint optimization of the sensor trajectory and 3D map is a crucial
  characteristic of bundle adjustment (BA), essential for autonomous driving.
  This paper presents <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-186-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1252" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1253"><span class="mi" id="MathJax-Span-1254" style="font-family: STIXGeneral-Italic;">ν</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-186">\nu</script>-DBA, a novel framework implementing geometric dense
  bundle adjustment (DBA) using 3D neural implicit surfaces for map
  parametrization, which optimizes both the map surface and trajectory poses
  using geometric error guided by dense optical flow prediction. Additionally, we
  fine-tune the optical flow model with per-scene self-supervision to further
  improve the quality of the dense mapping. Our experimental results on multiple
  driving scene datasets demonstrate that our method achieves superior trajectory
  optimization and dense reconstruction accuracy. We also investigate the
  influences of photometric error and different neural geometric priors on the
  performance of surface reconstruction and novel view synthesis. Our method
  stands as a significant step towards leveraging neural implicit representations
  in dense bundle adjustment for more accurate trajectories and detailed
  environmental mapping.
  </p>
  </div>
  </dd>
  <dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18443" title="Abstract">arXiv:2404.18443</a> [<a href="/pdf/2404.18443" title="Download PDF">pdf</a>, <a href="/format/2404.18443" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> BMRetriever: Tuning Large Language Models as Better Biomedical Text  Retrievers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+R">Ran Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+W">Wenqi Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yue Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+Y">Yuchen Zhuang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yanqiao Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M+D">May D. Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ho%2C+J+C">Joyce C. Ho</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+C">Carl Yang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Work in progress. The model and data will be uploaded to \url{<a href="https://github.com/ritaranx/BMRetriever">this https URL</a>}
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Quantitative Methods (q-bio.QM)
  
  </div>
  <p class="mathjax">Developing effective biomedical retrieval models is important for excelling
  at knowledge-intensive biomedical tasks but still challenging due to the
  deficiency of sufficient publicly annotated biomedical data and computational
  resources. We present BMRetriever, a series of dense retrievers for enhancing
  biomedical retrieval via unsupervised pre-training on large biomedical corpora,
  followed by instruction fine-tuning on a combination of labeled datasets and
  synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify
  BMRetriever's efficacy on various biomedical applications. BMRetriever also
  exhibits strong parameter efficiency, with the 410M variant outperforming
  baselines up to 11.7 times larger, and the 2B variant matching the performance
  of models with over 5B parameters. The training data and model checkpoints are
  released at \url{https://huggingface.co/BMRetriever} to ensure transparency,
  reproducibility, and application to new domains.
  </p>
  </div>
  </dd>
  <dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18444" title="Abstract">arXiv:2404.18444</a> [<a href="/pdf/2404.18444" title="Download PDF">pdf</a>, <a href="/format/2404.18444" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> U-Nets as Belief Propagation: Efficient Classification, Denoising, and  Diffusion in Generative Hierarchical Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mei%2C+S">Song Mei</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 35 pages, 2 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Statistics Theory (math.ST); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">U-Nets are among the most widely used architectures in computer vision,
  renowned for their exceptional performance in applications such as image
  segmentation, denoising, and diffusion modeling. However, a theoretical
  explanation of the U-Net architecture design has not yet been fully
  established.
  <br>This paper introduces a novel interpretation of the U-Net architecture by
  studying certain generative hierarchical models, which are tree-structured
  graphical models extensively utilized in both language and image domains. With
  their encoder-decoder structure, long skip connections, and pooling and
  up-sampling layers, we demonstrate how U-Nets can naturally implement the
  belief propagation denoising algorithm in such generative hierarchical models,
  thereby efficiently approximating the denoising functions. This leads to an
  efficient sample complexity bound for learning the denoising function using
  U-Nets within these models. Additionally, we discuss the broader implications
  of these findings for diffusion models in generative hierarchical models. We
  also demonstrate that the conventional architecture of convolutional neural
  networks (ConvNets) is ideally suited for classification tasks within these
  models. This offers a unified view of the roles of ConvNets and U-Nets,
  highlighting the versatility of generative hierarchical models in modeling
  complex data distributions across language and image domains.
  </p>
  </div>
  </dd>
  <dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18447" title="Abstract">arXiv:2404.18447</a> [<a href="/pdf/2404.18447" title="Download PDF">pdf</a>, <a href="/format/2404.18447" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The PRODSAT phase of random quantum satisfiability
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Joon Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Macris%2C+N">Nicolas Macris</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ravelomanana%2C+J+B">Jean Bernoulli Ravelomanana</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vantalon%2C+P">Perrine Vantalon</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Data Structures and Algorithms (cs.DS); Quantum Physics (quant-ph)
  
  </div>
  <p class="mathjax">The <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-187-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1255" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1256"><span class="mi" id="MathJax-Span-1257" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-187">k</script>-QSAT problem is a quantum analog of the famous <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-188-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1258" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1259"><span class="mi" id="MathJax-Span-1260" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-188">k</script>-SAT constraint
  satisfaction problem. We must determine the zero energy ground states of a
  Hamiltonian of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-189-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1261" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1262"><span class="mi" id="MathJax-Span-1263" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-189">N</script> qubits consisting of a sum of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-190-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1264" style="width: 1.132em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.906em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1265"><span class="mi" id="MathJax-Span-1266" style="font-family: STIXGeneral-Italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-190">M</script> random <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-191-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1267" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1268"><span class="mi" id="MathJax-Span-1269" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-191">k</script>-local rank-one
  projectors. It is known that product states of zero energy exist with high
  probability if and only if the underlying factor graph has a clause-covering
  dimer configuration. This means that the threshold of the PRODSAT phase is a
  purely geometric quantity equal to the dimer covering threshold. We revisit and
  fully prove this result through a combination of complex analysis and algebraic
  methods based on Buchberger's algorithm for complex polynomial equations with
  random coefficients. We also discuss numerical experiments investigating the
  presence of entanglement in the PRODSAT phase in the sense that product states
  do not span the whole zero energy ground state space.
  </p>
  </div>
  </dd>
  <dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18448" title="Abstract">arXiv:2404.18448</a> [<a href="/pdf/2404.18448" title="Download PDF">pdf</a>, <a href="/format/2404.18448" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MFP: Making Full Use of Probability Maps for Interactive Image  Segmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+C">Chaewon Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+S">Seon-Ho Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+C">Chang-Su Kim</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to CVPR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">In recent interactive segmentation algorithms, previous probability maps are
  used as network input to help predictions in the current segmentation round.
  However, despite the utilization of previous masks, useful information
  contained in the probability maps is not well propagated to the current
  predictions. In this paper, to overcome this limitation, we propose a novel and
  effective algorithm for click-based interactive image segmentation, called MFP,
  which attempts to make full use of probability maps. We first modulate previous
  probability maps to enhance their representations of user-specified objects.
  Then, we feed the modulated probability maps as additional input to the
  segmentation network. We implement the proposed MFP algorithm based on the
  ResNet-34, HRNet-18, and ViT-B backbones and assess the performance extensively
  on various datasets. It is demonstrated that MFP meaningfully outperforms the
  existing algorithms using identical backbones. The source codes are available
  at \href{https://github.com/cwlee00/MFP}{https://github.com/cwlee00/MFP}.
  </p>
  </div>
  </dd>
  <dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18453" title="Abstract">arXiv:2404.18453</a> [<a href="/pdf/2404.18453" title="Download PDF">pdf</a>, <a href="/format/2404.18453" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Fostering Trust in Smart Inverters: A Framework for Firmware Update  Management and Tracking in VPP Context
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dayaratne%2C+T">Thusitha Dayaratne</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rudolph%2C+C">Carsten Rudolph</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shirley%2C+T">Tom Shirley</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Levi%2C+S">Sol Levi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shirley%2C+D">David Shirley</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)
  
  </div>
  <p class="mathjax">Ensuring the reliability and security of smart inverters that provide the
  interface between distributed energy resources (DERs) and the power grid
  becomes paramount with the surge in integrating DERs into the (smart) power
  grid. Despite the importance of having updated firmware / software versions
  within a reasonable time frame, existing methods for establishing trust through
  firmware updates lack effective historical tracking and verification. This
  paper introduces a novel framework to manage and track firmware update history,
  leveraging verifiable credentials. By tracking the update history and
  implementing a trust cycle based on these verifiable updates, we aim to improve
  grid resilience, enhance cybersecurity, and increase transparency for
  stakeholders.
  </p>
  </div>
  </dd>
  <dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18454" title="Abstract">arXiv:2404.18454</a> [<a href="/pdf/2404.18454" title="Download PDF">pdf</a>, <a href="/format/2404.18454" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> 3D Gaussian Splatting with Deferred Reflection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+K">Keyang Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hou%2C+Q">Qiming Hou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+K">Kun Zhou</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
  
  </div>
  <p class="mathjax">The advent of neural and Gaussian-based radiance field methods have achieved
  great success in the field of novel view synthesis. However, specular
  reflection remains non-trivial, as the high frequency radiance field is
  notoriously difficult to fit stably and accurately. We present a deferred
  shading method to effectively render specular reflection with Gaussian
  splatting. The key challenge comes from the environment map reflection model,
  which requires accurate surface normal while simultaneously bottlenecks normal
  estimation with discontinuous gradients. We leverage the per-pixel reflection
  gradients generated by deferred shading to bridge the optimization process of
  neighboring Gaussians, allowing nearly correct normal estimations to gradually
  propagate and eventually spread over all reflective objects. Our method
  significantly outperforms state-of-the-art techniques and concurrent work in
  synthesizing high-quality specular reflection effects, demonstrating a
  consistent improvement of peak signal-to-noise ratio (PSNR) for both synthetic
  and real-world scenes, while running at a frame rate almost identical to
  vanilla Gaussian splatting.
  </p>
  </div>
  </dd>
  <dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18459" title="Abstract">arXiv:2404.18459</a> [<a href="/pdf/2404.18459" title="Download PDF">pdf</a>, <a href="/format/2404.18459" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Chameleon: A Data-Efficient Generalist for Dense Visual Prediction in  the Wild
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D">Donggyun Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cho%2C+S">Seongwoong Cho</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+S">Semin Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+C">Chong Luo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hong%2C+S">Seunghoon Hong</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Large language models have evolved data-efficient generalists, benefiting
  from the universal language interface and large-scale pre-training. However,
  constructing a data-efficient generalist for dense visual prediction presents a
  distinct challenge due to the variation in label structures across different
  tasks. Consequently, generalization to unseen dense prediction tasks in the
  low-data regime is not straightforward and has received less attention from
  previous vision generalists. In this study, we explore a universal model that
  can flexibly adapt to unseen dense label structures with a few examples,
  enabling it to serve as a data-efficient vision generalist in diverse
  real-world scenarios. To this end, we base our method on a powerful
  meta-learning framework and explore several axes to improve its performance and
  versatility for real-world problems, such as flexible adaptation mechanisms and
  scalability. We evaluate our model across a spectrum of unseen real-world
  scenarios where low-shot learning is desirable, including video, 3D, medical,
  biological, and user-interactive tasks. Equipped with a generic architecture
  and an effective adaptation mechanism, our model flexibly adapts to all of
  these tasks with at most 50 labeled images, showcasing a significant
  advancement over existing data-efficient generalist approaches. Codes are
  available at https://github.com/GitGyun/chameleon.
  </p>
  </div>
  </dd>
  <dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18460" title="Abstract">arXiv:2404.18460</a> [<a href="/pdf/2404.18460" title="Download PDF">pdf</a>, <a href="/format/2404.18460" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Ethical Reasoning and Moral Value Alignment of LLMs Depend on the  Language we Prompt them in
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+U">Utkarsh Agarwal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tanmay%2C+K">Kumar Tanmay</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khandelwal%2C+A">Aditi Khandelwal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Choudhury%2C+M">Monojit Choudhury</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Ethical reasoning is a crucial skill for Large Language Models (LLMs).
  However, moral values are not universal, but rather influenced by language and
  culture. This paper explores how three prominent LLMs -- GPT-4, ChatGPT, and
  Llama2-70B-Chat -- perform ethical reasoning in different languages and if
  their moral judgement depend on the language in which they are prompted. We
  extend the study of ethical reasoning of LLMs by Rao et al. (2023) to a
  multilingual setup following their framework of probing LLMs with ethical
  dilemmas and policies from three branches of normative ethics: deontology,
  virtue, and consequentialism. We experiment with six languages: English,
  Spanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most
  consistent and unbiased ethical reasoner across languages, while ChatGPT and
  Llama2-70B-Chat show significant moral value bias when we move to languages
  other than English. Interestingly, the nature of this bias significantly vary
  across languages for all LLMs, including GPT-4.
  </p>
  </div>
  </dd>
  <dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18461" title="Abstract">arXiv:2404.18461</a> [<a href="/pdf/2404.18461" title="Download PDF">pdf</a>, <a href="/format/2404.18461" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Clicks2Line: Using Lines for Interactive Image Segmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+C">Chaewon Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+C">Chang-Su Kim</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">For click-based interactive segmentation methods, reducing the number of
  clicks required to obtain a desired segmentation result is essential. Although
  recent click-based methods yield decent segmentation results, we observe that
  substantial amount of clicks are required to segment elongated regions. To
  reduce the amount of user-effort required, we propose using lines instead of
  clicks for such cases. In this paper, an interactive segmentation algorithm
  which adaptively adopts either clicks or lines as input is proposed.
  Experimental results demonstrate that using lines can generate better
  segmentation results than clicks for several cases.
  </p>
  </div>
  </dd>
  <dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18463" title="Abstract">arXiv:2404.18463</a> [<a href="/pdf/2404.18463" title="Download PDF">pdf</a>, <a href="/format/2404.18463" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Efficient bound preserving and asymptotic preserving semi-implicit  schemes for the fast reaction-diffusion system
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Zhao%2C+Y">Yu Zhao</a>, 
  <a href="/search/math?searchtype=author&amp;query=Zhou%2C+Z">Zhennan Zhou</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">We consider a special type of fast reaction-diffusion systems in which the
  coefficients of the reaction terms of the two substances are much larger than
  those of the diffusion terms while the diffusive motion to the substrate is
  negligible. Specifically speaking, the rate constants of the reaction terms are
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-192-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1270" style="width: 3.277em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.656em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.6em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1271"><span class="mi" id="MathJax-Span-1272" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1273" style="font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-1274" style="font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-1275"><span class="mrow" id="MathJax-Span-1276"><span class="mo" id="MathJax-Span-1277" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mi" id="MathJax-Span-1278" style="font-family: STIXGeneral-Italic;">ϵ</span><span class="mo" id="MathJax-Span-1279" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-192">O(1/\epsilon)</script> while the diffusion coefficients are <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-193-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1280" style="width: 2.374em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.922em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.866em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1281"><span class="mi" id="MathJax-Span-1282" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1283" style="font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-1284" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1285" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-193">O(1)</script> where the parameter
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-194-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1286" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1287"><span class="mi" id="MathJax-Span-1288" style="font-family: STIXGeneral-Italic;">ϵ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-194">\epsilon</script> is small. When the rate constants of the reaction terms become
  highly large, i.e. <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-195-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1289" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1290"><span class="mi" id="MathJax-Span-1291" style="font-family: STIXGeneral-Italic;">ϵ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-195">\epsilon</script> tends to 0, the singular limit behavior of such a
  fast reaction-diffusion system is inscribed by the Stefan problem with latent
  heat, which brings great challenges in numerical simulations. In this paper, we
  adopt a semi-implicit scheme, which is first-order accurate in time and can
  accurately approximate the interface propagation even when the reaction becomes
  extremely fast, that is to say, the parameter <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-196-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1292" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1293"><span class="mi" id="MathJax-Span-1294" style="font-family: STIXGeneral-Italic;">ϵ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-196">\epsilon</script> is sufficiently small.
  The scheme satisfies the positivity, bound preserving properties and has <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-197-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1295" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.076em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1296"><span class="msubsup" id="MathJax-Span-1297"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1298" style="font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.624em;"><span class="mn" id="MathJax-Span-1299" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-197">L^2</script>
  stability and the linearized stability results of the system. For better
  performance on numerical simulations, we then construct a semi-implicit
  Runge-Kutta scheme which is second-order accurate in time. Numerous numerical
  tests are carried out to demonstrate the properties, such as the order of
  accuracy, positivity and bound preserving, the capturing of the sharp interface
  with various <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-198-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1300" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1301"><span class="mi" id="MathJax-Span-1302" style="font-family: STIXGeneral-Italic;">ϵ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-198">\epsilon</script> and to simulate the dynamics of the substances and the
  substrate, and to explore the heat transfer process, such as solid melting or
  liquid solidification in two dimensions.
  </p>
  </div>
  </dd>
  <dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18464" title="Abstract">arXiv:2404.18464</a> [<a href="/pdf/2404.18464" title="Download PDF">pdf</a>, <a href="/format/2404.18464" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MRIC: Model-Based Reinforcement-Imitation Learning with  Mixture-of-Codebooks for Autonomous Driving Simulation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+B">Baotian He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yibing Li</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Accurately simulating diverse behaviors of heterogeneous agents in various
  scenarios is fundamental to autonomous driving simulation. This task is
  challenging due to the multi-modality of behavior distribution, the
  high-dimensionality of driving scenarios, distribution shift, and incomplete
  information. Our first insight is to leverage state-matching through
  differentiable simulation to provide meaningful learning signals and achieve
  efficient credit assignment for the policy. This is demonstrated by revealing
  the existence of gradient highways and interagent gradient pathways. However,
  the issues of gradient explosion and weak supervision in low-density regions
  are discovered. Our second insight is that these issues can be addressed by
  applying dual policy regularizations to narrow the function space. Further
  considering diversity, our third insight is that the behaviors of heterogeneous
  agents in the dataset can be effectively compressed as a series of prototype
  vectors for retrieval. These lead to our model-based reinforcement-imitation
  learning framework with temporally abstracted mixture-of-codebooks (MRIC). MRIC
  introduces the open-loop modelbased imitation learning regularization to
  stabilize training, and modelbased reinforcement learning (RL) regularization
  to inject domain knowledge. The RL regularization involves differentiable
  Minkowskidifference-based collision avoidance and projection-based on-road and
  traffic rule compliance rewards. A dynamic multiplier mechanism is further
  proposed to eliminate the interference from the regularizations while ensuring
  their effectiveness. Experimental results using the largescale Waymo open
  motion dataset show that MRIC outperforms state-ofthe-art baselines on
  diversity, behavioral realism, and distributional realism, with large margins
  on some key metrics (e.g., collision rate, minSADE, and time-to-collision JSD).
  </p>
  </div>
  </dd>
  <dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18465" title="Abstract">arXiv:2404.18465</a> [<a href="/pdf/2404.18465" title="Download PDF">pdf</a>, <a href="/format/2404.18465" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation  Framework
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zijian Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shuchang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Jiaao Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cai%2C+Q">Qingpeng Cai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xiangyu Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chunxu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziru Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qidong Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hongwei Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+L">Lantao Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+P">Peng Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gai%2C+K">Kun Gai</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Multi-domain recommendation and multi-task recommendation have demonstrated
  their effectiveness in leveraging common information from different domains and
  objectives for comprehensive user modeling. Nonetheless, the practical
  recommendation usually faces multiple domains and tasks simultaneously, which
  cannot be well-addressed by current methods. To this end, we introduce M3oE, an
  adaptive multi-domain multi-task mixture-of-experts recommendation framework.
  M3oE integrates multi-domain information, maps knowledge across domains and
  tasks, and optimizes multiple objectives. We leverage three mixture-of-experts
  modules to learn common, domain-aspect, and task-aspect user preferences
  respectively to address the complex dependencies among multiple domains and
  tasks in a disentangled manner. Additionally, we design a two-level fusion
  mechanism for precise control over feature extraction and fusion across diverse
  domains and tasks. The framework's adaptability is further enhanced by applying
  AutoML technique, which allows dynamic structure optimization. To the best of
  the authors' knowledge, our M3oE is the first effort to solve multi-domain
  multi-task recommendation self-adaptively. Extensive experiments on two
  benchmark datasets against diverse baselines demonstrate M3oE's superior
  performance. The implementation code is available to ensure reproducibility.
  </p>
  </div>
  </dd>
  <dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18466" title="Abstract">arXiv:2404.18466</a> [<a href="/pdf/2404.18466" title="Download PDF">pdf</a>, <a href="/format/2404.18466" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> HFT: Half Fine-Tuning for Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hui%2C+T">Tingfeng Hui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhenyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuohuan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Weiran Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yu Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Hua Wu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Work in progress
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Large language models (LLMs) with one or more fine-tuning phases have become
  a necessary step to unlock various capabilities, enabling LLMs to follow
  natural language instructions or align with human preferences. However, it
  carries the risk of catastrophic forgetting during sequential training, the
  parametric knowledge or the ability learned in previous stages may be
  overwhelmed by incoming training data. In this paper, we find that by regularly
  resetting partial parameters, LLMs can restore some of the original knowledge.
  Inspired by this, we introduce Half Fine-Tuning (HFT) for LLMs, as a substitute
  for full fine-tuning (FFT), to mitigate the forgetting issues, where half of
  the parameters are selected to learn new tasks while the other half are frozen
  to remain previous knowledge. We provide a feasibility analysis from the
  perspective of optimization and interpret the parameter selection operation as
  a regularization term. Without changing the model architecture, HFT could be
  seamlessly integrated into existing fine-tuning frameworks. Extensive
  experiments and analysis on supervised fine-tuning, direct preference
  optimization, and continual learning consistently demonstrate the
  effectiveness, robustness, and efficiency of HFT. Compared with FFT, HFT not
  only significantly alleviates the forgetting problem, but also achieves the
  best performance in a series of downstream benchmarks, with an approximately
  30% reduction in training time.
  </p>
  </div>
  </dd>
  <dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18469" title="Abstract">arXiv:2404.18469</a> [<a href="/pdf/2404.18469" title="Download PDF">pdf</a>, <a href="/format/2404.18469" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Error-Resilient Weakly Constrained Coding via Row-by-Row Coding
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mishra%2C+P">Prachi Mishra</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kashyap%2C+N">Navin Kashyap</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, a shorter version is submitted at the International Symposium on Information Theory (ISIT) 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">A weakly constrained code is a collection of finite-length strings over a
  finite alphabet in which certain substrings or patterns occur according to some
  prescribed frequencies. Buzaglo and Siegel (ITW 2017) gave a construction of
  weakly constrained codes based on row-by-row coding, that achieved the capacity
  of the weak constraint. In this paper, we propose a method to make this
  row-by-row coding scheme resilient to errors.
  </p>
  </div>
  </dd>
  <dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18470" title="Abstract">arXiv:2404.18470</a> [<a href="/pdf/2404.18470" title="Download PDF">pdf</a>, <a href="/format/2404.18470" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ECC Analyzer: Extract Trading Signal from Earnings Conference Calls  using Large Language Model for Stock Performance Prediction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+Y">Yupeng Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhi Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pei%2C+Q">Qingyun Pei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+P">Prashant Kumar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Subbalakshmi%2C+K+P">K.P. Subbalakshmi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ndiaye%2C+P+M">Papa Momar Ndiaye</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages, 3 figures, 5 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Risk Management (q-fin.RM); Trading and Market Microstructure (q-fin.TR)
  
  </div>
  <p class="mathjax">In the realm of financial analytics, leveraging unstructured data, such as
  earnings conference calls (ECCs), to forecast stock performance is a critical
  challenge that has attracted both academics and investors. While previous
  studies have used deep learning-based models to obtain a general view of ECCs,
  they often fail to capture detailed, complex information. Our study introduces
  a novel framework: \textbf{ECC Analyzer}, combining Large Language Models
  (LLMs) and multi-modal techniques to extract richer, more predictive insights.
  The model begins by summarizing the transcript's structure and analyzing the
  speakers' mode and confidence level by detecting variations in tone and pitch
  for audio. This analysis helps investors form an overview perception of the
  ECCs. Moreover, this model uses the Retrieval-Augmented Generation (RAG) based
  methods to meticulously extract the focuses that have a significant impact on
  stock performance from an expert's perspective, providing a more targeted
  analysis. The model goes a step further by enriching these extracted focuses
  with additional layers of analysis, such as sentiment and audio segment
  features. By integrating these insights, the ECC Analyzer performs multi-task
  predictions of stock performance, including volatility, value-at-risk (VaR),
  and return for different intervals. The results show that our model outperforms
  traditional analytic benchmarks, confirming the effectiveness of using advanced
  LLM techniques in financial analytics.
  </p>
  </div>
  </dd>
  <dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18476" title="Abstract">arXiv:2404.18476</a> [<a href="/pdf/2404.18476" title="Download PDF">pdf</a>, <a href="/ps/2404.18476" title="Download PostScript">ps</a>, <a href="/format/2404.18476" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mobile Networks on the Move: Optimizing Moving Base Stations Dynamics in  Urban Scenarios
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Finarelli%2C+L">Laura Finarelli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dressler%2C+F">Falko Dressler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ajmone%2C+M+M">Marco Marsan Ajmone</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rizzo%2C+G">Gianluca Rizzo</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>
  
  </div>
  <p class="mathjax">Base station densification is one of the key approaches for delivering high
  capacity in radio access networks. However, current static deployments are
  often impractical and financially unsustainable, as they increase both capital
  and operational expenditures of the network. An alternative paradigm is the
  moving base stations (MBSs) approach, by which part of base stations are
  installed on vehicles. However, to the best of our knowledge, it is still
  unclear if and up to which point MBSs allow decreasing the number of static
  base stations (BSs) deployed in urban settings. In this work, we start tackling
  this issue by proposing a modeling approach for a first-order evaluation of
  potential infrastructure savings enabled by the MBSs paradigm. Starting from a
  set of stochastic geometry results, and a traffic demand profile over time, we
  formulate an optimization problem for the derivation of the optimal combination
  of moving and static BSs which minimizes the overall amount of BSs deployed,
  while guaranteeing a target mean QoS for users. Initial results on a
  two-district scenario with measurement-based network traffic profiles suggest
  that substantial infrastructure savings are achievable. We show that these
  results are robust against different values of user density.
  </p>
  </div>
  </dd>
  <dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18477" title="Abstract">arXiv:2404.18477</a> [<a href="/pdf/2404.18477" title="Download PDF">pdf</a>, <a href="/format/2404.18477" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Long-term Robotics in the Wild
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hausler%2C+S">Stephen Hausler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Griffiths%2C+E">Ethan Griffiths</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ramezani%2C+M">Milad Ramezani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Moghadam%2C+P">Peyman Moghadam</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the 2024 IEEE ICRA Workshop on Field Robotics
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">In this paper, we emphasise the critical importance of large-scale datasets
  for advancing field robotics capabilities, particularly in natural
  environments. While numerous datasets exist for urban and suburban settings,
  those tailored to natural environments are scarce. Our recent benchmarks
  WildPlaces and WildScenes address this gap by providing synchronised image,
  lidar, semantic and accurate 6-DoF pose information in forest-type
  environments. We highlight the multi-modal nature of this dataset and discuss
  and demonstrate its utility in various downstream tasks, such as place
  recognition and 2D and 3D semantic segmentation tasks.
  </p>
  </div>
  </dd>
  <dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18479" title="Abstract">arXiv:2404.18479</a> [<a href="/pdf/2404.18479" title="Download PDF">pdf</a>, <a href="/ps/2404.18479" title="Download PostScript">ps</a>, <a href="/format/2404.18479" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ChatGPT as an inventor: Eliciting the strengths and weaknesses of  current large language models against humans in engineering design
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ege%2C+D+N">Daniel Nygård Ege</a>, 
  <a href="/search/cs?searchtype=author&amp;query=%C3%98vreb%C3%B8%2C+H+H">Henrik H. Øvrebø</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stubberud%2C+V">Vegar Stubberud</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Berg%2C+M+F">Martin Francis Berg</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Elverum%2C+C">Christer Elverum</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Steinert%2C+M">Martin Steinert</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vestad%2C+H">Håvard Vestad</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">This study compares the design practices and performance of ChatGPT 4.0, a
  large language model (LLM), against graduate engineering students in a 48-hour
  prototyping hackathon, based on a dataset comprising more than 100 prototypes.
  The LLM participated by instructing two participants who executed its
  instructions and provided objective feedback, generated ideas autonomously and
  made all design decisions without human intervention. The LLM exhibited similar
  prototyping practices to human participants and finished second among six
  teams, successfully designing and providing building instructions for
  functional prototypes. The LLM's concept generation capabilities were
  particularly strong. However, the LLM prematurely abandoned promising concepts
  when facing minor difficulties, added unnecessary complexity to designs, and
  experienced design fixation. Communication between the LLM and participants was
  challenging due to vague or unclear descriptions, and the LLM had difficulty
  maintaining continuity and relevance in answers. Based on these findings, six
  recommendations for implementing an LLM like ChatGPT in the design process are
  proposed, including leveraging it for ideation, ensuring human oversight for
  key decisions, implementing iterative feedback loops, prompting it to consider
  alternatives, and assigning specific and manageable tasks at a subsystem level.
  </p>
  </div>
  </dd>
  <dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18490" title="Abstract">arXiv:2404.18490</a> [<a href="/pdf/2404.18490" title="Download PDF">pdf</a>, <a href="/format/2404.18490" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Reduced-Rank Multi-objective Policy Learning and Optimization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nwankwo%2C+E">Ezinne Nwankwo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jordan%2C+M+I">Michael I. Jordan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+A">Angela Zhou</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">Evaluating the causal impacts of possible interventions is crucial for
  informing decision-making, especially towards improving access to opportunity.
  However, if causal effects are heterogeneous and predictable from covariates,
  personalized treatment decisions can improve individual outcomes and contribute
  to both efficiency and equity. In practice, however, causal researchers do not
  have a single outcome in mind a priori and often collect multiple outcomes of
  interest that are noisy estimates of the true target of interest. For example,
  in government-assisted social benefit programs, policymakers collect many
  outcomes to understand the multidimensional nature of poverty. The ultimate
  goal is to learn an optimal treatment policy that in some sense maximizes
  multiple outcomes simultaneously. To address such issues, we present a
  data-driven dimensionality-reduction methodology for multiple outcomes in the
  context of optimal policy learning with multiple objectives. We learn a
  low-dimensional representation of the true outcome from the observed outcomes
  using reduced rank regression. We develop a suite of estimates that use the
  model to denoise observed outcomes, including commonly-used index weightings.
  These methods improve estimation error in policy evaluation and optimization,
  including on a case study of real-world cash transfer and social intervention
  data. Reducing the variance of noisy social outcomes can improve the
  performance of algorithmic allocations.
  </p>
  </div>
  </dd>
  <dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18496" title="Abstract">arXiv:2404.18496</a> [<a href="/pdf/2404.18496" title="Download PDF">pdf</a>, <a href="/format/2404.18496" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> AI-powered Code Review with LLMs: Early Results
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rasheed%2C+Z">Zeeshan Rasheed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sami%2C+M+A">Malik Abdul Sami</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Waseem%2C+M">Muhammad Waseem</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kemell%2C+K">Kai-Kristian Kemell</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaofeng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+A">Anh Nguyen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Syst%C3%A4%2C+K">Kari Systä</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Abrahamsson%2C+P">Pekka Abrahamsson</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">In this paper, we present a novel approach to improving software quality and
  efficiency through a Large Language Model (LLM)-based model designed to review
  code and identify potential issues. Our proposed LLM-based AI agent model is
  trained on large code repositories. This training includes code reviews, bug
  reports, and documentation of best practices. It aims to detect code smells,
  identify potential bugs, provide suggestions for improvement, and optimize the
  code. Unlike traditional static code analysis tools, our LLM-based AI agent has
  the ability to predict future potential risks in the code. This supports a dual
  goal of improving code quality and enhancing developer education by encouraging
  a deeper understanding of best practices and efficient coding techniques.
  Furthermore, we explore the model's effectiveness in suggesting improvements
  that significantly reduce post-release bugs and enhance code review processes,
  as evidenced by an analysis of developer sentiment toward LLM feedback. For
  future work, we aim to assess the accuracy and efficiency of LLM-generated
  documentation updates in comparison to manual methods. This will involve an
  empirical study focusing on manually conducted code reviews to identify code
  smells and bugs, alongside an evaluation of best practice documentation,
  augmented by insights from developer discussions and code reviews. Our goal is
  to not only refine the accuracy of our LLM-based tool but also to underscore
  its potential in streamlining the software development lifecycle through
  proactive code improvement and education.
  </p>
  </div>
  </dd>
  <dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18497" title="Abstract">arXiv:2404.18497</a> [<a href="/pdf/2404.18497" title="Download PDF">pdf</a>, <a href="/format/2404.18497" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PHOBIC: Perfect Hashing with Optimized Bucket Sizes and Interleaved  Coding
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hermann%2C+S">Stefan Hermann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lehmann%2C+H">Hans-Peter Lehmann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pibiri%2C+G+E">Giulio Ermanno Pibiri</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sanders%2C+P">Peter Sanders</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Walzer%2C+S">Stefan Walzer</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  <p class="mathjax">A minimal perfect hash function (MPHF) maps a set of n keys to {1, ..., n}
  without collisions. Such functions find widespread application e.g. in
  bioinformatics and databases. In this paper we revisit PTHash - a construction
  technique particularly designed for fast queries. PTHash distributes the input
  keys into small buckets and, for each bucket, it searches for a hash function
  seed that places its keys in the output domain without collisions. The
  collection of all seeds is then stored in a compressed way. Since the first
  buckets are easier to place, buckets are considered in non-increasing order of
  size. Additionally, PTHash heuristically produces an imbalanced distribution of
  bucket sizes by distributing 60% of the keys into 30% of the buckets. Our main
  contribution is to characterize, up to lower order terms, an optimal
  distribution of expected bucket sizes. We arrive at a simple, closed form
  solution which improves construction throughput for space efficient
  configurations in practice. Our second contribution is a novel encoding scheme
  for the seeds. We split the keys into partitions. Within each partition, we run
  the bucket distribution and search step. We then store the seeds in an
  interleaved way by consecutively placing the seeds for the i-th buckets from
  all partitions. The seeds for the i-th bucket of each partition follow the same
  statistical distribution. This allows us to tune a compressor for each bucket.
  Hence, we call our technique PHOBIC - Perfect Hashing with Optimized Bucket
  sizes and Interleaved Coding. Compared to PTHash, PHOBIC is 0.17 bits/key more
  space efficient for same query time and construction throughput. We also
  contribute a GPU implementation to further accelerate MPHF construction. For a
  configuration with fast queries, PHOBIC-GPU can construct a perfect hash
  function at 2.17 bits/key in 28 ns per key, which can be queried in 37 ns on
  the CPU.
  </p>
  </div>
  </dd>
  <dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18504" title="Abstract">arXiv:2404.18504</a> [<a href="/pdf/2404.18504" title="Download PDF">pdf</a>, <a href="/format/2404.18504" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multisensor Data Fusion for Automatized Insect Monitoring (KInsecta)
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tschaikner%2C+M">Martin Tschaikner</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Brandt%2C+D">Danja Brandt</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schmidt%2C+H">Henning Schmidt</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bie%C3%9Fmann%2C+F">Felix Bießmann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chiaburu%2C+T">Teodor Chiaburu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schrimpf%2C+I">Ilona Schrimpf</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schrimpf%2C+T">Thomas Schrimpf</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stadel%2C+A">Alexandra Stadel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hau%C3%9Fer%2C+F">Frank Haußer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Beckers%2C+I">Ingeborg Beckers</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Remote Sensing for Agriculture, Ecosystems, and Hydrology XXV,
    SPIE 12727 (2023) 1272702
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)
  
  </div>
  <p class="mathjax">Insect populations are declining globally, making systematic monitoring
  essential for conservation. Most classical methods involve death traps and
  counter insect conservation. This paper presents a multisensor approach that
  uses AI-based data fusion for insect classification. The system is designed as
  low-cost setup and consists of a camera module and an optical wing beat sensor
  as well as environmental sensors to measure temperature, irradiance or daytime
  as prior information. The system has been tested in the laboratory and in the
  field. First tests on a small very unbalanced data set with 7 species show
  promising results for species classification. The multisensor system will
  support biodiversity and agriculture studies.
  </p>
  </div>
  </dd>
  <dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18505" title="Abstract">arXiv:2404.18505</a> [<a href="/pdf/2404.18505" title="Download PDF">pdf</a>, <a href="/format/2404.18505" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> R3MG: R-tree based agglomeration of polytopal grids with applications to  multilevel methods
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Feder%2C+M">Marco Feder</a>, 
  <a href="/search/math?searchtype=author&amp;query=Cangiani%2C+A">Andrea Cangiani</a>, 
  <a href="/search/math?searchtype=author&amp;query=Heltai%2C+L">Luca Heltai</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 23 pages, 16 figures, 6 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">We present a novel approach to perform agglomeration of polygonal and
  polyhedral grids based on spatial indices. Agglomeration strategies are a key
  ingredient in polytopal methods for PDEs as they are used to generate
  (hierarchies of) computational grids from an initial grid. Spatial indices are
  specialized data structures that significantly accelerate queries involving
  spatial relationships in arbitrary space dimensions. We show how the
  construction of the R-tree spatial database of an arbitrary fine grid offers a
  natural and efficient agglomeration strategy with the following
  characteristics: i) the process is fully automated, robust, and
  dimension-independent, ii) it automatically produces a balanced and nested
  hierarchy of agglomerates, and iii) the shape of the agglomerates is tightly
  close to the respective axis aligned bounding boxes. Moreover, the R-tree
  approach provides a full hierarchy of nested agglomerates which permits fast
  query and allows for efficient geometric multigrid methods to be applied also
  to those cases where a hierarchy of grids is not present at construction time.
  We present several examples based on polygonal discontinuous Galerkin methods,
  confirming the effectiveness of our approach in the context of challenging
  three-dimensional geometries and the design of geometric multigrid
  preconditioners.
  </p>
  </div>
  </dd>
  <dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18508" title="Abstract">arXiv:2404.18508</a> [<a href="/pdf/2404.18508" title="Download PDF">pdf</a>, <a href="/format/2404.18508" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Scalable Event-by-event Processing of Neuromorphic Sensory Signals With  Deep State-Space Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sch%C3%B6ne%2C+M">Mark Schöne</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sushma%2C+N+M">Neeraj Mohan Sushma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhuge%2C+J">Jingyue Zhuge</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mayr%2C+C">Christian Mayr</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Subramoney%2C+A">Anand Subramoney</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kappel%2C+D">David Kappel</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)
  
  </div>
  <p class="mathjax">Event-based sensors are well suited for real-time processing due to their
  fast response times and encoding of the sensory data as successive temporal
  differences. These and other valuable properties, such as a high dynamic range,
  are suppressed when the data is converted to a frame-based format. However,
  most current methods either collapse events into frames or cannot scale up when
  processing the event data directly event-by-event. In this work, we address the
  key challenges of scaling up event-by-event modeling of the long event streams
  emitted by such sensors, which is a particularly relevant problem for
  neuromorphic computing. While prior methods can process up to a few thousand
  time steps, our model, based on modern recurrent deep state-space models,
  scales to event streams of millions of events for both training and
  inference.We leverage their stable parameterization for learning long-range
  dependencies, parallelizability along the sequence dimension, and their ability
  to integrate asynchronous events effectively to scale them up to long event
  streams.We further augment these with novel event-centric techniques enabling
  our model to match or beat the state-of-the-art performance on several event
  stream benchmarks. In the Spiking Speech Commands task, we improve
  state-of-the-art by a large margin of 6.6% to 87.1%. On the DVS128-Gestures
  dataset, we achieve competitive results without using frames or convolutional
  neural networks. Our work demonstrates, for the first time, that it is possible
  to use fully event-based processing with purely recurrent networks to achieve
  state-of-the-art task performance in several event-based benchmarks.
  </p>
  </div>
  </dd>
  <dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18510" title="Abstract">arXiv:2404.18510</a> [<a href="/pdf/2404.18510" title="Download PDF">pdf</a>, <a href="/format/2404.18510" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Explainability of Machine Learning Approaches in Forensic Linguistics: A  Case Study in Geolinguistic Authorship Profiling
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Roemling%2C+D">Dana Roemling</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Scherrer%2C+Y">Yves Scherrer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Miletic%2C+A">Aleksandra Miletic</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Forensic authorship profiling uses linguistic markers to infer
  characteristics about an author of a text. This task is paralleled in dialect
  classification, where a prediction is made about the linguistic variety of a
  text based on the text itself. While there have been significant advances in
  the last years in variety classification (Jauhiainen et al., 2019) and
  state-of-the-art approaches reach accuracies of up to 100% depending on the
  similarity of varieties and the scope of prediction (e.g., Milne et al., 2012;
  Blodgett et al., 2017), forensic linguistics rarely relies on these approaches
  due to their lack of transparency (see Nini, 2023), amongst other reasons. In
  this paper we therefore explore explainability of machine learning approaches
  considering the forensic context. We focus on variety classification as a means
  of geolinguistic profiling of unknown texts. For this we work with an approach
  proposed by Xie et al. (2024) to extract the lexical items most relevant to the
  variety classifications. We find that the extracted lexical features are indeed
  representative of their respective varieties and note that the trained models
  also rely on place names for classifications.
  </p>
  </div>
  </dd>
  <dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18514" title="Abstract">arXiv:2404.18514</a> [<a href="/pdf/2404.18514" title="Download PDF">pdf</a>, <a href="/format/2404.18514" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Systematic Evaluation of Adversarial Attacks against Speech Emotion  Recognition Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Facchinetti%2C+N">Nicolas Facchinetti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Simonetta%2C+F">Federico Simonetta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ntalampiras%2C+S">Stavros Ntalampiras</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">Speech emotion recognition (SER) is constantly gaining attention in recent
  years due to its potential applications in diverse fields and thanks to the
  possibility offered by deep learning technologies. However, recent studies have
  shown that deep learning models can be vulnerable to adversarial attacks. In
  this paper, we systematically assess this problem by examining the impact of
  various adversarial white-box and black-box attacks on different languages and
  genders within the context of SER. We first propose a suitable methodology for
  audio data processing, feature extraction, and CNN-LSTM architecture. The
  observed outcomes highlighted the significant vulnerability of CNN-LSTM models
  to adversarial examples (AEs). In fact, all the considered adversarial attacks
  are able to significantly reduce the performance of the constructed models.
  Furthermore, when assessing the efficacy of the attacks, minor differences were
  noted between the languages analyzed as well as between male and female speech.
  In summary, this work contributes to the understanding of the robustness of
  CNN-LSTM models, particularly in SER scenarios, and the impact of AEs.
  Interestingly, our findings serve as a baseline for a) developing more robust
  algorithms for SER, b) designing more effective attacks, c) investigating
  possible defenses, d) improved understanding of the vocal differences between
  different languages and genders, and e) overall, enhancing our comprehension of
  the SER task.
  </p>
  </div>
  </dd>
  <dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18515" title="Abstract">arXiv:2404.18515</a> [<a href="/pdf/2404.18515" title="Download PDF">pdf</a>, <a href="/format/2404.18515" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An Agile Formal Specification Language Design Based on K Framework
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jianyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Long Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yixuan Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+F">Feng Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Formal Methods (FMs) are currently essential for verifying the safety and
  reliability of software systems. However, the specification writing in formal
  methods tends to be complex and challenging to learn, requiring familiarity
  with various intricate formal specification languages and verification
  technologies. In response to the increasing complexity of software frameworks,
  existing specification writing methods fall short in meeting agility
  requirements. To address this, this paper introduces an Agile Formal
  Specification Language (ASL). The ASL is defined based on the K Framework and
  YAML Ain't Markup Language (YAML). The design of ASL incorporates agile design
  principles, making the writing of formal specifications simpler, more
  efficient, and scalable. Additionally, a specification translation algorithm is
  developed, capable of converting ASL into K formal specification language that
  can be executed for verification. Experimental evaluations demonstrate that the
  proposed method significantly reduces the code size needed for specification
  writing, enhancing agility in formal specification writing.
  </p>
  </div>
  </dd>
  <dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18518" title="Abstract">arXiv:2404.18518</a> [<a href="/pdf/2404.18518" title="Download PDF">pdf</a>, <a href="/ps/2404.18518" title="Download PostScript">ps</a>, <a href="/format/2404.18518" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital  Humanities Research and Services?
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiangfeng Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+J">Jing Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pei%2C+L">Lei Pei</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 21 pages, 3 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)
  
  </div>
  <p class="mathjax">Generative large-scale language models create the fifth paradigm of
  scientific research, organically combine data science and computational
  intelligence, transform the research paradigm of natural language processing
  and multimodal information processing, promote the new trend of AI-enabled
  social science research, and provide new ideas for digital humanities research
  and application. This article profoundly explores the application of
  large-scale language models in digital humanities research, revealing their
  significant potential in ancient book protection, intelligent processing, and
  academic innovation. The article first outlines the importance of ancient book
  resources and the necessity of digital preservation, followed by a detailed
  introduction to developing large-scale language models, such as ChatGPT, and
  their applications in document management, content understanding, and
  cross-cultural research. Through specific cases, the article demonstrates how
  AI can assist in the organization, classification, and content generation of
  ancient books. Then, it explores the prospects of AI applications in artistic
  innovation and cultural heritage preservation. Finally, the article explores
  the challenges and opportunities in the interaction of technology, information,
  and society in the digital humanities triggered by AI technologies.
  </p>
  </div>
  </dd>
  <dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18519" title="Abstract">arXiv:2404.18519</a> [<a href="/pdf/2404.18519" title="Download PDF">pdf</a>, <a href="/format/2404.18519" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On the Impact of Data Heterogeneity in Federated Learning Environments  with Application to Healthcare Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Barbieri%2C+U+M+L">Usevalad Milasheuski. Luca Barbieri</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tedeschini%2C+B+C">Bernardo Camajori Tedeschini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nicoli%2C+M">Monica Nicoli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Savazzi%2C+S">Stefano Savazzi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Federated Learning (FL) allows multiple privacy-sensitive applications to
  leverage their dataset for a global model construction without any disclosure
  of the information. One of those domains is healthcare, where groups of silos
  collaborate in order to generate a global predictor with improved accuracy and
  generalization. However, the inherent challenge lies in the high heterogeneity
  of medical data, necessitating sophisticated techniques for assessment and
  compensation. This paper presents a comprehensive exploration of the
  mathematical formalization and taxonomy of heterogeneity within FL
  environments, focusing on the intricacies of medical data. In particular, we
  address the evaluation and comparison of the most popular FL algorithms with
  respect to their ability to cope with quantity-based, feature and label
  distribution-based heterogeneity. The goal is to provide a quantitative
  evaluation of the impact of data heterogeneity in FL systems for healthcare
  networks as well as a guideline on FL algorithm selection. Our research extends
  beyond existing studies by benchmarking seven of the most common FL algorithms
  against the unique challenges posed by medical data use cases. The paper
  targets the prediction of the risk of stroke recurrence through a set of
  tabular clinical reports collected by different federated hospital silos: data
  heterogeneity frequently encountered in this scenario and its impact on FL
  performance are discussed.
  </p>
  </div>
  </dd>
  <dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18522" title="Abstract">arXiv:2404.18522</a> [<a href="/pdf/2404.18522" title="Download PDF">pdf</a>, <a href="/format/2404.18522" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Did Fourier Really Meet Möbius? Fast Subset Convolution via FFT
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Stoian%2C+M">Mihail Stoian</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  <p class="mathjax">In their seminal work on subset convolution, Bj\"orklund, Husfeldt, Kaski and
  Koivisto introduced the now well-known <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-199-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1303" style="width: 3.955em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.221em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1003.165em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1304"><span class="mi" id="MathJax-Span-1305" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1306" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1307"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mn" id="MathJax-Span-1308" style="font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.511em;"><span class="mi" id="MathJax-Span-1309" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-1310"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1311" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="mn" id="MathJax-Span-1312" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1313" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-199">O(2^n n^2)</script>-time evaluation of the
  subset convolution in the sum-product ring. This sparked a wave of remarkable
  results for fundamental problems, such as the minimum Steiner tree and the
  chromatic number. However, in spite of its theoretical improvement, large
  intermediate outputs and floating-point precision errors due to alternating
  addition and subtraction in its set function transforms make the algorithm
  unusable in practice.
  <br>We provide a simple FFT-based algorithm that completely eliminates the need
  for set function transforms and maintains the running time of the original
  algorithm. This makes it possible to take advantage of nearly sixty years of
  research on efficient FFT implementations.
  </p>
  </div>
  </dd>
  <dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18525" title="Abstract">arXiv:2404.18525</a> [<a href="/pdf/2404.18525" title="Download PDF">pdf</a>, <a href="/format/2404.18525" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enabling Efficient and Flexible Interpretability of Data-driven Anomaly  Detection in Industrial Processes with AcME-AD
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zaccaria%2C+V">Valentina Zaccaria</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Masiero%2C+C">Chiara Masiero</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dandolo%2C+D">David Dandolo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Susto%2C+G+A">Gian Antonio Susto</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">While Machine Learning has become crucial for Industry 4.0, its opaque nature
  hinders trust and impedes the transformation of valuable insights into
  actionable decision, a challenge exacerbated in the evolving Industry 5.0 with
  its human-centric focus. This paper addresses this need by testing the
  applicability of AcME-AD in industrial settings. This recently developed
  framework facilitates fast and user-friendly explanations for anomaly
  detection. AcME-AD is model-agnostic, offering flexibility, and prioritizes
  real-time efficiency. Thus, it seems suitable for seamless integration with
  industrial Decision Support Systems. We present the first industrial
  application of AcME-AD, showcasing its effectiveness through experiments. These
  tests demonstrate AcME-AD's potential as a valuable tool for explainable AD and
  feature-based root cause analysis within industrial environments, paving the
  way for trustworthy and actionable insights in the age of Industry 5.0.
  </p>
  </div>
  </dd>
  <dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18527" title="Abstract">arXiv:2404.18527</a> [<a href="/pdf/2404.18527" title="Download PDF">pdf</a>, <a href="/ps/2404.18527" title="Download PostScript">ps</a>, <a href="/format/2404.18527" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bridging Data Barriers among Participants: Assessing the Potential of  Geoenergy through Federated Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+W">Weike Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+J">Jiaxin Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuntian Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shengwei Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Applications (stat.AP)
  
  </div>
  <p class="mathjax">Machine learning algorithms emerge as a promising approach in energy fields,
  but its practical is hindered by data barriers, stemming from high collection
  costs and privacy concerns. This study introduces a novel federated learning
  (FL) framework based on XGBoost models, enabling safe collaborative modeling
  with accessible yet concealed data from multiple parties. Hyperparameter tuning
  of the models is achieved through Bayesian Optimization. To ascertain the
  merits of the proposed FL-XGBoost method, a comparative analysis is conducted
  between separate and centralized models to address a classical binary
  classification problem in geoenergy sector. The results reveal that the
  proposed FL framework strikes an optimal balance between privacy and accuracy.
  FL models demonstrate superior accuracy and generalization capabilities
  compared to separate models, particularly for participants with limited data or
  low correlation features and offers significant privacy benefits compared to
  centralized model. The aggregated optimization approach within the FL agreement
  proves effective in tuning hyperparameters. This study opens new avenues for
  assessing unconventional reservoirs through collaborative and
  privacy-preserving FL techniques.
  </p>
  </div>
  </dd>
  <dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18528" title="Abstract">arXiv:2404.18528</a> [<a href="/pdf/2404.18528" title="Download PDF">pdf</a>, <a href="/format/2404.18528" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generation of Uncorrelated Residual Variables for Chemical Process Fault  Diagnosis via Transfer Learning-based Input-Output Decoupled Network
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+Z">Zhuofu Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sui%2C+Q">Qingkai Sui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yalin Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+J">Jiang Luo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jie Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hongtian Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Structural decoupling has played an essential role in model-based fault
  isolation and estimation in past decades, which facilitates accurate fault
  localization and reconstruction thanks to the diagonal transfer matrix design.
  However, traditional methods exhibit limited effectiveness in modeling
  high-dimensional nonlinearity and big data, and the decoupling idea has not
  been well-valued in data-driven frameworks. Known for big data and complex
  feature extraction capabilities, deep learning has recently been used to
  develop residual generation models. Nevertheless, it lacks decoupling-related
  diagnostic designs. To this end, this paper proposes a transfer learning-based
  input-output decoupled network (TDN) for diagnostic purposes, which consists of
  an input-output decoupled network (IDN) and a pre-trained variational autocoder
  (VAE). In IDN, uncorrelated residual variables are generated by diagonalization
  and parallel computing operations. During the transfer learning phase,
  knowledge of normal status is provided according to VAE's loss and maximum mean
  discrepancy loss to guide the training of IDN. After training, IDN learns the
  mapping from faulty to normal, thereby serving as the fault detection index and
  the estimated fault signal simultaneously. At last, the effectiveness of the
  developed TDN is verified by a numerical example and a chemical simulation.
  </p>
  </div>
  </dd>
  <dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18530" title="Abstract">arXiv:2404.18530</a> [<a href="/pdf/2404.18530" title="Download PDF">pdf</a>, <a href="/format/2404.18530" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Predicting PDEs Fast and Efficiently with Equivariant Extreme Learning  Machines
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Harder%2C+H">Hans Harder</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peitz%2C+S">Sebastian Peitz</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">We utilize extreme learning machines for the prediction of partial
  differential equations (PDEs). Our method splits the state space into multiple
  windows that are predicted individually using a single model. Despite requiring
  only few data points (in some cases, our method can learn from a single
  full-state snapshot), it still achieves high accuracy and can predict the flow
  of PDEs over long time horizons. Moreover, we show how additional symmetries
  can be exploited to increase sample efficiency and to enforce equivariance.
  </p>
  </div>
  </dd>
  <dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18531" title="Abstract">arXiv:2404.18531</a> [<a href="/pdf/2404.18531" title="Download PDF">pdf</a>, <a href="/format/2404.18531" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Framework to Model ML Engineering Processes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Morales%2C+S">Sergio Morales</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Claris%C3%B3%2C+R">Robert Clarisó</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cabot%2C+J">Jordi Cabot</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">The development of Machine Learning (ML) based systems is complex and
  requires multidisciplinary teams with diverse skill sets. This may lead to
  communication issues or misapplication of best practices. Process models can
  alleviate these challenges by standardizing task orchestration, providing a
  common language to facilitate communication, and nurturing a collaborative
  environment. Unfortunately, current process modeling languages are not suitable
  for describing the development of such systems. In this paper, we introduce a
  framework for modeling ML-based software development processes, built around a
  domain-specific language and derived from an analysis of scientific and gray
  literature. A supporting toolkit is also available.
  </p>
  </div>
  </dd>
  <dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18532" title="Abstract">arXiv:2404.18532</a> [<a href="/pdf/2404.18532" title="Download PDF">pdf</a>, <a href="/format/2404.18532" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MileBench: Benchmarking MLLMs in Long Context
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+D">Dingjie Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Shunian Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+G+H">Guiming Hardy Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+F">Fei Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wan%2C+X">Xiang Wan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Benyou Wang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 29 pages, 13 figures, 14 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Despite the advancements and impressive performance of Multimodal Large
  Language Models (MLLMs) on benchmarks, their effectiveness in real-world,
  long-context, and multi-image tasks is unclear due to the benchmarks' limited
  scope. Existing benchmarks often focus on single-image and short-text samples,
  and when assessing multi-image tasks, they either limit the image count or
  focus on specific task (e.g time-series captioning), potentially obscuring the
  performance challenges of MLLMs. To address these limitations, we introduce
  MileBench, a pioneering benchmark designed to test the MultImodal Long-contExt
  capabilities of MLLMs. This benchmark comprises not only multimodal long
  contexts, but also multiple tasks requiring both comprehension and generation.
  We establish two distinct evaluation sets, diagnostic and realistic, to
  systematically assess MLLMs' long-context adaptation capacity and their ability
  to complete tasks in long-context scenarios. Our experimental results, obtained
  from testing 20 models, revealed that while the closed-source GPT-4(Vision) and
  Gemini 1.5 outperform others, most open-source MLLMs struggle in long-context
  situations. Interestingly, the performance gap tends to widen with an increase
  in the number of images. We strongly encourage an intensification of research
  efforts towards enhancing MLLMs' long-context capabilities, especially in
  scenarios involving multiple images.
  </p>
  </div>
  </dd>
  <dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18533" title="Abstract">arXiv:2404.18533</a> [<a href="/pdf/2404.18533" title="Download PDF">pdf</a>, <a href="/format/2404.18533" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Evaluating Readability and Faithfulness of Concept-based Explanations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Meng Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jin%2C+H">Haoran Jin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+R">Ruixuan Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhihao Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lian%2C+D">Defu Lian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zijia Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+D">Di Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiting Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)
  
  </div>
  <p class="mathjax">Despite the surprisingly high intelligence exhibited by Large Language Models
  (LLMs), we are somehow intimidated to fully deploy them into real-life
  applications considering their black-box nature. Concept-based explanations
  arise as a promising avenue for explaining what the LLMs have learned, making
  them more transparent to humans. However, current evaluations for concepts tend
  to be heuristic and non-deterministic, e.g. case study or human evaluation,
  hindering the development of the field. To bridge the gap, we approach
  concept-based explanation evaluation via faithfulness and readability. We first
  introduce a formal definition of concept generalizable to diverse concept-based
  explanations. Based on this, we quantify faithfulness via the difference in the
  output upon perturbation. We then provide an automatic measure for readability,
  by measuring the coherence of patterns that maximally activate a concept. This
  measure serves as a cost-effective and reliable substitute for human
  evaluation. Finally, based on measurement theory, we describe a meta-evaluation
  method for evaluating the above measures via reliability and validity, which
  can be generalized to other tasks as well. Extensive experimental analysis has
  been conducted to validate and inform the selection of concept evaluation
  measures.
  </p>
  </div>
  </dd>
  <dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18534" title="Abstract">arXiv:2404.18534</a> [<a href="/pdf/2404.18534" title="Download PDF">pdf</a>, <a href="/format/2404.18534" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Evaluating and Mitigating Linguistic Discrimination in Large Language  Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+G">Guoliang Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Haoyu Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jun Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinyu Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">By training on text in various languages, large language models (LLMs)
  typically possess multilingual support and demonstrate remarkable capabilities
  in solving tasks described in different languages. However, LLMs can exhibit
  linguistic discrimination due to the uneven distribution of training data
  across languages. That is, LLMs are hard to keep the consistency of responses
  when faced with the same task but depicted in different languages.
  <br>In this study, we first explore the consistency in the LLMs' outputs
  responding to queries in various languages from two aspects: safety and
  quality. We conduct this analysis with two datasets (AdvBench and NQ) based on
  four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo and Gemini-pro). The results
  show that LLMs exhibit stronger human alignment capabilities with queries in
  English, French, Russian, and Spanish (only 1.04\% of harmful queries
  successfully jailbreak on average) compared to queries in Bengali, Georgian,
  Nepali and Maithili (27.7\% of harmful queries jailbreak successfully on
  average). Moreover, for queries in English, Danish, Czech and Slovenian, LLMs
  tend to produce responses with a higher quality (with 0.1494 <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-200-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1314" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1315"><span class="msubsup" id="MathJax-Span-1316"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.624em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1317" style="font-family: STIXGeneral-Italic;">F<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.624em;"><span class="mn" id="MathJax-Span-1318" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-200">F_1</script> score on
  average) compared to the other languages. Upon these findings, we propose
  LDFighter, a similarity-based voting, to mitigate the linguistic discrimination
  in LLMs. LDFighter ensures consistent service for different language speakers.
  We evaluate LDFighter with both benign queries and harmful queries. The results
  show that LDFighter not only significantly reduces the jailbreak success rate
  but also improve the response quality on average, demonstrating its
  effectiveness.
  </p>
  </div>
  </dd>
  <dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18537" title="Abstract">arXiv:2404.18537</a> [<a href="/pdf/2404.18537" title="Download PDF">pdf</a>, <a href="/format/2404.18537" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Time Series Data Augmentation as an Imbalanced Learning Problem
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cerqueira%2C+V">Vitor Cerqueira</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Moniz%2C+N">Nuno Moniz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=In%C3%A1cio%2C+R">Ricardo Inácio</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Soares%2C+C">Carlos Soares</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">Recent state-of-the-art forecasting methods are trained on collections of
  time series. These methods, often referred to as global models, can capture
  common patterns in different time series to improve their generalization
  performance. However, they require large amounts of data that might not be
  readily available. Besides this, global models sometimes fail to capture
  relevant patterns unique to a particular time series. In these cases, data
  augmentation can be useful to increase the sample size of time series datasets.
  The main contribution of this work is a novel method for generating univariate
  time series synthetic samples. Our approach stems from the insight that the
  observations concerning a particular time series of interest represent only a
  small fraction of all observations. In this context, we frame the problem of
  training a forecasting model as an imbalanced learning task. Oversampling
  strategies are popular approaches used to deal with the imbalance problem in
  machine learning. We use these techniques to create synthetic time series
  observations and improve the accuracy of forecasting models. We carried out
  experiments using 7 different databases that contain a total of 5502 univariate
  time series. We found that the proposed solution outperforms both a global and
  a local model, thus providing a better trade-off between these two approaches.
  </p>
  </div>
  </dd>
  <dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18538" title="Abstract">arXiv:2404.18538</a> [<a href="/pdf/2404.18538" title="Download PDF">pdf</a>, <a href="/ps/2404.18538" title="Download PostScript">ps</a>, <a href="/format/2404.18538" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Symmetry group based domain decomposition to enhance physics-informed  neural networks for solving partial differential equations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Ye Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jie-Ying Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Li-Sheng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+L">Lei-Lei Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhi-Yong Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)
  
  </div>
  <p class="mathjax">Domain decomposition provides an effective way to tackle the dilemma of
  physics-informed neural networks (PINN) which struggle to accurately and
  efficiently solve partial differential equations (PDEs) in the whole domain,
  but the lack of efficient tools for dealing with the interfaces between two
  adjacent sub-domains heavily hinders the training effects, even leads to the
  discontinuity of the learned solutions. In this paper, we propose a symmetry
  group based domain decomposition strategy to enhance the PINN for solving the
  forward and inverse problems of the PDEs possessing a Lie symmetry group.
  Specifically, for the forward problem, we first deploy the symmetry group to
  generate the dividing-lines having known solution information which can be
  adjusted flexibly and are used to divide the whole training domain into a
  finite number of non-overlapping sub-domains, then utilize the PINN and the
  symmetry-enhanced PINN methods to learn the solutions in each sub-domain and
  finally stitch them to the overall solution of PDEs. For the inverse problem,
  we first utilize the symmetry group acting on the data of the initial and
  boundary conditions to generate labeled data in the interior domain of PDEs and
  then find the undetermined parameters as well as the solution by only training
  the neural networks in a sub-domain. Consequently, the proposed method can
  predict high-accuracy solutions of PDEs which are failed by the vanilla PINN in
  the whole domain and the extended physics-informed neural network in the same
  sub-domains. Numerical results of the Korteweg-de Vries equation with a
  translation symmetry and the nonlinear viscous fluid equation with a scaling
  symmetry show that the accuracies of the learned solutions are improved
  largely.
  </p>
  </div>
  </dd>
  <dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18539" title="Abstract">arXiv:2404.18539</a> [<a href="/pdf/2404.18539" title="Download PDF">pdf</a>, <a href="/format/2404.18539" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhancing Boundary Segmentation for Topological Accuracy with  Skeleton-based Methods
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chuni Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+B">Boyuan Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ban%2C+X">Xiaojuan Ban</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+Y">Yujie Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+W">Weihua Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+J">Jingchao Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+K">Ke Xu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Topological consistency plays a crucial role in the task of boundary
  segmentation for reticular images, such as cell membrane segmentation in neuron
  electron microscopic images, grain boundary segmentation in material
  microscopic images and road segmentation in aerial images. In these fields,
  topological changes in segmentation results have a serious impact on the
  downstream tasks, which can even exceed the misalignment of the boundary
  itself. To enhance the topology accuracy in segmentation results, we propose
  the Skea-Topo Aware loss, which is a novel loss function that takes into
  account the shape of each object and topological significance of the pixels. It
  consists of two components. First, the skeleton-aware weighted loss improves
  the segmentation accuracy by better modeling the object geometry with
  skeletons. Second, a boundary rectified term effectively identifies and
  emphasizes topological critical pixels in the prediction errors using both
  foreground and background skeletons in the ground truth and predictions.
  Experiments prove that our method improves topological consistency by up to 7
  points in VI compared to 13 state-of-art methods, based on objective and
  subjective assessments across three different boundary segmentation datasets.
  The code is available at https://github.com/clovermini/Skea_topo.
  </p>
  </div>
  </dd>
  <dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18541" title="Abstract">arXiv:2404.18541</a> [<a href="/pdf/2404.18541" title="Download PDF">pdf</a>, <a href="/format/2404.18541" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Machine Learning for Windows Malware Detection and Classification:  Methods, Challenges and Ongoing Research
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gibert%2C+D">Daniel Gibert</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">In this chapter, readers will explore how machine learning has been applied
  to build malware detection systems designed for the Windows operating system.
  This chapter starts by introducing the main components of a Machine Learning
  pipeline, highlighting the challenges of collecting and maintaining up-to-date
  datasets. Following this introduction, various state-of-the-art malware
  detectors are presented, encompassing both feature-based and deep
  learning-based detectors. Subsequent sections introduce the primary challenges
  encountered by machine learning-based malware detectors, including concept
  drift and adversarial attacks. Lastly, this chapter concludes by providing a
  brief overview of the ongoing research on adversarial defenses.
  </p>
  </div>
  </dd>
  <dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18542" title="Abstract">arXiv:2404.18542</a> [<a href="/pdf/2404.18542" title="Download PDF">pdf</a>, <a href="/ps/2404.18542" title="Download PostScript">ps</a>, <a href="/format/2404.18542" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> OAEI Machine Learning Dataset for Online Model Generation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hertling%2C+S">Sven Hertling</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Norouzi%2C+E">Ebrahim Norouzi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sack%2C+H">Harald Sack</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> accepted as ESWC 2024 Poster
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">Ontology and knowledge graph matching systems are evaluated annually by the
  Ontology Alignment Evaluation Initiative (OAEI). More and more systems use
  machine learning-based approaches, including large language models. The
  training and validation datasets are usually determined by the system developer
  and often a subset of the reference alignments are used. This sampling is
  against the OAEI rules and makes a fair comparison impossible. Furthermore,
  those models are trained offline (a trained and optimized model is packaged
  into the matcher) and therefore the systems are specifically trained for those
  tasks. In this paper, we introduce a dataset that contains training,
  validation, and test sets for most of the OAEI tracks. Thus, online model
  learning (the systems must adapt to the given input alignment without human
  intervention) is made possible to enable a fair comparison for ML-based
  systems. We showcase the usefulness of the dataset by fine-tuning the
  confidence thresholds of popular systems.
  </p>
  </div>
  </dd>
  <dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18543" title="Abstract">arXiv:2404.18543</a> [<a href="/pdf/2404.18543" title="Download PDF">pdf</a>, <a href="/format/2404.18543" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Time Machine GPT
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Drinkall%2C+F">Felix Drinkall</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rahimikia%2C+E">Eghbal Rahimikia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pierrehumbert%2C+J+B">Janet B. Pierrehumbert</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zohren%2C+S">Stefan Zohren</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> NAACL Findings 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Large language models (LLMs) are often trained on extensive, temporally
  indiscriminate text corpora, reflecting the lack of datasets with temporal
  metadata. This approach is not aligned with the evolving nature of language.
  Conventional methods for creating temporally adapted language models often
  depend on further pre-training static models on time-specific data. This paper
  presents a new approach: a series of point-in-time LLMs called Time Machine GPT
  (TiMaGPT), specifically designed to be nonprognosticative. This ensures they
  remain uninformed about future factual information and linguistic changes. This
  strategy is beneficial for understanding language evolution and is of critical
  importance when applying models in dynamic contexts, such as time-series
  forecasting, where foresight of future information can prove problematic. We
  provide access to both the models and training datasets.
  </p>
  </div>
  </dd>
  <dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18546" title="Abstract">arXiv:2404.18546</a> [<a href="/pdf/2404.18546" title="Download PDF">pdf</a>, <a href="/format/2404.18546" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ir_explain: a Python Library of Explainable IR Methods
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Saha%2C+S">Sourav Saha</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+H">Harsh Agarwal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mohanty%2C+S">Swastik Mohanty</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mitra%2C+M">Mandar Mitra</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Majumdar%2C+D">Debapriyo Majumdar</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">While recent advancements in Neural Ranking Models have resulted in
  significant improvements over traditional statistical retrieval models, it is
  generally acknowledged that the use of large neural architectures and the
  application of complex language models in Information Retrieval (IR) have
  reduced the transparency of retrieval methods. Consequently, Explainability and
  Interpretability have emerged as important research topics in IR. Several
  axiomatic and post-hoc explanation methods, as well as approaches that attempt
  to be interpretable-by-design, have been proposed. This article presents
  \irexplain, an open-source Python library that implements a variety of
  well-known techniques for Explainable IR (ExIR) within a common, extensible
  framework. \irexplain supports the three standard categories of post-hoc
  explanations, namely pointwise, pairwise, and listwise explanations. The
  library is designed to make it easy to reproduce state-of-the-art ExIR
  baselines on standard test collections, as well as to explore new approaches to
  explaining IR models and methods. To facilitate adoption, \irexplain is
  well-integrated with widely-used toolkits such as Pyserini and \irdatasets.
  </p>
  </div>
  </dd>
  <dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18550" title="Abstract">arXiv:2404.18550</a> [<a href="/pdf/2404.18550" title="Download PDF">pdf</a>, <a href="/format/2404.18550" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> IncidentResponseGPT: Generating Traffic Incident Response Plans with  Generative Artificial Intelligence
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Grigorev%2C+A">Artur Grigorev</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Saleh%2C+K">Khaled Saleh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ou%2C+Y">Yuming Ou</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)
  
  </div>
  <p class="mathjax">Traffic congestion due to road incidents poses a significant challenge in
  urban environments, leading to increased pollution, economic losses, and
  traffic congestion. Efficiently managing these incidents is imperative for
  mitigating their adverse effects; however, the complexity of urban traffic
  systems and the variety of potential incidents represent a considerable
  obstacle. This paper introduces IncidentResponseGPT, an innovative solution
  designed to assist traffic management authorities by providing rapid, informed,
  and adaptable traffic incident response plans. By integrating a Generative AI
  platform with real-time traffic incident reports and operational guidelines,
  our system aims to streamline the decision-making process in responding to
  traffic incidents. The research addresses the critical challenges involved in
  deploying AI in traffic management, including overcoming the complexity of
  urban traffic networks, ensuring real-time decision-making capabilities,
  aligning with local laws and regulations, and securing public acceptance for
  AI-driven systems. Through a combination of text analysis of accident reports,
  validation of AI recommendations through traffic simulation, and implementation
  of transparent and validated AI systems, IncidentResponseGPT offers a promising
  approach to optimizing traffic flow and reducing congestion in the face of
  traffic incidents. The relevance of this work extends to traffic management
  authorities, emergency response teams, and municipal bodies, all integral
  stakeholders in urban traffic control and incident management. By proposing a
  novel solution to the identified challenges, this research aims to develop a
  framework that not only facilitates faster resolution of traffic incidents but
  also minimizes their overall impact on urban traffic systems.
  </p>
  </div>
  </dd>
  <dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18552" title="Abstract">arXiv:2404.18552</a> [<a href="/pdf/2404.18552" title="Download PDF">pdf</a>, <a href="/format/2404.18552" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SIDBench: A Python Framework for Reliably Assessing Synthetic Image  Detection Methods
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Schinas%2C+M">Manos Schinas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Papadopoulos%2C+S">Symeon Papadopoulos</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">The generative AI technology offers an increasing variety of tools for
  generating entirely synthetic images that are increasingly indistinguishable
  from real ones. Unlike methods that alter portions of an image, the creation of
  completely synthetic images presents a unique challenge and several Synthetic
  Image Detection (SID) methods have recently appeared to tackle it. Yet, there
  is often a large gap between experimental results on benchmark datasets and the
  performance of methods in the wild. To better address the evaluation needs of
  SID and help close this gap, this paper introduces a benchmarking framework
  that integrates several state-of-the-art SID models. Our selection of
  integrated models was based on the utilization of varied input features, and
  different network architectures, aiming to encompass a broad spectrum of
  techniques. The framework leverages recent datasets with a diverse set of
  generative models, high level of photo-realism and resolution, reflecting the
  rapid improvements in image synthesis technology. Additionally, the framework
  enables the study of how image transformations, common in assets shared online,
  such as JPEG compression, affect detection performance. SIDBench is available
  on https://github.com/mever-team/sidbench and is designed in a modular manner
  to enable easy inclusion of new datasets and SID models.
  </p>
  </div>
  </dd>
  <dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18553" title="Abstract">arXiv:2404.18553</a> [<a href="/pdf/2404.18553" title="Download PDF">pdf</a>, <a href="/format/2404.18553" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Evaluating the effectiveness of predicting covariates in LSTM Networks  for Time Series Forecasting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Davies%2C+G">Gareth Davies</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 content pages (22 total pages), 11 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Autoregressive Recurrent Neural Networks are widely employed in time-series
  forecasting tasks, demonstrating effectiveness in univariate and certain
  multivariate scenarios. However, their inherent structure does not readily
  accommodate the integration of future, time-dependent covariates. A proposed
  solution, outlined by Salinas et al 2019, suggests forecasting both covariates
  and the target variable in a multivariate framework. In this study, we
  conducted comprehensive tests on publicly available time-series datasets,
  artificially introducing highly correlated covariates to future time-step
  values. Our evaluation aimed to assess the performance of an LSTM network when
  considering these covariates and compare it against a univariate baseline. As
  part of this study we introduce a novel approach using seasonal time segments
  in combination with an RNN architecture, which is both simple and extremely
  effective over long forecast horizons with comparable performance to many state
  of the art architectures. Our findings from the results of more than 120 models
  reveal that under certain conditions jointly training covariates with target
  variables can improve overall performance of the model, but often there exists
  a significant performance disparity between multivariate and univariate
  predictions. Surprisingly, even when provided with covariates informing the
  network about future target values, multivariate predictions exhibited inferior
  performance. In essence, compelling the network to predict multiple values can
  prove detrimental to model performance, even in the presence of informative
  covariates. These results suggest that LSTM architectures may not be suitable
  for forecasting tasks where predicting covariates would typically be expected
  to enhance model accuracy.
  </p>
  </div>
  </dd>
  <dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18557" title="Abstract">arXiv:2404.18557</a> [<a href="/pdf/2404.18557" title="Download PDF">pdf</a>, <a href="/format/2404.18557" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Can GPT-4 do L2 analytic assessment?
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bann%C3%B2%2C+S">Stefano Bannò</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vydana%2C+H+K">Hari Krishna Vydana</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Knill%2C+K+M">Kate M. Knill</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gales%2C+M+J+F">Mark J. F. Gales</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted for the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Automated essay scoring (AES) to evaluate second language (L2) proficiency
  has been a firmly established technology used in educational contexts for
  decades. Although holistic scoring has seen advancements in AES that match or
  even exceed human performance, analytic scoring still encounters issues as it
  inherits flaws and shortcomings from the human scoring process. The recent
  introduction of large language models presents new opportunities for automating
  the evaluation of specific aspects of L2 writing proficiency. In this paper, we
  perform a series of experiments using GPT-4 in a zero-shot fashion on a
  publicly available dataset annotated with holistic scores based on the Common
  European Framework of Reference and aim to extract detailed information about
  their underlying analytic components. We observe significant correlations
  between the automatically predicted analytic scores and multiple features
  associated with the individual proficiency components.
  </p>
  </div>
  </dd>
  <dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18558" title="Abstract">arXiv:2404.18558</a> [<a href="/pdf/2404.18558" title="Download PDF">pdf</a>, <a href="/format/2404.18558" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LangBiTe: A Platform for Testing Bias in Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Morales%2C+S">Sergio Morales</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Claris%C3%B3%2C+R">Robert Clarisó</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cabot%2C+J">Jordi Cabot</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">The integration of Large Language Models (LLMs) into various software
  applications raises concerns about their potential biases. Typically, those
  models are trained on a vast amount of data scrapped from forums, websites,
  social media and other internet sources, which may instill harmful and
  discriminating behavior into the model. To address this issue, we present
  LangBiTe, a testing platform to systematically assess the presence of biases
  within an LLM. LangBiTe enables development teams to tailor their test
  scenarios, and automatically generate and execute the test cases according to a
  set of user-defined ethical requirements. Each test consists of a prompt fed
  into the LLM and a corresponding test oracle that scrutinizes the LLM's
  response for the identification of biases. LangBite provides users with the
  bias evaluation of LLMs, and end-to-end traceability between the initial
  ethical requirements and the insights obtained.
  </p>
  </div>
  </dd>
  <dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18562" title="Abstract">arXiv:2404.18562</a> [<a href="/pdf/2404.18562" title="Download PDF">pdf</a>, <a href="/ps/2404.18562" title="Download PostScript">ps</a>, <a href="/format/2404.18562" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Time Reversal for Near-Field Communications on Multi-chip Wireless  Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rodr%C3%ADguez-Gal%C3%A1n%2C+F">Fátima Rodríguez-Galán</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bandara%2C+A">Ama Bandara</a>, 
  <a href="/search/cs?searchtype=author&amp;query=de+Santana%2C+E+P">Elana Pereira de Santana</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bol%C3%ADvar%2C+P+H">Peter Haring Bolívar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Alarc%C3%B3n%2C+E">Eduard Alarcón</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Abadal%2C+S">Sergi Abadal</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>
  
  </div>
  <p class="mathjax">Wireless Network-on-Chip (WNoC) has been proposed as a low-latency,
  versatile, and broadcast-capable complement to current interconnects in the
  quest for satisfying the ever-increasing communications needs of modern
  computing systems. However, to realize the promise of WNoC, multiple wireless
  links operating at several tens of Gb/s need to be created within a computing
  package. Unfortunately, the highly integrated and enclosed nature of such
  computing packages incurs significant Co-Channel Interference (CCI) and
  Inter-Symbol Interference (ISI), not only preventing the deployment of multiple
  spatial channels, but also severely limiting the symbol rate of each individual
  channel. In this work, Time Reversal (TR) is proposed as a means to compensate
  the channel impairments and enable multiple concurrent high-speed links at the
  chip scale. We offer evidence, via full-wave simulations at 140 GHz, that TR
  can increase the symbol rate by an order of magnitude and allow the deployment
  of multiple concurrent links towards achieving aggregate speeds in excess of
  100 Gb/s. Finally, the challenges relative to the realization of TR at the chip
  scale are analyzed from the implementation, protocol support, and architectural
  perspectives.
  </p>
  </div>
  </dd>
  <dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18564" title="Abstract">arXiv:2404.18564</a> [<a href="/pdf/2404.18564" title="Download PDF">pdf</a>, <a href="/format/2404.18564" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Injecting Salesperson's Dialogue Strategies in Large Language Models  with Chain-of-Thought Reasoning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chang%2C+W">Wen-Yu Chang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yun-Nung Chen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2308.14266">arXiv:2308.14266</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Recent research in dialogue systems and corpora has focused on two main
  categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD
  systems help users accomplish specific tasks, while open-domain systems aim to
  create engaging conversations. However, in real-world scenarios, user intents
  are often revealed during interactions. A recent study introduced SalesBot,
  which simulates dialogues transitioning from chit-chat to task-oriented
  scenarios to train sales agents. Unfortunately, the initial data lacked smooth
  transitions and coherent long-turn dialogues, resulting in poor naturalness in
  sales-customer interactions. To address these issues, this paper presents
  SalesBot 2.0, an improved dataset. It leverages commonsense knowledge from
  large language models (LLMs) through strategic prompting. Additionally, we
  introduce a novel model called SalesAgent, trained on salesperson's
  interactions, using chain-of-thought (CoT) reasoning. This model excels in
  transitioning topics, understanding user intents, and selecting appropriate
  strategies. Experiments using diverse user simulations validate the
  effectiveness of our method in controlling dialogue strategies in LLMs.
  Furthermore, SalesBot 2.0 enhances coherence and reduces aggression,
  facilitating better model learning for sales-customer interactions.
  </p>
  </div>
  </dd>
  <dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18567" title="Abstract">arXiv:2404.18567</a> [<a href="/pdf/2404.18567" title="Download PDF">pdf</a>, <a href="/format/2404.18567" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Assessing Cybersecurity Vulnerabilities in Code Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hossen%2C+M+I">Md Imran Hossen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jianyi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+Y">Yinzhi Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hei%2C+X">Xiali Hei</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>
  
  </div>
  <p class="mathjax">Instruction-tuned Code Large Language Models (Code LLMs) are increasingly
  utilized as AI coding assistants and integrated into various applications.
  However, the cybersecurity vulnerabilities and implications arising from the
  widespread integration of these models are not yet fully understood due to
  limited research in this domain. To bridge this gap, this paper presents
  EvilInstructCoder, a framework specifically designed to assess the
  cybersecurity vulnerabilities of instruction-tuned Code LLMs to adversarial
  attacks. EvilInstructCoder introduces the Adversarial Code Injection Engine to
  automatically generate malicious code snippets and inject them into benign code
  to poison instruction tuning datasets. It incorporates practical threat models
  to reflect real-world adversaries with varying capabilities and evaluates the
  exploitability of instruction-tuned Code LLMs under these diverse adversarial
  attack scenarios. Through the use of EvilInstructCoder, we conduct a
  comprehensive investigation into the exploitability of instruction tuning for
  coding tasks using three state-of-the-art Code LLM models: CodeLlama,
  DeepSeek-Coder, and StarCoder2, under various adversarial attack scenarios. Our
  experimental results reveal a significant vulnerability in these models,
  demonstrating that adversaries can manipulate the models to generate malicious
  payloads within benign code contexts in response to natural language
  instructions. For instance, under the backdoor attack setting, by poisoning
  only 81 samples (0.5\% of the entire instruction dataset), we achieve Attack
  Success Rate at 1 (ASR@1) scores ranging from 76\% to 86\% for different model
  families. Our study sheds light on the critical cybersecurity vulnerabilities
  posed by instruction-tuned Code LLMs and emphasizes the urgent necessity for
  robust defense mechanisms to mitigate the identified vulnerabilities.
  </p>
  </div>
  </dd>
  <dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18568" title="Abstract">arXiv:2404.18568</a> [<a href="/pdf/2404.18568" title="Download PDF">pdf</a>, <a href="/format/2404.18568" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multigrid method for nonlinear eigenvalue problems based on Newton  iteration
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Xu%2C+F">Fei Xu</a>, 
  <a href="/search/math?searchtype=author&amp;query=Xie%2C+M">Manting Xie</a>, 
  <a href="/search/math?searchtype=author&amp;query=Yue%2C+M">Meiling Yue</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">In this paper, a novel multigrid method based on Newton iteration is proposed
  to solve nonlinear eigenvalue problems. Instead of handling the eigenvalue
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-201-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1319" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1320"><span class="mi" id="MathJax-Span-1321" style="font-family: STIXGeneral-Italic;">λ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-201">\lambda</script> and eigenfunction <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-202-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1322" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1323"><span class="mi" id="MathJax-Span-1324" style="font-family: STIXGeneral-Italic;">u</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-202">u</script> separately, we treat the eigenpair <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-203-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1325" style="width: 2.6em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.092em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.035em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1326"><span class="mo" id="MathJax-Span-1327" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1328" style="font-family: STIXGeneral-Italic;">λ</span><span class="mo" id="MathJax-Span-1329" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-1330" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">u</span><span class="mo" id="MathJax-Span-1331" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-203">(\lambda,
  u)</script> as one element in a product space <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-204-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1332" style="width: 5.592em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.52em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1004.463em, 3.052em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1333"><span class="texatom" id="MathJax-Span-1334"><span class="mrow" id="MathJax-Span-1335"><span class="mi" id="MathJax-Span-1336" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span class="mo" id="MathJax-Span-1337" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">×</span><span class="msubsup" id="MathJax-Span-1338" style="padding-left: 0.229em;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.793em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1339" style="font-family: STIXGeneral-Italic;">H<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.345em; left: 0.85em;"><span class="mn" id="MathJax-Span-1340" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -3.667em; left: 0.737em;"><span class="mn" id="MathJax-Span-1341" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1342" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1343" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-1344" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.531em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-204">\mathbb R \times H_0^1(\Omega)</script>. Then in
  the presented multigrid method, only one discrete linear boundary value problem
  needs to be solved for each level of the multigrid sequence. Because we avoid
  solving large-scale nonlinear eigenvalue problems directly, the overall
  efficiency is significantly improved. The optimal error estimate and linear
  computational complexity can be derived simultaneously. In addition, we also
  provide an improved multigrid method coupled with a mixing scheme to further
  guarantee the convergence and stability of the iteration scheme. More
  importantly, we prove convergence for the residuals after each iteration step.
  For nonlinear eigenvalue problems, such theoretical analysis is missing from
  the existing literatures on the mixing iteration scheme.
  </p>
  </div>
  </dd>
  <dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18569" title="Abstract">arXiv:2404.18569</a> [<a href="/pdf/2404.18569" title="Download PDF">pdf</a>, <a href="/ps/2404.18569" title="Download PostScript">ps</a>, <a href="/format/2404.18569" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exponential Convergence of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-205-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1345" style="width: 1.302em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.033em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1000.988em, 2.87em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-1346"><span class="mi" id="MathJax-Span-1347" style="font-family: STIXGeneral-Italic;">h</span><span class="mi" id="MathJax-Span-1348" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.331em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.225em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-205">hp</script>-ILGFEM for semilinear elliptic boundary  value problems with monomial reaction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=He%2C+Y">Yanchen He</a>, 
  <a href="/search/math?searchtype=author&amp;query=Houston%2C+P">Paul Houston</a>, 
  <a href="/search/math?searchtype=author&amp;query=Schwab%2C+C">Christoph Schwab</a>, 
  <a href="/search/math?searchtype=author&amp;query=Wihler%2C+T+P">Thomas P. Wihler</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">We study the fully explicit numerical approximation of a semilinear elliptic
  boundary value model problem, which features a monomial reaction and analytic
  forcing, in a bounded polygon <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-206-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1349" style="width: 4.124em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.334em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1003.334em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1350"><span class="mi" id="MathJax-Span-1351" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-1352" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">⊂</span><span class="msubsup" id="MathJax-Span-1353" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 1.188em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1354"><span class="mrow" id="MathJax-Span-1355"><span class="mi" id="MathJax-Span-1356" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.737em;"><span class="mn" id="MathJax-Span-1357" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-206">\Omega\subset\mathbb{R}^2</script> with a finite number
  of straight edges. In particular, we analyze the convergence of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-207-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1358" style="width: 1.245em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.963em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1359"><span class="mi" id="MathJax-Span-1360" style="font-family: STIXGeneral-Italic;">h</span><span class="mi" id="MathJax-Span-1361" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-207">hp</script>-type
  iterative linearized Galerkin (<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-208-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1362" style="width: 1.245em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.963em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1363"><span class="mi" id="MathJax-Span-1364" style="font-family: STIXGeneral-Italic;">h</span><span class="mi" id="MathJax-Span-1365" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-208">hp</script>-ILG) solvers. Our convergence analysis is
  carried out for conforming <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-209-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1366" style="width: 1.245em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.963em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1367"><span class="mi" id="MathJax-Span-1368" style="font-family: STIXGeneral-Italic;">h</span><span class="mi" id="MathJax-Span-1369" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-209">hp</script>-finite element (FE) Galerkin discretizations on
  sequences of regular, simplicial partitions of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-210-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1370" style="width: 1.019em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.793em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1371"><span class="mi" id="MathJax-Span-1372" style="font-family: STIXGeneral-Regular;">Ω</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-210">\Omega</script>, with geometric corner
  refinement, with polynomial degrees increasing in sync with the geometric mesh
  refinement towards the corners of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-211-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1373" style="width: 1.019em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.793em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1374"><span class="mi" id="MathJax-Span-1375" style="font-family: STIXGeneral-Regular;">Ω</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-211">\Omega</script>. For a sequence of discrete
  solutions generated by the ILG solver, with a stopping criterion that is
  consistent with the exponential convergence of the exact <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-212-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1376" style="width: 1.245em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.963em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1377"><span class="mi" id="MathJax-Span-1378" style="font-family: STIXGeneral-Italic;">h</span><span class="mi" id="MathJax-Span-1379" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-212">hp</script>-FE Galerkin
  solution, we prove exponential convergence in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-213-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1380" style="width: 3.221em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.6em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1002.543em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1381"><span class="msubsup" id="MathJax-Span-1382"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1383"><span class="mrow" id="MathJax-Span-1384"><span class="mi" id="MathJax-Span-1385" style="font-family: STIXGeneral-Regular;">H</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.737em;"><span class="mn" id="MathJax-Span-1386" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1387" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1388" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-1389" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-213">\mathrm{H}^1(\Omega)</script> to the
  unique weak solution of the boundary value problem. Numerical experiments
  illustrate the exponential convergence of the numerical approximations obtained
  from the proposed scheme in terms of the number of degrees of freedom as well
  as of the computational complexity involved.
  </p>
  </div>
  </dd>
  <dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18570" title="Abstract">arXiv:2404.18570</a> [<a href="/pdf/2404.18570" title="Download PDF">pdf</a>, <a href="/format/2404.18570" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Analyzing Semantic Change through Lexical Replacements
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Periti%2C+F">Francesco Periti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cassotti%2C+P">Pierluigi Cassotti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dubossarsky%2C+H">Haim Dubossarsky</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tahmasebi%2C+N">Nina Tahmasebi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Modern language models are capable of contextualizing words based on their
  surrounding context. However, this capability is often compromised due to
  semantic change that leads to words being used in new, unexpected contexts not
  encountered during pre-training. In this paper, we model \textit{semantic
  change} by studying the effect of unexpected contexts introduced by
  \textit{lexical replacements}. We propose a \textit{replacement schema} where a
  target word is substituted with lexical replacements of varying relatedness,
  thus simulating different kinds of semantic change. Furthermore, we leverage
  the replacement schema as a basis for a novel \textit{interpretable} model for
  semantic change. We are also the first to evaluate the use of LLaMa for
  semantic change detection.
  </p>
  </div>
  </dd>
  <dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18572" title="Abstract">arXiv:2404.18572</a> [<a href="/pdf/2404.18572" title="Download PDF">pdf</a>, <a href="/format/2404.18572" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning Governing Equations of Unobserved States in Dynamical Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Grigorian%2C+G">Gevik Grigorian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=George%2C+S+V">Sandip V. George</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Arridge%2C+S">Simon Arridge</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Data driven modelling and scientific machine learning have been responsible
  for significant advances in determining suitable models to describe data.
  Within dynamical systems, neural ordinary differential equations (ODEs), where
  the system equations are set to be governed by a neural network, have become a
  popular tool for this challenge in recent years. However, less emphasis has
  been placed on systems that are only partially-observed. In this work, we
  employ a hybrid neural ODE structure, where the system equations are governed
  by a combination of a neural network and domain-specific knowledge, together
  with symbolic regression (SR), to learn governing equations of
  partially-observed dynamical systems. We test this approach on two case
  studies: A 3-dimensional model of the Lotka-Volterra system and a 5-dimensional
  model of the Lorenz system. We demonstrate that the method is capable of
  successfully learning the true underlying governing equations of unobserved
  states within these systems, with robustness to measurement noise.
  </p>
  </div>
  </dd>
  <dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18573" title="Abstract">arXiv:2404.18573</a> [<a href="/pdf/2404.18573" title="Download PDF">pdf</a>, <a href="/format/2404.18573" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Predicting Safety Misbehaviours in Autonomous Driving Systems using  Uncertainty Quantification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Grewal%2C+R">Ruben Grewal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tonella%2C+P">Paolo Tonella</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stocco%2C+A">Andrea Stocco</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> In Proceedings of 17th IEEE International Conference on Software Testing, Verification and Validation 2024 (ICST '24)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO); Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">The automated real-time recognition of unexpected situations plays a crucial
  role in the safety of autonomous vehicles, especially in unsupported and
  unpredictable scenarios. This paper evaluates different Bayesian uncertainty
  quantification methods from the deep learning domain for the anticipatory
  testing of safety-critical misbehaviours during system-level simulation-based
  testing. Specifically, we compute uncertainty scores as the vehicle executes,
  following the intuition that high uncertainty scores are indicative of
  unsupported runtime conditions that can be used to distinguish safe from
  failure-inducing driving behaviors. In our study, we conducted an evaluation of
  the effectiveness and computational overhead associated with two Bayesian
  uncertainty quantification methods, namely MC- Dropout and Deep Ensembles, for
  misbehaviour avoidance. Overall, for three benchmarks from the Udacity
  simulator comprising both out-of-distribution and unsafe conditions introduced
  via mutation testing, both methods successfully detected a high number of
  out-of-bounds episodes providing early warnings several seconds in advance,
  outperforming two state-of-the-art misbehaviour prediction methods based on
  autoencoders and attention maps in terms of effectiveness and efficiency.
  Notably, Deep Ensembles detected most misbehaviours without any false alarms
  and did so even when employing a relatively small number of models, making them
  computationally feasible for real-time detection. Our findings suggest that
  incorporating uncertainty quantification methods is a viable approach for
  building fail-safe mechanisms in deep neural network-based autonomous vehicles.
  </p>
  </div>
  </dd>
  <dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18574" title="Abstract">arXiv:2404.18574</a> [<a href="/pdf/2404.18574" title="Download PDF">pdf</a>, <a href="/format/2404.18574" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> GEEvo: Game Economy Generation and Balancing with Evolutionary  Algorithms
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rupp%2C+F">Florian Rupp</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Eckert%2C+K">Kai Eckert</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 4 figures, 3 tables. Accepted at IEEE Congress on Evolutionary Computation (IEEE CEC) 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>
  
  </div>
  <p class="mathjax">Game economy design significantly shapes the player experience and
  progression speed. Modern game economies are becoming increasingly complex and
  can be very sensitive to even minor numerical adjustments, which may have an
  unexpected impact on the overall gaming experience. Consequently, thorough
  manual testing and fine-tuning during development are essential. Unlike
  existing works that address algorithmic balancing for specific games or genres,
  this work adopts a more abstract approach, focusing on game balancing through
  its economy, detached from a specific game. We propose GEEvo (Game Economy
  Evolution), a framework to generate graph-based game economies and balancing
  both, newly generated or existing economies. GEEvo uses a two-step approach
  where evolutionary algorithms are used to first generate an economy and then
  balance it based on specified objectives, such as generated resources or damage
  dealt over time. We define different objectives by differently parameterizing
  the fitness function using data from multiple simulation runs of the economy.
  To support this, we define a lightweight and flexible game economy simulation
  framework. Our method is tested and benchmarked with various balancing
  objectives on a generated dataset, and we conduct a case study evaluating
  damage balancing for two fictional economies of two popular game character
  classes.
  </p>
  </div>
  </dd>
  <dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18575" title="Abstract">arXiv:2404.18575</a> [<a href="/pdf/2404.18575" title="Download PDF">pdf</a>, <a href="/format/2404.18575" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Comparing Z3 and A3 PKM Heads: Which Is Superior and Why?
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nigatu%2C+H">Hassen Nigatu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> submit
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">This study presents a comparison between the Sprint Z3 and A3 head parallel
  kinematics machines, distinguished by their joint sequence. The analysis
  focuses on performance attributes critical for precision machining
  specifically, parasitic motion, workspace capability, stiffness performance
  over the independent and parasitic spaces, and condition number distribution.
  Although these machines are extensively utilized in precision machining for the
  aerospace and automotive industries, a definitive superior choice has not been
  identified for machining large components. Moreover, the distribution of
  stiffness across the configuration of parasitic space has not previously been
  addressed for either mechanism. This research reveals that despite identical
  parameters used and exhibiting similar parasitic motions, the Sprint Z3
  demonstrates superior stiffness, workspace volume, and condition number
  distribution. This performance advantage is attributed to variations in joint
  and link sequence, which enhance deflection resilience, crucial for
  manufacturing large-scale components. This also results in a higher condition
  number and a larger workspace. The result highlights the importance of design
  architecture in the efficacy of parallel kinematics machines and suggest
  </p>
  </div>
  </dd>
  <dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18577" title="Abstract">arXiv:2404.18577</a> [<a href="/pdf/2404.18577" title="Download PDF">pdf</a>, <a href="/format/2404.18577" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Assessing Quality Metrics for Neural Reality Gap Input Mitigation in  Autonomous Driving Testing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lambertenghi%2C+S+C">Stefano Carlo Lambertenghi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stocco%2C+A">Andrea Stocco</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> In Proceedings of 17th IEEE International Conference on Software Testing, Verification and Validation 2024 (ICST '24)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Simulation-based testing of automated driving systems (ADS) is the industry
  standard, being a controlled, safe, and cost-effective alternative to
  real-world testing. Despite these advantages, virtual simulations often fail to
  accurately replicate real-world conditions like image fidelity, texture
  representation, and environmental accuracy. This can lead to significant
  differences in ADS behavior between simulated and real-world domains, a
  phenomenon known as the sim2real gap. Researchers have used Image-to-Image
  (I2I) neural translation to mitigate the sim2real gap, enhancing the realism of
  simulated environments by transforming synthetic data into more authentic
  representations of real-world conditions. However, while promising, these
  techniques may potentially introduce artifacts, distortions, or inconsistencies
  in the generated data that can affect the effectiveness of ADS testing. In our
  empirical study, we investigated how the quality of image-to-image (I2I)
  techniques influences the mitigation of the sim2real gap, using a set of
  established metrics from the literature. We evaluated two popular generative
  I2I architectures, pix2pix, and CycleGAN, across two ADS perception tasks at a
  model level, namely vehicle detection and end-to-end lane keeping, using paired
  simulated and real-world datasets. Our findings reveal that the effectiveness
  of I2I architectures varies across different ADS tasks, and existing evaluation
  metrics do not consistently align with the ADS behavior. Thus, we conducted
  task-specific fine-tuning of perception metrics, which yielded a stronger
  correlation. Our findings indicate that a perception metric that incorporates
  semantic elements, tailored to each task, can facilitate selecting the most
  appropriate I2I technique for a reliable assessment of the sim2real gap
  mitigation.
  </p>
  </div>
  </dd>
  <dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18580" title="Abstract">arXiv:2404.18580</a> [<a href="/pdf/2404.18580" title="Download PDF">pdf</a>, <a href="/format/2404.18580" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Data-Driven Dynamics Modeling of Miniature Robotic Blimps Using Neural  ODEs With Parameter Auto-Tuning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yongjian Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+H">Hao Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+F">Feitian Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 8 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)
  
  </div>
  <p class="mathjax">Miniature robotic blimps, as one type of lighter-than-air aerial vehicles,
  have attracted increasing attention in the science and engineering community
  for their enhanced safety, extended endurance, and quieter operation compared
  to quadrotors. Accurately modeling the dynamics of these robotic blimps poses a
  significant challenge due to the complex aerodynamics stemming from their large
  lifting bodies. Traditional first-principle models have difficulty obtaining
  accurate aerodynamic parameters and often overlook high-order nonlinearities,
  thus coming to its limit in modeling the motion dynamics of miniature robotic
  blimps. To tackle this challenge, this letter proposes the Auto-tuning
  Blimp-oriented Neural Ordinary Differential Equation method (ABNODE), a
  data-driven approach that integrates first-principle and neural network
  modeling. Spiraling motion experiments of robotic blimps are conducted,
  comparing the ABNODE with first-principle and other data-driven benchmark
  models, the results of which demonstrate the effectiveness of the proposed
  method.
  </p>
  </div>
  </dd>
  <dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18583" title="Abstract">arXiv:2404.18583</a> [<a href="/pdf/2404.18583" title="Download PDF">pdf</a>, <a href="/format/2404.18583" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Context Matters: Leveraging Spatiotemporal Metadata for Semi-Supervised  Learning on Remote Sensing Images
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bernhard%2C+M">Maximilian Bernhard</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hannan%2C+T">Tanveer Hannan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Strau%C3%9F%2C+N">Niklas Strauß</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schubert%2C+M">Matthias Schubert</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Remote sensing projects typically generate large amounts of imagery that can
  be used to train powerful deep neural networks. However, the amount of labeled
  images is often small, as remote sensing applications generally require expert
  labelers. Thus, semi-supervised learning (SSL), i.e., learning with a small
  pool of labeled and a larger pool of unlabeled data, is particularly useful in
  this domain. Current SSL approaches generate pseudo-labels from model
  predictions for unlabeled samples. As the quality of these pseudo-labels is
  crucial for performance, utilizing additional information to improve
  pseudo-label quality yields a promising direction. For remote sensing images,
  geolocation and recording time are generally available and provide a valuable
  source of information as semantic concepts, such as land cover, are highly
  dependent on spatiotemporal context, e.g., due to seasonal effects and
  vegetation zones. In this paper, we propose to exploit spatiotemporal
  metainformation in SSL to improve the quality of pseudo-labels and, therefore,
  the final model performance. We show that directly adding the available
  metadata to the input of the predictor at test time degenerates the prediction
  quality for metadata outside the spatiotemporal distribution of the training
  set. Thus, we propose a teacher-student SSL framework where only the teacher
  network uses metainformation to improve the quality of pseudo-labels on the
  training set. Correspondingly, our student network benefits from the improved
  pseudo-labels but does not receive metadata as input, making it invariant to
  spatiotemporal shifts at test time. Furthermore, we propose methods for
  encoding and injecting spatiotemporal information into the model and introduce
  a novel distillation mechanism to enhance the knowledge transfer between
  teacher and student. Our framework dubbed Spatiotemporal SSL can be easily
  combined with several stat...
  </p>
  </div>
  </dd>
  <dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18584" title="Abstract">arXiv:2404.18584</a> [<a href="/pdf/2404.18584" title="Download PDF">pdf</a>, <a href="/ps/2404.18584" title="Download PostScript">ps</a>, <a href="/format/2404.18584" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Controller Synthesis in Timed Büchi Automata: Robustness and Punctual  Guards
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Barbot%2C+B">Benoît Barbot</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Busatto-Gaston%2C+D">Damien Busatto-Gaston</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dima%2C+C">Catalin Dima</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oualhadj%2C+Y">Youssouf Oualhadj</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>
  
  </div>
  <p class="mathjax">We consider the synthesis problem on timed automata with B\"uchi objectives,
  where delay choices made by a controller are subjected to small perturbations.
  Usually, the controller needs to avoid punctual guards, such as testing the
  equality of a clock to a constant. In this work, we generalize to a robustness
  setting that allows for punctual transitions in the automaton to be taken by
  controller with no perturbation. In order to characterize cycles that resist
  perturbations in our setting, we introduce a new structural requirement on the
  reachability relation along an accepting cycle of the automaton. This property
  is formulated on the region abstraction, and generalizes the existing
  characterization of winning cycles in the absence of punctual guards. We show
  that the problem remains within PSPACE despite the presence of punctual guards.
  </p>
  </div>
  </dd>
  <dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18585" title="Abstract">arXiv:2404.18585</a> [<a href="/pdf/2404.18585" title="Download PDF">pdf</a>, <a href="/format/2404.18585" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table  Question Answering
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+W">Wei Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mesgar%2C+M">Mohsen Mesgar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Adel%2C+H">Heike Adel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Friedrich%2C+A">Annemarie Friedrich</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at NAACL 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Table Question Answering (TQA) aims at composing an answer to a question
  based on tabular data. While prior research has shown that TQA models lack
  robustness, understanding the underlying cause and nature of this issue remains
  predominantly unclear, posing a significant obstacle to the development of
  robust TQA systems. In this paper, we formalize three major desiderata for a
  fine-grained evaluation of robustness of TQA systems. They should (i) answer
  questions regardless of alterations in table structure, (ii) base their
  responses on the content of relevant cells rather than on biases, and (iii)
  demonstrate robust numerical reasoning capabilities. To investigate these
  aspects, we create and publish a novel TQA evaluation benchmark in English. Our
  extensive experimental analysis reveals that none of the examined
  state-of-the-art TQA systems consistently excels in these three aspects. Our
  benchmark is a crucial instrument for monitoring the behavior of TQA systems
  and paves the way for the development of robust TQA systems. We release our
  benchmark publicly.
  </p>
  </div>
  </dd>
  <dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18587" title="Abstract">arXiv:2404.18587</a> [<a href="/pdf/2404.18587" title="Download PDF">pdf</a>, <a href="/ps/2404.18587" title="Download PostScript">ps</a>, <a href="/format/2404.18587" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Unlocking Potentials of Near-Field Propagation: ELAA-Empowered  Integrated Sensing and Communication
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+Z">Zhenyao He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Wei Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhaohui Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shen%2C+H">Hong Shen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fu%2C+N">Ningning Fu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yongming Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=You%2C+X">Xiaohu You</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">The exploration of extremely large antenna arrays (ELAAs) using
  high-frequency spectrum has led to a paradigm shift in electromagnetic
  radiation field, transitioning from the common use case of far-field
  propagation to near-field propagation. This shift necessitates the modification
  of the conventional planar-wavefront approximation to more accurate spherical
  waves, exerting a profound impact on wireless transmission technologies
  encompassing communication and sensing. Concurrently, integrated sensing and
  communication (ISAC) has gained prominence in the context of the
  sixth-generation (6G) wireless networks owing to its ability to cater to the
  ever-increasing demands of future networks. In line with this evolving trend,
  this article presents a systematical investigation on ELAA-empowered near-field
  ISAC. We begin by introducing the fundamentals of near-field propagation with
  an emphasis on its double-edged effects to near-field communications. Then, we
  turn to near-field sensing and expound upon various typical applications.
  Following the separate elaborations on communications and sensing, we
  articulate in-depth advantages of ELAA-empowered ISAC in near field,
  particularly including featured opportunities arising from the dual-functional
  integrations, potential ISAC applications benefiting from the additional
  degrees-of-freedom in near field, and enablements of other complementary
  technologies. Finally, we outline key technical challenges that merit further
  exploration in the realm of ELAA-empowered near-field ISAC.
  </p>
  </div>
  </dd>
  <dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18591" title="Abstract">arXiv:2404.18591</a> [<a href="/pdf/2404.18591" title="Download PDF">pdf</a>, <a href="/format/2404.18591" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FashionSD-X: Multimodal Fashion Garment Synthesis using Latent Diffusion
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Singh%2C+A+K">Abhishek Kumar Singh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Patras%2C+I">Ioannis Patras</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 8 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">The rapid evolution of the fashion industry increasingly intersects with
  technological advancements, particularly through the integration of generative
  AI. This study introduces a novel generative pipeline designed to transform the
  fashion design process by employing latent diffusion models. Utilizing
  ControlNet and LoRA fine-tuning, our approach generates high-quality images
  from multimodal inputs such as text and sketches. We leverage and enhance
  state-of-the-art virtual try-on datasets, including Multimodal Dress Code and
  VITON-HD, by integrating sketch data. Our evaluation, utilizing metrics like
  FID, CLIP Score, and KID, demonstrates that our model significantly outperforms
  traditional stable diffusion models. The results not only highlight the
  effectiveness of our model in generating fashion-appropriate outputs but also
  underscore the potential of diffusion models in revolutionizing fashion design
  workflows. This research paves the way for more interactive, personalized, and
  technologically enriched methodologies in fashion design and representation,
  bridging the gap between creative vision and practical application.
  </p>
  </div>
  </dd>
  <dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18593" title="Abstract">arXiv:2404.18593</a> [<a href="/pdf/2404.18593" title="Download PDF">pdf</a>, <a href="/format/2404.18593" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A hybrid prognosis approach for robust lifetime control of commercial  wind turbines
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Kipchirchir%2C+E">Edwin Kipchirchir</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Liebeton%2C+J">Jonathan Liebeton</a>, 
  <a href="/search/eess?searchtype=author&amp;query=S%C3%B6ffker%2C+D">Dirk Söffker</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Manuscript: 19 pages, 7 figures, 5 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  <p class="mathjax">Dynamic fluctuations in the wind field to which a wind turbine (WT) is
  exposed to are responsible for fatigue loads on its components. To reduce
  structural loads in WTs, advanced control schemes have been proposed. In recent
  years, prognosis-based lifetime control of WTs has become increasingly
  important. In this approach, the prognostic controller gains are adapted based
  on the stateof-health (SOH) of the WT component to achieve the desired
  lifetime. However, stochastic wind dynamics complicates estimation of the SOH
  of a WT. More recently, robust controllers have been combined with real-time
  damage evaluation models to meet prognosis objectives. Most rely on model-based
  online load cycle counting algorithms to determine fatigue damage, with
  analytical models providing the degradation estimate. However, most use load
  measurements that are either unreliable or unavailable in commercial WTs,
  limiting their practicality. In this contribution, a hybrid prognosis scheme
  combining data-driven load prediction and model-based damage estimation models
  for robust lifetime control of commercial WTs is proposed. A data-driven
  support vector machine (SVM) regression model is trained using loading data
  obtained from dynamic simulations using a {\mu}-synthesis robust disturbance
  accommodating controller (RDAC). The regression model uses available WT
  measurements to predict tower load. Based on this prediction, an online
  rain-flow counting (RFC) damage evaluation model estimates the damage level and
  lifetime of the tower. The RDAC controller gains are dynamically adapted to
  achieve a predefined damage limit and lifetime. The proposed approach is
  evaluated on a 5 MW reference WT and its performance is compared with a
  model-based prognosis scheme using ideal WT tower measurement. Results
  demonstrate the efficacy of the proposed approach to control the fatigue
  lifetime in WT components.
  </p>
  </div>
  </dd>
  <dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18596" title="Abstract">arXiv:2404.18596</a> [<a href="/pdf/2404.18596" title="Download PDF">pdf</a>, <a href="/format/2404.18596" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FauxPy: A Fault Localization Tool for Python
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rezaalipour%2C+M">Mohammad Rezaalipour</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Furia%2C+C+A">Carlo A. Furia</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">This paper presents FauxPy, a fault localization tool for Python programs.
  FauxPy supports seven well-known fault localization techniques in four
  families: spectrum-based, mutation-based, predicate switching, and stack trace
  fault localization. It is implemented as plugin of the popular Pytest testing
  framework, but also works with tests written for Unittest and Hypothesis (two
  other popular testing frameworks). The paper showcases how to use FauxPy on two
  illustrative examples, and then discusses its main features and capabilities
  from a user's perspective. To demonstrate that FauxPy is applicable to analyze
  Python projects of realistic size, the paper also summarizes the results of an
  extensive experimental evaluation that applied FauxPy to 135 real-world bugs
  from the BugsInPy curated collection. To our knowledge, FauxPy is the first
  open-source fault localization tool for Python that supports multiple fault
  localization families.
  </p>
  </div>
  </dd>
  <dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18598" title="Abstract">arXiv:2404.18598</a> [<a href="/pdf/2404.18598" title="Download PDF">pdf</a>, <a href="/format/2404.18598" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Anywhere: A Multi-Agent Framework for Reliable and Diverse  Foreground-Conditioned Image Inpainting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+T">Tianyidan Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+R">Rui Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qian Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+X">Xiaoqian Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+F">Feixuan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tai%2C+Y">Ying Tai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhenyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yi%2C+Z">Zili Yi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 16 pages, 9 figures, project page: <a href="https://anywheremultiagent.github.io">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
  
  </div>
  <p class="mathjax">Recent advancements in image inpainting, particularly through diffusion
  modeling, have yielded promising outcomes. However, when tested in scenarios
  involving the completion of images based on the foreground objects, current
  methods that aim to inpaint an image in an end-to-end manner encounter
  challenges such as "over-imagination", inconsistency between foreground and
  background, and limited diversity. In response, we introduce Anywhere, a
  pioneering multi-agent framework designed to address these issues. Anywhere
  utilizes a sophisticated pipeline framework comprising various agents such as
  Visual Language Model (VLM), Large Language Model (LLM), and image generation
  models. This framework consists of three principal components: the prompt
  generation module, the image generation module, and the outcome analyzer. The
  prompt generation module conducts a semantic analysis of the input foreground
  image, leveraging VLM to predict relevant language descriptions and LLM to
  recommend optimal language prompts. In the image generation module, we employ a
  text-guided canny-to-image generation model to create a template image based on
  the edge map of the foreground image and language prompts, and an image refiner
  to produce the outcome by blending the input foreground and the template image.
  The outcome analyzer employs VLM to evaluate image content rationality,
  aesthetic score, and foreground-background relevance, triggering prompt and
  image regeneration as needed. Extensive experiments demonstrate that our
  Anywhere framework excels in foreground-conditioned image inpainting,
  mitigating "over-imagination", resolving foreground-background discrepancies,
  and enhancing diversity. It successfully elevates foreground-conditioned image
  inpainting to produce more reliable and diverse results.
  </p>
  </div>
  </dd>
  <dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18602" title="Abstract">arXiv:2404.18602</a> [<a href="/pdf/2404.18602" title="Download PDF">pdf</a>, <a href="/format/2404.18602" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Unraveling the Italian and English Telegram Conspiracy Spheres through  Message Forwarding
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Alvisi%2C+L">Lorenzo Alvisi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tardelli%2C+S">Serena Tardelli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tesconi%2C+M">Maurizio Tesconi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> submitted to ASONAM 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>
  
  </div>
  <p class="mathjax">Telegram has grown into a significant platform for news and information
  sharing, favored for its anonymity and minimal moderation. This openness,
  however, makes it vulnerable to misinformation and conspiracy theories. In this
  study, we explore the dynamics of conspiratorial narrative dissemination within
  Telegram, focusing on Italian and English landscapes. In particular, we
  leverage the mechanism of message forwarding within Telegram and collect two
  extensive datasets through snowball strategy. We adopt a network-based approach
  and build the Italian and English Telegram networks to reveal their respective
  communities. By employing topic modeling, we uncover distinct narratives and
  dynamics of misinformation spread. Results highlight differences between
  Italian and English conspiracy landscapes, with Italian discourse involving
  assorted conspiracy theories and alternative news sources intertwined with
  legitimate news sources, whereas English discourse is characterized by a more
  focused approach on specific narratives such as QAnon and political
  conspiracies. Finally, we show that our methodology exhibits robustness across
  initial seed selections, suggesting broader applicability. This study
  contributes to understanding information and misinformation spread on Italian
  and English Telegram ecosystems through the mechanism of message forwarding
  </p>
  </div>
  </dd>
  <dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18603" title="Abstract">arXiv:2404.18603</a> [<a href="/pdf/2404.18603" title="Download PDF">pdf</a>, <a href="/format/2404.18603" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Beating Posits at Their Own Game: Takum Arithmetic
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Hunhold%2C+L">Laslo Hunhold</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 72 pages, 22 figures, Conference for Next Generation Arithmetic 2024 (CoNGA 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Data Structures and Algorithms (cs.DS)
  
  </div>
  <p class="mathjax">Recent evaluations have highlighted the tapered posit number format as a
  promising alternative to the uniform precision IEEE 754 floating-point numbers,
  which suffer from various deficiencies. Although the posit encoding scheme
  offers superior coding efficiency at values close to unity, its efficiency
  markedly diminishes with deviation from unity. This reduction in efficiency
  leads to suboptimal encodings and a consequent diminution in dynamic range,
  thereby rendering posits suboptimal for general-purpose computer arithmetic.
  <br>This paper introduces and formally proves 'takum' as a novel general-purpose
  logarithmic tapered-precision number format, synthesising the advantages of
  posits in low-bit applications with high encoding efficiency for numbers
  distant from unity. Takums exhibit an asymptotically constant dynamic range in
  terms of bit string length, which is delineated in the paper to be suitable for
  a general-purpose number format. It is demonstrated that takums either match or
  surpass existing alternatives. Moreover, takums address several issues
  previously identified in posits while unveiling novel and beneficial arithmetic
  properties.
  </p>
  </div>
  </dd>
  <dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18604" title="Abstract">arXiv:2404.18604</a> [<a href="/pdf/2404.18604" title="Download PDF">pdf</a>, <a href="/format/2404.18604" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CSTalk: Correlation Supervised Speech-driven 3D Emotional Facial  Animation Generation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+X">Xiangyu Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+W">Wenlin Zhuang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Tianyong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Geng%2C+G">Guangxing Geng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Geng%2C+G">Guangyue Geng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xia%2C+H">Haifeng Xia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xia%2C+S">Siyu Xia</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Speech-driven 3D facial animation technology has been developed for years,
  but its practical application still lacks expectations. The main challenges lie
  in data limitations, lip alignment, and the naturalness of facial expressions.
  Although lip alignment has seen many related studies, existing methods struggle
  to synthesize natural and realistic expressions, resulting in a mechanical and
  stiff appearance of facial animations. Even with some research extracting
  emotional features from speech, the randomness of facial movements limits the
  effective expression of emotions. To address this issue, this paper proposes a
  method called CSTalk (Correlation Supervised) that models the correlations
  among different regions of facial movements and supervises the training of the
  generative model to generate realistic expressions that conform to human facial
  motion patterns. To generate more intricate animations, we employ a rich set of
  control parameters based on the metahuman character model and capture a dataset
  for five different emotions. We train a generative network using an autoencoder
  structure and input an emotion embedding vector to achieve the generation of
  user-control expressions. Experimental results demonstrate that our method
  outperforms existing state-of-the-art methods.
  </p>
  </div>
  </dd>
  <dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18610" title="Abstract">arXiv:2404.18610</a> [<a href="/pdf/2404.18610" title="Download PDF">pdf</a>, <a href="/format/2404.18610" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Differentiable Geodesic Distance for Intrinsic Minimization on Triangle  Meshes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yue Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Numerow%2C+L">Logan Numerow</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Thomaszewski%2C+B">Bernhard Thomaszewski</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Coros%2C+S">Stelian Coros</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computational Geometry (cs.CG)
  
  </div>
  <p class="mathjax">Computing intrinsic distances on discrete surfaces is at the heart of many
  minimization problems in geometry processing and beyond. Solving these problems
  is extremely challenging as it demands the computation of on-surface distances
  along with their derivatives. We present a novel approach for intrinsic
  minimization of distance-based objectives defined on triangle meshes. Using a
  variational formulation of shortest-path geodesics, we compute first and
  second-order distance derivatives based on the implicit function theorem, thus
  opening the door to efficient Newton-type minimization solvers. We demonstrate
  our differentiable geodesic distance framework on a wide range of examples,
  including geodesic networks and membranes on surfaces of arbitrary genus,
  two-way coupling between hosting surface and embedded system, differentiable
  geodesic Voronoi diagrams, and efficient computation of Karcher means on
  complex shapes. Our analysis shows that second-order descent methods based on
  our differentiable geodesics outperform existing first-order and quasi-Newton
  methods by large margins.
  </p>
  </div>
  </dd>
  <dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18612" title="Abstract">arXiv:2404.18612</a> [<a href="/pdf/2404.18612" title="Download PDF">pdf</a>, <a href="/ps/2404.18612" title="Download PostScript">ps</a>, <a href="/format/2404.18612" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhancing Prosthetic Safety and Environmental Adaptability: A  Visual-Inertial Prosthesis Motion Estimation Approach on Uneven Terrains
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C">Chuheng Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xinxing Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yin%2C+S">Shucong Yin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuxuan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+B">Binxin Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Leng%2C+Y">Yuquan Leng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fu%2C+C">Chenglong Fu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">Environment awareness is crucial for enhancing walking safety and stability
  of amputee wearing powered prosthesis when crossing uneven terrains such as
  stairs and obstacles. However, existing environmental perception systems for
  prosthesis only provide terrain types and corresponding parameters, which fails
  to prevent potential collisions when crossing uneven terrains and may lead to
  falls and other severe consequences. In this paper, a visual-inertial motion
  estimation approach is proposed for prosthesis to perceive its movement and the
  changes of spatial relationship between the prosthesis and uneven terrain when
  traversing them. To achieve this, we estimate the knee motion by utilizing a
  depth camera to perceive the environment and align feature points extracted
  from stairs and obstacles. Subsequently, an error-state Kalman filter is
  incorporated to fuse the inertial data into visual estimations to reduce the
  feature extraction error and obtain a more robust estimation. The motion of
  prosthetic joint and toe are derived using the prosthesis model parameters.
  Experiment conducted on our collected dataset and stair walking trials with a
  powered prosthesis shows that the proposed method can accurately tracking the
  motion of the human leg and prosthesis with an average root-mean-square error
  of toe trajectory less than 5 cm. The proposed method is expected to enable the
  environmental adaptive control for prosthesis, thereby enhancing amputee's
  safety and mobility in uneven terrains.
  </p>
  </div>
  </dd>
  <dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18615" title="Abstract">arXiv:2404.18615</a> [<a href="/pdf/2404.18615" title="Download PDF">pdf</a>, <a href="/format/2404.18615" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The SAMER Arabic Text Simplification Corpus
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Alhafni%2C+B">Bashar Alhafni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hazim%2C+R">Reem Hazim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liberato%2C+J+P">Juan Piñeros Liberato</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khalil%2C+M+A">Muhamed Al Khalil</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Habash%2C+N">Nizar Habash</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024. 15 pages, 6 tables, 1 figure
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">We present the SAMER Corpus, the first manually annotated Arabic parallel
  corpus for text simplification targeting school-aged learners. Our corpus
  comprises texts of 159K words selected from 15 publicly available Arabic
  fiction novels most of which were published between 1865 and 1955. Our corpus
  includes readability level annotations at both the document and word levels, as
  well as two simplified parallel versions for each text targeting learners at
  two different readability levels. We describe the corpus selection process, and
  outline the guidelines we followed to create the annotations and ensure their
  quality. Our corpus is publicly available to support and encourage research on
  Arabic text simplification, Arabic automatic readability assessment, and the
  development of Arabic pedagogical language technologies.
  </p>
  </div>
  </dd>
  <dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18617" title="Abstract">arXiv:2404.18617</a> [<a href="/pdf/2404.18617" title="Download PDF">pdf</a>, <a href="/format/2404.18617" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CoSense3D: an Agent-based Efficient Learning Framework for Collective  Perception
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yunshuang Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sester%2C+M">Monika Sester</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Collective Perception has attracted significant attention in recent years due
  to its advantage for mitigating occlusion and expanding the field-of-view,
  thereby enhancing reliability, efficiency, and, most crucially, decision-making
  safety. However, developing collective perception models is highly resource
  demanding due to extensive requirements of processing input data for many
  agents, usually dozens of images and point clouds for a single frame. This not
  only slows down the model development process for collective perception but
  also impedes the utilization of larger models. In this paper, we propose an
  agent-based training framework that handles the deep learning modules and agent
  data separately to have a cleaner data flow structure. This framework not only
  provides an API for flexibly prototyping the data processing pipeline and
  defining the gradient calculation for each agent, but also provides the user
  interface for interactive training, testing and data visualization. Training
  experiment results of four collective object detection models on the prominent
  collective perception benchmark OPV2V show that the agent-based training can
  significantly reduce the GPU memory consumption and training time while
  retaining inference performance. The framework and model implementations are
  available at \url{https://github.com/YuanYunshuang/CoSense3D}
  </p>
  </div>
  </dd>
  <dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18620" title="Abstract">arXiv:2404.18620</a> [<a href="/pdf/2404.18620" title="Download PDF">pdf</a>, <a href="/format/2404.18620" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FlexiFilm: Long Video Generation with Flexible Conditions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ouyang%2C+Y">Yichen Ouyang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+j">jianhao Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hao Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+G">Gaoang Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=zhao%2C+B">Bo zhao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 9 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Generating long and consistent videos has emerged as a significant yet
  challenging problem. While most existing diffusion-based video generation
  models, derived from image generation models, demonstrate promising performance
  in generating short videos, their simple conditioning mechanism and sampling
  strategy-originally designed for image generation-cause severe performance
  degradation when adapted to long video generation. This results in prominent
  temporal inconsistency and overexposure. Thus, in this work, we introduce
  FlexiFilm, a new diffusion model tailored for long video generation. Our
  framework incorporates a temporal conditioner to establish a more consistent
  relationship between generation and multi-modal conditions, and a resampling
  strategy to tackle overexposure. Empirical results demonstrate FlexiFilm
  generates long and consistent videos, each over 30 seconds in length,
  outperforming competitors in qualitative and quantitative analyses. Project
  page: https://y-ichen.github.io/FlexiFilm-Page/
  </p>
  </div>
  </dd>
  <dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18624" title="Abstract">arXiv:2404.18624</a> [<a href="/pdf/2404.18624" title="Download PDF">pdf</a>, <a href="/format/2404.18624" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Do Vision &amp; Language Decoders use Images and Text equally? How  Self-consistent are their Explanations?
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Parcalabescu%2C+L">Letitia Parcalabescu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Frank%2C+A">Anette Frank</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 27 pages, from which 12 pages contain the text of the main paper. 8 figures, 11 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Vision and language models (VLMs) are currently the most generally performant
  architectures on multimodal tasks. Next to their predictions, they can also
  produce explanations, either in post-hoc or CoT settings. However, it is not
  clear how much they use the vision and text modalities when generating
  predictions or explanations. In this work, we investigate if VLMs rely on
  modalities differently when generating explanations as opposed to when they
  provide answers. We also evaluate the self-consistency of VLM decoders in both
  post-hoc and CoT explanation settings, by extending existing tests and measures
  to VLM decoders. We find that VLMs are less self-consistent than LLMs. The text
  contributions in VL decoders are much larger than the image contributions
  across all measured tasks. And the contributions of the image are significantly
  larger for explanation generations than for answer generation. This difference
  is even larger in CoT compared to the post-hoc explanation setting. We also
  provide an up-to-date benchmarking of state-of-the-art VL decoders on the VALSE
  benchmark, which to date focused only on VL encoders. We find that VL decoders
  are still struggling with most phenomena tested by VALSE.
  </p>
  </div>
  </dd>
  <dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18626" title="Abstract">arXiv:2404.18626</a> [<a href="/pdf/2404.18626" title="Download PDF">pdf</a>, <a href="/format/2404.18626" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Analysis for Implicit and Implicit-Explicit ADER and DeC Methods for  Ordinary Differential Equations, Advection-Diffusion and Advection-Dispersion  Equations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=%C3%96ffner%2C+P">Philipp Öffner</a>, 
  <a href="/search/math?searchtype=author&amp;query=Petri%2C+L">Louis Petri</a>, 
  <a href="/search/math?searchtype=author&amp;query=Torlo%2C+D">Davide Torlo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 32 pages, 18 figures, 2 tables. For the associated repository, see <a href="https://github.com/accdavlo/IMEX_DeC_ADER">this https URL</a> . Submitted to Elsevier
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">In this manuscript, we present the development of implicit and
  implicit-explicit ADER and DeC methodologies within the DeC framework using the
  two-operators formulation, with a focus on their stability analysis both as
  solvers for ordinary differential equations (ODEs) and within the context of
  linear partial differential equations (PDEs). To analyze their stability, we
  reinterpret these methods as Runge-Kutta schemes and uncover significant
  variations in stability behavior, ranging from A-stable to bounded stability
  regions, depending on the chosen order, method, and quadrature nodes. This
  differentiation contrasts with their explicit counterparts. When applied to
  advection-diffusion and advection-dispersion equations employing finite
  difference spatial discretization, the von Neumann stability analysis
  demonstrates stability under CFL-like conditions. Particularly noteworthy is
  the stability maintenance observed for the advection-diffusion equation, even
  under spatial-independent constraints. Furthermore, we establish precise
  boundaries for relevant coefficients and provide suggestions regarding the
  suitability of specific schemes for different problem.
  </p>
  </div>
  </dd>
  <dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18628" title="Abstract">arXiv:2404.18628</a> [<a href="/pdf/2404.18628" title="Download PDF">pdf</a>, <a href="/format/2404.18628" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Self-Avatar Animation in Virtual Reality: Impact of Motion Signals  Artifacts on the Full-Body Pose Reconstruction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Maiorca%2C+A">Antoine Maiorca</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ghasemzadeh%2C+S+A">Seyed Abolfazl Ghasemzadeh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ravet%2C+T">Thierry Ravet</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cresson%2C+F">François Cresson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dutoit%2C+T">Thierry Dutoit</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Vleeschouwer%2C+C">Christophe De Vleeschouwer</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 5 figures and 1 table
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Virtual Reality (VR) applications have revolutionized user experiences by
  immersing individuals in interactive 3D environments. These environments find
  applications in numerous fields, including healthcare, education, or
  architecture. A significant aspect of VR is the inclusion of self-avatars,
  representing users within the virtual world, which enhances interaction and
  embodiment. However, generating lifelike full-body self-avatar animations
  remains challenging, particularly in consumer-grade VR systems, where
  lower-body tracking is often absent. One method to tackle this problem is by
  providing an external source of motion information that includes lower body
  information such as full Cartesian positions estimated from RGB(D) cameras.
  Nevertheless, the limitations of these systems are multiples: the
  desynchronization between the two motion sources and occlusions are examples of
  significant issues that hinder the implementations of such systems. In this
  paper, we aim to measure the impact on the reconstruction of the articulated
  self-avatar's full-body pose of (1) the latency between the VR motion features
  and estimated positions, (2) the data acquisition rate, (3) occlusions, and (4)
  the inaccuracy of the position estimation algorithm. In addition, we analyze
  the motion reconstruction errors using ground truth and 3D Cartesian
  coordinates estimated from \textit{YOLOv8} pose estimation. These analyzes show
  that the studied methods are significantly sensitive to any degradation tested,
  especially regarding the velocity reconstruction error.
  </p>
  </div>
  </dd>
  <dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18629" title="Abstract">arXiv:2404.18629</a> [<a href="/pdf/2404.18629" title="Download PDF">pdf</a>, <a href="/format/2404.18629" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Differentiable Voronoi Diagrams for Simulation of Cell-Based Mechanical  Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Numerow%2C+L">Logan Numerow</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yue Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Coros%2C+S">Stelian Coros</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Thomaszewski%2C+B">Bernhard Thomaszewski</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 11 pages, 10 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computational Geometry (cs.CG)
  
  </div>
  <p class="mathjax">Navigating topological transitions in cellular mechanical systems is a
  significant challenge for existing simulation methods. While abstract models
  lack predictive capabilities at the cellular level, explicit network
  representations struggle with topology changes, and per-cell representations
  are computationally too demanding for large-scale simulations. To address these
  challenges, we propose a novel cell-centered approach based on differentiable
  Voronoi diagrams. Representing each cell with a Voronoi site, our method
  defines shape and topology of the interface network implicitly. In this way, we
  substantially reduce the number of problem variables, eliminate the need for
  explicit contact handling, and ensure continuous geometry changes during
  topological transitions. Closed-form derivatives of network positions
  facilitate simulation with Newton-type methods for a wide range of per-cell
  energies. Finally, we extend our differentiable Voronoi diagrams to enable
  coupling with arbitrary rigid and deformable boundaries. We apply our approach
  to a diverse set of examples, highlighting splitting and merging of cells as
  well as neighborhood changes. We illustrate applications to inverse problems by
  matching soap foam simulations to real-world images. Comparative analysis with
  explicit cell models reveals that our method achieves qualitatively comparable
  results at significantly faster computation times.
  </p>
  </div>
  </dd>
  <dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18630" title="Abstract">arXiv:2404.18630</a> [<a href="/pdf/2404.18630" title="Download PDF">pdf</a>, <a href="/format/2404.18630" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> 4D-DRESS: A 4D Dataset of Real-world Human Clothing with Semantic  Annotations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenbo Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ho%2C+H">Hsuan-I Ho</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+C">Chen Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rong%2C+B">Boxiang Rong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Grigorev%2C+A">Artur Grigorev</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+J">Jie Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zarate%2C+J+J">Juan Jose Zarate</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hilliges%2C+O">Otmar Hilliges</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> CVPR 2024 paper, 21 figures, 9 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">The studies of human clothing for digital avatars have predominantly relied
  on synthetic datasets. While easy to collect, synthetic data often fall short
  in realism and fail to capture authentic clothing dynamics. Addressing this
  gap, we introduce 4D-DRESS, the first real-world 4D dataset advancing human
  clothing research with its high-quality 4D textured scans and garment meshes.
  4D-DRESS captures 64 outfits in 520 human motion sequences, amounting to 78k
  textured scans. Creating a real-world clothing dataset is challenging,
  particularly in annotating and segmenting the extensive and complex 4D human
  scans. To address this, we develop a semi-automatic 4D human parsing pipeline.
  We efficiently combine a human-in-the-loop process with automation to
  accurately label 4D scans in diverse garments and body movements. Leveraging
  precise annotations and high-quality garment meshes, we establish several
  benchmarks for clothing simulation and reconstruction. 4D-DRESS offers
  realistic and challenging data that complements synthetic sources, paving the
  way for advancements in research of lifelike human clothing. Website:
  https://ait.ethz.ch/4d-dress.
  </p>
  </div>
  </dd>
  <dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18631" title="Abstract">arXiv:2404.18631</a> [<a href="/pdf/2404.18631" title="Download PDF">pdf</a>, <a href="/format/2404.18631" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Feature importance to explain multimodal prediction models. A clinical  use case
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=van+de+Beld%2C+J">Jorn-Jan van de Beld</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pathak%2C+S">Shreyasi Pathak</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Geerdink%2C+J">Jeroen Geerdink</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hegeman%2C+J+H">Johannes H. Hegeman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Seifert%2C+C">Christin Seifert</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at World Conference on Explainable Artificial Intelligence; 19 pages, 2 figures, 7 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Surgery to treat elderly hip fracture patients may cause complications that
  can lead to early mortality. An early warning system for complications could
  provoke clinicians to monitor high-risk patients more carefully and address
  potential complications early, or inform the patient. In this work, we develop
  a multimodal deep-learning model for post-operative mortality prediction using
  pre-operative and per-operative data from elderly hip fracture patients.
  Specifically, we include static patient data, hip and chest images before
  surgery in pre-operative data, vital signals, and medications administered
  during surgery in per-operative data. We extract features from image modalities
  using ResNet and from vital signals using LSTM. Explainable model outcomes are
  essential for clinical applicability, therefore we compute Shapley values to
  explain the predictions of our multimodal black box model. We find that i)
  Shapley values can be used to estimate the relative contribution of each
  modality both locally and globally, and ii) a modified version of the chain
  rule can be used to propagate Shapley values through a sequence of models
  supporting interpretable local explanations. Our findings imply that a
  multimodal combination of black box models can be explained by propagating
  Shapley values through the model sequence.
  </p>
  </div>
  </dd>
  <dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18638" title="Abstract">arXiv:2404.18638</a> [<a href="/pdf/2404.18638" title="Download PDF">pdf</a>, <a href="/format/2404.18638" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Reinforcement Learning Problem Solving with Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gholamian%2C+S">Sina Gholamian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huh%2C+D">Domingo Huh</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
  
  </div>
  <p class="mathjax">Large Language Models (LLMs) encapsulate an extensive amount of world
  knowledge, and this has enabled their application in various domains to improve
  the performance of a variety of Natural Language Processing (NLP) tasks. This
  has also facilitated a more accessible paradigm of conversation-based
  interactions between humans and AI systems to solve intended problems. However,
  one interesting avenue that shows untapped potential is the use of LLMs as
  Reinforcement Learning (RL) agents to enable conversational RL problem solving.
  Therefore, in this study, we explore the concept of formulating Markov Decision
  Process-based RL problems as LLM prompting tasks. We demonstrate how LLMs can
  be iteratively prompted to learn and optimize policies for specific RL tasks.
  In addition, we leverage the introduced prompting technique for episode
  simulation and Q-Learning, facilitated by LLMs. We then show the practicality
  of our approach through two detailed case studies for "Research Scientist" and
  "Legal Matter Intake" workflows.
  </p>
  </div>
  </dd>
  <dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18639" title="Abstract">arXiv:2404.18639</a> [<a href="/pdf/2404.18639" title="Download PDF">pdf</a>, <a href="/format/2404.18639" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Efficient preconditioners for coupled Stokes-Darcy problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Strohbeck%2C+P">Paula Strohbeck</a>, 
  <a href="/search/math?searchtype=author&amp;query=Rybak%2C+I">Iryna Rybak</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">Coupled systems of free flow and porous media arise in a variety of technical
  and environmental applications. For laminar flow regimes, such systems are
  described by the Stokes equations in the free-flow region and Darcy's law in
  the porous medium. An appropriate set of coupling conditions is needed on the
  fluid-porous interface. Discretisations of the Stokes-Darcy problems yield
  large, sparse, ill-conditioned, and, depending on the interface conditions,
  non-symmetric linear systems. Therefore, robust and efficient preconditioners
  are needed to accelerate convergence of the applied Krylov method. In this
  work, we develop and investigate block diagonal, block triangular and
  constraint preconditioners for the coupled Stokes-Darcy problems. We apply two
  classical sets of coupling conditions considering the Beavers-Joseph and the
  Beavers-Joseph-Saffman condition for the tangential velocity. For the
  Beavers-Joseph interface condition, the resulting system is non-symmetric,
  therefore GMRES method is used. Spectral and field-of-values bounds independent
  of the grid width are derived for the exact versions of the preconditioners.
  Furthermore, we develop efficient inexact versions of the preconditioners. We
  demonstrate the effectiveness and robustness of the proposed preconditioners in
  numerical experiments.
  </p>
  </div>
  </dd>
  <dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18640" title="Abstract">arXiv:2404.18640</a> [<a href="/pdf/2404.18640" title="Download PDF">pdf</a>, <a href="/format/2404.18640" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Going Beyond Popularity and Positivity Bias: Correcting for  Multifactorial Bias in Recommender Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jin Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oosterhuis%2C+H">Harrie Oosterhuis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mansoury%2C+M">Masoud Mansoury</a>, 
  <a href="/search/cs?searchtype=author&amp;query=van+Hoof%2C+H">Herke van Hoof</a>, 
  <a href="/search/cs?searchtype=author&amp;query=de+Rijke%2C+M">Maarten de Rijke</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> SIGIR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">Two typical forms of bias in user interaction data with recommender systems
  (RSs) are popularity bias and positivity bias, which manifest themselves as the
  over-representation of interactions with popular items or items that users
  prefer, respectively. Debiasing methods aim to mitigate the effect of selection
  bias on the evaluation and optimization of RSs. However, existing debiasing
  methods only consider single-factor forms of bias, e.g., only the item
  (popularity) or only the rating value (positivity). This is in stark contrast
  with the real world where user selections are generally affected by multiple
  factors at once. In this work, we consider multifactorial selection bias in
  RSs. Our focus is on selection bias affected by both item and rating value
  factors, which is a generalization and combination of popularity and positivity
  bias. While the concept of multifactorial bias is intuitive, it brings a severe
  practical challenge as it requires substantially more data for accurate bias
  estimation. As a solution, we propose smoothing and alternating gradient
  descent techniques to reduce variance and improve the robustness of its
  optimization. Our experimental results reveal that, with our proposed
  techniques, multifactorial bias corrections are more effective and robust than
  single-factor counterparts on real-world and synthetic datasets.
  </p>
  </div>
  </dd>
  <dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18645" title="Abstract">arXiv:2404.18645</a> [<a href="/pdf/2404.18645" title="Download PDF">pdf</a>, <a href="/format/2404.18645" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Graph Search Trees and the Intermezzo Problem
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Beisegel%2C+J">Jesse Beisegel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=K%C3%B6hler%2C+E">Ekkehard Köhler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ratajczak%2C+F">Fabienne Ratajczak</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Scheffler%2C+R">Robert Scheffler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Strehler%2C+M">Martin Strehler</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)
  
  </div>
  <p class="mathjax">The last in-tree recognition problem asks whether a given spanning tree can
  be derived by connecting each vertex with its rightmost left neighbor of some
  search ordering. In this study, we demonstrate that the last-in-tree
  recognition problem for Generic Search is <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-214-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1390" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.245em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1391"><span class="texatom" id="MathJax-Span-1392"><span class="mrow" id="MathJax-Span-1393"><span class="mi" id="MathJax-Span-1394" style="font-family: STIXGeneral-Regular;">𝖭</span><span class="mi" id="MathJax-Span-1395" style="font-family: STIXGeneral-Regular;">𝖯</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-214">\mathsf{NP}</script>-complete. We utilize
  this finding to strengthen a complexity result from order theory. Given partial
  order <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-215-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1396" style="width: 0.737em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.567em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.567em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1397"><span class="mi" id="MathJax-Span-1398" style="font-family: STIXGeneral-Italic;">π<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-215">\pi</script> and a set of triples, the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-216-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1399" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.245em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1400"><span class="texatom" id="MathJax-Span-1401"><span class="mrow" id="MathJax-Span-1402"><span class="mi" id="MathJax-Span-1403" style="font-family: STIXGeneral-Regular;">𝖭</span><span class="mi" id="MathJax-Span-1404" style="font-family: STIXGeneral-Regular;">𝖯</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-216">\mathsf{NP}</script>-complete intermezzo problem
  asks for a linear extension of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-217-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1405" style="width: 0.737em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.567em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.567em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1406"><span class="mi" id="MathJax-Span-1407" style="font-family: STIXGeneral-Italic;">π<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-217">\pi</script> where each first element of a triple is
  not between the other two. We show that this problem remains
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-218-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1408" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.245em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1409"><span class="texatom" id="MathJax-Span-1410"><span class="mrow" id="MathJax-Span-1411"><span class="mi" id="MathJax-Span-1412" style="font-family: STIXGeneral-Regular;">𝖭</span><span class="mi" id="MathJax-Span-1413" style="font-family: STIXGeneral-Regular;">𝖯</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-218">\mathsf{NP}</script>-complete even when the Hasse diagram of the partial order forms a
  tree of bounded height. In contrast, we give an <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-219-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1414" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.245em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1415"><span class="texatom" id="MathJax-Span-1416"><span class="mrow" id="MathJax-Span-1417"><span class="mi" id="MathJax-Span-1418" style="font-family: STIXGeneral-Regular;">𝖷</span><span class="mi" id="MathJax-Span-1419" style="font-family: STIXGeneral-Regular;">𝖯</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-219">\mathsf{XP}</script> algorithm for the
  problem when parameterized by the width of the partial order. Furthermore, we
  show that <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-220-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1420" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(2.148em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1421"><span class="mtext" id="MathJax-Span-1422" style="font-family: STIXGeneral-Regular;">–</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.42em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-220">\unicode{x2013}</script> under the assumption of the Exponential Time
  Hypothesis <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-221-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1423" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(2.148em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1424"><span class="mtext" id="MathJax-Span-1425" style="font-family: STIXGeneral-Regular;">–</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.42em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-221">\unicode{x2013}</script> the running time of this algorithm is
  asymptotically optimal.
  </p>
  </div>
  </dd>
  <dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18648" title="Abstract">arXiv:2404.18648</a> [<a href="/pdf/2404.18648" title="Download PDF">pdf</a>, <a href="/format/2404.18648" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Uncertainty-boosted Robust Video Activity Anticipation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Qi%2C+Z">Zhaobo Qi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuhui Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weigang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Q">Qingming Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by T-PAMI
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Video activity anticipation aims to predict what will happen in the future,
  embracing a broad application prospect ranging from robot vision and autonomous
  driving. Despite the recent progress, the data uncertainty issue, reflected as
  the content evolution process and dynamic correlation in event labels, has been
  somehow ignored. This reduces the model generalization ability and deep
  understanding on video content, leading to serious error accumulation and
  degraded performance. In this paper, we address the uncertainty learning
  problem and propose an uncertainty-boosted robust video activity anticipation
  framework, which generates uncertainty values to indicate the credibility of
  the anticipation results. The uncertainty value is used to derive a temperature
  parameter in the softmax function to modulate the predicted target activity
  distribution. To guarantee the distribution adjustment, we construct a
  reasonable target activity label representation by incorporating the activity
  evolution from the temporal class correlation and the semantic relationship.
  Moreover, we quantify the uncertainty into relative values by comparing the
  uncertainty among sample pairs and their temporal-lengths. This relative
  strategy provides a more accessible way in uncertainty modeling than
  quantifying the absolute uncertainty values on the whole dataset. Experiments
  on multiple backbones and benchmarks show our framework achieves promising
  performance and better robustness/interpretability. Source codes are available
  at https://github.com/qzhb/UbRV2A.
  </p>
  </div>
  </dd>
  <dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18649" title="Abstract">arXiv:2404.18649</a> [<a href="/pdf/2404.18649" title="Download PDF">pdf</a>, <a href="/format/2404.18649" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Quantitative Evaluation of Explainable AI Methods for Deepfake  Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tsigos%2C+K">Konstantinos Tsigos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Apostolidis%2C+E">Evlampios Apostolidis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Baxevanakis%2C+S">Spyridon Baxevanakis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Papadopoulos%2C+S">Symeon Papadopoulos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mezaris%2C+V">Vasileios Mezaris</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted for publication, 3rd ACM Int. Workshop on Multimedia AI against Disinformation (MAD'24) at ACM ICMR'24, June 10, 2024, Phuket, Thailand. This is the "accepted version"
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">In this paper we propose a new framework for evaluating the performance of
  explanation methods on the decisions of a deepfake detector. This framework
  assesses the ability of an explanation method to spot the regions of a fake
  image with the biggest influence on the decision of the deepfake detector, by
  examining the extent to which these regions can be modified through a set of
  adversarial attacks, in order to flip the detector's prediction or reduce its
  initial prediction; we anticipate a larger drop in deepfake detection accuracy
  and prediction, for methods that spot these regions more accurately. Based on
  this framework, we conduct a comparative study using a state-of-the-art model
  for deepfake detection that has been trained on the FaceForensics++ dataset,
  and five explanation methods from the literature. The findings of our
  quantitative and qualitative evaluations document the advanced performance of
  the LIME explanation method against the other compared ones, and indicate this
  method as the most appropriate for explaining the decisions of the utilized
  deepfake detector.
  </p>
  </div>
  </dd>
  <dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18655" title="Abstract">arXiv:2404.18655</a> [<a href="/pdf/2404.18655" title="Download PDF">pdf</a>, <a href="/format/2404.18655" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Revealing the Parametric Knowledge of Language Models: A Unified  Framework for Attribution Methods
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Haeun Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Atanasova%2C+P">Pepa Atanasova</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Augenstein%2C+I">Isabelle Augenstein</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, 6 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Language Models (LMs) acquire parametric knowledge from their training
  process, embedding it within their weights. The increasing scalability of LMs,
  however, poses significant challenges for understanding a model's inner
  workings and further for updating or correcting this embedded knowledge without
  the significant cost of retraining. This underscores the importance of
  unveiling exactly what knowledge is stored and its association with specific
  model components. Instance Attribution (IA) and Neuron Attribution (NA) offer
  insights into this training-acquired knowledge, though they have not been
  compared systematically. Our study introduces a novel evaluation framework to
  quantify and compare the knowledge revealed by IA and NA. To align the results
  of the methods we introduce the attribution method NA-Instances to apply NA for
  retrieving influential training instances, and IA-Neurons to discover important
  neurons of influential instances discovered by IA. We further propose a
  comprehensive list of faithfulness tests to evaluate the comprehensiveness and
  sufficiency of the explanations provided by both methods. Through extensive
  experiments and analysis, we demonstrate that NA generally reveals more diverse
  and comprehensive information regarding the LM's parametric knowledge compared
  to IA. Nevertheless, IA provides unique and valuable insights into the LM's
  parametric knowledge, which are not revealed by NA. Our findings further
  suggest the potential of a synergistic approach of combining the diverse
  findings of IA and NA for a more holistic understanding of an LM's parametric
  knowledge.
  </p>
  </div>
  </dd>
  <dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18656" title="Abstract">arXiv:2404.18656</a> [<a href="/pdf/2404.18656" title="Download PDF">pdf</a>, <a href="/format/2404.18656" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Symmetric Entropy Regions of Degrees Six and Seven
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zihan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shaocheng Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qi Chen</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> 2024 IEEE International Symposium on Information Theory
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">In this paper, we classify all G-symmetric almost entropic regions according
  to their Shannon-tightness, that is, whether they can be fully characterized by
  Shannon-type inequalities, where G is a permutation group of degree 6 or 7.
  </p>
  </div>
  </dd>
  <dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18657" title="Abstract">arXiv:2404.18657</a> [<a href="/pdf/2404.18657" title="Download PDF">pdf</a>, <a href="/format/2404.18657" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On the Evaluation of Procedural Level Generation Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Withington%2C+O">Oliver Withington</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cook%2C+M">Michael Cook</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tokarchuk%2C+L">Laurissa Tokarchuk</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> To be published in the proceedings of the Foundations of Digital Games Conference 2024. 10 Pages, 4 Figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">The evaluation of procedural content generation (PCG) systems for generating
  video game levels is a complex and contested topic. Ideally, the field would
  have access to robust, generalisable and widely accepted evaluation approaches
  that can be used to compare novel PCG systems to prior work, but consensus on
  how to evaluate novel systems is currently limited. We argue that the field can
  benefit from a structured analysis of how procedural level generation systems
  can be evaluated, and how these techniques are currently used by researchers.
  This analysis can then be used to both inform on the current state of affairs,
  and to provide data to justify changes to this practice. This work aims to
  provide this by first developing a novel taxonomy of PCG evaluation approaches,
  and then presenting the results of a survey of recent work in the field through
  the lens of this taxonomy. The results of this survey highlight several
  important weaknesses in current practice which we argue could be substantially
  mitigated by 1) promoting use of evaluation free system descriptions where
  appropriate, 2) promoting the development of diverse research frameworks, 3)
  promoting reuse of code and methodology wherever possible.
  </p>
  </div>
  </dd>
  <dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18663" title="Abstract">arXiv:2404.18663</a> [<a href="/pdf/2404.18663" title="Download PDF">pdf</a>, <a href="/ps/2404.18663" title="Download PostScript">ps</a>, <a href="/format/2404.18663" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Terrain characterisation for online adaptability of automated sonar  processing: Lessons learnt from operationally applying ATR to sidescan sonar  in MCM applications
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Guerneve%2C+T">Thomas Guerneve</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Loizou%2C+S">Stephanos Loizou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Munafo%2C+A">Andrea Munafo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mignotte%2C+P">Pierre-Yves Mignotte</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Presented at UACE (Underwater Acoustics Conference &amp; Exhibition) 2023, Kalamata, Greece
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">The performance of Automated Recognition (ATR) algorithms on side-scan sonar
  imagery has shown to degrade rapidly when deployed on non benign environments.
  Complex seafloors and acoustic artefacts constitute distractors in the form of
  strong textural patterns, creating false detections or preventing detections of
  true objects. This paper presents two online seafloor characterisation
  techniques to improve explainability during Autonomous Underwater Vehicles
  (AUVs) missions. Importantly and as opposed to previous work in the domain,
  these techniques are not based on a model and require limited input from human
  operators, making it suitable for real-time onboard processing. Both techniques
  rely on an unsupervised machine learning approach to extract terrain features
  which relate to the human understanding of terrain complexity. The first
  technnique provides a quantitative, application-driven terrain characterisation
  metric based on the performance of an ATR algorithm. The second method provides
  a way to incorporate subject matter expertise and enables contextualisation and
  explainability in support for scenario-dependent subjective terrain
  characterisation. The terrain complexity matches the expectation of seasoned
  users making this tool desirable and trustworthy in comparison to traditional
  unsupervised approaches. We finally detail an application of these techniques
  to repair a Mine Countermeasures (MCM) mission carried with SeeByte autonomy
  framework Neptune.
  </p>
  </div>
  </dd>
  <dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18664" title="Abstract">arXiv:2404.18664</a> [<a href="/pdf/2404.18664" title="Download PDF">pdf</a>, <a href="/format/2404.18664" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Reading Order Independent Metrics for Information Extraction in  Handwritten Documents
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Villanova-Aparisi%2C+D">David Villanova-Aparisi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tarride%2C+S">Solène Tarride</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mart%C3%ADnez-Hinarejos%2C+C">Carlos-D. Martínez-Hinarejos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Romero%2C+V">Verónica Romero</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kermorvant%2C+C">Christopher Kermorvant</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pastor-Gadea%2C+M">Moisés Pastor-Gadea</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Information Extraction processes in handwritten documents tend to rely on
  obtaining an automatic transcription and performing Named Entity Recognition
  (NER) over such transcription. For this reason, in publicly available datasets,
  the performance of the systems is usually evaluated with metrics particular to
  each dataset. Moreover, most of the metrics employed are sensitive to reading
  order errors. Therefore, they do not reflect the expected final application of
  the system and introduce biases in more complex documents. In this paper, we
  propose and publicly release a set of reading order independent metrics
  tailored to Information Extraction evaluation in handwritten documents. In our
  experimentation, we perform an in-depth analysis of the behavior of the metrics
  to recommend what we consider to be the minimal set of metrics to evaluate a
  task correctly.
  </p>
  </div>
  </dd>
  <dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18665" title="Abstract">arXiv:2404.18665</a> [<a href="/pdf/2404.18665" title="Download PDF">pdf</a>, <a href="/format/2404.18665" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Leveraging PointNet and PointNet++ for Lyft Point Cloud Classification  Challenge
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Doshi%2C+R+K">Rajat K. Doshi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">This study investigates the application of PointNet and PointNet++ in the
  classification of LiDAR-generated point cloud data, a critical component for
  achieving fully autonomous vehicles. Utilizing a modified dataset from the Lyft
  3D Object Detection Challenge, we examine the models' capabilities to handle
  dynamic and complex environments essential for autonomous navigation. Our
  analysis shows that PointNet and PointNet++ achieved accuracy rates of 79.53%
  and 84.24%, respectively. These results underscore the models' robustness in
  interpreting intricate environmental data, which is pivotal for the safety and
  efficiency of autonomous vehicles. Moreover, the enhanced detection accuracy,
  particularly in distinguishing pedestrians from other objects, highlights the
  potential of these models to contribute substantially to the advancement of
  autonomous vehicle technology.
  </p>
  </div>
  </dd>
  <dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18669" title="Abstract">arXiv:2404.18669</a> [<a href="/pdf/2404.18669" title="Download PDF">pdf</a>, <a href="/format/2404.18669" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bootstrap 3D Reconstructed Scenes from 3D Gaussian Splatting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yifei Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ou%2C+J">Jie Ou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+J">Jun Cheng</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Recent developments in neural rendering techniques have greatly enhanced the
  rendering of photo-realistic 3D scenes across both academic and commercial
  fields. The latest method, known as 3D Gaussian Splatting (3D-GS), has set new
  benchmarks for rendering quality and speed. Nevertheless, the limitations of
  3D-GS become pronounced in synthesizing new viewpoints, especially for views
  that greatly deviate from those seen during training. Additionally, issues such
  as dilation and aliasing arise when zooming in or out. These challenges can all
  be traced back to a single underlying issue: insufficient sampling. In our
  paper, we present a bootstrapping method that significantly addresses this
  problem. This approach employs a diffusion model to enhance the rendering of
  novel views using trained 3D-GS, thereby streamlining the training process. Our
  results indicate that bootstrapping effectively reduces artifacts, as well as
  clear enhancements on the evaluation metrics. Furthermore, we show that our
  method is versatile and can be easily integrated, allowing various 3D
  reconstruction projects to benefit from our approach.
  </p>
  </div>
  </dd>
  <dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18670" title="Abstract">arXiv:2404.18670</a> [<a href="/pdf/2404.18670" title="Download PDF">pdf</a>, <a href="/format/2404.18670" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhancing Uncertain Demand Prediction in Hospitals Using Simple and  Advanced Machine Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+A">Annie Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stockman%2C+S">Samuel Stockman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xun Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wood%2C+R">Richard Wood</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhi%2C+B">Bangdong Zhi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ch%C3%A9n%2C+O+Y">Oliver Y. Chén</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)
  
  </div>
  <p class="mathjax">Early and timely prediction of patient care demand not only affects effective
  resource allocation but also influences clinical decision-making as well as
  patient experience. Accurately predicting patient care demand, however, is a
  ubiquitous challenge for hospitals across the world due, in part, to the
  demand's time-varying temporal variability, and, in part, to the difficulty in
  modelling trends in advance. To address this issue, here, we develop two
  methods, a relatively simple time-vary linear model, and a more advanced neural
  network model. The former forecasts patient arrivals hourly over a week based
  on factors such as day of the week and previous 7-day arrival patterns. The
  latter leverages a long short-term memory (LSTM) model, capturing non-linear
  relationships between past data and a three-day forecasting window. We evaluate
  the predictive capabilities of the two proposed approaches compared to two
  na\"ive approaches - a reduced-rank vector autoregressive (VAR) model and the
  TBATS model. Using patient care demand data from Rambam Medical Center in
  Israel, our results show that both proposed models effectively capture hourly
  variations of patient demand. Additionally, the linear model is more
  explainable thanks to its simple architecture, whereas, by accurately modelling
  weekly seasonal trends, the LSTM model delivers lower prediction errors. Taken
  together, our explorations suggest the utility of machine learning in
  predicting time-varying patient care demand; additionally, it is possible to
  predict patient care demand with good accuracy (around 4 patients) three days
  or a week in advance using machine learning.
  </p>
  </div>
  </dd>
  <dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18672" title="Abstract">arXiv:2404.18672</a> [<a href="/pdf/2404.18672" title="Download PDF">pdf</a>, <a href="/ps/2404.18672" title="Download PostScript">ps</a>, <a href="/format/2404.18672" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Graph Convolutional Networks and Graph Attention Networks for  Approximating Arguments Acceptability -- Technical Report
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cibier%2C+P">Paul Cibier</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mailly%2C+J">Jean-Guy Mailly</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages, 2 figures. Submitted to the 10th International Conference on Computational Models of Argument (COMMA 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  <p class="mathjax">Various approaches have been proposed for providing efficient computational
  approaches for abstract argumentation. Among them, neural networks have
  permitted to solve various decision problems, notably related to arguments
  (credulous or skeptical) acceptability. In this work, we push further this
  study in various ways. First, relying on the state-of-the-art approach AFGCN,
  we show how we can improve the performances of the Graph Convolutional Networks
  (GCNs) regarding both runtime and accuracy. Then, we show that it is possible
  to improve even more the efficiency of the approach by modifying the
  architecture of the network, using Graph Attention Networks (GATs) instead.
  </p>
  </div>
  </dd>
  <dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18673" title="Abstract">arXiv:2404.18673</a> [<a href="/pdf/2404.18673" title="Download PDF">pdf</a>, <a href="/format/2404.18673" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Open-Source Drift Detection Tools in Action: Insights from Two Use Cases
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+R">Rieke Müller</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Abdelaal%2C+M">Mohamed Abdelaal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stjelja%2C+D">Davor Stjelja</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Data drifts pose a critical challenge in the lifecycle of machine learning
  (ML) models, affecting their performance and reliability. In response to this
  challenge, we present a microbenchmark study, called D3Bench, which evaluates
  the efficacy of open-source drift detection tools. D3Bench examines the
  capabilities of Evidently AI, NannyML, and Alibi-Detect, leveraging real-world
  data from two smart building use cases.We prioritize assessing the functional
  suitability of these tools to identify and analyze data drifts. Furthermore, we
  consider a comprehensive set of non-functional criteria, such as the
  integrability with ML pipelines, the adaptability to diverse data types,
  user-friendliness, computational efficiency, and resource demands. Our findings
  reveal that Evidently AI stands out for its general data drift detection,
  whereas NannyML excels at pinpointing the precise timing of shifts and
  evaluating their consequent effects on predictive accuracy.
  </p>
  </div>
  </dd>
  <dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18676" title="Abstract">arXiv:2404.18676</a> [<a href="/pdf/2404.18676" title="Download PDF">pdf</a>, <a href="/format/2404.18676" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exact symmetry conservation and automatic mesh refinement in discrete  initial boundary value problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Rothkopf%2C+A">Alexander Rothkopf</a>, 
  <a href="/search/math?searchtype=author&amp;query=Horowitz%2C+W+A">W. A. Horowitz</a>, 
  <a href="/search/math?searchtype=author&amp;query=Nordstr%C3%B6m%2C+J">Jan Nordström</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 50 pages, 12 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; High Energy Physics - Lattice (hep-lat); High Energy Physics - Theory (hep-th); Computational Physics (physics.comp-ph)
  
  </div>
  <p class="mathjax">We present a novel solution procedure for initial boundary value problems.
  The procedure is based on an action principle, in which coordinate maps are
  included as dynamical degrees of freedom. This reparametrization invariant
  action is formulated in an abstract parameter space and an energy density scale
  associated with the space-time coordinates separates the dynamics of the
  coordinate maps and of the propagating fields. Treating coordinates as
  dependent, i.e. dynamical quantities, offers the opportunity to discretize the
  action while retaining all space-time symmetries and also provides the basis
  for automatic adaptive mesh refinement (AMR). The presence of unbroken
  space-time symmetries after discretization also ensures that the associated
  continuum Noether charges remain exactly conserved. The presence of coordinate
  maps in addition provides new freedom in the choice of boundary conditions. An
  explicit numerical example for wave propagation in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-222-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1426" style="width: 2.656em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.148em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.035em, 2.769em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1427"><span class="mn" id="MathJax-Span-1428" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1429" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">+</span><span class="mn" id="MathJax-Span-1430" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-222">1+1</script> dimensions is
  provided, using recently developed regularized summation-by-parts finite
  difference operators.
  </p>
  </div>
  </dd>
  <dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18677" title="Abstract">arXiv:2404.18677</a> [<a href="/pdf/2404.18677" title="Download PDF">pdf</a>, <a href="/format/2404.18677" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards the First Code Contribution: Processes and Information Needs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Treude%2C+C">Christoph Treude</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gerosa%2C+M+A">Marco A. Gerosa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Steinmacher%2C+I">Igor Steinmacher</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Newcomers to a software project must overcome many barriers before they can
  successfully place their first code contribution, and they often struggle to
  find information that is relevant to them. In this work, we argue that much of
  the information needed by newcomers already exists, albeit scattered among many
  different sources, and that many barriers can be addressed by automatically
  identifying, extracting, generating, summarizing, and presenting documentation
  that is specifically aimed and customized for newcomers. To gain a detailed
  understanding of the processes followed by newcomers and their information
  needs before making their first code contribution, we conducted an empirical
  study. Based on a survey with about 100 practitioners, grounded theory
  analysis, and validation interviews, we contribute a 16-step model for the
  processes followed by newcomers to a software project and we identify relevant
  information, along with individual and project characteristics that influence
  the relevancy of information types and sources. Our findings form an essential
  step towards automated tool support that provides relevant information to
  project newcomers in each step of their contribution processes.
  </p>
  </div>
  </dd>
  <dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18680" title="Abstract">arXiv:2404.18680</a> [<a href="/pdf/2404.18680" title="Download PDF">pdf</a>, <a href="/format/2404.18680" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> How Deep Is Your Gaze? Leveraging Distance in Image-Based Gaze Analysis
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Koch%2C+M">Maurice Koch</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pathmanathan%2C+N">Nelusa Pathmanathan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Weiskopf%2C+D">Daniel Weiskopf</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kurzhals%2C+K">Kuno Kurzhals</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">Image thumbnails are a valuable data source for fixation filtering, scanpath
  classification, and visualization of eye tracking data. They are typically
  extracted with a constant size, approximating the foveated area. As a
  consequence, the focused area of interest in the scene becomes less prominent
  in the thumbnail with increasing distance, affecting image-based analysis
  techniques. In this work, we propose depth-adaptive thumbnails, a method for
  varying image size according to the eye-to-object distance. Adjusting the
  visual angle relative to the distance leads to a zoom effect on the focused
  area. We evaluate our approach on recordings in augmented reality,
  investigating the similarity of thumbnails and scanpaths. Our quantitative
  findings suggest that considering the eye-to-object distance improves the
  quality of data analysis and visualization. We demonstrate the utility of
  depth-adaptive thumbnails for applications in scanpath comparison and
  visualization.
  </p>
  </div>
  </dd>
  <dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18681" title="Abstract">arXiv:2404.18681</a> [<a href="/pdf/2404.18681" title="Download PDF">pdf</a>, <a href="/format/2404.18681" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LLMClean: Context-Aware Tabular Data Cleaning via LLM-Generated OFDs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Biester%2C+F">Fabian Biester</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Abdelaal%2C+M">Mohamed Abdelaal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Del+Gaudio%2C+D">Daniel Del Gaudio</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>
  
  </div>
  <p class="mathjax">Machine learning's influence is expanding rapidly, now integral to
  decision-making processes from corporate strategy to the advancements in
  Industry 4.0. The efficacy of Artificial Intelligence broadly hinges on the
  caliber of data used during its training phase; optimal performance is tied to
  exceptional data quality. Data cleaning tools, particularly those that exploit
  functional dependencies within ontological frameworks or context models, are
  instrumental in augmenting data quality. Nevertheless, crafting these context
  models is a demanding task, both in terms of resources and expertise, often
  necessitating specialized knowledge from domain experts.
  <br>In light of these challenges, this paper introduces an innovative approach,
  called LLMClean, for the automated generation of context models, utilizing
  Large Language Models to analyze and understand various datasets. LLMClean
  encompasses a sequence of actions, starting with categorizing the dataset,
  extracting or mapping relevant models, and ultimately synthesizing the context
  model. To demonstrate its potential, we have developed and tested a prototype
  that applies our approach to three distinct datasets from the Internet of
  Things, healthcare, and Industry 4.0 sectors. The results of our evaluation
  indicate that our automated approach can achieve data cleaning efficacy
  comparable with that of context models crafted by human experts.
  </p>
  </div>
  </dd>
  <dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18682" title="Abstract">arXiv:2404.18682</a> [<a href="/pdf/2404.18682" title="Download PDF">pdf</a>, <a href="/format/2404.18682" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Human Factors in Model-Driven Engineering: Future Research Goals and  Initiatives for MDE
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liebel%2C+G">Grischa Liebel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kl%C3%BCnder%2C+J">Jil Klünder</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hebig%2C+R">Regina Hebig</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lazik%2C+C">Christopher Lazik</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nunes%2C+I">Inês Nunes</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gra%C3%9Fl%2C+I">Isabella Graßl</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stegh%C3%B6fer%2C+J">Jan-Philipp Steghöfer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Exelmans%2C+J">Joeri Exelmans</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oertel%2C+J">Julian Oertel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Marquardt%2C+K">Kai Marquardt</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Juhnke%2C+K">Katharina Juhnke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schneider%2C+K">Kurt Schneider</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gren%2C+L">Lucas Gren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Happe%2C+L">Lucia Happe</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Herrmann%2C+M">Marc Herrmann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wyrich%2C+M">Marvin Wyrich</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tichy%2C+M">Matthias Tichy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Goul%C3%A3o%2C+M">Miguel Goulão</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wohlrab%2C+R">Rebekka Wohlrab</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kalantari%2C+R">Reyhaneh Kalantari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Heinrich%2C+R">Robert Heinrich</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Greiner%2C+S">Sandra Greiner</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rukmono%2C+S+A">Satrio Adi Rukmono</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chakraborty%2C+S">Shalini Chakraborty</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Abrah%C3%A3o%2C+S">Silvia Abrahão</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Amaral%2C+V">Vasco Amaral</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Purpose: Software modelling and Model-Driven Engineering (MDE) is
  traditionally studied from a technical perspective. However, one of the core
  motivations behind the use of software models is inherently human-centred.
  Models aim to enable practitioners to communicate about software designs, make
  software understandable, or make software easier to write through
  domain-specific modelling languages. Several recent studies challenge the idea
  that these aims can always be reached and indicate that human factors play a
  role in the success of MDE. However, there is an under-representation of
  research focusing on human factors in modelling. Methods: During a GI-Dagstuhl
  seminar, topics related to human factors in modelling were discussed by 26
  expert participants from research and industry. Results: In breakout groups,
  five topics were covered in depth, namely modelling human aspects, factors of
  modeller experience, diversity and inclusion in MDE, collaboration and MDE, and
  teaching human-aware MDE. Conclusion: We summarise our insights gained during
  the discussions on the five topics. We formulate research goals, questions, and
  propositions that support directing future initiatives towards an MDE community
  that is aware of and supportive of human factors and values.
  </p>
  </div>
  </dd>
  <dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18684" title="Abstract">arXiv:2404.18684</a> [<a href="/pdf/2404.18684" title="Download PDF">pdf</a>, <a href="/format/2404.18684" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Work Smarter...Not Harder: Efficient Minimization of Dependency Length  in SOV Languages
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ranjan%2C+S">Sidharth Ranjan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=von+der+Malsburg%2C+T">Titus von der Malsburg</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at CogSci-2024 as talk with full paper publication
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Theoretical Economics (econ.TH); Optimization and Control (math.OC)
  
  </div>
  <p class="mathjax">Dependency length minimization is a universally observed quantitative
  property of natural languages. However, the extent of dependency length
  minimization, and the cognitive mechanisms through which the language processor
  achieves this minimization remain unclear. This research offers mechanistic
  insights by postulating that moving a short preverbal constituent next to the
  main verb explains preverbal constituent ordering decisions better than global
  minimization of dependency length in SOV languages. This approach constitutes a
  least-effort strategy because it's just one operation but simultaneously
  reduces the length of all preverbal dependencies linked to the main verb. We
  corroborate this strategy using large-scale corpus evidence across all seven
  SOV languages that are prominently represented in the Universal Dependency
  Treebank. These findings align with the concept of bounded rationality, where
  decision-making is influenced by 'quick-yet-economical' heuristics rather than
  exhaustive searches for optimal solutions. Overall, this work sheds light on
  the role of bounded rationality in linguistic decision-making and language
  evolution.
  </p>
  </div>
  </dd>
  <dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18685" title="Abstract">arXiv:2404.18685</a> [<a href="/pdf/2404.18685" title="Download PDF">pdf</a>, <a href="/format/2404.18685" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FALE: Fairness-Aware ALE Plots for Auditing Bias in Subgroups
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Giannopoulos%2C+G">Giorgos Giannopoulos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sacharidis%2C+D">Dimitris Sacharidis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Theologitis%2C+N">Nikolas Theologitis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kavouras%2C+L">Loukas Kavouras</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Emiris%2C+I">Ioannis Emiris</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Presented in Uncertainty meets Explainability Workshop @ ECML/PKDD 2023
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)
  
  </div>
  <p class="mathjax">Fairness is steadily becoming a crucial requirement of Machine Learning (ML)
  systems. A particularly important notion is subgroup fairness, i.e., fairness
  in subgroups of individuals that are defined by more than one attributes.
  Identifying bias in subgroups can become both computationally challenging, as
  well as problematic with respect to comprehensibility and intuitiveness of the
  finding to end users. In this work we focus on the latter aspects; we propose
  an explainability method tailored to identifying potential bias in subgroups
  and visualizing the findings in a user friendly manner to end users. In
  particular, we extend the ALE plots explainability method, proposing FALE
  (Fairness aware Accumulated Local Effects) plots, a method for measuring the
  change in fairness for an affected population corresponding to different values
  of a feature (attribute). We envision FALE to function as an efficient, user
  friendly, comprehensible and reliable first-stage tool for identifying
  subgroups with potential bias issues.
  </p>
  </div>
  </dd>
  <dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18687" title="Abstract">arXiv:2404.18687</a> [<a href="/pdf/2404.18687" title="Download PDF">pdf</a>, <a href="/format/2404.18687" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Socially Adaptive Path Planning Based on Generative Adversarial Network
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kong%2C+Y">Yuqi Kong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chi%2C+W">Wenzheng Chi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+L">Lining Sun</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)
  
  </div>
  <p class="mathjax">The natural interaction between robots and pedestrians in the process of
  autonomous navigation is crucial for the intelligent development of mobile
  robots, which requires robots to fully consider social rules and guarantee the
  psychological comfort of pedestrians. Among the research results in the field
  of robotic path planning, the learning-based socially adaptive algorithms have
  performed well in some specific human-robot interaction environments. However,
  human-robot interaction scenarios are diverse and constantly changing in daily
  life, and the generalization of robot socially adaptive path planning remains
  to be further investigated. In order to address this issue, this work proposes
  a new socially adaptive path planning algorithm by combining the generative
  adversarial network (GAN) with the Optimal Rapidly-exploring Random Tree (RRT*)
  navigation algorithm. Firstly, a GAN model with strong generalization
  performance is proposed to adapt the navigation algorithm to more scenarios.
  Secondly, a GAN model based Optimal Rapidly-exploring Random Tree navigation
  algorithm (GAN-RRT*) is proposed to generate paths in human-robot interaction
  environments. Finally, we propose a socially adaptive path planning framework
  named GAN-RTIRL, which combines the GAN model with Rapidly-exploring random
  Trees Inverse Reinforcement Learning (RTIRL) to improve the homotopy rate
  between planned and demonstration paths. In the GAN-RTIRL framework, the
  GAN-RRT* path planner can update the GAN model from the demonstration path. In
  this way, the robot can generate more anthropomorphic paths in human-robot
  interaction environments and has stronger generalization in more complex
  environments. Experimental results reveal that our proposed method can
  effectively improve the anthropomorphic degree of robot motion planning and the
  homotopy rate between planned and demonstration paths.
  </p>
  </div>
  </dd>
  <dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18688" title="Abstract">arXiv:2404.18688</a> [<a href="/pdf/2404.18688" title="Download PDF">pdf</a>, <a href="/format/2404.18688" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Distributed Source Coding for Parametric and Non-Parametric Regression
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+J">Jiahui Wei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dupraz%2C+E">Elsa Dupraz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mary%2C+P">Philippe Mary</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  <p class="mathjax">The design of communication systems dedicated to machine learning tasks is
  one key aspect of goal-oriented communications. In this framework, this article
  investigates the interplay between data reconstruction and learning from the
  same compressed observations, particularly focusing on the regression problem.
  We establish achievable rate-generalization error regions for both parametric
  and non-parametric regression, where the generalization error measures the
  regression performance on previously unseen data. The analysis covers both
  asymptotic and finite block-length regimes, providing fundamental results and
  practical insights for the design of coding schemes dedicated to regression.
  The asymptotic analysis relies on conventional Wyner-Ziv coding schemes which
  we extend to study the convergence of the generalization error. The
  finite-length analysis uses the notions of information density and dispersion
  with additional term for the generalization error. We further investigate the
  trade-off between reconstruction and regression in both asymptotic and
  non-asymptotic regimes. Contrary to the existing literature which focused on
  other learning tasks, our results state that in the case of regression, there
  is no trade-off between data reconstruction and regression in the asymptotic
  regime. We also observe the same absence of trade-off for the considered
  achievable scheme in the finite-length regime, by analyzing correlation between
  distortion and generalization error.
  </p>
  </div>
  </dd>
  <dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18692" title="Abstract">arXiv:2404.18692</a> [<a href="/pdf/2404.18692" title="Download PDF">pdf</a>, <a href="/format/2404.18692" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Private graph colouring with limited defectiveness
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Christiansen%2C+A+B+G">Aleksander B. G. Christiansen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rotenberg%2C+E">Eva Rotenberg</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Steiner%2C+T+A">Teresa Anna Steiner</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vlieghe%2C+J">Juliette Vlieghe</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  <p class="mathjax">Differential privacy is the gold standard in the problem of privacy
  preserving data analysis, which is crucial in a wide range of disciplines.
  Vertex colouring is one of the most fundamental questions about a graph. In
  this paper, we study the vertex colouring problem in the differentially private
  setting.
  <br>To be edge-differentially private, a colouring algorithm needs to be
  defective: a colouring is d-defective if a vertex can share a colour with at
  most d of its neighbours. Without defectiveness, the only differentially
  private colouring algorithm needs to assign n different colours to the n
  different vertices. We show the following lower bound for the defectiveness: a
  differentially private c-edge colouring algorithm of a graph of maximum degree
  {\Delta} &gt; 0 has defectiveness at least d = {\Omega} (log n / (log c+log
  {\Delta})).
  <br>We also present an {\epsilon}-differentially private algorithm to {\Theta} (
  {\Delta} / log n + 1 / {\epsilon})-colour a graph with defectiveness at most
  {\Theta}(log n).
  </p>
  </div>
  </dd>
  <dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18694" title="Abstract">arXiv:2404.18694</a> [<a href="/pdf/2404.18694" title="Download PDF">pdf</a>, <a href="/format/2404.18694" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Beyond Gaze Points: Augmenting Eye Movement with Brainwave Data for  Multimodal User Authentication in Extended Reality
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fallahi%2C+M">Matin Fallahi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Arias-Cabarcos%2C+P">Patricia Arias-Cabarcos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Strufe%2C+T">Thorsten Strufe</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>
  
  </div>
  <p class="mathjax">The increasing adoption of Extended Reality (XR) in various applications
  underscores the need for secure and user-friendly authentication methods.
  However, existing methods can disrupt the immersive experience in XR settings,
  or suffer from higher false acceptance rates. In this paper, we introduce a
  multimodal biometric authentication system that combines eye movement and
  brainwave patterns, as captured by consumer-grade low-fidelity sensors. Our
  multimodal authentication exploits the non-invasive and hands-free properties
  of eye movement and brainwaves to provide a seamless XR user experience and
  enhanced security as well. Using synchronized eye and brainwave data collected
  from 30 participants through consumer-grade devices, we investigated whether
  twin neural networks can utilize these biometrics for identity verification.
  Our multimodal authentication system yields an excellent Equal Error Rate (EER)
  of 0.298\%, which means an 83.6\% reduction in EER compared to the single eye
  movement modality or a 93.9\% reduction in EER compared to the single brainwave
  modality.
  </p>
  </div>
  </dd>
  <dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18695" title="Abstract">arXiv:2404.18695</a> [<a href="/pdf/2404.18695" title="Download PDF">pdf</a>, <a href="/format/2404.18695" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Dual-Modal Prompting for Sketch-Based Image Retrieval
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+L">Liying Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiao%2C+B">Bingliang Jiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+P">Peng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shizhou Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hanwang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yanning Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Sketch-based image retrieval (SBIR) associates hand-drawn sketches with their
  corresponding realistic images. In this study, we aim to tackle two major
  challenges of this task simultaneously: i) zero-shot, dealing with unseen
  categories, and ii) fine-grained, referring to intra-category instance-level
  retrieval. Our key innovation lies in the realization that solely addressing
  this cross-category and fine-grained recognition task from the generalization
  perspective may be inadequate since the knowledge accumulated from limited seen
  categories might not be fully valuable or transferable to unseen target
  categories. Inspired by this, in this work, we propose a dual-modal prompting
  CLIP (DP-CLIP) network, in which an adaptive prompting strategy is designed.
  Specifically, to facilitate the adaptation of our DP-CLIP toward unpredictable
  target categories, we employ a set of images within the target category and the
  textual category label to respectively construct a set of category-adaptive
  prompt tokens and channel scales. By integrating the generated guidance,
  DP-CLIP could gain valuable category-centric insights, efficiently adapting to
  novel categories and capturing unique discriminative clues for effective
  retrieval within each target category. With these designs, our DP-CLIP
  outperforms the state-of-the-art fine-grained zero-shot SBIR method by 7.3% in
  Acc.@1 on the Sketchy dataset. Meanwhile, in the other two category-level
  zero-shot SBIR benchmarks, our method also achieves promising performance.
  </p>
  </div>
  </dd>
  <dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18699" title="Abstract">arXiv:2404.18699</a> [<a href="/pdf/2404.18699" title="Download PDF">pdf</a>, <a href="/format/2404.18699" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Convergence Properties of Score-Based Models using Graduated  Optimisation for Linear Inverse Problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fernsel%2C+P">Pascal Fernsel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kereta%2C+%C5%BD">Željko Kereta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Denker%2C+A">Alexander Denker</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)
  
  </div>
  <p class="mathjax">The incorporation of generative models as regularisers within variational
  formulations for inverse problems has proven effective across numerous image
  reconstruction tasks. However, the resulting optimisation problem is often
  non-convex and challenging to solve. In this work, we show that score-based
  generative models (SGMs) can be used in a graduated optimisation framework to
  solve inverse problems. We show that the resulting graduated non-convexity flow
  converge to stationary points of the original problem and provide a numerical
  convergence analysis of a 2D toy example. We further provide experiments on
  computed tomography image reconstruction, where we show that this framework is
  able to recover high-quality images, independent of the initial value. The
  experiments highlight the potential of using SGMs in graduated optimisation
  frameworks.
  </p>
  </div>
  </dd>
  <dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18702" title="Abstract">arXiv:2404.18702</a> [<a href="/pdf/2404.18702" title="Download PDF">pdf</a>, <a href="/format/2404.18702" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Why You Should Not Trust Interpretations in Machine Learning:  Adversarial Attacks on Partial Dependence Plots
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xin%2C+X">Xi Xin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+F">Fei Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hooker%2C+G">Giles Hooker</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Applications (stat.AP); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">The adoption of artificial intelligence (AI) across industries has led to the
  widespread use of complex black-box models and interpretation tools for
  decision making. This paper proposes an adversarial framework to uncover the
  vulnerability of permutation-based interpretation methods for machine learning
  tasks, with a particular focus on partial dependence (PD) plots. This
  adversarial framework modifies the original black box model to manipulate its
  predictions for instances in the extrapolation domain. As a result, it produces
  deceptive PD plots that can conceal discriminatory behaviors while preserving
  most of the original model's predictions. This framework can produce multiple
  fooled PD plots via a single model. By using real-world datasets including an
  auto insurance claims dataset and COMPAS (Correctional Offender Management
  Profiling for Alternative Sanctions) dataset, our results show that it is
  possible to intentionally hide the discriminatory behavior of a predictor and
  make the black-box model appear neutral through interpretation tools like PD
  plots while retaining almost all the predictions of the original black-box
  model. Managerial insights for regulators and practitioners are provided based
  on the findings.
  </p>
  </div>
  </dd>
  <dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18705" title="Abstract">arXiv:2404.18705</a> [<a href="/pdf/2404.18705" title="Download PDF">pdf</a>, <a href="/format/2404.18705" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Wireless Information and Energy Transfer in the Era of 6G Communications
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Psomas%2C+C">Constantinos Psomas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ntougias%2C+K">Konstantinos Ntougias</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shanin%2C+N">Nikita Shanin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+D">Dongfang Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mayer%2C+K+M">Kenneth MacSporran Mayer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tran%2C+N+M">Nguyen Minh Tran</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cottatellucci%2C+L">Laura Cottatellucci</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Choi%2C+K+W">Kae Won Choi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D+I">Dong In Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schober%2C+R">Robert Schober</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Krikidis%2C+I">Ioannis Krikidis</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Proceedings of the IEEE, 36 pages, 33 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
  
  </div>
  <p class="mathjax">Wireless information and energy transfer (WIET) represents an emerging
  paradigm which employs controllable transmission of radio-frequency signals for
  the dual purpose of data communication and wireless charging. As such, WIET is
  widely regarded as an enabler of envisioned 6G use cases that rely on
  energy-sustainable Internet-of-Things (IoT) networks, such as smart cities and
  smart grids. Meeting the quality-of-service demands of WIET, in terms of both
  data transfer and power delivery, requires effective co-design of the
  information and energy signals. In this article, we present the main principles
  and design aspects of WIET, focusing on its integration in 6G networks. First,
  we discuss how conventional communication notions such as resource allocation
  and waveform design need to be revisited in the context of WIET. Next, we
  consider various candidate 6G technologies that can boost WIET efficiency,
  namely, holographic multiple-input multiple-output, near-field beamforming,
  terahertz communication, intelligent reflecting surfaces (IRSs), and
  reconfigurable (fluid) antenna arrays. We introduce respective WIET design
  methods, analyze the promising performance gains of these WIET systems, and
  discuss challenges, open issues, and future research directions. Finally, a
  near-field energy beamforming scheme and a power-based IRS beamforming
  algorithm are experimentally validated using a wireless energy transfer
  testbed. The vision of WIET in communication systems has been gaining momentum
  in recent years, with constant progress with respect to theoretical but also
  practical aspects. The comprehensive overview of the state of the art of WIET
  presented in this paper highlights the potentials of WIET systems as well as
  their overall benefits in 6G networks.
  </p>
  </div>
  </dd>
  <dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18706" title="Abstract">arXiv:2404.18706</a> [<a href="/pdf/2404.18706" title="Download PDF">pdf</a>, <a href="/format/2404.18706" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Socface Project: Large-Scale Collection, Processing, and Analysis of  a Century of French Censuses
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Boillet%2C+M">Mélodie Boillet</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tarride%2C+S">Solène Tarride</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schneider%2C+Y">Yoann Schneider</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Abadie%2C+B">Bastien Abadie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kesztenbaum%2C+L">Lionel Kesztenbaum</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kermorvant%2C+C">Christopher Kermorvant</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">This paper presents a complete processing workflow for extracting information
  from French census lists from 1836 to 1936. These lists contain information
  about individuals living in France and their households. We aim at extracting
  all the information contained in these tables using automatic handwritten table
  recognition. At the end of the Socface project, in which our work is taking
  place, the extracted information will be redistributed to the departmental
  archives, and the nominative lists will be freely available to the public,
  allowing anyone to browse hundreds of millions of records. The extracted data
  will be used by demographers to analyze social change over time, significantly
  improving our understanding of French economic and social structures. For this
  project, we developed a complete processing workflow: large-scale data
  collection from French departmental archives, collaborative annotation of
  documents, training of handwritten table text and structure recognition models,
  and mass processing of millions of images. We present the tools we have
  developed to easily collect and process millions of pages. We also show that it
  is possible to process such a wide variety of tables with a single table
  recognition model that uses the image of the entire page to recognize
  information about individuals, categorize them and automatically group them
  into households. The entire process has been successfully used to process the
  documents of a departmental archive, representing more than 450,000 images.
  </p>
  </div>
  </dd>
  <dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18708" title="Abstract">arXiv:2404.18708</a> [<a href="/pdf/2404.18708" title="Download PDF">pdf</a>, <a href="/format/2404.18708" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Iconic Gesture Semantics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=L%C3%BCcking%2C+A">Andy Lücking</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Henlein%2C+A">Alexander Henlein</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mehler%2C+A">Alexander Mehler</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 39 pages, 28 figures, under revision
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">The "meaning" of an iconic gesture is conditioned on its informational
  evaluation. Only informational evaluation lifts a gesture to a quasi-linguistic
  level that can interact with verbal content. Interaction is either vacuous or
  regimented by usual lexicon-driven inferences. Informational evaluation is
  spelled out as extended exemplification (extemplification) in terms of
  perceptual classification of a gesture's visual iconic model. The iconic model
  is derived from Frege/Montague-like truth-functional evaluation of a gesture's
  form within spatially extended domains. We further argue that the perceptual
  classification of instances of visual communication requires a notion of
  meaning different from Frege/Montague frameworks. Therefore, a heuristic for
  gesture interpretation is provided that can guide the working semanticist. In
  sum, an iconic gesture semantics is introduced which covers the full range from
  kinematic gesture representations over model-theoretic evaluation to
  inferential interpretation in dynamic semantic frameworks.
  </p>
  </div>
  </dd>
  <dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18713" title="Abstract">arXiv:2404.18713</a> [<a href="/pdf/2404.18713" title="Download PDF">pdf</a>, <a href="/format/2404.18713" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Adaptive Reinforcement Learning for Robot Control
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y+T">Yu Tang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Singh%2C+N">Nilaksh Singh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ahmad%2C+A">Aamir Ahmad</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)
  
  </div>
  <p class="mathjax">Deep reinforcement learning (DRL) has shown remarkable success in simulation
  domains, yet its application in designing robot controllers remains limited,
  due to its single-task orientation and insufficient adaptability to
  environmental changes. To overcome these limitations, we present a novel
  adaptive agent that leverages transfer learning techniques to dynamically adapt
  policy in response to different tasks and environmental conditions. The
  approach is validated through the blimp control challenge, where multitasking
  capabilities and environmental adaptability are essential. The agent is trained
  using a custom, highly parallelized simulator built on IsaacGym. We perform
  zero-shot transfer to fly the blimp in the real world to solve various tasks.
  We share our code at
  \url{https://github.com/robot-perception-group/adaptive\_agent/}.
  </p>
  </div>
  </dd>
  <dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18720" title="Abstract">arXiv:2404.18720</a> [<a href="/pdf/2404.18720" title="Download PDF">pdf</a>, <a href="/format/2404.18720" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Innovative Integration of Visual Foundation Model with a Robotic Arm on  a Mobile Platform
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shimian Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Q">Qiuhong Lu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">In the rapidly advancing field of robotics, the fusion of state-of-the-art
  visual technologies with mobile robotic arms has emerged as a critical
  integration. This paper introduces a novel system that combines the Segment
  Anything model (SAM) -- a transformer-based visual foundation model -- with a
  robotic arm on a mobile platform. The design of integrating a depth camera on
  the robotic arm's end-effector ensures continuous object tracking,
  significantly mitigating environmental uncertainties. By deploying on a mobile
  platform, our grasping system has an enhanced mobility, playing a key role in
  dynamic environments where adaptability are critical. This synthesis enables
  dynamic object segmentation, tracking, and grasping. It also elevates user
  interaction, allowing the robot to intuitively respond to various modalities
  such as clicks, drawings, or voice commands, beyond traditional robotic
  systems. Empirical assessments in both simulated and real-world demonstrate the
  system's capabilities. This configuration opens avenues for wide-ranging
  applications, from industrial settings, agriculture, and household tasks, to
  specialized assignments and beyond.
  </p>
  </div>
  </dd>
  <dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18721" title="Abstract">arXiv:2404.18721</a> [<a href="/pdf/2404.18721" title="Download PDF">pdf</a>, <a href="/format/2404.18721" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Risk-Aware Coverage Path Planning for Lunar Micro-Rovers Leveraging  Global and Local Environmental Data
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Santra%2C+S">Shreya Santra</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Uno%2C+K">Kentaro Uno</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kudo%2C+G">Gen Kudo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yoshida%2C+K">Kazuya Yoshida</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages, 11 figures. Manuscript accepted at the IEEE International Conference on Space Robotics 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">This paper presents a novel 3D myopic coverage path planning algorithm for
  lunar micro-rovers that can explore unknown environments with limited sensing
  and computational capabilities. The algorithm expands upon traditional
  non-graph path planning methods to accommodate the complexities of lunar
  terrain, utilizing global data with local topographic features into motion cost
  calculations. The algorithm also integrates localization and mapping to update
  the rover's pose and map the environment. The resulting environment map's
  accuracy is evaluated and tested in a 3D simulator. Outdoor field tests were
  conducted to validate the algorithm's efficacy in sim-to-real scenarios. The
  results showed that the algorithm could achieve high coverage with low energy
  consumption and computational cost, while incrementally exploring the terrain
  and avoiding obstacles. This study contributes to the advancement of path
  planning methodologies for space exploration, paving the way for efficient,
  scalable and autonomous exploration of lunar environments by small rovers.
  </p>
  </div>
  </dd>
  <dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18722" title="Abstract">arXiv:2404.18722</a> [<a href="/pdf/2404.18722" title="Download PDF">pdf</a>, <a href="/ps/2404.18722" title="Download PostScript">ps</a>, <a href="/format/2404.18722" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Improving Automatic Text Recognition with Language Models in the PyLaia  Open-Source Library
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tarride%2C+S">Solène Tarride</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schneider%2C+Y">Yoann Schneider</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Generali-Lince%2C+M">Marie Generali-Lince</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Boillet%2C+M">Mélodie Boillet</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Abadie%2C+B">Bastien Abadie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kermorvant%2C+C">Christopher Kermorvant</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)
  
  </div>
  <p class="mathjax">PyLaia is one of the most popular open-source software for Automatic Text
  Recognition (ATR), delivering strong performance in terms of speed and
  accuracy. In this paper, we outline our recent contributions to the PyLaia
  library, focusing on the incorporation of reliable confidence scores and the
  integration of statistical language modeling during decoding. Our
  implementation provides an easy way to combine PyLaia with n-grams language
  models at different levels. One of the highlights of this work is that language
  models are completely auto-tuned: they can be built and used easily without any
  expert knowledge, and without requiring any additional data. To demonstrate the
  significance of our contribution, we evaluate PyLaia's performance on twelve
  datasets, both with and without language modelling. The results show that
  decoding with small language models improves the Word Error Rate by 13% and the
  Character Error Rate by 12% in average. Additionally, we conduct an analysis of
  confidence scores and highlight the importance of calibration techniques. Our
  implementation is publicly available in the official PyLaia repository at
  https://gitlab.teklia.com/atr/pylaia, and twelve open-source models are
  released on Hugging Face.
  </p>
  </div>
  </dd>
  <dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18723" title="Abstract">arXiv:2404.18723</a> [<a href="/pdf/2404.18723" title="Download PDF">pdf</a>, <a href="/ps/2404.18723" title="Download PostScript">ps</a>, <a href="/format/2404.18723" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring Chebyshev Polynomial Approximations: Error Estimates for  Functions of Bounded Variation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Akansha%2C+S">S Akansha</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">Approximation theory plays a central role in numerical analysis, undergoing
  continuous evolution through a spectrum of methodologies. Notably, Lebesgue,
  Weierstrass, Fourier, and Chebyshev approximations stand out among these
  methods. However, each technique possesses inherent limitations, underscoring
  the critical importance of selecting an appropriate approximation method
  tailored to specific problem domains. This article delves into the utilization
  of Chebyshev polynomials at Chebyshev nodes for approximation. For sufficiently
  smooth functions, the partial sum of Chebyshev series expansion offers optimal
  polynomial approximation, rendering it a preferred choice in various
  applications such as digital signal processing and graph filters due to its
  computational efficiency. In this article, we focus on functions of bounded
  variation, which find numerous applications across mathematical physics,
  hyperbolic conservations, and optimization. We present two optimal error
  estimations associated with Chebyshev polynomial approximations tailored for
  such functions. To validate our theoretical assertions, we conduct numerical
  experiments. Additionally, we delineate promising future avenues aligned with
  this research, particularly within the realms of machine learning and related
  fields.
  </p>
  </div>
  </dd>
  <dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18726" title="Abstract">arXiv:2404.18726</a> [<a href="/pdf/2404.18726" title="Download PDF">pdf</a>, <a href="/format/2404.18726" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Constant in HATE: Analyzing Toxicity in Reddit across Topics and  Languages
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tufa%2C+W+T">Wondimagegnhue Tsegaye Tufa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Markov%2C+I">Ilia Markov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vossen%2C+P">Piek Vossen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to TRAC 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Toxic language remains an ongoing challenge on social media platforms,
  presenting significant issues for users and communities. This paper provides a
  cross-topic and cross-lingual analysis of toxicity in Reddit conversations. We
  collect 1.5 million comment threads from 481 communities in six languages:
  English, German, Spanish, Turkish,Arabic, and Dutch, covering 80 topics such as
  Culture, Politics, and News. We thoroughly analyze how toxicity spikes within
  different communities in relation to specific topics. We observe consistent
  patterns of increased toxicity across languages for certain topics, while also
  noting significant variations within specific language communities.
  </p>
  </div>
  </dd>
  <dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18729" title="Abstract">arXiv:2404.18729</a> [<a href="/pdf/2404.18729" title="Download PDF">pdf</a>, <a href="/format/2404.18729" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Fast Swarming of UAVs in GNSS-denied Feature-poor Environments without  Explicit Communication
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Horyna%2C+J">Jiri Horyna</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kratky%2C+V">Vit Kratky</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pritzl%2C+V">Vaclav Pritzl</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Baca%2C+T">Tomas Baca</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ferrante%2C+E">Eliseo Ferrante</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Saska%2C+M">Martin Saska</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to IEEE RA-L on March 22, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">A decentralized swarm approach for the fast cooperative flight of Unmanned
  Aerial Vehicles (UAVs) in feature-poor environments without any external
  localization and communication is introduced in this paper.
  <br>A novel model of a UAV neighborhood is proposed to achieve robust onboard
  mutual perception and flocking state feedback control, which is designed to
  decrease the inter-agent oscillations common in standard reactive swarm models
  employed in fast collective motion.
  <br>The novel swarming methodology is supplemented with an enhanced Multi-Robot
  State Estimation (MRSE) strategy to increase the reliability of the purely
  onboard localization, which may be unreliable in real environments.
  <br>Although MRSE and the neighborhood model may rely on information exchange
  between agents, we introduce a communication-less version of the swarming
  framework based on estimating communicated states to decrease dependence on the
  often unreliable communication networks of large swarms.
  <br>The proposed solution has been verified by a set of complex real-world
  experiments to demonstrate its overall capability in different conditions,
  including a UAV interception-motivated task with a group velocity reaching the
  physical limits of the individual hardware platforms.
  </p>
  </div>
  </dd>
  <dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18730" title="Abstract">arXiv:2404.18730</a> [<a href="/pdf/2404.18730" title="Download PDF">pdf</a>, <a href="/format/2404.18730" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CVTN: Cross Variable and Temporal Integration for Time Series  Forecasting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+H">Han Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuntian Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP)
  
  </div>
  <p class="mathjax">In multivariate time series forecasting, the Transformer architecture
  encounters two significant challenges: effectively mining features from
  historical sequences and avoiding overfitting during the learning of temporal
  dependencies. To tackle these challenges, this paper deconstructs time series
  forecasting into the learning of historical sequences and prediction sequences,
  introducing the Cross-Variable and Time Network (CVTN). This unique method
  divides multivariate time series forecasting into two phases: cross-variable
  learning for effectively mining fea tures from historical sequences, and
  cross-time learning to capture the temporal dependencies of prediction
  sequences. Separating these two phases helps avoid the impact of overfitting in
  cross-time learning on cross-variable learning. Exten sive experiments on
  various real-world datasets have confirmed its state-of-the-art (SOTA)
  performance. CVTN emphasizes three key dimensions in time series fore casting:
  the short-term and long-term nature of time series (locality and longevity),
  feature mining from both historical and prediction sequences, and the
  integration of cross-variable and cross-time learning. This approach not only
  advances the current state of time series forecasting but also provides a more
  comprehensive framework for future research in this field.
  </p>
  </div>
  </dd>
  <dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18731" title="Abstract">arXiv:2404.18731</a> [<a href="/pdf/2404.18731" title="Download PDF">pdf</a>, <a href="/format/2404.18731" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Real Time Multi Organ Classification on Computed Tomography Images
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yerebakan%2C+H+Z">Halid Ziya Yerebakan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shinagawa%2C+Y">Yoshihisa Shinagawa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Valadez%2C+G+H">Gerardo Hermosillo Valadez</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Organ segmentation is a fundamental task in medical imaging, and it is useful
  for many clinical automation pipelines. Typically, the process involves
  segmenting the entire volume, which can be unnecessary when the points of
  interest are limited. In those cases, a classifier could be used instead of
  segmentation. However, there is an inherent trade-off between the context size
  and the speed of classifiers. To address this issue, we propose a new method
  that employs a data selection strategy with sparse sampling across a wide field
  of view without image resampling. This sparse sampling strategy makes it
  possible to classify voxels into multiple organs in real time without using
  accelerators. Although our method is an independent classifier, it can generate
  full segmentation by querying grid locations at any resolution. We have
  compared our method with existing segmentation techniques, demonstrating its
  potential for superior runtime in practical applications in medical imaging.
  </p>
  </div>
  </dd>
  <dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18736" title="Abstract">arXiv:2404.18736</a> [<a href="/pdf/2404.18736" title="Download PDF">pdf</a>, <a href="/format/2404.18736" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mapping the Potential of Explainable Artificial Intelligence (XAI) for  Fairness Along the AI Lifecycle
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Deck%2C+L">Luca Deck</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schoem%C3%A4cker%2C+A">Astrid Schoemäcker</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Speith%2C+T">Timo Speith</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sch%C3%B6ffer%2C+J">Jakob Schöffer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=K%C3%A4stner%2C+L">Lena Kästner</a>, 
  <a href="/search/cs?searchtype=author&amp;query=K%C3%BChl%2C+N">Niklas Kühl</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
  
  </div>
  <p class="mathjax">The widespread use of artificial intelligence (AI) systems across various
  domains is increasingly highlighting issues related to algorithmic fairness,
  especially in high-stakes scenarios. Thus, critical considerations of how
  fairness in AI systems might be improved, and what measures are available to
  aid this process, are overdue. Many researchers and policymakers see
  explainable AI (XAI) as a promising way to increase fairness in AI systems.
  However, there is a wide variety of XAI methods and fairness conceptions
  expressing different desiderata, and the precise connections between XAI and
  fairness remain largely nebulous. Besides, different measures to increase
  algorithmic fairness might be applicable at different points throughout an AI
  system's lifecycle. Yet, there currently is no coherent mapping of fairness
  desiderata along the AI lifecycle. In this paper, we set out to bridge both
  these gaps: We distill eight fairness desiderata, map them along the AI
  lifecycle, and discuss how XAI could help address each of them. We hope to
  provide orientation for practical applications and to inspire XAI research
  specifically focused on these fairness desiderata.
  </p>
  </div>
  </dd>
  <dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18738" title="Abstract">arXiv:2404.18738</a> [<a href="/pdf/2404.18738" title="Download PDF">pdf</a>, <a href="/format/2404.18738" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A faster algorithm for the Fréchet distance in 1D for the imbalanced  case
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Blank%2C+L">Lotte Blank</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Driemel%2C+A">Anne Driemel</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>
  
  </div>
  <p class="mathjax">The fine-grained complexity of computing the Fr\'echet distance has been a
  topic of much recent work, starting with the quadratic SETH-based conditional
  lower bound by Bringmann from 2014. Subsequent work established largely the
  same complexity lower bounds for the Fr\'echet distance in 1D. However, the
  imbalanced case, which was shown by Bringmann to be tight in dimensions <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-223-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1431" style="width: 2.939em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.374em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.374em, 2.826em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1432"><span class="mi" id="MathJax-Span-1433" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1434" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≥</span><span class="mn" id="MathJax-Span-1435" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-223">d\geq
  2</script>, was still left open. Filling in this gap, we show that a faster algorithm
  for the Fr\'echet distance in the imbalanced case is possible: Given two
  1-dimensional curves of complexity <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-224-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1436" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1437"><span class="mi" id="MathJax-Span-1438" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-224">n</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-225-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1439" style="width: 1.245em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.019em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1440"><span class="msubsup" id="MathJax-Span-1441"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1442" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-1443"><span class="mrow" id="MathJax-Span-1444"><span class="mi" id="MathJax-Span-1445" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">α</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-225">n^{\alpha}</script> for some <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-226-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1446" style="width: 4.971em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.011em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.955em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1447"><span class="mi" id="MathJax-Span-1448" style="font-family: STIXGeneral-Italic;">α</span><span class="mo" id="MathJax-Span-1449" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="mo" id="MathJax-Span-1450" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">(</span><span class="mn" id="MathJax-Span-1451" style="font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-1452" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-1453" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">1</span><span class="mo" id="MathJax-Span-1454" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-226">\alpha \in
  (0,1)</script>, we can compute their Fr\'echet distance in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-227-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1455" style="width: 11.125em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.036em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.471em, 1008.98em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1456"><span class="mi" id="MathJax-Span-1457" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1458" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1459"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1460" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.511em;"><span class="texatom" id="MathJax-Span-1461"><span class="mrow" id="MathJax-Span-1462"><span class="mn" id="MathJax-Span-1463" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mi" id="MathJax-Span-1464" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">α</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-1465" style="padding-left: 0.172em;"><span style="display: inline-block; position: relative; width: 1.697em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1001.245em, 4.407em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1466" style="font-family: STIXGeneral-Regular;">log</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.301em;"><span class="mn" id="MathJax-Span-1467" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1468"></span><span class="mi" id="MathJax-Span-1469" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">n</span><span class="mo" id="MathJax-Span-1470" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">+</span><span class="mi" id="MathJax-Span-1471" style="font-family: STIXGeneral-Italic; padding-left: 0.229em;">n</span><span class="mi" id="MathJax-Span-1472" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">log</span><span class="mo" id="MathJax-Span-1473"></span><span class="mi" id="MathJax-Span-1474" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">n</span><span class="mo" id="MathJax-Span-1475" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.531em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-227">O(n^{2\alpha} \log^2 n + n
  \log n)</script> time. This rules out a conditional lower bound of the form
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-228-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1476" style="width: 5.649em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.576em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1004.52em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1477"><span class="mi" id="MathJax-Span-1478" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1479" style="font-family: STIXGeneral-Regular;">(</span><span class="mo" id="MathJax-Span-1480" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1481" style="font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-1482" style="font-family: STIXGeneral-Italic;">m</span><span class="msubsup" id="MathJax-Span-1483"><span style="display: inline-block; position: relative; width: 1.584em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.285em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="mo" id="MathJax-Span-1484" style="font-family: STIXGeneral-Regular;">)</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.342em;"><span class="texatom" id="MathJax-Span-1485"><span class="mrow" id="MathJax-Span-1486"><span class="mn" id="MathJax-Span-1487" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1488" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mi" id="MathJax-Span-1489" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">ϵ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1490" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-228">O((nm)^{1-\epsilon})</script> that Bringmann showed for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-229-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1491" style="width: 2.939em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.374em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.374em, 2.826em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1492"><span class="mi" id="MathJax-Span-1493" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1494" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≥</span><span class="mn" id="MathJax-Span-1495" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-229">d \geq 2</script> and any
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-230-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1496" style="width: 2.882em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.318em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1497"><span class="mi" id="MathJax-Span-1498" style="font-family: STIXGeneral-Italic;">ε</span><span class="mo" id="MathJax-Span-1499" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">&gt;</span><span class="mn" id="MathJax-Span-1500" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">0</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-230">\varepsilon>0</script> in turn showing a strict separation with the setting <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-231-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1501" style="width: 2.939em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.374em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.261em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1502"><span class="mi" id="MathJax-Span-1503" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1504" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mn" id="MathJax-Span-1505" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-231">d=1</script>. At
  the heart of our approach lies a data structure that stores a 1-dimensional
  curve <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-232-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1506" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1507"><span class="mi" id="MathJax-Span-1508" style="font-family: STIXGeneral-Italic;">P</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-232">P</script> of complexity <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-233-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1509" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1510"><span class="mi" id="MathJax-Span-1511" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-233">n</script>, and supports queries with a curve <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-234-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1512" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1513"><span class="mi" id="MathJax-Span-1514" style="font-family: STIXGeneral-Italic;">Q</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-234">Q</script> of
  complexity~<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-235-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1515" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1516"><span class="mi" id="MathJax-Span-1517" style="font-family: STIXGeneral-Italic;">m</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-235">m</script> for the continuous Fr\'echet distance between <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-236-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1518" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1519"><span class="mi" id="MathJax-Span-1520" style="font-family: STIXGeneral-Italic;">P</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-236">P</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-237-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1521" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.737em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1522"><span class="mi" id="MathJax-Span-1523" style="font-family: STIXGeneral-Italic;">Q</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-237">Q</script>. The
  data structure has size in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-238-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1524" style="width: 5.028em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.068em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(2.205em, 1004.011em, 3.447em, -999.997em); top: -3.046em; left: 0em;"><span class="mrow" id="MathJax-Span-1525"><span class="texatom" id="MathJax-Span-1526"><span class="mrow" id="MathJax-Span-1527"><span class="mi" id="MathJax-Span-1528" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-1529" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1530" style="font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-1531" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">log</span><span class="mo" id="MathJax-Span-1532"></span><span class="mi" id="MathJax-Span-1533" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">n</span><span class="mo" id="MathJax-Span-1534" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 3.052em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-238">\mathcal{O}(n\log n)</script> and uses query time in
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-239-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1535" style="width: 6.27em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.084em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.979em, 1005.028em, 3.447em, -999.997em); top: -3.046em; left: 0em;"><span class="mrow" id="MathJax-Span-1536"><span class="texatom" id="MathJax-Span-1537"><span class="mrow" id="MathJax-Span-1538"><span class="mi" id="MathJax-Span-1539" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-1540" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1541"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1542" style="font-family: STIXGeneral-Italic;">m</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.737em;"><span class="mn" id="MathJax-Span-1543" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-1544" style="padding-left: 0.172em;"><span style="display: inline-block; position: relative; width: 1.697em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1001.245em, 4.407em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1545" style="font-family: STIXGeneral-Regular;">log</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.301em;"><span class="mn" id="MathJax-Span-1546" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1547"></span><span class="mi" id="MathJax-Span-1548" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">n</span><span class="mo" id="MathJax-Span-1549" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 3.052em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.531em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-239">\mathcal{O}(m^2 \log^2 n)</script>. Our proof uses a key lemma that is based on the
  concept of visiting orders and may be of independent interest. We demonstrate
  this by substantially simplifying the correctness proof of a clustering
  algorithm by Driemel, Krivo\v{s}ija and Sohler from 2015.
  </p>
  </div>
  </dd>
  <dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18739" title="Abstract">arXiv:2404.18739</a> [<a href="/pdf/2404.18739" title="Download PDF">pdf</a>, <a href="/format/2404.18739" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Dog Bark Decoding: Leveraging Human Speech Processing for  Automated Bark Classification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Abzaliev%2C+A">Artem Abzaliev</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Espinosa%2C+H+P">Humberto Pérez Espinosa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mihalcea%2C+R">Rada Mihalcea</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> to be published in LREC-COLING 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Similar to humans, animals make extensive use of verbal and non-verbal forms
  of communication, including a large range of audio signals. In this paper, we
  address dog vocalizations and explore the use of self-supervised speech
  representation models pre-trained on human speech to address dog bark
  classification tasks that find parallels in human-centered tasks in speech
  recognition. We specifically address four tasks: dog recognition, breed
  identification, gender classification, and context grounding. We show that
  using speech embedding representations significantly improves over simpler
  classification baselines. Further, we also find that models pre-trained on
  large human speech acoustics can provide additional performance boosts on
  several tasks.
  </p>
  </div>
  </dd>
  <dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18746" title="Abstract">arXiv:2404.18746</a> [<a href="/pdf/2404.18746" title="Download PDF">pdf</a>, <a href="/format/2404.18746" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhancing Interactive Image Retrieval With Query Rewriting Using Large  Language Models and Vision Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+H">Hongyi Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jia-Hong Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rudinac%2C+S">Stevan Rudinac</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kanoulas%2C+E">Evangelos Kanoulas</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Image search stands as a pivotal task in multimedia and computer vision,
  finding applications across diverse domains, ranging from internet search to
  medical diagnostics. Conventional image search systems operate by accepting
  textual or visual queries, retrieving the top-relevant candidate results from
  the database. However, prevalent methods often rely on single-turn procedures,
  introducing potential inaccuracies and limited recall. These methods also face
  the challenges, such as vocabulary mismatch and the semantic gap, constraining
  their overall effectiveness. To address these issues, we propose an interactive
  image retrieval system capable of refining queries based on user relevance
  feedback in a multi-turn setting. This system incorporates a vision language
  model (VLM) based image captioner to enhance the quality of text-based queries,
  resulting in more informative queries with each iteration. Moreover, we
  introduce a large language model (LLM) based denoiser to refine text-based
  query expansions, mitigating inaccuracies in image descriptions generated by
  captioning models. To evaluate our system, we curate a new dataset by adapting
  the MSR-VTT video retrieval dataset to the image retrieval task, offering
  multiple relevant ground truth images for each query. Through comprehensive
  experiments, we validate the effectiveness of our proposed system against
  baseline methods, achieving state-of-the-art performance with a notable 10\%
  improvement in terms of recall. Our contributions encompass the development of
  an innovative interactive image retrieval system, the integration of an
  LLM-based denoiser, the curation of a meticulously designed evaluation dataset,
  and thorough experimental validation.
  </p>
  </div>
  </dd>
  <dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18747" title="Abstract">arXiv:2404.18747</a> [<a href="/pdf/2404.18747" title="Download PDF">pdf</a>, <a href="/format/2404.18747" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Evaluating the Effectiveness of Video Anomaly Detection in the Wild:  Online Learning and Inference for Real-world Deployment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yao%2C+S">Shanle Yao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Noghre%2C+G+A">Ghazal Alinezhad Noghre</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pazho%2C+A+D">Armin Danesh Pazho</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tabkhi%2C+H">Hamed Tabkhi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Video Anomaly Detection (VAD) identifies unusual activities in video streams,
  a key technology with broad applications ranging from surveillance to
  healthcare. Tackling VAD in real-life settings poses significant challenges due
  to the dynamic nature of human actions, environmental variations, and domain
  shifts. Many research initiatives neglect these complexities, often
  concentrating on traditional testing methods that fail to account for
  performance on unseen datasets, creating a gap between theoretical models and
  their real-world utility. Online learning is a potential strategy to mitigate
  this issue by allowing models to adapt to new information continuously. This
  paper assesses how well current VAD algorithms can adjust to real-life
  conditions through an online learning framework, particularly those based on
  pose analysis, for their efficiency and privacy advantages. Our proposed
  framework enables continuous model updates with streaming data from novel
  environments, thus mirroring actual world challenges and evaluating the models'
  ability to adapt in real-time while maintaining accuracy. We investigate three
  state-of-the-art models in this setting, focusing on their adaptability across
  different domains. Our findings indicate that, even under the most challenging
  conditions, our online learning approach allows a model to preserve 89.39% of
  its original effectiveness compared to its offline-trained counterpart in a
  specific target domain.
  </p>
  </div>
  </dd>
  <dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18750" title="Abstract">arXiv:2404.18750</a> [<a href="/pdf/2404.18750" title="Download PDF">pdf</a>, <a href="/format/2404.18750" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Survey on Datasets for Perception in Unstructured Outdoor Environments
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mortimer%2C+P">Peter Mortimer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Maehlisch%2C+M">Mirko Maehlisch</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the IEEE ICRA Workshop on Field Robotics 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
  
  </div>
  <p class="mathjax">Perception is an essential component of pipelines in field robotics. In this
  survey, we quantitatively compare publicly available datasets available in
  unstructured outdoor environments. We focus on datasets for common perception
  tasks in field robotics. Our survey categorizes and compares available research
  datasets. This survey also reports on relevant dataset characteristics to help
  practitioners determine which dataset fits best for their own application. We
  believe more consideration should be taken in choosing compatible annotation
  policies across the datasets in unstructured outdoor environments.
  </p>
  </div>
  </dd>
  <dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18755" title="Abstract">arXiv:2404.18755</a> [<a href="/pdf/2404.18755" title="Download PDF">pdf</a>, <a href="/ps/2404.18755" title="Download PostScript">ps</a>, <a href="/format/2404.18755" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Desirability and social rankings
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Aleandri%2C+M">Michele Aleandri</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fritz%2C+F">Felix Fritz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Moretti%2C+S">Stefano Moretti</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>
  
  </div>
  <p class="mathjax">In coalitional games, a player <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-240-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1550" style="width: 0.342em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.285em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.285em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1551"><span class="mi" id="MathJax-Span-1552" style="font-family: STIXGeneral-Italic;">i</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-240">i</script> is regarded as strictly more desirable
  than player <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-241-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1553" style="width: 0.342em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.285em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.285em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1554"><span class="mi" id="MathJax-Span-1555" style="font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-241">j</script> if substituting <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-242-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1556" style="width: 0.342em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.285em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.285em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1557"><span class="mi" id="MathJax-Span-1558" style="font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-242">j</script> with <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-243-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1559" style="width: 0.342em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.285em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.285em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1560"><span class="mi" id="MathJax-Span-1561" style="font-family: STIXGeneral-Italic;">i</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-243">i</script> within any coalition leads to a
  strict augmentation in the value of certain coalitions, while preserving the
  value of the others. We adopt a property-driven approach to 'integrate' the
  notion of the desirability relation into a total relation by establishing sets
  of independent axioms leading to the characterization of solutionconcepts from
  the related literature. We focus on social ranking solutions consistent with
  the desirability relation and propose complementary sets of properties for the
  axiomatic characterization of five existing solutions: Ceteris Paribus
  (CP-)majority, lexicographic excellence (lex-cel), dual-lex, <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-244-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1562" style="width: 1.979em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.584em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.584em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1563"><span class="msubsup" id="MathJax-Span-1564"><span style="display: inline-block; position: relative; width: 1.527em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1565" style="font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.624em;"><span class="texatom" id="MathJax-Span-1566"><span class="mrow" id="MathJax-Span-1567"><span class="mo" id="MathJax-Span-1568" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-1569" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1570" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-244">L^{(1)}</script> solution
  and its dual version <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-245-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1571" style="width: 1.979em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.584em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.11em, 1001.584em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1572"><span class="msubsup" id="MathJax-Span-1573"><span style="display: inline-block; position: relative; width: 1.527em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.567em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1574" style="font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.39em, 1000.906em, 4.294em, -999.997em); top: -4.457em; left: 0.624em;"><span class="texatom" id="MathJax-Span-1575"><span class="mrow" id="MathJax-Span-1576"><span class="mo" id="MathJax-Span-1577" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-1578" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1579" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1000.454em, 4.181em, -999.997em); top: -3.836em; left: 0.567em;"><span class="texatom" id="MathJax-Span-1580"><span class="mrow" id="MathJax-Span-1581"><span class="mo" id="MathJax-Span-1582" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∗</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-245">L^{(1)}_{*}</script> . These characterizations reveal additional
  similarities among the five solutions and emphasize the essential
  characteristics that should be taken into account when selecting a social
  ranking. A practical scenario involving a bicameral legislature is studied.
  </p>
  </div>
  </dd>
  <dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18756" title="Abstract">arXiv:2404.18756</a> [<a href="/pdf/2404.18756" title="Download PDF">pdf</a>, <a href="/format/2404.18756" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> K-CIRCT: A Layered, Composable, and Executable Formal Semantics for  CIRCT Hardware IRs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jianhong Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kang%2C+J">Jinhui Kang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yongwang Zhao</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)
  
  </div>
  <p class="mathjax">CIRCT, an open-source EDA framework akin to LLVM for software, is a
  foundation for various hardware description languages. Despite its crucial
  role, CIRCT's lack of formal semantics challenges necessary rigorous hardware
  verification. Thus, this paper introduces K-CIRCT, the first formal semantics
  in {\K} for a substantial CIRCT subset adequate for simulating a RISC-V
  processor. Our semantics are structured into multiple layers: (1) MLIR static
  semantics, which covers fundamental MLIR concepts across domains; (2) CIRCT
  common semantics, featuring a generic hardware model that captures key hardware
  features across dialects; and (3) composable and extensible semantics for
  specific dialects, formalized individually using a unified approach. This
  approach has been applied to formalize CIRCT core dialects. We validated our
  semantics through full-rule coverage tests and assessed its practicality using
  the popular RISC-V hardware design, riscv-mini.
  </p>
  </div>
  </dd>
  <dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18758" title="Abstract">arXiv:2404.18758</a> [<a href="/pdf/2404.18758" title="Download PDF">pdf</a>, <a href="/format/2404.18758" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Transitive Vision-Language Prompt Learning for Domain Generalization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Liyuan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jin%2C+Y">Yan Jin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhen Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+J">Jinlin Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Mengke Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yang Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hanzi Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">The vision-language pre-training has enabled deep models to make a huge step
  forward in generalizing across unseen domains. The recent learning method based
  on the vision-language pre-training model is a great tool for domain
  generalization and can solve this problem to a large extent. However, there are
  still some issues that an advancement still suffers from trading-off between
  domain invariance and class separability, which are crucial in current DG
  problems. However, there are still some issues that an advancement still
  suffers from trading-off between domain invariance and class separability,
  which are crucial in current DG problems. In this paper, we introduce a novel
  prompt learning strategy that leverages deep vision prompts to address domain
  invariance while utilizing language prompts to ensure class separability,
  coupled with adaptive weighting mechanisms to balance domain invariance and
  class separability. Extensive experiments demonstrate that deep vision prompts
  effectively extract domain-invariant features, significantly improving the
  generalization ability of deep models and achieving state-of-the-art
  performance on three datasets.
  </p>
  </div>
  </dd>
  <dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18759" title="Abstract">arXiv:2404.18759</a> [<a href="/pdf/2404.18759" title="Download PDF">pdf</a>, <a href="/ps/2404.18759" title="Download PostScript">ps</a>, <a href="/format/2404.18759" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards A Structured Overview of Use Cases for Natural Language  Processing in the Legal Domain: A German Perspective
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Vladika%2C+J">Juraj Vladika</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Meisenbacher%2C+S">Stephen Meisenbacher</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Preis%2C+M">Martina Preis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Klymenko%2C+A">Alexandra Klymenko</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Matthes%2C+F">Florian Matthes</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 6 tables, 30th Americas Conference on Information Systems (AMCIS 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)
  
  </div>
  <p class="mathjax">In recent years, the field of Legal Tech has risen in prevalence, as the
  Natural Language Processing (NLP) and legal disciplines have combined forces to
  digitalize legal processes. Amidst the steady flow of research solutions
  stemming from the NLP domain, the study of use cases has fallen behind, leading
  to a number of innovative technical methods without a place in practice. In
  this work, we aim to build a structured overview of Legal Tech use cases,
  grounded in NLP literature, but also supplemented by voices from legal practice
  in Germany. Based upon a Systematic Literature Review, we identify seven
  categories of NLP technologies for the legal domain, which are then studied in
  juxtaposition to 22 legal use cases. In the investigation of these use cases,
  we identify 15 ethical, legal, and social aspects (ELSA), shedding light on the
  potential concerns of digitally transforming the legal domain.
  </p>
  </div>
  </dd>
  <dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18760" title="Abstract">arXiv:2404.18760</a> [<a href="/pdf/2404.18760" title="Download PDF">pdf</a>, <a href="/format/2404.18760" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Flow AM: Generating Point Cloud Global Explanations by Latent Alignment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tan%2C+H">Hanxiao Tan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Although point cloud models have gained significant improvements in
  prediction accuracy over recent years, their trustworthiness is still not
  sufficiently investigated. In terms of global explainability, Activation
  Maximization (AM) techniques in the image domain are not directly
  transplantable due to the special structure of the point cloud models. Existing
  studies exploit generative models to yield global explanations that can be
  perceived by humans. However, the opacity of the generative models themselves
  and the introduction of additional priors call into question the plausibility
  and fidelity of the explanations. In this work, we demonstrate that when the
  classifier predicts different types of instances, the intermediate layer
  activations are differently activated, known as activation flows. Based on this
  property, we propose an activation flow-based AM method that generates global
  explanations that can be perceived without incorporating any generative model.
  Furthermore, we reveal that AM based on generative models fails the sanity
  checks and thus lack of fidelity. Extensive experiments show that our approach
  dramatically enhances the perceptibility of explanations compared to other AM
  methods that are not based on generative models. Our code is available at:
  https://github.com/Explain3D/FlowAM
  </p>
  </div>
  </dd>
  <dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18763" title="Abstract">arXiv:2404.18763</a> [<a href="/pdf/2404.18763" title="Download PDF">pdf</a>, <a href="/ps/2404.18763" title="Download PostScript">ps</a>, <a href="/format/2404.18763" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> From Density to Geometry: YOLOv8 Instance Segmentation for Reverse  Engineering of Optimized Structures
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rochefort-Beaudoin%2C+T">Thomas Rochefort-Beaudoin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vadean%2C+A">Aurelian Vadean</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Achiche%2C+S">Sofiane Achiche</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aage%2C+N">Niels Aage</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Engineering, Finance, and Science (cs.CE)
  
  </div>
  <p class="mathjax">This paper introduces YOLOv8-TO, a novel approach for reverse engineering of
  topology-optimized structures into interpretable geometric parameters using the
  YOLOv8 instance segmentation model. Density-based topology optimization methods
  require post-processing to convert the optimal density distribution into a
  parametric representation for design exploration and integration with CAD
  tools. Traditional methods such as skeletonization struggle with complex
  geometries and require manual intervention. YOLOv8-TO addresses these
  challenges by training a custom YOLOv8 model to automatically detect and
  reconstruct structural components from binary density distributions. The model
  is trained on a diverse dataset of both optimized and random structures
  generated using the Moving Morphable Components method. A custom reconstruction
  loss function based on the dice coefficient of the predicted geometry is used
  to train the new regression head of the model via self-supervised learning. The
  method is evaluated on test sets generated from different topology optimization
  methods, including out-of-distribution samples, and compared against a
  skeletonization approach. Results show that YOLOv8-TO significantly outperforms
  skeletonization in reconstructing visually and structurally similar designs.
  The method showcases an average improvement of 13.84% in the Dice coefficient,
  with peak enhancements reaching 20.78%. The method demonstrates good
  generalization to complex geometries and fast inference times, making it
  suitable for integration into design workflows using regular workstations.
  Limitations include the sensitivity to non-max suppression thresholds.
  YOLOv8-TO represents a significant advancement in topology optimization
  post-processing, enabling efficient and accurate reverse engineering of
  optimized structures for design exploration and manufacturing.
  </p>
  </div>
  </dd>
  <dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18766" title="Abstract">arXiv:2404.18766</a> [<a href="/pdf/2404.18766" title="Download PDF">pdf</a>, <a href="/format/2404.18766" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PECC: Problem Extraction and Coding Challenges
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Haller%2C+P">Patrick Haller</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Golde%2C+J">Jonas Golde</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Akbik%2C+A">Alan Akbik</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This paper got accepted at LREC-COLING 2024 (long)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  <p class="mathjax">Recent advancements in large language models (LLMs) have showcased their
  exceptional abilities across various tasks, such as code generation,
  problem-solving and reasoning. Existing benchmarks evaluate tasks in isolation,
  yet the extent to which LLMs can understand prose-style tasks, identify the
  underlying problems, and then generate appropriate code solutions is still
  unexplored. Addressing this gap, we introduce PECC, a novel benchmark derived
  from Advent Of Code (AoC) challenges and Project Euler, including 2396
  problems. Unlike conventional benchmarks, PECC requires LLMs to interpret
  narrative-embedded problems, extract requirements, and generate executable
  code. A key feature of our dataset is the complexity added by natural language
  prompting in chat-based evaluations, mirroring real-world instruction
  ambiguities. Results show varying model performance between narrative and
  neutral problems, with specific challenges in the Euler math-based subset with
  GPT-3.5-Turbo passing 50% of the AoC challenges and only 8% on the Euler
  problems. By probing the limits of LLMs' capabilities, our benchmark provides a
  framework to monitor and assess the subsequent progress of LLMs as a universal
  problem solver.
  </p>
  </div>
  </dd>
  <dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18767" title="Abstract">arXiv:2404.18767</a> [<a href="/pdf/2404.18767" title="Download PDF">pdf</a>, <a href="/ps/2404.18767" title="Download PostScript">ps</a>, <a href="/format/2404.18767" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Port-Hamiltonian System Perspective on Electromagneto-Quasistatic  Field Formulations of Darwin-Type
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Clemens%2C+M">Markus Clemens</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Henkel%2C+M">Marvin-Lucas Henkel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kasolis%2C+F">Fotios Kasolis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=G%C3%BCnther%2C+M">Michael Günther</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 0 figures, pre-submission version (preprint), presented at and submitted to the proceedings of "The 15th International Conference on Scientific Computing in Electrical Engineering" (SCEE 2024), March 4-8, 2024, Darmstadt, Germany
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>
  
  </div>
  <p class="mathjax">Electromagneto-quasistatic (EMQS) field formulations are often dubbed as
  Darwin-type field formulations which approximate the Maxwell equations by
  neglecting radiation effects while modelling resistive, capacitive, and
  inductive effects. A common feature of EMQS field models is the Darwin-Amp\'ere
  equation formulated with the magnetic vector potential and the electric scalar
  potential. EMQS field formulations yield different approximations to the
  Maxwell equations by choice of additional gauge equations. These EMQS
  formulations are analyzed within the port-Hamiltonian system (PHS) framework.
  It is shown via the PHS compatibility equation that formulations based on the
  combination of the Darwin-Amp\'ere equation and the full Maxwell continuity
  equation yield port-Hamiltonian systems implying numerical stability and
  specific EMQS energy conservation.
  </p>
  </div>
  </dd>
  <dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18771" title="Abstract">arXiv:2404.18771</a> [<a href="/pdf/2404.18771" title="Download PDF">pdf</a>, <a href="/format/2404.18771" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> KBX: Verified Model Synchronization via Formal Bidirectional  Transformation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jianhong Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yongwang Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yao%2C+P">Peisen Yao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+F">Fanlang Zeng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhan%2C+B">Bohua Zhan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+K">Kui Ren</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  <p class="mathjax">Complex safety-critical systems require multiple models for a comprehensive
  description, resulting in error-prone development and laborious verification.
  Bidirectional transformation (BX) is an approach to automatically synchronizing
  these models. However, existing BX frameworks lack formal verification to
  enforce these models' consistency rigorously. This paper introduces KBX, a
  formal bidirectional transformation framework for verified model
  synchronization. First, we present a matching logic-based BX model, providing a
  logical foundation for constructing BX definitions within the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-246-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1583" style="width: 1.019em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.793em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.793em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1584"><span class="texatom" id="MathJax-Span-1585"><span class="mrow" id="MathJax-Span-1586"><span class="mi" id="MathJax-Span-1587" style="font-family: STIXGeneral-Regular;">𝕂</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-246">\mathbb{K}</script>
  framework. Second, we propose algorithms to synthesize formal BX definitions
  from unidirectional ones, which allows developers to focus on crafting the
  unidirectional definitions while disregarding the reverse direction and missing
  information recovery for synchronization. Afterward, we harness <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-247-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1588" style="width: 1.019em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.793em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.793em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1589"><span class="texatom" id="MathJax-Span-1590"><span class="mrow" id="MathJax-Span-1591"><span class="mi" id="MathJax-Span-1592" style="font-family: STIXGeneral-Regular;">𝕂</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-247">\mathbb{K}</script> to
  generate a formal synchronizer from the synthesized definitions for consistency
  maintenance and verification. To evaluate the effectiveness of KBX, we conduct
  a comparative analysis against existing BX frameworks. Furthermore, we
  demonstrate the application of KBX in constructing a BX between UML and HCSP
  for real-world scenarios, showcasing an 82.8\% reduction in BX development
  effort compared to manual specification writing in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-248-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1593" style="width: 1.019em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.793em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.793em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1594"><span class="texatom" id="MathJax-Span-1595"><span class="mrow" id="MathJax-Span-1596"><span class="mi" id="MathJax-Span-1597" style="font-family: STIXGeneral-Regular;">𝕂</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-248">\mathbb{K}</script>.
  </p>
  </div>
  </dd>
  <dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18772" title="Abstract">arXiv:2404.18772</a> [<a href="/pdf/2404.18772" title="Download PDF">pdf</a>, <a href="/format/2404.18772" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Saliency Suppressed, Semantics Surfaced: Visual Transformations in  Neural Networks and the Brain
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Opie%C5%82ka%2C+G">Gustaw Opiełka</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Loke%2C+J">Jessica Loke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Scholte%2C+S">Steven Scholte</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Deep learning algorithms lack human-interpretable accounts of how they
  transform raw visual input into a robust semantic understanding, which impedes
  comparisons between different architectures, training objectives, and the human
  brain. In this work, we take inspiration from neuroscience and employ
  representational approaches to shed light on how neural networks encode
  information at low (visual saliency) and high (semantic similarity) levels of
  abstraction. Moreover, we introduce a custom image dataset where we
  systematically manipulate salient and semantic information. We find that
  ResNets are more sensitive to saliency information than ViTs, when trained with
  object classification objectives. We uncover that networks suppress saliency in
  early layers, a process enhanced by natural language supervision (CLIP) in
  ResNets. CLIP also enhances semantic encoding in both architectures. Finally,
  we show that semantic encoding is a key factor in aligning AI with human visual
  perception, while saliency suppression is a non-brain-like strategy.
  </p>
  </div>
  </dd>
  <dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18773" title="Abstract">arXiv:2404.18773</a> [<a href="/pdf/2404.18773" title="Download PDF">pdf</a>, <a href="/format/2404.18773" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Universal Metric of Dataset Similarity for Cross-silo Federated  Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Elhussein%2C+A">Ahmed Elhussein</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gursoy%2C+G">Gamze Gursoy</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Federated Learning is increasingly used in domains such as healthcare to
  facilitate collaborative model training without data-sharing. However, datasets
  located in different sites are often non-identically distributed, leading to
  degradation of model performance in FL. Most existing methods for assessing
  these distribution shifts are limited by being dataset or task-specific.
  Moreover, these metrics can only be calculated by exchanging data, a practice
  restricted in many FL scenarios. To address these challenges, we propose a
  novel metric for assessing dataset similarity. Our metric exhibits several
  desirable properties for FL: it is dataset-agnostic, is calculated in a
  privacy-preserving manner, and is computationally efficient, requiring no model
  training. In this paper, we first establish a theoretical connection between
  our metric and training dynamics in FL. Next, we extensively evaluate our
  metric on a range of datasets including synthetic, benchmark, and medical
  imaging datasets. We demonstrate that our metric shows a robust and
  interpretable relationship with model performance and can be calculated in
  privacy-preserving manner. As the first federated dataset similarity metric, we
  believe this metric can better facilitate successful collaborations between
  sites.
  </p>
  </div>
  </dd>
  <dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18780" title="Abstract">arXiv:2404.18780</a> [<a href="/pdf/2404.18780" title="Download PDF">pdf</a>, <a href="/format/2404.18780" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Optimal time sampling in physics-informed neural networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Turinici%2C+G">Gabriel Turinici</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)
  
  </div>
  <p class="mathjax">Physics-informed neural networks (PINN) is a extremely powerful paradigm used
  to solve equations encountered in scientific computing applications. An
  important part of the procedure is the minimization of the equation residual
  which includes, when the equation is time-dependent, a time sampling. It was
  argued in the literature that the sampling need not be uniform but should
  overweight initial time instants, but no rigorous explanation was provided for
  these choice. In this paper we take some prototypical examples and, under
  standard hypothesis concerning the neural network convergence, we show that the
  optimal time sampling follows a truncated exponential distribution. In
  particular we explain when the time sampling is best to be uniform and when it
  should not be. The findings are illustrated with numerical examples on linear
  equation, Burgers' equation and the Lorenz system.
  </p>
  </div>
  </dd>
  <dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18782" title="Abstract">arXiv:2404.18782</a> [<a href="/pdf/2404.18782" title="Download PDF">pdf</a>, <a href="/ps/2404.18782" title="Download PostScript">ps</a>, <a href="/format/2404.18782" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Whale Optimization Algorithm-based Fractional Order Fuzzy Type-II PI  Control for Modular Multilevel Converters
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Labbaf-Khaniki%2C+M+A">Mohammad Ali Labbaf-Khaniki</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Manthouri%2C+M">Mohammad Manthouri</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Hajizadeh%2C+A">Amin Hajizadeh</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  <p class="mathjax">Designing a robust controller for Modular Multilevel Converters (MMCs) is
  crucial to ensure stability and optimal dynamic performance under various
  operating conditions, including faulty and disturbed scenarios. The primary
  objective of controlling grid-connected MMCs (GC-MMCs) is to accurately track
  real and reactive power references while maintaining excellent harmonic
  performance in the output response. This paper proposes a novel model-free
  control strategy for GC-MMCs, employing a Fractional Order
  Proportional-Integral (FOPI) controller and a Fractional Order Fuzzy type-II
  Proportional-Integral (FOFPI) controller. The FOFPI controller utilizes a
  type-II Fuzzy Inference System (FIS) to adaptively adjust the proportional and
  derivative gains during the control process, enabling effective control of the
  MMC under diverse operating conditions. The type-II FIS, which leverages
  type-II fuzzy sets, can mitigate uncertainty and nonlinearity in the system.
  Furthermore, the incorporation of fractional-order mathematics enhances the
  flexibility of the proposed controllers. To optimize the initial parameters of
  the proposed controllers, the Whale Optimization Algorithm (WOA), a
  meta-heuristic algorithm, is employed. The results demonstrate that the
  proposed controllers exhibit superior performance under voltage disturbance
  conditions, varying input voltage, and can ensure the stability of the MMC.
  </p>
  </div>
  </dd>
  <dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18783" title="Abstract">arXiv:2404.18783</a> [<a href="/pdf/2404.18783" title="Download PDF">pdf</a>, <a href="/ps/2404.18783" title="Download PostScript">ps</a>, <a href="/format/2404.18783" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Improved bounds for group testing in arbitrary hypergraphs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=De+Bonis%2C+A">Annalisa De Bonis</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  <p class="mathjax">Recent papers initiated the study of a generalization of group testing where
  the potentially contaminated sets are the members of a given hypergraph
  F=(V,E). This generalization finds application in contexts where contaminations
  can be conditioned by some kinds of social and geographical clusterings. The
  paper focuses on few-stage group testing algorithms, i.e., slightly adaptive
  algorithms where tests are performed in stages and all tests performed in the
  same stage should be decided at the very beginning of the stage. In particular,
  the paper presents the first two-stage algorithm that uses o(dlog|E|) tests for
  general hypergraphs with hyperedges of size at most d, and a three-stage
  algorithm that improves by a d^{1/6} factor on the number of tests of the best
  known three-stage algorithm. These algorithms are special cases of an s-stage
  algorithm designed for an arbitrary positive integer s&lt;= d. The design of this
  algorithm resort to a new non-adaptive algorithm (one-stage algorithm), i.e.,
  an algorithm where all tests must be decided beforehand. Further, we derive a
  lower bound for non-adaptive group testing. For E sufficiently large, the lower
  bound is very close to the upper bound on the number of tests of the best
  non-adaptive group testing algorithm known in the literature, and it is the
  first lower bound that improves on the information theoretic lower bound
  Omega(log |E|).
  </p>
  </div>
  </dd>
  <dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18784" title="Abstract">arXiv:2404.18784</a> [<a href="/pdf/2404.18784" title="Download PDF">pdf</a>, <a href="/format/2404.18784" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy  Multilingual User Input
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Masis%2C+T">Tessa Masis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=O%27Connor%2C+B">Brendan O'Connor</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> NLP+CSS workshop at NAACL 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Geo-entity linking is the task of linking a location mention to the
  real-world geographic location. In this paper we explore the challenging task
  of geo-entity linking for noisy, multilingual social media data. There are few
  open-source multilingual geo-entity linking tools available and existing ones
  are often rule-based, which break easily in social media settings, or
  LLM-based, which are too expensive for large-scale datasets. We present a
  method which represents real-world locations as averaged embeddings from
  labeled user-input location names and allows for selective prediction via an
  interpretable confidence score. We show that our approach improves geo-entity
  linking on a global and multilingual social media dataset, and discuss progress
  and problems with evaluating at different geographic granularities.
  </p>
  </div>
  </dd>
  <dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18790" title="Abstract">arXiv:2404.18790</a> [<a href="/pdf/2404.18790" title="Download PDF">pdf</a>, <a href="/format/2404.18790" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> 3D Mapping of Glacier Moulins: Challenges and lessons learned
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dubois%2C+W">William Dubois</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Boxan%2C+M">Matěj Boxan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Laconte%2C+J">Johann Laconte</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pomerleau%2C+F">François Pomerleau</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the IEEE ICRA Workshop on Field Robotics 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  <p class="mathjax">In this paper, we present a field report of the mapping of the Athabasca
  Glacier, using a custom-made lidar-inertial mapping platform. With the
  increasing autonomy of robotics, a wider spectrum of applications emerges.
  Among these, the surveying of environmental areas presents arduous and
  hazardous challenges for human operators. Leveraging automated platforms for
  data collection holds the promise of unlocking new applications and a deeper
  comprehension of the environment. Over the course of a week-long deployment, we
  collected glacier data using a tailor-made measurement platform and reflected
  on the inherent challenges associated with such experiments. We focus on the
  insights gained and the forthcoming challenges that robotics must surmount to
  effectively map these terrains.
  </p>
  </div>
  </dd>
  <dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18791" title="Abstract">arXiv:2404.18791</a> [<a href="/pdf/2404.18791" title="Download PDF">pdf</a>, <a href="/format/2404.18791" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Certification of Speaker Recognition Models to Additive Perturbations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Korzh%2C+D">Dmitrii Korzh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Karimov%2C+E">Elvir Karimov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pautov%2C+M">Mikhail Pautov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rogov%2C+O+Y">Oleg Y. Rogov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oseledets%2C+I">Ivan Oseledets</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 9 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
  
  </div>
  <p class="mathjax">Speaker recognition technology is applied in various tasks ranging from
  personal virtual assistants to secure access systems. However, the robustness
  of these systems against adversarial attacks, particularly to additive
  perturbations, remains a significant challenge. In this paper, we pioneer
  applying robustness certification techniques to speaker recognition, originally
  developed for the image domain. In our work, we cover this gap by transferring
  and improving randomized smoothing certification techniques against
  norm-bounded additive perturbations for classification and few-shot learning
  tasks to speaker recognition. We demonstrate the effectiveness of these methods
  on VoxCeleb 1 and 2 datasets for several models. We expect this work to improve
  voice-biometry robustness, establish a new certification benchmark, and
  accelerate research of certification methods in the audio domain.
  </p>
  </div>
  </dd>
  <dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18796" title="Abstract">arXiv:2404.18796</a> [<a href="/pdf/2404.18796" title="Download PDF">pdf</a>, <a href="/format/2404.18796" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Replacing Judges with Juries: Evaluating LLM Generations with a Panel of  Diverse Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Verga%2C+P">Pat Verga</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hofstatter%2C+S">Sebastian Hofstatter</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Althammer%2C+S">Sophia Althammer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Su%2C+Y">Yixuan Su</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Piktus%2C+A">Aleksandra Piktus</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Arkhangorodsky%2C+A">Arkady Arkhangorodsky</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+M">Minjie Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=White%2C+N">Naomi White</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lewis%2C+P">Patrick Lewis</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">As Large Language Models (LLMs) have become more advanced, they have outpaced
  our abilities to accurately evaluate their quality. Not only is finding data to
  adequately probe particular model properties difficult, but evaluating the
  correctness of a model's freeform generation alone is a challenge. To address
  this, many evaluations now rely on using LLMs themselves as judges to score the
  quality of outputs from other LLMs. Evaluations most commonly use a single
  large model like GPT4. While this method has grown in popularity, it is costly,
  has been shown to introduce intramodel bias, and in this work, we find that
  very large models are often unnecessary. We propose instead to evaluate models
  using a Panel of LLm evaluators (PoLL). Across three distinct judge settings
  and spanning six different datasets, we find that using a PoLL composed of a
  larger number of smaller models outperforms a single large judge, exhibits less
  intra-model bias due to its composition of disjoint model families, and does so
  while being over seven times less expensive.
  </p>
  </div>
  </dd>
  <dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18797" title="Abstract">arXiv:2404.18797</a> [<a href="/pdf/2404.18797" title="Download PDF">pdf</a>, <a href="/format/2404.18797" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Efficiency-Effectiveness Tradeoff of Probabilistic Structured Queries  for Cross-Language Information Retrieval
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+E">Eugene Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nair%2C+S">Suraj Nair</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lawrie%2C+D">Dawn Lawrie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mayfield%2C+J">James Mayfield</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oard%2C+D+W">Douglas W. Oard</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Duh%2C+K">Kevin Duh</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 11 pages, 5 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">Probabilistic Structured Queries (PSQ) is a cross-language information
  retrieval (CLIR) method that uses translation probabilities statistically
  derived from aligned corpora. PSQ is a strong baseline for efficient CLIR using
  sparse indexing. It is, therefore, useful as the first stage in a cascaded
  neural CLIR system whose second stage is more effective but too inefficient to
  be used on its own to search a large text collection. In this reproducibility
  study, we revisit PSQ by introducing an efficient Python implementation.
  Unconstrained use of all translation probabilities that can be estimated from
  aligned parallel text would in the limit assign a weight to every vocabulary
  term, precluding use of an inverted index to serve queries efficiently. Thus,
  PSQ's effectiveness and efficiency both depend on how translation probabilities
  are pruned. This paper presents experiments over a range of modern CLIR test
  collections to demonstrate that achieving Pareto optimal PSQ
  effectiveness-efficiency tradeoffs benefits from multi-criteria pruning, which
  has not been fully explored in prior work. Our Python PSQ implementation is
  available on GitHub(https://github.com/hltcoe/PSQ) and unpruned translation
  tables are available on Huggingface
  Models(https://huggingface.co/hltcoe/psq_translation_tables).
  </p>
  </div>
  </dd>
  <dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18798" title="Abstract">arXiv:2404.18798</a> [<a href="/pdf/2404.18798" title="Download PDF">pdf</a>, <a href="/format/2404.18798" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-Agent Synchronization Tasks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fernandez%2C+R">Rolando Fernandez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Warnell%2C+G">Garrett Warnell</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Asher%2C+D+E">Derrik E. Asher</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stone%2C+P">Peter Stone</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Adaptive Learning Agents Workshop at AAMAS 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>
  
  </div>
  <p class="mathjax">In multi-agent reinforcement learning (MARL), coordination plays a crucial
  role in enhancing agents' performance beyond what they could achieve through
  cooperation alone. The interdependence of agents' actions, coupled with the
  need for communication, leads to a domain where effective coordination is
  crucial. In this paper, we introduce and define <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-249-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1598" style="width: 17.166em; display: inline-block;"><span style="display: inline-block; position: relative; width: 13.948em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1013.948em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1599"><span class="texatom" id="MathJax-Span-1600"><span class="mrow" id="MathJax-Span-1601"><span class="mtext" id="MathJax-Span-1602" style="font-family: STIXGeneral-Italic;">Multi-Agent Synchronization Tasks</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-249">\textit{Multi-Agent
  Synchronization Tasks}</script> (MSTs), a novel subset of multi-agent tasks. We
  describe one MST, that we call <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-250-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1603" style="width: 14.005em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.351em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1011.351em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1604"><span class="texatom" id="MathJax-Span-1605"><span class="mrow" id="MathJax-Span-1606"><span class="mtext" id="MathJax-Span-1607" style="font-family: STIXGeneral-Italic;">Synchronized Predator-Prey</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-250">\textit{Synchronized Predator-Prey}</script>, offering
  a detailed description that will serve as the basis for evaluating a selection
  of recent state-of-the-art (SOTA) MARL algorithms explicitly designed to
  address coordination challenges through the use of communication strategies.
  Furthermore, we present empirical evidence that reveals the limitations of the
  algorithms assessed to solve MSTs, demonstrating their inability to scale
  effectively beyond 2-agent coordination tasks in scenarios where communication
  is a requisite component. Finally, the results raise questions about the
  applicability of recent SOTA approaches for complex coordination tasks (i.e.
  MSTs) and prompt further exploration into the underlying causes of their
  limitations in this context.
  </p>
  </div>
  </dd>
  <dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18800" title="Abstract">arXiv:2404.18800</a> [<a href="/pdf/2404.18800" title="Download PDF">pdf</a>, <a href="/format/2404.18800" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Extending h adaptivity with refinement patterns
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Avancini%2C+G">Giovane Avancini</a>, 
  <a href="/search/math?searchtype=author&amp;query=Shauer%2C+N">Nathan Shauer</a>, 
  <a href="/search/math?searchtype=author&amp;query=Orlandini%2C+F+T">Francisco T. Orlandini</a>, 
  <a href="/search/math?searchtype=author&amp;query=Lucci%2C+P+C+A">Paulo Cesar A. Lucci</a>, 
  <a href="/search/math?searchtype=author&amp;query=Devloo%2C+P+R+B">Philippe R. B. Devloo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Preprint accepted for publication in the Book series "Advances in Applied Mathematics, Vol 59, by Elsevier
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">This contribution introduces the idea of refinement patterns for the
  generation of optimal meshes in the context of the Finite Element Method. The
  main idea is to generate a library of possible patterns on which elements can
  be refined and use this library to inform an h adaptive code on how to handle
  complex refinements in regions of interest. There are no restrictions on the
  type of elements that can be refined, and the patterns can be generated for any
  element type. The main advantage of this approach is that it allows for the
  generation of optimal meshes in a systematic way where, even if a certain
  pattern is not available, it can easily be included through a simple text file
  with nodes and sub-elements. The contribution presents a detailed methodology
  for incorporating refinement patterns into h adaptive Finite Element Method
  codes and demonstrates the effectiveness of the approach through mesh
  refinement of problems with complex geometries.
  </p>
  </div>
  </dd>
  <dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18801" title="Abstract">arXiv:2404.18801</a> [<a href="/pdf/2404.18801" title="Download PDF">pdf</a>, <a href="/format/2404.18801" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Partial Replication of MaskFormer in TensorFlow on TPUs for the  TensorFlow Model Garden
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Purohit%2C+V">Vishal Purohit</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+W">Wenxin Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ravikiran%2C+A+R">Akshath R. Ravikiran</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Davis%2C+J+C">James C. Davis</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">This paper undertakes the task of replicating the MaskFormer model a
  universal image segmentation model originally developed using the PyTorch
  framework, within the TensorFlow ecosystem, specifically optimized for
  execution on Tensor Processing Units (TPUs). Our implementation exploits the
  modular constructs available within the TensorFlow Model Garden (TFMG),
  encompassing elements such as the data loader, training orchestrator, and
  various architectural components, tailored and adapted to meet the
  specifications of the MaskFormer model. We address key challenges encountered
  during the replication, non-convergence issues, slow training, adaptation of
  loss functions, and the integration of TPU-specific functionalities. We verify
  our reproduced implementation and present qualitative results on the COCO
  dataset. Although our implementation meets some of the objectives for
  end-to-end reproducibility, we encountered challenges in replicating the
  PyTorch version of MaskFormer in TensorFlow. This replication process is not
  straightforward and requires substantial engineering efforts. Specifically, it
  necessitates the customization of various components within the TFMG, alongside
  thorough verification and hyper-parameter tuning. The replication is available
  at:
  https://github.com/PurdueDualityLab/tf-maskformer/tree/main/official/projects/maskformer
  </p>
  </div>
  </dd>
  <dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18810" title="Abstract">arXiv:2404.18810</a> [<a href="/pdf/2404.18810" title="Download PDF">pdf</a>, <a href="/format/2404.18810" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Unknown Script: Impact of Script on Cross-Lingual Transfer
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tufa%2C+W+T">Wondimagegnhue Tsegaye Tufa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Markov%2C+I">Ilia Markov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vossen%2C+P">Piek Vossen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Paper accepted to NAACL Student Research Workshop (SRW) 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Cross-lingual transfer has become an effective way of transferring knowledge
  between languages. In this paper, we explore an often-overlooked aspect in this
  domain: the influence of the source language of the base language model on
  transfer performance. We conduct a series of experiments to determine the
  effect of the script and tokenizer used in the pre-trained model on the
  performance of the downstream task. Our findings reveal the importance of the
  tokenizer as a stronger factor than the sharing of the script, the language
  typology match, and the model size.
  </p>
  </div>
  </dd>
  <dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18812" title="Abstract">arXiv:2404.18812</a> [<a href="/pdf/2404.18812" title="Download PDF">pdf</a>, <a href="/format/2404.18812" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Efficient Inverted Indexes for Approximate Retrieval over Learned Sparse  Representations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bruch%2C+S">Sebastian Bruch</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nardini%2C+F+M">Franco Maria Nardini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rulli%2C+C">Cosimo Rulli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Venturini%2C+R">Rossano Venturini</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  <p class="mathjax">Learned sparse representations form an attractive class of contextual
  embeddings for text retrieval. That is so because they are effective models of
  relevance and are interpretable by design. Despite their apparent compatibility
  with inverted indexes, however, retrieval over sparse embeddings remains
  challenging. That is due to the distributional differences between learned
  embeddings and term frequency-based lexical models of relevance such as BM25.
  Recognizing this challenge, a great deal of research has gone into, among other
  things, designing retrieval algorithms tailored to the properties of learned
  sparse representations, including approximate retrieval systems. In fact, this
  task featured prominently in the latest BigANN Challenge at NeurIPS 2023, where
  approximate algorithms were evaluated on a large benchmark dataset by
  throughput and recall. In this work, we propose a novel organization of the
  inverted index that enables fast yet effective approximate retrieval over
  learned sparse embeddings. Our approach organizes inverted lists into
  geometrically-cohesive blocks, each equipped with a summary vector. During
  query processing, we quickly determine if a block must be evaluated using the
  summaries. As we show experimentally, single-threaded query processing using
  our method, Seismic, reaches sub-millisecond per-query latency on various
  sparse embeddings of the MS MARCO dataset while maintaining high recall. Our
  results indicate that Seismic is one to two orders of magnitude faster than
  state-of-the-art inverted index-based solutions and further outperforms the
  winning (graph-based) submissions to the BigANN Challenge by a significant
  margin.
  </p>
  </div>
  </dd>
  <dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18813" title="Abstract">arXiv:2404.18813</a> [<a href="/pdf/2404.18813" title="Download PDF">pdf</a>, <a href="/format/2404.18813" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Safe Reach Set Computation via Neural Barrier Certificates
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Abate%2C+A">Alessandro Abate</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Bogomolov%2C+S">Sergiy Bogomolov</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Edwards%2C+A">Alec Edwards</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Potomkin%2C+K">Kostiantyn Potomkin</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Soudjani%2C+S">Sadegh Soudjani</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zuliani%2C+P">Paolo Zuliani</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> IFAC Conference on Analysis and Design of Hybrid Systems
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)
  
  </div>
  <p class="mathjax">We present a novel technique for online safety verification of autonomous
  systems, which performs reachability analysis efficiently for both bounded and
  unbounded horizons by employing neural barrier certificates. Our approach uses
  barrier certificates given by parameterized neural networks that depend on a
  given initial set, unsafe sets, and time horizon. Such networks are trained
  efficiently offline using system simulations sampled from regions of the state
  space. We then employ a meta-neural network to generalize the barrier
  certificates to state space regions that are outside the training set. These
  certificates are generated and validated online as sound over-approximations of
  the reachable states, thus either ensuring system safety or activating
  appropriate alternative actions in unsafe scenarios. We demonstrate our
  technique on case studies from linear models to nonlinear control-dependent
  models for online autonomous driving scenarios.
  </p>
  </div>
  </dd>
  <dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18814" title="Abstract">arXiv:2404.18814</a> [<a href="/pdf/2404.18814" title="Download PDF">pdf</a>, <a href="/ps/2404.18814" title="Download PostScript">ps</a>, <a href="/format/2404.18814" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Belt and Brace: When Federated Learning Meets Differential Privacy
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+X">Xuebin Ren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+S">Shusen Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+C">Cong Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McCann%2C+J">Julie McCann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zongben Xu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 4 figures, accepted by and to appear in Communications of the ACM (CACM)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>
  
  </div>
  <p class="mathjax">Federated learning (FL) has great potential for large-scale machine learning
  (ML) without exposing raw data.Differential privacy (DP) is the de facto
  standard of privacy protection with provable guarantees.Advances in ML suggest
  that DP would be a perfect fit for FL with comprehensive privacy preservation.
  Hence, extensive efforts have been devoted to achieving practically usable FL
  with DP, which however is still challenging.Practitioners often not only are
  not fully aware of its development and categorization, but also face a hard
  choice between privacy and utility. Therefore, it calls for a holistic review
  of current advances and an investigation on the challenges and opportunities
  for highly usable FL systems with a DP guarantee. In this article, we first
  introduce the primary concepts of FL and DP, and highlight the benefits of
  integration. We then review the current developments by categorizing different
  paradigms and notions. Aiming at usable FL with DP, we present the optimization
  principles to seek a better tradeoff between model utility and privacy loss.
  Finally, we discuss future challenges in the emergent areas and relevant
  research topics.
  </p>
  </div>
  </dd>
  <dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18816" title="Abstract">arXiv:2404.18816</a> [<a href="/pdf/2404.18816" title="Download PDF">pdf</a>, <a href="/format/2404.18816" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> AppPoet: Large Language Model based Android malware detection via  multi-view prompt engineering
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+W">Wenxiang Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+J">Juntao Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Meng%2C+Z">Zhaoyi Meng</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">Due to the vast array of Android applications, their multifarious functions
  and intricate behavioral semantics, attackers can adopt various tactics to
  conceal their genuine attack intentions within legitimate functions. However,
  numerous feature engineering based methods suffer from a limitation in mining
  behavioral semantic information, thus impeding the accuracy and efficiency of
  Android malware detection. Besides, the majority of existing feature
  engineering based methods are weakly interpretive and fail to furnish
  researchers with effective and readable detection reports. Inspired by the
  success of the Large Language Models (LLMs) in natural language understanding,
  we propose AppPoet, a LLM-assisted multi-view system for Android malware
  detection. Firstly, AppPoet employs a static method to comprehensively collect
  application features and formulate various observation views. Subsequently, it
  steers the LLM to produce function descriptions and behavioral summaries for
  views via our meticulously devised multi-view prompt engineering technique to
  realize the deep mining of view semantics. Finally, we collaboratively fuse the
  multi-view information to efficiently and accurately detect malware through a
  deep neural network (DNN) classifier and then generate the heuristic diagnostic
  reports. Experimental results demonstrate that our method achieves a detection
  accuracy of 97.15% and an F1 score of 97.21%, which is superior to the baseline
  method Drebin and its variant. Furthermore, the case study evaluates the
  effectiveness of our generated diagnostic reports.
  </p>
  </div>
  </dd>
  <dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18817" title="Abstract">arXiv:2404.18817</a> [<a href="/pdf/2404.18817" title="Download PDF">pdf</a>, <a href="/ps/2404.18817" title="Download PostScript">ps</a>, <a href="/format/2404.18817" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Hiding from Facebook: An Encryption Protocol resistant to Correlation  Attacks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chen-Da Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Santini%2C+S">Simone Santini</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Social and Information Networks (cs.SI)
  
  </div>
  <p class="mathjax">In many social networks, one publishes information that one wants to reveal
  (e.g., the photograph of some friends) together with information that may lead
  to privacy breaches (e.g., the name of these people). One might want to hide
  this sensitive information by encrypting it and sharing the decryption key only
  with trusted people, but this might not be enough. If the cipher associated to
  a face is always the same, correlation between the output of a face recognition
  system and the cipher can give useful clues and help train recognizers to
  identify untagged instances of the face. We refer to these as "correlation
  attacks".
  <br>In this paper we present a coding system that attempts to counter correlation
  attacks by associating to each instance of a face a different encryption of the
  same tag in such a way that the correlation between different instances is
  minimal.
  <br>In addition, we present a key distribution code that allows only the owner of
  the images to encode the tags, but allows a group of trusted friends to decode
  them.
  </p>
  </div>
  </dd>
  <dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18821" title="Abstract">arXiv:2404.18821</a> [<a href="/pdf/2404.18821" title="Download PDF">pdf</a>, <a href="/format/2404.18821" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Control Policy Correction Framework for Reinforcement Learning-based  Energy Arbitrage Strategies
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Madahi%2C+S+S+K">Seyed Soroush Karimi Madahi</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Gokhale%2C+G">Gargya Gokhale</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Verwee%2C+M">Marie-Sophie Verwee</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Claessens%2C+B">Bert Claessens</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Develder%2C+C">Chris Develder</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ACM e-Energy 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">A continuous rise in the penetration of renewable energy sources, along with
  the use of the single imbalance pricing, provides a new opportunity for balance
  responsible parties to reduce their cost through energy arbitrage in the
  imbalance settlement mechanism. Model-free reinforcement learning (RL) methods
  are an appropriate choice for solving the energy arbitrage problem due to their
  outstanding performance in solving complex stochastic sequential problems.
  However, RL is rarely deployed in real-world applications since its learned
  policy does not necessarily guarantee safety during the execution phase. In
  this paper, we propose a new RL-based control framework for batteries to obtain
  a safe energy arbitrage strategy in the imbalance settlement mechanism. In our
  proposed control framework, the agent initially aims to optimize the arbitrage
  revenue. Subsequently, in the post-processing step, we correct (constrain) the
  learned policy following a knowledge distillation process based on properties
  that follow human intuition. Our post-processing step is a generic method and
  is not restricted to the energy arbitrage domain. We use the Belgian imbalance
  price of 2023 to evaluate the performance of our proposed framework.
  Furthermore, we deploy our proposed control framework on a real battery to show
  its capability in the real world.
  </p>
  </div>
  </dd>
  <dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18824" title="Abstract">arXiv:2404.18824</a> [<a href="/pdf/2404.18824" title="Download PDF">pdf</a>, <a href="/format/2404.18824" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Benchmarking Benchmark Leakage in Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+R">Ruijie Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zengzhi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+R">Run-Ze Fan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+P">Pengfei Liu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 30 pages; Homepage: <a href="https://gair-nlp.github.io/benbench">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Amid the expanding use of pre-training data, the phenomenon of benchmark
  dataset leakage has become increasingly prominent, exacerbated by opaque
  training processes and the often undisclosed inclusion of supervised data in
  contemporary Large Language Models (LLMs). This issue skews benchmark
  effectiveness and fosters potentially unfair comparisons, impeding the field's
  healthy development. To address this, we introduce a detection pipeline
  utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that
  gauge a model's prediction precision on benchmark, to identify potential data
  leakages. By analyzing 31 LLMs under the context of mathematical reasoning, we
  reveal substantial instances of training even test set misuse, resulting in
  potentially unfair comparisons. These findings prompt us to offer several
  recommendations regarding model documentation, benchmark setup, and future
  evaluations. Notably, we propose the "Benchmark Transparency Card" to encourage
  clear documentation of benchmark utilization, promoting transparency and
  healthy developments of LLMs. we have made our leaderboard, pipeline
  implementation, and model predictions publicly available, fostering future
  research.
  </p>
  </div>
  </dd>
  <dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18825" title="Abstract">arXiv:2404.18825</a> [<a href="/pdf/2404.18825" title="Download PDF">pdf</a>, <a href="/format/2404.18825" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Harmonic Machine Learning Models are Robust
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kersting%2C+N+S">Nicholas S. Kersting</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yi Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mohanty%2C+A">Aman Mohanty</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Obisesan%2C+O">Oyindamola Obisesan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Okochu%2C+R">Raphael Okochu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 18 pages, 13 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">We introduce Harmonic Robustness, a powerful and intuitive method to test the
  robustness of any machine-learning model either during training or in black-box
  real-time inference monitoring without ground-truth labels. It is based on
  functional deviation from the harmonic mean value property, indicating
  instability and lack of explainability. We show implementation examples in
  low-dimensional trees and feedforward NNs, where the method reliably identifies
  overfitting, as well as in more complex high-dimensional models such as
  ResNet-50 and Vision Transformer where it efficiently measures adversarial
  vulnerability across image classes.
  </p>
  </div>
  </dd>
  <dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18826" title="Abstract">arXiv:2404.18826</a> [<a href="/pdf/2404.18826" title="Download PDF">pdf</a>, <a href="/format/2404.18826" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Winning the Social Media Influence Battle: Uncertainty-Aware Opinions to  Understand and Spread True Information via Competitive Influence Maximization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kaplan%2C+L+M">Lance M. Kaplan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=J%C3%B8sang%2C+A">Audun Jøsang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jeong%2C+D+H">Dong Hyun. Jeong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+F">Feng Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cho%2C+J">Jin-Hee Cho</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 3 figures, submitted to ASONAM 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>
  
  </div>
  <p class="mathjax">Competitive Influence Maximization (CIM) involves entities competing to
  maximize influence in online social networks (OSNs). Current Deep Reinforcement
  Learning (DRL) methods in CIM rely on simplistic binary opinion models (i.e.,
  an opinion is represented by either 0 or 1) and often overlook the complexity
  of user behaviors and prior knowledge. We propose a novel DRL-based framework
  that enhances CIM analysis by integrating Subjective Logic (SL) to accommodate
  uncertain opinions, user behaviors, and preferences. This approach targets the
  mitigation of false information by effectively propagating true information. By
  modeling two competitive agents, one spreading true information and the other
  spreading false information, we capture the strategic interplay essential to
  CIM. Our framework utilizes an uncertainty-based opinion model (UOM) to assess
  the impact on information quality in OSNs, emphasizing the importance of user
  behavior alongside network topology in selecting influential seed nodes.
  Extensive experiments demonstrate that our approach significantly outperforms
  state-of-the-art methods, achieving faster and more influential results (i.e.,
  outperforming over 20%) under realistic network conditions. Moreover, our
  method shows robust performance in partially observable networks, effectively
  doubling the performance when users are predisposed to disbelieve true
  information.
  </p>
  </div>
  </dd>
  <dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18831" title="Abstract">arXiv:2404.18831</a> [<a href="/pdf/2404.18831" title="Download PDF">pdf</a>, <a href="/format/2404.18831" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ConPro: Learning Severity Representation for Medical Images using  Contrastive Learning and Preference Optimization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+H">Hong Nguyen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+H">Hoang Nguyen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chang%2C+M">Melinda Chang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pham%2C+H">Hieu Pham</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Narayanan%2C+S">Shrikanth Narayanan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pazzani%2C+M">Michael Pazzani</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Understanding the severity of conditions shown in images in medical diagnosis
  is crucial, serving as a key guide for clinical assessment, treatment, as well
  as evaluating longitudinal progression. This paper proposes Con- PrO: a novel
  representation learning method for severity assessment in medical images using
  Contrastive learningintegrated Preference Optimization. Different from
  conventional contrastive learning methods that maximize the distance between
  classes, ConPrO injects into the latent vector the distance preference
  knowledge between various severity classes and the normal class. We
  systematically examine the key components of our framework to illuminate how
  contrastive prediction tasks acquire valuable representations. We show that our
  representation learning framework offers valuable severity ordering in the
  feature space while outperforming previous state-of-the-art methods on
  classification tasks. We achieve a 6% and 20% relative improvement compared to
  a supervised and a self-supervised baseline, respectively. In addition, we
  derived discussions on severity indicators and related applications of
  preference comparison in the medical domain.
  </p>
  </div>
  </dd>
  <dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18832" title="Abstract">arXiv:2404.18832</a> [<a href="/pdf/2404.18832" title="Download PDF">pdf</a>, <a href="/format/2404.18832" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation  of Patient Comments
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=M%C3%A6hlum%2C+P">Petter Mæhlum</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Samuel%2C+D">David Samuel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Norman%2C+R+M">Rebecka Maria Norman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jelin%2C+E">Elma Jelin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bjertn%C3%A6s%2C+%C3%98+A">Øyvind Andresen Bjertnæs</a>, 
  <a href="/search/cs?searchtype=author&amp;query=%C3%98vrelid%2C+L">Lilja Øvrelid</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Velldal%2C+E">Erik Velldal</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Sentiment analysis is an important tool for aggregating patient voices, in
  order to provide targeted improvements in healthcare services. A prerequisite
  for this is the availability of in-domain data annotated for sentiment. This
  article documents an effort to add sentiment annotations to free-text comments
  in patient surveys collected by the Norwegian Institute of Public Health
  (NIPH). However, annotation can be a time-consuming and resource-intensive
  process, particularly when it requires domain expertise. We therefore also
  evaluate a possible alternative to human annotation, using large language
  models (LLMs) as annotators. We perform an extensive evaluation of the approach
  for two openly available pretrained LLMs for Norwegian, experimenting with
  different configurations of prompts and in-context learning, comparing their
  performance to human annotators. We find that even for zero-shot runs, models
  perform well above the baseline for binary sentiment, but still cannot compete
  with human annotators on the full dataset.
  </p>
  </div>
  </dd>
  <dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18838" title="Abstract">arXiv:2404.18838</a> [<a href="/pdf/2404.18838" title="Download PDF">pdf</a>, <a href="/format/2404.18838" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Accurate adaptive deep learning method for solving elliptic problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Ying%2C+J">Jingyong Ying</a>, 
  <a href="/search/math?searchtype=author&amp;query=Xie%2C+Y">Yaqi Xie</a>, 
  <a href="/search/math?searchtype=author&amp;query=Li%2C+J">Jiao Li</a>, 
  <a href="/search/math?searchtype=author&amp;query=Wang%2C+H">Hongqiao Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computation (stat.CO)
  
  </div>
  <p class="mathjax">Deep learning method is of great importance in solving partial differential
  equations. In this paper, inspired by the failure-informed idea proposed by Gao
  et.al. (SIAM Journal on Scientific Computing 45(4)(2023)) and as an
  improvement, a new accurate adaptive deep learning method is proposed for
  solving elliptic problems, including the interface problems and the
  convection-dominated problems. Based on the failure probability framework, the
  piece-wise uniform distribution is used to approximate the optimal proposal
  distribution and an kernel-based method is proposed for efficient sampling.
  Together with the improved Levenberg-Marquardt optimization method, the
  proposed adaptive deep learning method shows great potential in improving
  solution accuracy. Numerical tests on the elliptic problems without interface
  conditions, on the elliptic interface problem, and on the convection-dominated
  problems demonstrate the effectiveness of the proposed method, as it reduces
  the relative errors by a factor varying from <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-251-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1608" style="width: 1.81em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1001.471em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1609"><span class="msubsup" id="MathJax-Span-1610"><span style="display: inline-block; position: relative; width: 1.414em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.963em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mn" id="MathJax-Span-1611" style="font-family: STIXGeneral-Regular;">10</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.019em;"><span class="mn" id="MathJax-Span-1612" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-251">10^2</script> to <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-252-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1613" style="width: 1.81em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.471em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1001.471em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1614"><span class="msubsup" id="MathJax-Span-1615"><span style="display: inline-block; position: relative; width: 1.414em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.963em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mn" id="MathJax-Span-1616" style="font-family: STIXGeneral-Regular;">10</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.019em;"><span class="mn" id="MathJax-Span-1617" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">4</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-252">10^4</script> for different
  cases.
  </p>
  </div>
  </dd>
  <dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18839" title="Abstract">arXiv:2404.18839</a> [<a href="/pdf/2404.18839" title="Download PDF">pdf</a>, <a href="/format/2404.18839" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Construction of local reduced spaces for Friedrichs' systems via  randomized training
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Engwer%2C+C">Christian Engwer</a>, 
  <a href="/search/math?searchtype=author&amp;query=Ohlberger%2C+M">Mario Ohlberger</a>, 
  <a href="/search/math?searchtype=author&amp;query=Renelt%2C+L">Lukas Renelt</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> submitted to Proceedings of Algoritmy 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">This contribution extends the localized training approach, traditionally
  employed for multiscale problems and parameterized partial differential
  equations (PDEs) featuring locally heterogeneous coefficients, to the class of
  linear, positive symmetric operators, known as Friedrichs' operators.
  Considering a local subdomain with corresponding oversampling domain we prove
  the compactness of the transfer operator which maps boundary data to solutions
  on the interior domain. While a Caccioppoli-inequality quantifying the energy
  decay to the interior holds true for all Friedrichs' systems, showing a
  compactness result for the graph-spaces hosting the solution is additionally
  necessary. We discuss the mixed formulation of a convection-diffusion-reaction
  problem where the necessary compactness result is obtained by the
  Picard-Weck-Weber theorem. Our numerical results, focusing on a scenario
  involving heterogeneous diffusion fields with multiple high-conductivity
  channels, demonstrate the effectiveness of the proposed method.
  </p>
  </div>
  </dd>
  <dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18841" title="Abstract">arXiv:2404.18841</a> [<a href="/pdf/2404.18841" title="Download PDF">pdf</a>, <a href="/format/2404.18841" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Deep orthogonal decomposition: a continuously adaptive data-driven  approach to model order reduction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Franco%2C+N+R">Nicola Rares Franco</a>, 
  <a href="/search/math?searchtype=author&amp;query=Manzoni%2C+A">Andrea Manzoni</a>, 
  <a href="/search/math?searchtype=author&amp;query=Zunino%2C+P">Paolo Zunino</a>, 
  <a href="/search/math?searchtype=author&amp;query=Hesthaven%2C+J+S">Jan S. Hesthaven</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  <p class="mathjax">We develop a novel deep learning technique, termed Deep Orthogonal
  Decomposition (DOD), for dimensionality reduction and reduced order modeling of
  parameter dependent partial differential equations. The approach consists in
  the construction of a deep neural network model that approximates the solution
  manifold through a continuously adaptive local basis. In contrast to global
  methods, such as Principal Orthogonal Decomposition (POD), the adaptivity
  allows the DOD to overcome the Kolmogorov barrier, making the approach
  applicable to a wide spectrum of parametric problems. Furthermore, due to its
  hybrid linear-nonlinear nature, the DOD can accommodate both intrusive and
  nonintrusive techniques, providing highly interpretable latent representations
  and tighter control on error propagation. For this reason, the proposed
  approach stands out as a valuable alternative to other nonlinear techniques,
  such as deep autoencoders. The methodology is discussed both theoretically and
  practically, evaluating its performances on problems featuring nonlinear PDEs,
  singularities, and parametrized geometries.
  </p>
  </div>
  </dd>
  <dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18842" title="Abstract">arXiv:2404.18842</a> [<a href="/pdf/2404.18842" title="Download PDF">pdf</a>, <a href="/format/2404.18842" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> VISION: Toward a Standardized Process for Radiology Image Management at  the National Level
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Knight%2C+K">Kathryn Knight</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Danciu%2C+I">Ioana Danciu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ovchinnikova%2C+O">Olga Ovchinnikova</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hinkle%2C+J">Jacob Hinkle</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shekar%2C+M+C">Mayanka Chandra Shekar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mukherjee%2C+D">Debangshu Mukherjee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McAllister%2C+E">Eileen McAllister</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rizy%2C+C">Caitlin Rizy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cho%2C+K">Kelly Cho</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Justice%2C+A+C">Amy C. Justice</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Erdos%2C+J">Joseph Erdos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kuzmak%2C+P">Peter Kuzmak</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Costa%2C+L">Lauren Costa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ho%2C+Y">Yuk-Lam Ho</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Madipadga%2C+R">Reddy Madipadga</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tamang%2C+S">Suzanne Tamang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Goethert%2C+I">Ian Goethert</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">The compilation and analysis of radiological images poses numerous challenges
  for researchers. The sheer volume of data as well as the computational needs of
  algorithms capable of operating on images are extensive. Additionally, the
  assembly of these images alone is difficult, as these exams may differ widely
  in terms of clinical context, structured annotation available for model
  training, modality, and patient identifiers. In this paper, we describe our
  experiences and challenges in establishing a trusted collection of radiology
  images linked to the United States Department of Veterans Affairs (VA)
  electronic health record database. We also discuss implications in making this
  repository research-ready for medical investigators. Key insights include
  uncovering the specific procedures required for transferring images from a
  clinical to a research-ready environment, as well as roadblocks and bottlenecks
  in this process that may hinder future efforts at automation.
  </p>
  </div>
  </dd>
  <dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18848" title="Abstract">arXiv:2404.18848</a> [<a href="/pdf/2404.18848" title="Download PDF">pdf</a>, <a href="/format/2404.18848" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning  Leveraging Weight Decomposition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yuxuan Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+S">Shunpu Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zhiguo Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qianqian Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  <p class="mathjax">Pre-trained Language Models (PLMs) have shown excellent performance on
  various downstream tasks after fine-tuning. Nevertheless, the escalating
  concerns surrounding user privacy have posed significant challenges to
  centralized training reliant on extensive data collection. Federated
  learning(FL), which only requires training on the clients and aggregates
  weights on the server without sharing data, has emerged as a solution. However,
  the substantial parameter size of PLMs places a significant burden on the
  computational resources of client devices, while also leading to costly
  communication expenses. Introducing Parameter-Efficient Fine-Tuning(PEFT) into
  FL can effectively address this problem. However, we observe that the non-IID
  data in federated learning leads to a gap in performance between the PEFT
  method and full parameter fine-tuning(FT). To overcome this, we propose FeDeRA,
  an improvement over the LoRA method in FL. FeDeRA uses the same adapter module
  as LoRA. However, the difference lies in FeDeRA's initialization of the adapter
  module by performing Singular Value Decomposition (SVD) on the pre-trained
  matrix and selecting its principal components. We conducted extensive
  experiments, using RoBERTa and DeBERTaV3, on three tasks and six datasets,
  comparing the methods including FT and the other three different PEFT methods.
  FeDeRA outperforms all other PEFT methods and is comparable to or even
  surpasses the performance of FT methods. We also deployed federated learning on
  Jetson AGX Orin and compared the time required by different methods to achieve
  the target accuracy on specific tasks. Compared to FT, FeDeRA reduces the
  training time by 95.9%, 97.9%, 96.9%, and 97.3%, 96.5%, and 96.5% respectively
  on three tasks using RoBERTa and DeBERTaV3. The overall experiments indicate
  that FeDeRA achieves good performance while also maintaining efficiency.
  </p>
  </div>
  </dd>
  <dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18849" title="Abstract">arXiv:2404.18849</a> [<a href="/pdf/2404.18849" title="Download PDF">pdf</a>, <a href="/format/2404.18849" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MiPa: Mixed Patch Infrared-Visible Modality Agnostic Object Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Medeiros%2C+H+R">Heitor R. Medeiros</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Latortue%2C+D">David Latortue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pena%2C+F+G">Fidel Guerrero Pena</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Granger%2C+E">Eric Granger</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pedersoli%2C+M">Marco Pedersoli</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">In this paper, we present a different way to use two modalities, in which
  either one modality or the other is seen by a single model. This can be useful
  when adapting an unimodal model to leverage more information while respecting a
  limited computational budget. This would mean having a single model that is
  able to deal with any modalities. To describe this, we coined the term anymodal
  learning. An example of this, is a use case where, surveillance in a room when
  the lights are off would be much more valuable using an infrared modality while
  a visible one would provide more discriminative information when lights are on.
  This work investigates how to efficiently leverage visible and infrared/thermal
  modalities for transformer-based object detection backbone to create an
  anymodal architecture. Our work does not create any inference overhead during
  the testing while exploring an effective way to exploit the two modalities
  during the training. To accomplish such a task, we introduce the novel anymodal
  training technique: Mixed Patches (MiPa), in conjunction with a patch-wise
  domain agnostic module, which is responsible of learning the best way to find a
  common representation of both modalities. This approach proves to be able to
  balance modalities by reaching competitive results on individual modality
  benchmarks with the alternative of using an unimodal architecture on three
  different visible-infrared object detection datasets. Finally, our proposed
  method, when used as a regularization for the strongest modality, can beat the
  performance of multimodal fusion methods while only requiring a single modality
  during inference. Notably, MiPa became the state-of-the-art on the LLVIP
  visible/infrared benchmark. Code: https://github.com/heitorrapela/MiPa
  </p>
  </div>
  </dd>
  <dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18850" title="Abstract">arXiv:2404.18850</a> [<a href="/pdf/2404.18850" title="Download PDF">pdf</a>, <a href="/format/2404.18850" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Sparse Sampling in Fractional Fourier Domain: Recovery Guarantees and  Cramér-Rao Bounds
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pavl%C3%AD%C4%8Dek%2C+V">Václav Pavlíček</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bhandari%2C+A">Ayush Bhandari</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted with minor revisions, IEEE SPL
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
  
  </div>
  <p class="mathjax">Sampling theory in fractional Fourier Transform (FrFT) domain has been
  studied extensively in the last decades. This interest stems from the ability
  of the FrFT to generalize the traditional Fourier Transform, broadening the
  traditional concept of bandwidth and accommodating a wider range of functions
  that may not be bandlimited in the Fourier sense. Beyond bandlimited functions,
  sampling and recovery of sparse signals has also been studied in the FrFT
  domain. Existing methods for sparse recovery typically operate in the transform
  domain, capitalizing on the spectral features of spikes in the FrFT domain. Our
  paper contributes two new theoretical advancements in this area. First, we
  introduce a novel time-domain sparse recovery method that avoids the typical
  bottlenecks of transform domain methods, such as spectral leakage. This method
  is backed by a sparse sampling theorem applicable to arbitrary FrFT-bandlimited
  kernels and is validated through a hardware experiment. Second, we present
  Cram\'er-Rao Bounds for the sparse sampling problem, addressing a gap in
  existing literature.
  </p>
  </div>
  </dd>
  <dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18851" title="Abstract">arXiv:2404.18851</a> [<a href="/pdf/2404.18851" title="Download PDF">pdf</a>, <a href="/format/2404.18851" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Comprehensive Rubric for Annotating Pathological Speech
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Corrales-Astorgano%2C+M">Mario Corrales-Astorgano</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Escudero-Mancebo%2C+D">David Escudero-Mancebo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aguilar%2C+L">Lourdes Aguilar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Flores-Lucas%2C+V">Valle Flores-Lucas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Carde%C3%B1oso-Payo%2C+V">Valentín Cardeñoso-Payo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vivaracho-Pascual%2C+C">Carlos Vivaracho-Pascual</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gonz%C3%A1lez-Ferreras%2C+C">César González-Ferreras</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to LREC-Coling 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Rubrics are a commonly used tool for labeling voice corpora in speech quality
  assessment, although their application in the context of pathological speech
  remains relatively limited. In this study, we introduce a comprehensive rubric
  based on various dimensions of speech quality, including phonetics, fluency,
  and prosody. The objective is to establish standardized criteria for
  identifying errors within the speech of individuals with Down syndrome, thereby
  enabling the development of automated assessment systems. To achieve this
  objective, we utilized the Prautocal corpus. To assess the quality of
  annotations using our rubric, two experiments were conducted, focusing on
  phonetics and fluency. For phonetic evaluation, we employed the Goodness of
  Pronunciation (GoP) metric, utilizing automatic segmentation systems and
  correlating the results with evaluations conducted by a specialized speech
  therapist. While the obtained correlation values were not notably high, a
  positive trend was observed. In terms of fluency assessment, deep learning
  models like wav2vec were used to extract audio features, and we employed an SVM
  classifier trained on a corpus focused on identifying fluency issues to
  categorize Prautocal corpus samples. The outcomes highlight the complexities of
  evaluating such phenomena, with variability depending on the specific type of
  disfluency detected.
  </p>
  </div>
  </dd>
  <dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18852" title="Abstract">arXiv:2404.18852</a> [<a href="/pdf/2404.18852" title="Download PDF">pdf</a>, <a href="/format/2404.18852" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> VERT: Verified Equivalent Rust Transpilation with Few-Shot Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+A+Z+H">Aidan Z.H. Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Takashima%2C+Y">Yoshiki Takashima</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Paulsen%2C+B">Brandon Paulsen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dodds%2C+J">Josiah Dodds</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kroening%2C+D">Daniel Kroening</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">Rust is a programming language that combines memory safety and low-level
  control, providing C-like performance while guaranteeing the absence of
  undefined behaviors by default. Rust's growing popularity has prompted research
  on safe and correct transpiling of existing code-bases to Rust. Existing work
  falls into two categories: rule-based and large language model (LLM)-based.
  While rule-based approaches can theoretically produce correct transpilations
  that maintain input-output equivalence to the original, they often yield
  unreadable Rust code that uses unsafe subsets of the Rust language. On the
  other hand, while LLM-based approaches typically produce more readable,
  maintainable, and safe code, they do not provide any guarantees about
  correctness. In this work, we present VERT, a tool that can produce readable
  Rust transpilations with formal guarantees of correctness. VERT's only
  requirement is that there is Web Assembly compiler for the source language,
  which is true for most major languages. VERT first uses the Web Assembly
  compiler to obtain an oracle Rust program. In parallel, VERT uses an LLM to
  generate a readable candidate Rust program. This candidate is verified against
  the oracle, and if verification fails, we regenerate a new candidate
  transpilation until verification succeeds. We evaluate VERT by transpiling a
  suite of 1,394 programs taken from competitive programming style benchmarks.
  Combining Anthropic's Claude-2 and VERT increases Rust transpilations passing
  property-based testing from 31% to 54% and bounded model-checking from 1% to
  42% compared to using Claude alone. In addition, we evaluate VERT's ability to
  generate non-trivial safe Rust on programs taken from real-world C projects
  that make significant use of pointers. Our results provide insights into the
  limitations of LLMs to write safe Rust.
  </p>
  </div>
  </dd>
  <dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18861" title="Abstract">arXiv:2404.18861</a> [<a href="/pdf/2404.18861" title="Download PDF">pdf</a>, <a href="/format/2404.18861" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Survey on Vision Mamba: Models, Applications and Challenges
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+R">Rui Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+S">Shu Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yihui Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Du%2C+B">Bo Du</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Mamba, a recent selective structured state space model, performs excellently
  on long sequence modeling tasks. Mamba mitigates the modeling constraints of
  convolutional neural networks and offers advanced modeling capabilities similar
  to those of Transformers, through global receptive fields and dynamic
  weighting. Crucially, it achieves this without incurring the quadratic
  computational complexity typically associated with Transformers. Due to its
  advantages over the former two mainstream foundation models, Mamba exhibits
  great potential to be a visual foundation model. Researchers are actively
  applying Mamba to various computer vision tasks, leading to numerous emerging
  works. To help keep pace with the rapid advancements in computer vision, this
  paper aims to provide a comprehensive review of visual Mamba approaches. This
  paper begins by delineating the formulation of the original Mamba model.
  Subsequently, our review of visual Mamba delves into several representative
  backbone networks to elucidate the core insights of the visual Mamba. We then
  categorize related works using different modalities, including image, video,
  point cloud, multi-modal, and others. Specifically, for image applications, we
  further organize them into distinct tasks to facilitate a more structured
  discussion. Finally, we discuss the challenges and future research directions
  for visual Mamba, providing insights for future research in this quickly
  evolving area. A comprehensive list of visual Mamba models reviewed in this
  work is available at https://github.com/Ruixxxx/Awesome-Vision-Mamba-Models.
  </p>
  </div>
  </dd>
  <dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18863" title="Abstract">arXiv:2404.18863</a> [<a href="/pdf/2404.18863" title="Download PDF">pdf</a>, <a href="/format/2404.18863" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PlanNetX: Learning an Efficient Neural Network Planner from MPC for  Longitudinal Control
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hoffmann%2C+J">Jasper Hoffmann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fernandez%2C+D">Diego Fernandez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Brosseit%2C+J">Julien Brosseit</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bernhard%2C+J">Julian Bernhard</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Esterle%2C+K">Klemens Esterle</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Werling%2C+M">Moritz Werling</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Karg%2C+M">Michael Karg</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Boedecker%2C+J">Joschka Boedecker</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> under revision for the 6th Annual Learning for Dynamics &amp; Control Conference (L4DC 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)
  
  </div>
  <p class="mathjax">Model predictive control (MPC) is a powerful, optimization-based approach for
  controlling dynamical systems. However, the computational complexity of online
  optimization can be problematic on embedded devices. Especially, when we need
  to guarantee fixed control frequencies. Thus, previous work proposed to reduce
  the computational burden using imitation learning (IL) approximating the MPC
  policy by a neural network. In this work, we instead learn the whole planned
  trajectory of the MPC. We introduce a combination of a novel neural network
  architecture PlanNetX and a simple loss function based on the state trajectory
  that leverages the parameterized optimal control structure of the MPC. We
  validate our approach in the context of autonomous driving by learning a
  longitudinal planner and benchmarking it extensively in the CommonRoad
  simulator using synthetic scenarios and scenarios derived from real data. Our
  experimental results show that we can learn the open-loop MPC trajectory with
  high accuracy while improving the closed-loop performance of the learned
  control policy over other baselines like behavior cloning.
  </p>
  </div>
  </dd>
  <dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18864" title="Abstract">arXiv:2404.18864</a> [<a href="/pdf/2404.18864" title="Download PDF">pdf</a>, <a href="/format/2404.18864" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Performance-Aligned LLMs for Generating Fast Code
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nichols%2C+D">Daniel Nichols</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Polasam%2C+P">Pranav Polasam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Menon%2C+H">Harshitha Menon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Marathe%2C+A">Aniruddha Marathe</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gamblin%2C+T">Todd Gamblin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bhatele%2C+A">Abhinav Bhatele</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">Optimizing scientific software is a difficult task because codebases are
  often large and complex, and performance can depend upon several factors
  including the algorithm, its implementation, and hardware among others. Causes
  of poor performance can originate from disparate sources and be difficult to
  diagnose. Recent years have seen a multitude of work that use large language
  models (LLMs) to assist in software development tasks. However, these tools are
  trained to model the distribution of code as text, and are not specifically
  designed to understand performance aspects of code. In this work, we introduce
  a reinforcement learning based methodology to align the outputs of code LLMs
  with performance. This allows us to build upon the current code modeling
  capabilities of LLMs and extend them to generate better performing code. We
  demonstrate that our fine-tuned model improves the expected speedup of
  generated code over base models for a set of benchmark tasks from 0.9 to 1.6
  for serial code and 1.9 to 4.5 for OpenMP code.
  </p>
  </div>
  </dd>
  <dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18865" title="Abstract">arXiv:2404.18865</a> [<a href="/pdf/2404.18865" title="Download PDF">pdf</a>, <a href="/format/2404.18865" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Truth-value judgment in language models: belief directions are context  sensitive
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Schouten%2C+S+F">Stefan F. Schouten</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bloem%2C+P">Peter Bloem</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Markov%2C+I">Ilia Markov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vossen%2C+P">Piek Vossen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">Recent work has demonstrated that the latent spaces of large language models
  (LLMs) contain directions predictive of the truth of sentences. Multiple
  methods recover such directions and build probes that are described as getting
  at a model's "knowledge" or "beliefs". We investigate this phenomenon, looking
  closely at the impact of context on the probes. Our experiments establish where
  in the LLM the probe's predictions can be described as being conditional on the
  preceding (related) sentences. Specifically, we quantify the responsiveness of
  the probes to the presence of (negated) supporting and contradicting sentences,
  and score the probes on their consistency. We also perform a causal
  intervention experiment, investigating whether moving the representation of a
  premise along these belief directions influences the position of the hypothesis
  along that same direction. We find that the probes we test are generally
  context sensitive, but that contexts which should not affect the truth often
  still impact the probe outputs. Our experiments show that the type of errors
  depend on the layer, the (type of) model, and the kind of data. Finally, our
  results suggest that belief directions are (one of the) causal mediators in the
  inference process that incorporates in-context information.
  </p>
  </div>
  </dd>
  <dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18867" title="Abstract">arXiv:2404.18867</a> [<a href="/pdf/2404.18867" title="Download PDF">pdf</a>, <a href="/format/2404.18867" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Feminist Interaction Techniques: Deterring Non-Consensual Screenshots  with Interaction Techniques
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Qiwei%2C+L">Li Qiwei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lameiro%2C+F">Francesca Lameiro</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Patel%2C+S">Shefali Patel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cristi-Isaula-Reyes">Cristi-Isaula-Reyes</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Adar%2C+E">Eytan Adar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gilbert%2C+E">Eric Gilbert</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schoenebeck%2C+S">Sarita Schoenebeck</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  <p class="mathjax">Non-consensual Intimate Media (NCIM) refers to the distribution of sexual or
  intimate content without consent. NCIM is common and causes significant
  emotional, financial, and reputational harm. We developed Hands-Off, an
  interaction technique for messaging applications that deters non-consensual
  screenshots. Hands-Off requires recipients to perform a hand gesture in the
  air, above the device, to unlock media -- which makes simultaneous
  screenshotting difficult. A lab study shows that Hands-Off gestures are easy to
  perform and reduce non-consensual screenshots by 67 percent. We conclude by
  generalizing this approach and introduce the idea of Feminist Interaction
  Techniques (FIT), interaction techniques that encode feminist values and speak
  to societal problems, and reflect on FIT's opportunities and limitations.
  </p>
  </div>
  </dd>
  <dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18869" title="Abstract">arXiv:2404.18869</a> [<a href="/pdf/2404.18869" title="Download PDF">pdf</a>, <a href="/ps/2404.18869" title="Download PostScript">ps</a>, <a href="/format/2404.18869" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning Mixtures of Gaussians Using Diffusion Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gatmiry%2C+K">Khashayar Gatmiry</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kelner%2C+J">Jonathan Kelner</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+H">Holden Lee</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Probability (math.PR); Statistics Theory (math.ST); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">We give a new algorithm for learning mixtures of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-253-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1618" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1619"><span class="mi" id="MathJax-Span-1620" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-253">k</script> Gaussians (with identity
  covariance in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-254-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1621" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.245em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1622"><span class="msubsup" id="MathJax-Span-1623"><span style="display: inline-block; position: relative; width: 1.188em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1624"><span class="mrow" id="MathJax-Span-1625"><span class="mi" id="MathJax-Span-1626" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.737em;"><span class="mi" id="MathJax-Span-1627" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-254">\mathbb{R}^n</script>) to TV error <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-255-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1628" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1629"><span class="mi" id="MathJax-Span-1630" style="font-family: STIXGeneral-Italic;">ε</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-255">\varepsilon</script>, with quasi-polynomial
  (<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-256-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1631" style="width: 7.681em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.213em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.245em, 1006.157em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1632"><span class="mi" id="MathJax-Span-1633" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1634" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1635"><span style="display: inline-block; position: relative; width: 4.802em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1636" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.511em;"><span class="texatom" id="MathJax-Span-1637"><span class="mrow" id="MathJax-Span-1638"><span class="mtext" id="MathJax-Span-1639" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">poly log</span><span class="mrow" id="MathJax-Span-1640"><span class="mo" id="MathJax-Span-1641" style="vertical-align: -0.167em;"><span><span style="font-size: 77.8%; font-family: STIXSizeOneSym;">(</span></span></span><span class="mfrac" id="MathJax-Span-1642"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.85em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.392em;"><span class="mrow" id="MathJax-Span-1643"><span class="mi" id="MathJax-Span-1644" style="font-size: 50%; font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-1645" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-1646" style="font-size: 50%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.616em, 1000.229em, 4.181em, -999.997em); top: -3.78em; left: 50%; margin-left: -0.11em;"><span class="mi" id="MathJax-Span-1647" style="font-size: 50%; font-family: STIXGeneral-Italic;">ε</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.963em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.963em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span class="mo" id="MathJax-Span-1648" style="vertical-align: -0.167em;"><span><span style="font-size: 77.8%; font-family: STIXSizeOneSym;">)</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1649" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.74em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-256">O(n^{\text{poly log}\left(\frac{n+k}{\varepsilon}\right)})</script>) time and sample
  complexity, under a minimum weight assumption. Unlike previous approaches, most
  of which are algebraic in nature, our approach is analytic and relies on the
  framework of diffusion models. Diffusion models are a modern paradigm for
  generative modeling, which typically rely on learning the score function
  (gradient log-pdf) along a process transforming a pure noise distribution, in
  our case a Gaussian, to the data distribution. Despite their dazzling
  performance in tasks such as image generation, there are few end-to-end
  theoretical guarantees that they can efficiently learn nontrivial families of
  distributions; we give some of the first such guarantees. We proceed by
  deriving higher-order Gaussian noise sensitivity bounds for the score functions
  for a Gaussian mixture to show that that they can be inductively learned using
  piecewise polynomial regression (up to poly-logarithmic degree), and combine
  this with known convergence results for diffusion models. Our results extend to
  continuous mixtures of Gaussians where the mixing distribution is supported on
  a union of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-257-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1650" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1651"><span class="mi" id="MathJax-Span-1652" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-257">k</script> balls of constant radius. In particular, this applies to the
  case of Gaussian convolutions of distributions on low-dimensional manifolds, or
  more generally sets with small covering number.
  </p>
  </div>
  </dd>
  <dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18870" title="Abstract">arXiv:2404.18870</a> [<a href="/pdf/2404.18870" title="Download PDF">pdf</a>, <a href="/format/2404.18870" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> More RLHF, More Trust? On The Impact of Human Preference Alignment On  Language Model Trustworthiness
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+A+J">Aaron J. Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Krishna%2C+S">Satyapriya Krishna</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">The surge in Large Language Models (LLMs) development has led to improved
  performance on cognitive tasks as well as an urgent need to align these models
  with human values in order to safely exploit their power. Despite the
  effectiveness of preference learning algorithms like Reinforcement Learning
  From Human Feedback (RLHF) in aligning human preferences, their assumed
  improvements on model trustworthiness haven't been thoroughly testified. Toward
  this end, this study investigates how models that have been aligned with
  general-purpose preference data on helpfulness and harmlessness perform across
  five trustworthiness verticals: toxicity, stereotypical bias, machine ethics,
  truthfulness, and privacy. For model alignment, we focus on three widely used
  RLHF variants: Supervised Finetuning (SFT), Proximal Policy Optimization (PPO),
  and Direct Preference Optimization (DPO). Through extensive empirical
  investigations, we discover that the improvement in trustworthiness by RLHF is
  far from guaranteed, and there exists a complex interplay between preference
  data, alignment algorithms, and specific trustworthiness aspects. Together, our
  results underscore the need for more nuanced approaches for model alignment. By
  shedding light on the intricate dynamics of these components within model
  alignment, we hope this research will guide the community towards developing
  language models that are both capable and trustworthy.
  </p>
  </div>
  </dd>
  <dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18873" title="Abstract">arXiv:2404.18873</a> [<a href="/pdf/2404.18873" title="Download PDF">pdf</a>, <a href="/format/2404.18873" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> OpenStreetView-5M: The Many Roads to Global Visual Geolocation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Astruc%2C+G">Guillaume Astruc</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dufour%2C+N">Nicolas Dufour</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Siglidis%2C+I">Ioannis Siglidis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aronssohn%2C+C">Constantin Aronssohn</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bouia%2C+N">Nacim Bouia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fu%2C+S">Stephanie Fu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Loiseau%2C+R">Romain Loiseau</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+V+N">Van Nguyen Nguyen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Raude%2C+C">Charles Raude</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vincent%2C+E">Elliot Vincent</a>, 
  <a href="/search/cs?searchtype=author&amp;query=XU%2C+L">Lintao XU</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hongyu Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Landrieu%2C+L">Loic Landrieu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> CVPR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Determining the location of an image anywhere on Earth is a complex visual
  task, which makes it particularly relevant for evaluating computer vision
  algorithms. Yet, the absence of standard, large-scale, open-access datasets
  with reliably localizable images has limited its potential. To address this
  issue, we introduce OpenStreetView-5M, a large-scale, open-access dataset
  comprising over 5.1 million geo-referenced street view images, covering 225
  countries and territories. In contrast to existing benchmarks, we enforce a
  strict train/test separation, allowing us to evaluate the relevance of learned
  geographical features beyond mere memorization. To demonstrate the utility of
  our dataset, we conduct an extensive benchmark of various state-of-the-art
  image encoders, spatial representations, and training strategies. All
  associated codes and models can be found at https://github.com/gastruc/osv5m.
  </p>
  </div>
  </dd>
  <dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18874" title="Abstract">arXiv:2404.18874</a> [<a href="/pdf/2404.18874" title="Download PDF">pdf</a>, <a href="/ps/2404.18874" title="Download PostScript">ps</a>, <a href="/format/2404.18874" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Essense of Useful Evaluation Through Quantitative Types (Extended  Version)
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Barenbaum%2C+P">Pablo Barenbaum</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kesner%2C+D">Delia Kesner</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Milicich%2C+M">Mariana Milicich</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)
  
  </div>
  <p class="mathjax">Several evaluation notions for lambda calculus qualify as reasonable cost
  models according to Slot and van Emde Boas' Invariance Thesis. A notable result
  achieved by Accattoli and Dal Lago is that leftmost-outermost reduction is
  reasonable, where the term representation uses sharing and the steps are
  useful. These results, initially studied in call-by-name, have also been
  extended to call-by-value. However, the existing formulations of usefulness
  lack inductive structure, making it challenging in particular to define and
  reason about type systems on top of the untyped syntax. Additionally, no
  type-based quantitative interpretations exist for useful evaluation. In this
  work, we establish the first inductive definition of useful evaluation for open
  weak call-by-value. This new useful strategy connects to a previous
  implementation of usefulness through a low-level abstract machine, incurring
  only in linear time overhead, thus providing a reasonable cost model for open
  call-by-value implementation. We also propose a semantic interpretation of
  useful call-by-value using a non-idempotent intersection type system equipped
  with a notion of tightness. The resulting interpretation is quantitative, i.e.
  provides exact step-count information for program evaluation. This turns out to
  be the first semantical interpretation in the literature for a notion of useful
  evaluation.
  </p>
  </div>
  </dd>
  <dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18876" title="Abstract">arXiv:2404.18876</a> [<a href="/pdf/2404.18876" title="Download PDF">pdf</a>, <a href="/format/2404.18876" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Multilevel Strategy to Improve People Tracking in a Real-World  Scenario
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=de+Oliveira%2C+C+B">Cristiano B. de Oliveira</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Neves%2C+J+C">Joao C. Neves</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ribeiro%2C+R+O">Rafael O. Ribeiro</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Menotti%2C+D">David Menotti</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted for presentation at the International Conference on Computer Vision Theory and Applications (VISAPP) 2024
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Proceedings of the 19th International Joint Conference on Computer
    Vision, Imaging and Computer Graphics Theory and Applications - Volume 4:
    VISAPP, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">The Pal\'acio do Planalto, office of the President of Brazil, was invaded by
  protesters on January 8, 2023. Surveillance videos taken from inside the
  building were subsequently released by the Brazilian Supreme Court for public
  scrutiny. We used segments of such footage to create the UFPR-Planalto801
  dataset for people tracking and re-identification in a real-world scenario.
  This dataset consists of more than 500,000 images. This paper presents a
  tracking approach targeting this dataset. The method proposed in this paper
  relies on the use of known state-of-the-art trackers combined in a multilevel
  hierarchy to correct the ID association over the trajectories. We evaluated our
  method using IDF1, MOTA, MOTP and HOTA metrics. The results show improvements
  for every tracker used in the experiments, with IDF1 score increasing by a
  margin up to 9.5%.
  </p>
  </div>
  </dd>
  <dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18880" title="Abstract">arXiv:2404.18880</a> [<a href="/pdf/2404.18880" title="Download PDF">pdf</a>, <a href="/ps/2404.18880" title="Download PostScript">ps</a>, <a href="/format/2404.18880" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Spivavtor: An Instruction Tuned Ukrainian Text Editing Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Saini%2C+A">Aman Saini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chernodub%2C+A">Artem Chernodub</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Raheja%2C+V">Vipul Raheja</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kulkarni%2C+V">Vivek Kulkarni</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to UNLP Workshop 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">We introduce Spivavtor, a dataset, and instruction-tuned models for text
  editing focused on the Ukrainian language. Spivavtor is the Ukrainian-focused
  adaptation of the English-only CoEdIT model. Similar to CoEdIT, Spivavtor
  performs text editing tasks by following instructions in Ukrainian. This paper
  describes the details of the Spivavtor-Instruct dataset and Spivavtor models.
  We evaluate Spivavtor on a variety of text editing tasks in Ukrainian, such as
  Grammatical Error Correction (GEC), Text Simplification, Coherence, and
  Paraphrasing, and demonstrate its superior performance on all of them. We
  publicly release our best-performing models and data as resources to the
  community to advance further research in this space.
  </p>
  </div>
  </dd>
  <dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18881" title="Abstract">arXiv:2404.18881</a> [<a href="/pdf/2404.18881" title="Download PDF">pdf</a>, <a href="/format/2404.18881" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Human-in-the-Loop Synthetic Text Data Inspection with Provenance  Tracking
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kang%2C+H+J">Hong Jin Kang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Harel-Canada%2C+F">Fabrice Harel-Canada</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gulzar%2C+M+A">Muhammad Ali Gulzar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+V">Violet Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+M">Miryung Kim</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> NAACL 2024 Findings
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)
  
  </div>
  <p class="mathjax">Data augmentation techniques apply transformations to existing texts to
  generate additional data. The transformations may produce low-quality texts,
  where the meaning of the text is changed and the text may even be mangled
  beyond human comprehension. Analyzing the synthetically generated texts and
  their corresponding labels is slow and demanding. To winnow out texts with
  incorrect labels, we develop INSPECTOR, a human-in-the-loop data inspection
  technique. INSPECTOR combines the strengths of provenance tracking techniques
  with assistive labeling. INSPECTOR allows users to group related texts by their
  transformation provenance, i.e., the transformations applied to the original
  text, or feature provenance, the linguistic features of the original text. For
  assistive labeling, INSPECTOR computes metrics that approximate data quality,
  and allows users to compare the corresponding label of each text against the
  predictions of a large language model. In a user study, INSPECTOR increases the
  number of texts with correct labels identified by 3X on a sentiment analysis
  task and by 4X on a hate speech detection task. The participants found grouping
  the synthetically generated texts by their common transformation to be the most
  useful technique. Surprisingly, grouping texts by common linguistic features
  was perceived to be unhelpful. Contrary to prior work, our study finds that no
  single technique obviates the need for human inspection effort. This validates
  the design of INSPECTOR which combines both analysis of data provenance and
  assistive labeling to reduce human inspection effort.
  </p>
  </div>
  </dd>
  <dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18886" title="Abstract">arXiv:2404.18886</a> [<a href="/pdf/2404.18886" title="Download PDF">pdf</a>, <a href="/format/2404.18886" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Survey on Diffusion Models for Time Series and Spatio-Temporal Data
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yiyuan Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jin%2C+M">Ming Jin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wen%2C+H">Haomin Wen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chaoli Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yuxuan Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+L">Lintao Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chenghao Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+B">Bin Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zenglin Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bian%2C+J">Jiang Bian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+S">Shirui Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wen%2C+Q">Qingsong Wen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Ongoing work; 27 pages, 8 figures, 2 tables; Github Repo: <a href="https://github.com/yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">The study of time series data is crucial for understanding trends and
  anomalies over time, enabling predictive insights across various sectors.
  Spatio-temporal data, on the other hand, is vital for analyzing phenomena in
  both space and time, providing a dynamic perspective on complex system
  interactions. Recently, diffusion models have seen widespread application in
  time series and spatio-temporal data mining. Not only do they enhance the
  generative and inferential capabilities for sequential and temporal data, but
  they also extend to other downstream tasks. In this survey, we comprehensively
  and thoroughly review the use of diffusion models in time series and
  spatio-temporal data, categorizing them by model category, task type, data
  modality, and practical application domain. In detail, we categorize diffusion
  models into unconditioned and conditioned types and discuss time series data
  and spatio-temporal data separately. Unconditioned models, which operate
  unsupervised, are subdivided into probability-based and score-based models,
  serving predictive and generative tasks such as forecasting, anomaly detection,
  classification, and imputation. Conditioned models, on the other hand, utilize
  extra information to enhance performance and are similarly divided for both
  predictive and generative tasks. Our survey extensively covers their
  application in various fields, including healthcare, recommendation, climate,
  energy, audio, and transportation, providing a foundational understanding of
  how these models analyze and generate data. Through this structured overview,
  we aim to provide researchers and practitioners with a comprehensive
  understanding of diffusion models for time series and spatio-temporal data
  analysis, aiming to direct future innovations and applications by addressing
  traditional challenges and exploring innovative solutions within the diffusion
  model framework.
  </p>
  </div>
  </dd>
  <dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18887" title="Abstract">arXiv:2404.18887</a> [<a href="/pdf/2404.18887" title="Download PDF">pdf</a>, <a href="/format/2404.18887" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PrescientFuzz: A more effective exploration approach for grey-box  fuzzing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Blackwell%2C+D">Daniel Blackwell</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Clark%2C+D">David Clark</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 20 pages, 12 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)
  
  </div>
  <p class="mathjax">In this paper, we introduce an approach for improving the early exploration
  of grey-box fuzzing campaigns; allowing the fuzzer to reach the interesting
  coverage earlier. To do this, it leverages information from the system under
  test's (SUT's) control flow graph in order to decide which inputs are likely to
  lead to discovering most coverage when mutated.
  </p>
  </div>
  </dd>
  <dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18890" title="Abstract">arXiv:2404.18890</a> [<a href="/pdf/2404.18890" title="Download PDF">pdf</a>, <a href="/format/2404.18890" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Hide and Seek: How Does Watermarking Impact Face Recognition?
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yuguang Yao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Grosz%2C+S">Steven Grosz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Sijia Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jain%2C+A">Anil Jain</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">The recent progress in generative models has revolutionized the synthesis of
  highly realistic images, including face images. This technological development
  has undoubtedly helped face recognition, such as training data augmentation for
  higher recognition accuracy and data privacy. However, it has also introduced
  novel challenges concerning the responsible use and proper attribution of
  computer generated images. We investigate the impact of digital watermarking, a
  technique for embedding ownership signatures into images, on the effectiveness
  of face recognition models. We propose a comprehensive pipeline that integrates
  face image generation, watermarking, and face recognition to systematically
  examine this question. The proposed watermarking scheme, based on an
  encoder-decoder architecture, successfully embeds and recovers signatures from
  both real and synthetic face images while preserving their visual fidelity.
  Through extensive experiments, we unveil that while watermarking enables robust
  image attribution, it results in a slight decline in face recognition accuracy,
  particularly evident for face images with challenging poses and expressions.
  Additionally, we find that directly training face recognition models on
  watermarked images offers only a limited alleviation of this performance
  decline. Our findings underscore the intricate trade off between watermarking
  and face recognition accuracy. This work represents a pivotal step towards the
  responsible utilization of generative models in face recognition and serves to
  initiate discussions regarding the broader implications of watermarking in
  biometrics.
  </p>
  </div>
  </dd>
  <dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18891" title="Abstract">arXiv:2404.18891</a> [<a href="/pdf/2404.18891" title="Download PDF">pdf</a>, <a href="/format/2404.18891" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel  Relation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+K">Kebin Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Wenbin Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+X">Xiaofei Xiao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 2 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">The scarcity of labeled data in real-world scenarios is a critical bottleneck
  of deep learning's effectiveness. Semi-supervised semantic segmentation has
  been a typical solution to achieve a desirable tradeoff between annotation cost
  and segmentation performance. However, previous approaches, whether based on
  consistency regularization or self-training, tend to neglect the contextual
  knowledge embedded within inter-pixel relations. This negligence leads to
  suboptimal performance and limited generalization. In this paper, we propose a
  novel approach IPixMatch designed to mine the neglected but valuable
  Inter-Pixel information for semi-supervised learning. Specifically, IPixMatch
  is constructed as an extension of the standard teacher-student network,
  incorporating additional loss terms to capture inter-pixel relations. It shines
  in low-data regimes by efficiently leveraging the limited labeled data and
  extracting maximum utility from the available unlabeled data. Furthermore,
  IPixMatch can be integrated seamlessly into most teacher-student frameworks
  without the need of model modification or adding additional components. Our
  straightforward IPixMatch method demonstrates consistent performance
  improvements across various benchmark datasets under different partitioning
  protocols.
  </p>
  </div>
  </dd>
  <dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18893" title="Abstract">arXiv:2404.18893</a> [<a href="/pdf/2404.18893" title="Download PDF">pdf</a>, <a href="/format/2404.18893" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning general Gaussian mixtures with efficient score matching
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Sitan Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kontonis%2C+V">Vasilis Kontonis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shah%2C+K">Kulin Shah</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 57 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">We study the problem of learning mixtures of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-258-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1653" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1654"><span class="mi" id="MathJax-Span-1655" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-258">k</script> Gaussians in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-259-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1656" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1657"><span class="mi" id="MathJax-Span-1658" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-259">d</script> dimensions.
  We make no separation assumptions on the underlying mixture components: we only
  require that the covariance matrices have bounded condition number and that the
  means and covariances lie in a ball of bounded radius. We give an algorithm
  that draws <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-260-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1659" style="width: 4.068em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.277em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1003.277em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1660"><span class="msubsup" id="MathJax-Span-1661"><span style="display: inline-block; position: relative; width: 3.221em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1662" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.567em;"><span class="texatom" id="MathJax-Span-1663"><span class="mrow" id="MathJax-Span-1664"><span class="texatom" id="MathJax-Span-1665"><span class="mrow" id="MathJax-Span-1666"><span class="mi" id="MathJax-Span-1667" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">p</span><span class="mi" id="MathJax-Span-1668" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">o</span><span class="mi" id="MathJax-Span-1669" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">l</span><span class="mi" id="MathJax-Span-1670" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">y</span></span></span><span class="mo" id="MathJax-Span-1671" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1672" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-1673"><span class="mrow" id="MathJax-Span-1674"><span class="mo" id="MathJax-Span-1675" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">/</span></span></span><span class="mi" id="MathJax-Span-1676" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">ε</span><span class="mo" id="MathJax-Span-1677" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-260">d^{\mathrm{poly}(k/\varepsilon)}</script> samples from the target mixture,
  runs in sample-polynomial time, and constructs a sampler whose output
  distribution is <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-261-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1678" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1679"><span class="mi" id="MathJax-Span-1680" style="font-family: STIXGeneral-Italic;">ε</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-261">\varepsilon</script>-far from the unknown mixture in total variation.
  Prior works for this problem either (i) required exponential runtime in the
  dimension <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-262-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1681" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1682"><span class="mi" id="MathJax-Span-1683" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-262">d</script>, (ii) placed strong assumptions on the instance (e.g., spherical
  covariances or clusterability), or (iii) had doubly exponential dependence on
  the number of components <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-263-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1684" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1685"><span class="mi" id="MathJax-Span-1686" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-263">k</script>.
  <br>Our approach departs from commonly used techniques for this problem like the
  method of moments. Instead, we leverage a recently developed reduction, based
  on diffusion models, from distribution learning to a supervised learning task
  called score matching. We give an algorithm for the latter by proving a
  structural result showing that the score function of a Gaussian mixture can be
  approximated by a piecewise-polynomial function, and there is an efficient
  algorithm for finding it. To our knowledge, this is the first example of
  diffusion models achieving a state-of-the-art theoretical guarantee for an
  unsupervised learning task.
  </p>
  </div>
  </dd>
  <dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18895" title="Abstract">arXiv:2404.18895</a> [<a href="/pdf/2404.18895" title="Download PDF">pdf</a>, <a href="/format/2404.18895" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> RSCaMa: Remote Sensing Image Change Captioning with State Space Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chenyang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+K">Keyan Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+B">Bowen Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Haotian Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zou%2C+Z">Zhengxia Zou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zhenwei Shi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Remote Sensing Image Change Captioning (RSICC) aims to identify surface
  changes in multi-temporal remote sensing images and describe them in natural
  language. Current methods typically rely on an encoder-decoder architecture and
  focus on designing a sophisticated neck to process bi-temporal features
  extracted by the backbone. Recently, State Space Models (SSMs), especially
  Mamba, have demonstrated outstanding performance in many fields, owing to their
  efficient feature-selective modelling capability. However, their potential in
  the RSICC task remains unexplored. In this paper, we introduce Mamba into RSICC
  and propose a novel approach called RSCaMa (Remote Sensing Change Captioning
  Mamba). Specifically, we utilize Siamese backbones to extract bi-temporal
  features, which are then processed through multiple CaMa layers consisting of
  Spatial Difference-guided SSM (SD-SSM) and Temporal Traveling SSM (TT-SSM).
  SD-SSM uses differential features to enhance change perception, while TT-SSM
  promotes bitemporal interactions in a token-wise cross-scanning manner.
  Experimental results validate the effectiveness of CaMa layers and demonstrate
  the superior performance of RSCaMa, as well as the potential of Mamba in the
  RSICC task. Additionally, we systematically compare the effects of three
  language decoders, including Mamba, GPT-style decoder with causal attention
  mechanism, and Transformer decoder with cross-attention mechanism. This
  provides valuable insights for future RSICC research. The code will be
  available at https://github.com/Chen-Yang-Liu/RSCaMa
  </p>
  </div>
  </dd>
  <dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18896" title="Abstract">arXiv:2404.18896</a> [<a href="/pdf/2404.18896" title="Download PDF">pdf</a>, <a href="/format/2404.18896" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Overcoming Knowledge Barriers: Online Imitation Learning from  Observation with Pretrained World Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xingyuan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Becker-Ehmck%2C+P">Philip Becker-Ehmck</a>, 
  <a href="/search/cs?searchtype=author&amp;query=van+der+Smagt%2C+P">Patrick van der Smagt</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Karl%2C+M">Maximilian Karl</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 19 pages, 7 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  <p class="mathjax">Incorporating the successful paradigm of pretraining and finetuning from
  Computer Vision and Natural Language Processing into decision-making has become
  increasingly popular in recent years. In this paper, we study Imitation
  Learning from Observation with pretrained models and find existing approaches
  such as BCO and AIME face knowledge barriers, specifically the Embodiment
  Knowledge Barrier (EKB) and the Demonstration Knowledge Barrier (DKB), greatly
  limiting their performance. The EKB arises when pretrained models lack
  knowledge about unseen observations, leading to errors in action inference. The
  DKB results from policies trained on limited demonstrations, hindering
  adaptability to diverse scenarios. We thoroughly analyse the underlying
  mechanism of these barriers and propose AIME-v2 upon AIME as a solution.
  AIME-v2 uses online interactions with data-driven regulariser to alleviate the
  EKB and mitigates the DKB by introducing a surrogate reward function to enhance
  policy training. Experimental results on tasks from the DeepMind Control Suite
  and Meta-World benchmarks demonstrate the effectiveness of these modifications
  in improving both sample-efficiency and converged performance. The study
  contributes valuable insights into resolving knowledge barriers for enhanced
  decision-making in pretraining-based approaches. Code will be available at
  https://github.com/argmax-ai/aime-v2.
  </p>
  </div>
  </dd>
  <dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18901" title="Abstract">arXiv:2404.18901</a> [<a href="/pdf/2404.18901" title="Download PDF">pdf</a>, <a href="/format/2404.18901" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Finite Element Approximation of the Fractional Porous Medium Equation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Carrillo%2C+J+A">José A. Carrillo</a>, 
  <a href="/search/math?searchtype=author&amp;query=Fronzoni%2C+S">Stefano Fronzoni</a>, 
  <a href="/search/math?searchtype=author&amp;query=S%C3%BCli%2C+E">Endre Süli</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)
  
  </div>
  <p class="mathjax">We construct a finite element method for the numerical solution of a
  fractional porous medium equation on a bounded open Lipschitz polytopal domain
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-264-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1687" style="width: 4.124em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.334em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1003.334em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1688"><span class="mi" id="MathJax-Span-1689" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-1690" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">⊂</span><span class="msubsup" id="MathJax-Span-1691" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 1.188em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1692"><span class="mrow" id="MathJax-Span-1693"><span class="mi" id="MathJax-Span-1694" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.737em;"><span class="texatom" id="MathJax-Span-1695"><span class="mrow" id="MathJax-Span-1696"><span class="mi" id="MathJax-Span-1697" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-264">\Omega \subset \mathbb{R}^{d}</script>, where <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-265-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1698" style="width: 2.939em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.374em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.374em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1699"><span class="mi" id="MathJax-Span-1700" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1701" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mn" id="MathJax-Span-1702" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-265">d = 2</script> or <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-266-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1703" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1704"><span class="mn" id="MathJax-Span-1705" style="font-family: STIXGeneral-Regular;">3</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-266">3</script>. The pressure in the
  model is defined as the solution of a fractional Poisson equation, involving
  the fractional Neumann Laplacian in terms of its spectral definition. We
  perform a rigorous passage to the limit as the spatial and temporal
  discretization parameters tend to zero and show that a subsequence of the
  sequence of finite element approximations defined by the proposed numerical
  method converges to a bounded and nonnegative weak solution of the
  initial-boundary-value problem under consideration. This result can be
  therefore viewed as a constructive proof of the existence of a nonnegative,
  energy-dissipative, weak solution to the initial-boundary-value problem for the
  fractional porous medium equation under consideration, based on the Neumann
  Laplacian. The convergence proof relies on results concerning the finite
  element approximation of the spectral fractional Laplacian and compactness
  techniques for nonlinear partial differential equations, together with
  properties of the equation, which are shown to be inherited by the numerical
  method. We also prove that the total energy associated with the problem under
  consideration exhibits exponential decay in time.
  </p>
  </div>
  </dd>
  <dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18904" title="Abstract">arXiv:2404.18904</a> [<a href="/pdf/2404.18904" title="Download PDF">pdf</a>, <a href="/format/2404.18904" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On classes of bounded tree rank, their interpretations, and efficient  sparsification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gajarsk%C3%BD%2C+J">Jakub Gajarský</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McCarty%2C+R">Rose McCarty</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to ICALP 2024, track B
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS); Logic in Computer Science (cs.LO)
  
  </div>
  <p class="mathjax">Graph classes of bounded tree rank were introduced recently in the context of
  the model checking problem for first-order logic of graphs. These graph classes
  are a common generalization of graph classes of bounded degree and bounded
  treedepth, and they are a special case of graph classes of bounded expansion.
  We introduce a notion of decomposition for these classes and show that these
  decompositions can be efficiently computed. Also, a natural extension of our
  decomposition leads to a new characterization and decomposition for graph
  classes of bounded expansion (and an efficient algorithm computing this
  decomposition).
  <br>We then focus on interpretations of graph classes of bounded tree rank. We
  give a characterization of graph classes interpretable in graph classes of tree
  rank <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-267-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1706" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1707"><span class="mn" id="MathJax-Span-1708" style="font-family: STIXGeneral-Regular;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-267">2</script>. Importantly, our characterization leads to an efficient
  sparsification procedure: For any graph class <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-268-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1709" style="width: 0.85em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.68em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1710"><span class="mi" id="MathJax-Span-1711" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-268">C</script> interpretable in a
  efficiently bounded graph class of tree rank at most <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-269-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1712" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1713"><span class="mn" id="MathJax-Span-1714" style="font-family: STIXGeneral-Regular;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-269">2</script>, there is a polynomial
  time algorithm that to any <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-270-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1715" style="width: 3.447em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.769em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.769em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1716"><span class="mi" id="MathJax-Span-1717" style="font-family: STIXGeneral-Italic;">G</span><span class="mo" id="MathJax-Span-1718" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="mi" id="MathJax-Span-1719" style="font-family: STIXGeneral-Italic; padding-left: 0.342em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-270">G \in C</script> computes a (sparse) graph <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-271-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1720" style="width: 1.019em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.793em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.793em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1721"><span class="mi" id="MathJax-Span-1722" style="font-family: STIXGeneral-Italic;">H<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-271">H</script> from a fixed
  graph class of tree rank at most <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-272-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1723" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1724"><span class="mn" id="MathJax-Span-1725" style="font-family: STIXGeneral-Regular;">2</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-272">2</script> such that <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-273-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1726" style="width: 4.858em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.955em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.898em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1727"><span class="mi" id="MathJax-Span-1728" style="font-family: STIXGeneral-Italic;">G</span><span class="mo" id="MathJax-Span-1729" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mi" id="MathJax-Span-1730" style="font-family: STIXGeneral-Italic; padding-left: 0.342em;">I<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-1731" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1732" style="font-family: STIXGeneral-Italic;">H<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-1733" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-273">G = I(H)</script> for a fixed
  interpretation <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-274-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1734" style="width: 0.511em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.398em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.398em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1735"><span class="mi" id="MathJax-Span-1736" style="font-family: STIXGeneral-Italic;">I<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-274">I</script>. To the best of our knowledge, this is the first efficient
  "interpretation reversal" result that generalizes the result of Gajarsk\'y et
  al. [LICS 2016], who showed an analogous result for graph classes interpretable
  in classes of graphs of bounded degree.
  </p>
  </div>
  </dd>
  <dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18906" title="Abstract">arXiv:2404.18906</a> [<a href="/pdf/2404.18906" title="Download PDF">pdf</a>, <a href="/format/2404.18906" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On Clustering Induced Voronoi Diagrams
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+D+Z">Danny Z. Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Ziyun Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yangwei Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Jinhui Xu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> <a href="https://info.arxiv.org/help/prep#comments">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>
  
  </div>
  <p class="mathjax">In this paper, we study a generalization of the classical Voronoi diagram,
  called clustering induced Voronoi diagram (CIVD). Different from the
  traditional model, CIVD takes as its sites the power set <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-275-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1737" style="width: 1.019em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.793em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.793em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1738"><span class="mi" id="MathJax-Span-1739" style="font-family: STIXGeneral-Italic;">U<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-275">U</script> of an input set
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-276-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1740" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1741"><span class="mi" id="MathJax-Span-1742" style="font-family: STIXGeneral-Italic;">P</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-276">P</script> of objects. For each subset <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-277-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1743" style="width: 0.85em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.68em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1744"><span class="mi" id="MathJax-Span-1745" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-277">C</script> of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-278-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1746" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1747"><span class="mi" id="MathJax-Span-1748" style="font-family: STIXGeneral-Italic;">P</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-278">P</script>, CIVD uses an influence function
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-279-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1749" style="width: 3.616em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.939em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.882em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1750"><span class="mi" id="MathJax-Span-1751" style="font-family: STIXGeneral-Italic;">F<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span class="mo" id="MathJax-Span-1752" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1753" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1754" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-1755" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">q</span><span class="mo" id="MathJax-Span-1756" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-279">F(C,q)</script> to measure the total (or joint) influence of all objects in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-280-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1757" style="width: 0.85em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.68em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1758"><span class="mi" id="MathJax-Span-1759" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-280">C</script> on an
  arbitrary point <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-281-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1760" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1761"><span class="mi" id="MathJax-Span-1762" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-281">q</script> in the space <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-282-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1763" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.245em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1764"><span class="msubsup" id="MathJax-Span-1765"><span style="display: inline-block; position: relative; width: 1.188em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1766"><span class="mrow" id="MathJax-Span-1767"><span class="mi" id="MathJax-Span-1768" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.737em;"><span class="mi" id="MathJax-Span-1769" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-282">\mathbb{R}^d</script>, and determines the
  influence-based Voronoi cell in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-283-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1770" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.245em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1771"><span class="msubsup" id="MathJax-Span-1772"><span style="display: inline-block; position: relative; width: 1.188em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1773"><span class="mrow" id="MathJax-Span-1774"><span class="mi" id="MathJax-Span-1775" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.737em;"><span class="mi" id="MathJax-Span-1776" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-283">\mathbb{R}^d</script> for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-284-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1777" style="width: 0.85em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.68em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1778"><span class="mi" id="MathJax-Span-1779" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-284">C</script>. This generalized model
  offers a number of new features (e.g., simultaneous clustering and space
  partition) to Voronoi diagram which are useful in various new applications. We
  investigate the general conditions for the influence function which ensure the
  existence of a small-size (e.g., nearly linear) approximate CIVD for a set <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-285-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1780" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1781"><span class="mi" id="MathJax-Span-1782" style="font-family: STIXGeneral-Italic;">P</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-285">P</script>
  of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-286-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1783" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1784"><span class="mi" id="MathJax-Span-1785" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-286">n</script> points in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-287-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1786" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.245em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1787"><span class="msubsup" id="MathJax-Span-1788"><span style="display: inline-block; position: relative; width: 1.188em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1789"><span class="mrow" id="MathJax-Span-1790"><span class="mi" id="MathJax-Span-1791" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.737em;"><span class="mi" id="MathJax-Span-1792" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-287">\mathbb{R}^d</script> for some fixed <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-288-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1793" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1794"><span class="mi" id="MathJax-Span-1795" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-288">d</script>. To construct CIVD, we first
  present a standalone new technique, called approximate influence (AI)
  decomposition, for the general CIVD problem. With only <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-289-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1796" style="width: 4.971em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.011em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.955em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1797"><span class="mi" id="MathJax-Span-1798" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1799" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1800" style="font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-1801" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">log</span><span class="mo" id="MathJax-Span-1802"></span><span class="mi" id="MathJax-Span-1803" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">n</span><span class="mo" id="MathJax-Span-1804" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-289">O(n\log n)</script> time, the
  AI decomposition partitions the space <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-290-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1805" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.245em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1806"><span class="msubsup" id="MathJax-Span-1807"><span style="display: inline-block; position: relative; width: 1.188em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1808"><span class="mrow" id="MathJax-Span-1809"><span class="mi" id="MathJax-Span-1810" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.737em;"><span class="texatom" id="MathJax-Span-1811"><span class="mrow" id="MathJax-Span-1812"><span class="mi" id="MathJax-Span-1813" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-290">\mathbb{R}^{d}</script> into a nearly linear
  number of cells so that all points in each cell receive their approximate
  maximum influence from the same (possibly unknown) site (i.e., a subset of
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-291-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1814" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1815"><span class="mi" id="MathJax-Span-1816" style="font-family: STIXGeneral-Italic;">P</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-291">P</script>). Based on this technique, we develop assignment algorithms to determine a
  proper site for each cell in the decomposition and form various
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-292-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1817" style="width: 3.447em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.769em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.713em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1818"><span class="mo" id="MathJax-Span-1819" style="font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-1820" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1821" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">−</span><span class="mi" id="MathJax-Span-1822" style="font-family: STIXGeneral-Italic; padding-left: 0.229em;">ϵ</span><span class="mo" id="MathJax-Span-1823" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-292">(1-\epsilon)</script>-approximate CIVDs for some small fixed <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-293-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1824" style="width: 2.882em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.318em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1825"><span class="mi" id="MathJax-Span-1826" style="font-family: STIXGeneral-Italic;">ϵ</span><span class="mo" id="MathJax-Span-1827" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">&gt;</span><span class="mn" id="MathJax-Span-1828" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">0</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-293">\epsilon>0</script>.
  Particularly, we consider two representative CIVD problems, vector CIVD and
  density-based CIVD, and show that both of them admit fast assignment
  algorithms; consequently, their <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-294-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1829" style="width: 3.447em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.769em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.713em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1830"><span class="mo" id="MathJax-Span-1831" style="font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-1832" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1833" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">−</span><span class="mi" id="MathJax-Span-1834" style="font-family: STIXGeneral-Italic; padding-left: 0.229em;">ϵ</span><span class="mo" id="MathJax-Span-1835" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-294">(1-\epsilon)</script>-approximate CIVDs can be built
  in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-295-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1836" style="width: 9.544em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.738em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.471em, 1007.681em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1837"><span class="mi" id="MathJax-Span-1838" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1839" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1840" style="font-family: STIXGeneral-Italic;">n</span><span class="msubsup" id="MathJax-Span-1841" style="padding-left: 0.172em;"><span style="display: inline-block; position: relative; width: 4.971em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1001.245em, 4.407em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1842" style="font-family: STIXGeneral-Regular;">log</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.301em;"><span class="texatom" id="MathJax-Span-1843"><span class="mrow" id="MathJax-Span-1844"><span class="mo" id="MathJax-Span-1845" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">max</span><span class="mo" id="MathJax-Span-1846" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">{</span><span class="mn" id="MathJax-Span-1847" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span class="mo" id="MathJax-Span-1848" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-1849" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1850" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-1851" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1852" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">}</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1853"></span><span class="mi" id="MathJax-Span-1854" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">n</span><span class="mo" id="MathJax-Span-1855" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.531em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-295">O(n \log^{\max\{3,d+1\}}n)</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-296-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1856" style="width: 5.479em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.463em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.471em, 1004.407em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1857"><span class="mi" id="MathJax-Span-1858" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-1859" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1860" style="font-family: STIXGeneral-Italic;">n</span><span class="msubsup" id="MathJax-Span-1861" style="padding-left: 0.172em;"><span style="display: inline-block; position: relative; width: 1.697em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1001.245em, 4.407em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1862" style="font-family: STIXGeneral-Regular;">log</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.301em;"><span class="texatom" id="MathJax-Span-1863"><span class="mrow" id="MathJax-Span-1864"><span class="mn" id="MathJax-Span-1865" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1866"></span><span class="mi" id="MathJax-Span-1867" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">n</span><span class="mo" id="MathJax-Span-1868" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.531em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-296">O(n \log^{2} n)</script> time, respectively.
  </p>
  </div>
  </dd>
  <dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18909" title="Abstract">arXiv:2404.18909</a> [<a href="/pdf/2404.18909" title="Download PDF">pdf</a>, <a href="/format/2404.18909" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Sample-Efficient Robust Multi-Agent Reinforcement Learning in the Face  of Environmental Uncertainty
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+L">Laixi Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mazumdar%2C+E">Eric Mazumdar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chi%2C+Y">Yuejie Chi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wierman%2C+A">Adam Wierman</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">To overcome the sim-to-real gap in reinforcement learning (RL), learned
  policies must maintain robustness against environmental uncertainties. While
  robust RL has been widely studied in single-agent regimes, in multi-agent
  environments, the problem remains understudied -- despite the fact that the
  problems posed by environmental uncertainties are often exacerbated by
  strategic interactions. This work focuses on learning in distributionally
  robust Markov games (RMGs), a robust variant of standard Markov games, wherein
  each agent aims to learn a policy that maximizes its own worst-case performance
  when the deployed environment deviates within its own prescribed uncertainty
  set. This results in a set of robust equilibrium strategies for all agents that
  align with classic notions of game-theoretic equilibria. Assuming a
  non-adaptive sampling mechanism from a generative model, we propose a
  sample-efficient model-based algorithm (DRNVI) with finite-sample complexity
  guarantees for learning robust variants of various notions of game-theoretic
  equilibria. We also establish an information-theoretic lower bound for solving
  RMGs, which confirms the near-optimal sample complexity of DRNVI with respect
  to problem-dependent factors such as the size of the state space, the target
  accuracy, and the horizon length.
  </p>
  </div>
  </dd>
  <dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18911" title="Abstract">arXiv:2404.18911</a> [<a href="/pdf/2404.18911" title="Download PDF">pdf</a>, <a href="/format/2404.18911" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+F">Fangcheng Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yehui Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhenhua Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ni%2C+Y">Yunsheng Ni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+K">Kai Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yunhe Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Speculative decoding has demonstrated its effectiveness in accelerating the
  inference of large language models while maintaining a consistent sampling
  distribution. However, the conventional approach of training a separate draft
  model to achieve a satisfactory token acceptance rate can be costly. Drawing
  inspiration from early exiting, we propose a novel self-speculative decoding
  framework \emph{Kangaroo}, which uses a fixed shallow sub-network as a
  self-draft model, with the remaining layers serving as the larger target model.
  We train a lightweight and efficient adapter module on top of the sub-network
  to bridge the gap between the sub-network and the full model's representation
  ability. It is noteworthy that the inference latency of the self-draft model
  may no longer be negligible compared to the large model, necessitating
  strategies to increase the token acceptance rate while minimizing the drafting
  steps of the small model. To address this challenge, we introduce an additional
  early exiting mechanism for generating draft tokens. Specifically, we halt the
  small model's subsequent prediction during the drafting phase once the
  confidence level for the current token falls below a certain threshold.
  Extensive experiments on the Spec-Bench demonstrate the effectiveness of
  Kangaroo. Under single-sequence verification, Kangaroo achieves speedups up to
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-297-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1869" style="width: 2.995em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.431em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.374em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1870"><span class="mn" id="MathJax-Span-1871" style="font-family: STIXGeneral-Regular;">1.68</span><span class="mo" id="MathJax-Span-1872" style="font-family: STIXGeneral-Regular;">×</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-297">1.68\times</script> on Spec-Bench, outperforming Medusa-1 with 88.7\% fewer additional
  parameters (67M compared to 591M). The code for Kangaroo is available at
  https://github.com/Equationliu/Kangaroo.
  </p>
  </div>
  </dd>
  <dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18919" title="Abstract">arXiv:2404.18919</a> [<a href="/pdf/2404.18919" title="Download PDF">pdf</a>, <a href="/format/2404.18919" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> TheaterGen: Character Management with LLM for Consistent Multi-turn  Image Generation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+J">Junhao Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yin%2C+B">Baiqiao Yin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cai%2C+K">Kaixin Cai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+M">Minbin Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+H">Hanhui Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+Y">Yuxin He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+X">Xi Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yue Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yifei Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Y">Yuhao Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yiqiang Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+X">Xiaodan Liang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">Recent advances in diffusion models can generate high-quality and stunning
  images from text. However, multi-turn image generation, which is of high demand
  in real-world scenarios, still faces challenges in maintaining semantic
  consistency between images and texts, as well as contextual consistency of the
  same subject across multiple interactive turns. To address this issue, we
  introduce TheaterGen, a training-free framework that integrates large language
  models (LLMs) and text-to-image (T2I) models to provide the capability of
  multi-turn image generation. Within this framework, LLMs, acting as a
  "Screenwriter", engage in multi-turn interaction, generating and managing a
  standardized prompt book that encompasses prompts and layout designs for each
  character in the target image. Based on these, Theatergen generate a list of
  character images and extract guidance information, akin to the "Rehearsal".
  Subsequently, through incorporating the prompt book and guidance information
  into the reverse denoising process of T2I diffusion models, Theatergen generate
  the final image, as conducting the "Final Performance". With the effective
  management of prompt books and character images, TheaterGen significantly
  improves semantic and contextual consistency in synthesized images.
  Furthermore, we introduce a dedicated benchmark, CMIGBench (Consistent
  Multi-turn Image Generation Benchmark) with 8000 multi-turn instructions.
  Different from previous multi-turn benchmarks, CMIGBench does not define
  characters in advance. Both the tasks of story generation and multi-turn
  editing are included on CMIGBench for comprehensive evaluation. Extensive
  experimental results show that TheaterGen outperforms state-of-the-art methods
  significantly. It raises the performance bar of the cutting-edge Mini DALLE 3
  model by 21% in average character-character similarity and 19% in average
  text-image similarity.
  </p>
  </div>
  </dd>
  <dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18922" title="Abstract">arXiv:2404.18922</a> [<a href="/pdf/2404.18922" title="Download PDF">pdf</a>, <a href="/format/2404.18922" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DPO Meets PPO: Reinforced Token Optimization for RLHF
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+H">Han Zhong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+G">Guhao Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+W">Wei Xiong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+L">Li Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+D">Di He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bian%2C+J">Jiang Bian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Liwei Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">In the classical Reinforcement Learning from Human Feedback (RLHF) framework,
  Proximal Policy Optimization (PPO) is employed to learn from sparse,
  sentence-level rewards -- a challenging scenario in traditional deep
  reinforcement learning. Despite the great successes of PPO in the alignment of
  state-of-the-art closed-source large language models (LLMs), its open-source
  implementation is still largely sub-optimal, as widely reported by numerous
  research studies. To address these issues, we introduce a framework that models
  RLHF problems as a Markov decision process (MDP), enabling the capture of
  fine-grained token-wise information. Furthermore, we provide theoretical
  insights that demonstrate the superiority of our MDP framework over the
  previous sentence-level bandit formulation. Under this framework, we introduce
  an algorithm, dubbed as Reinforced Token Optimization (\texttt{RTO}), which
  learns the token-wise reward function from preference data and performs policy
  optimization based on this learned token-wise reward signal. Theoretically,
  \texttt{RTO} is proven to have the capability of finding the near-optimal
  policy sample-efficiently. For its practical implementation, \texttt{RTO}
  innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO,
  originally derived from sparse sentence rewards, surprisingly provides us with
  a token-wise characterization of response quality, which is seamlessly
  incorporated into our subsequent PPO training stage. Extensive real-world
  alignment experiments verify the effectiveness of the proposed approach.
  </p>
  </div>
  </dd>
  <dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18923" title="Abstract">arXiv:2404.18923</a> [<a href="/pdf/2404.18923" title="Download PDF">pdf</a>, <a href="/format/2404.18923" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Holmes: Benchmark the Linguistic Competence of Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Waldis%2C+A">Andreas Waldis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Perlitz%2C+Y">Yotam Perlitz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Choshen%2C+L">Leshem Choshen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hou%2C+Y">Yufang Hou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gurevych%2C+I">Iryna Gurevych</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  <p class="mathjax">We introduce Holmes, a benchmark to assess the linguistic competence of
  language models (LMs) - their ability to grasp linguistic phenomena. Unlike
  prior prompting-based evaluations, Holmes assesses the linguistic competence of
  LMs via their internal representations using classifier-based probing. In doing
  so, we disentangle specific phenomena (e.g., part-of-speech of words) from
  other cognitive abilities, like following textual instructions, and meet recent
  calls to assess LMs' linguistic competence in isolation. Composing Holmes, we
  review over 250 probing studies and feature more than 200 datasets to assess
  syntax, morphology, semantics, reasoning, and discourse phenomena. Analyzing
  over 50 LMs reveals that, aligned with known trends, their linguistic
  competence correlates with model size. However, surprisingly, model
  architecture and instruction tuning also significantly influence performance,
  particularly in morphology and syntax. Finally, we propose FlashHolmes, a
  streamlined version of Holmes designed to lower the high computation load while
  maintaining high-ranking precision.
  </p>
  </div>
  </dd>
  <dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18924" title="Abstract">arXiv:2404.18924</a> [<a href="/pdf/2404.18924" title="Download PDF">pdf</a>, <a href="/format/2404.18924" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Swin2-MoSE: A New Single Image Super-Resolution Model for Remote Sensing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rossi%2C+L">Leonardo Rossi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bernuzzi%2C+V">Vittorio Bernuzzi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fontanini%2C+T">Tomaso Fontanini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bertozzi%2C+M">Massimo Bertozzi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Prati%2C+A">Andrea Prati</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
  
  </div>
  <p class="mathjax">Due to the limitations of current optical and sensor technologies and the
  high cost of updating them, the spectral and spatial resolution of satellites
  may not always meet desired requirements. For these reasons, Remote-Sensing
  Single-Image Super-Resolution (RS-SISR) techniques have gained significant
  interest. In this paper, we propose Swin2-MoSE model, an enhanced version of
  Swin2SR. Our model introduces MoE-SM, an enhanced Mixture-of-Experts (MoE) to
  replace the Feed-Forward inside all Transformer block. MoE-SM is designed with
  Smart-Merger, and new layer for merging the output of individual experts, and
  with a new way to split the work between experts, defining a new per-example
  strategy instead of the commonly used per-token one. Furthermore, we analyze
  how positional encodings interact with each other, demonstrating that
  per-channel bias and per-head bias can positively cooperate. Finally, we
  propose to use a combination of Normalized-Cross-Correlation (NCC) and
  Structural Similarity Index Measure (SSIM) losses, to avoid typical MSE loss
  limitations. Experimental results demonstrate that Swin2-MoSE outperforms SOTA
  by up to 0.377 ~ 0.958 dB (PSNR) on task of 2x, 3x and 4x resolution-upscaling
  (Sen2Venus and OLI2MSI datasets). We show the efficacy of Swin2-MoSE, applying
  it to a semantic segmentation task (SeasoNet dataset). Code and pretrained are
  available on https://github.com/IMPLabUniPr/swin2-mose/tree/official_code
  </p>
  </div>
  </dd>
  <dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18926" title="Abstract">arXiv:2404.18926</a> [<a href="/pdf/2404.18926" title="Download PDF">pdf</a>, <a href="/format/2404.18926" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Point Cloud Models Improve Visual Robustness in Robotic Learners
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Peri%2C+S">Skand Peri</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+I">Iain Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+C">Chanho Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fuxin%2C+L">Li Fuxin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hermans%2C+T">Tucker Hermans</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+S">Stefan Lee</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at International Conference on Robotics and Automation, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Visual control policies can encounter significant performance degradation
  when visual conditions like lighting or camera position differ from those seen
  during training -- often exhibiting sharp declines in capability even for minor
  differences. In this work, we examine robustness to a suite of these types of
  visual changes for RGB-D and point cloud based visual control policies. To
  perform these experiments on both model-free and model-based reinforcement
  learners, we introduce a novel Point Cloud World Model (PCWM) and point cloud
  based control policies. Our experiments show that policies that explicitly
  encode point clouds are significantly more robust than their RGB-D
  counterparts. Further, we find our proposed PCWM significantly outperforms
  prior works in terms of sample efficiency during training. Taken together,
  these results suggest reasoning about the 3D scene through point clouds can
  improve performance, reduce learning time, and increase robustness for robotic
  learners. Project Webpage: https://pvskand.github.io/projects/PCWM
  </p>
  </div>
  </dd>
  <dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18928" title="Abstract">arXiv:2404.18928</a> [<a href="/pdf/2404.18928" title="Download PDF">pdf</a>, <a href="/format/2404.18928" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Stylus: Automatic Adapter Selection for Diffusion Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+M">Michael Luo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wong%2C+J">Justin Wong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Trabucco%2C+B">Brandon Trabucco</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yanping Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhifeng Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stoica%2C+I">Ion Stoica</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Project Website: <a href="https://stylus-diffusion.github.io">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Graphics (cs.GR); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Beyond scaling base models with more data or parameters, fine-tuned adapters
  provide an alternative way to generate high fidelity, custom images at reduced
  costs. As such, adapters have been widely adopted by open-source communities,
  accumulating a database of over 100K adapters-most of which are highly
  customized with insufficient descriptions. This paper explores the problem of
  matching the prompt to a set of relevant adapters, built on recent work that
  highlight the performance gains of composing adapters. We introduce Stylus,
  which efficiently selects and automatically composes task-specific adapters
  based on a prompt's keywords. Stylus outlines a three-stage approach that first
  summarizes adapters with improved descriptions and embeddings, retrieves
  relevant adapters, and then further assembles adapters based on prompts'
  keywords by checking how well they fit the prompt. To evaluate Stylus, we
  developed StylusDocs, a curated dataset featuring 75K adapters with
  pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion
  checkpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as
  preferred, with humans and multimodal models as evaluators, over the base
  model. See stylus-diffusion.github.io for more.
  </p>
  </div>
  </dd>
  <dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18929" title="Abstract">arXiv:2404.18929</a> [<a href="/pdf/2404.18929" title="Download PDF">pdf</a>, <a href="/format/2404.18929" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DGE: Direct Gaussian 3D Editing by Consistent Multi-view Editing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Minghao Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Laina%2C+I">Iro Laina</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vedaldi%2C+A">Andrea Vedaldi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Project Page: <a href="https://silent-chen.github.io/DGE/">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">We consider the problem of editing 3D objects and scenes based on open-ended
  language instructions. The established paradigm to solve this problem is to use
  a 2D image generator or editor to guide the 3D editing process. However, this
  is often slow as it requires do update a computationally expensive 3D
  representations such as a neural radiance field, and to do so by using
  contradictory guidance from a 2D model which is inherently not multi-view
  consistent. We thus introduce the Direct Gaussian Editor (DGE), a method that
  addresses these issues in two ways. First, we modify a given high-quality image
  editor like InstructPix2Pix to be multi-view consistent. We do so by utilizing
  a training-free approach which integrates cues from the underlying 3D geometry
  of the scene. Second, given a multi-view consistent edited sequence of images
  of the object, we directly and efficiently optimize the 3D object
  representation, which is based on 3D Gaussian Splatting. Because it does not
  require to apply edits incrementally and iteratively, DGE is significantly more
  efficient than existing approaches, and comes with other perks such as allowing
  selective editing of parts of the scene.
  </p>
  </div>
  </dd>
  <dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18930" title="Abstract">arXiv:2404.18930</a> [<a href="/pdf/2404.18930" title="Download PDF">pdf</a>, <a href="/format/2404.18930" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Hallucination of Multimodal Large Language Models: A Survey
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bai%2C+Z">Zechen Bai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+P">Pichao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+T">Tianjun Xiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+T">Tong He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+Z">Zongbo Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zheng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shou%2C+M+Z">Mike Zheng Shou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 140 references
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  <p class="mathjax">This survey presents a comprehensive analysis of the phenomenon of
  hallucination in multimodal large language models (MLLMs), also known as Large
  Vision-Language Models (LVLMs), which have demonstrated significant
  advancements and remarkable abilities in multimodal tasks. Despite these
  promising developments, MLLMs often generate outputs that are inconsistent with
  the visual content, a challenge known as hallucination, which poses substantial
  obstacles to their practical deployment and raises concerns regarding their
  reliability in real-world applications. This problem has attracted increasing
  attention, prompting efforts to detect and mitigate such inaccuracies. We
  review recent advances in identifying, evaluating, and mitigating these
  hallucinations, offering a detailed overview of the underlying causes,
  evaluation benchmarks, metrics, and strategies developed to address this issue.
  Additionally, we analyze the current challenges and limitations, formulating
  open questions that delineate potential pathways for future research. By
  drawing the granular classification and landscapes of hallucination causes,
  evaluation benchmarks, and mitigation methods, this survey aims to deepen the
  understanding of hallucinations in MLLMs and inspire further advancements in
  the field. Through our thorough and in-depth review, we contribute to the
  ongoing dialogue on enhancing the robustness and reliability of MLLMs,
  providing valuable insights and resources for researchers and practitioners
  alike. Resources are available at:
  https://github.com/showlab/Awesome-MLLM-Hallucination.
  </p>
  </div>
  </dd>
  </dl>
  <h3>Cross-lists for Tue, 30 Apr 24</h3>
  <dl>
  <dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17139" title="Abstract">arXiv:2404.17139</a> (cross-list from nlin.AO) [<a href="/pdf/2404.17139" title="Download PDF">pdf</a>, <a href="/format/2404.17139" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Central Pattern Generator Network for Simple Control of Gait  Transitions in Hexapod Robots based on Phase Reduction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/nlin?searchtype=author&amp;query=Namura%2C+N">Norihisa Namura</a>, 
  <a href="/search/nlin?searchtype=author&amp;query=Nakao%2C+H">Hiroya Nakao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, 6 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Systems and Control (eess.SY)
  
  </div>
  <p class="mathjax">We present a model of the central pattern generator (CPG) network that can
  control gait transitions in hexapod robots in a simple manner based on phase
  reduction. The CPG network consists of six weakly coupled limit-cycle
  oscillators, whose synchronization dynamics can be described by six phase
  equations through phase reduction. Focusing on the transitions between the
  hexapod gaits with specific symmetries, the six phase equations of the CPG
  network can further be reduced to two independent equations for the phase
  differences. By choosing appropriate coupling functions for the network, we can
  achieve desired synchronization dynamics regardless of the detailed properties
  of the limit-cycle oscillators used for the CPG. The effectiveness of our CPG
  network is demonstrated by numerical simulations of gait transitions between
  the wave, tetrapod, and tripod gaits, using the FitzHugh-Nagumo oscillator as
  the CPG unit.
  </p>
  </div>
  </dd>
  <dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17227" title="Abstract">arXiv:2404.17227</a> (cross-list from econ.GN) [<a href="/pdf/2404.17227" title="Download PDF">pdf</a>, <a href="/format/2404.17227" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Trust Dynamics and Market Behavior in Cryptocurrency: A Comparative  Study of Centralized and Decentralized Exchanges
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/econ?searchtype=author&amp;query=Wu%2C+X">Xintong Wu</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Deng%2C+W">Wanling Deng</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Quan%2C+Y">Yuotng Quan</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Zhang%2C+L">Luyao Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Computational Engineering, Finance, and Science (cs.CE); Cryptography and Security (cs.CR); Computers and Society (cs.CY); Risk Management (q-fin.RM)
  
  </div>
  <p class="mathjax">In the evolving landscape of digital finance, the transition from centralized
  to decentralized trust mechanisms, primarily driven by blockchain technology,
  plays a critical role in shaping the cryptocurrency ecosystem. This paradigm
  shift raises questions about the traditional reliance on centralized trust and
  introduces a novel, decentralized trust framework built upon distributed
  networks. Our research delves into the consequences of this shift, particularly
  focusing on how incidents influence trust within cryptocurrency markets,
  thereby affecting trade behaviors in centralized (CEXs) and decentralized
  exchanges (DEXs). We conduct a comprehensive analysis of various events,
  assessing their effects on market dynamics, including token valuation and
  trading volumes in both CEXs and DEXs. Our findings highlight the pivotal role
  of trust in directing user preferences and the fluidity of trust transfer
  between centralized and decentralized platforms. Despite certain anomalies, the
  results largely align with our initial hypotheses, revealing the intricate
  nature of user trust in cryptocurrency markets. This study contributes
  significantly to interdisciplinary research, bridging distributed systems,
  behavioral finance, and Decentralized Finance (DeFi). It offers valuable
  insights for the distributed computing community, particularly in understanding
  and applying distributed trust mechanisms in digital economies, paving the way
  for future research that could further explore the socio-economic dimensions
  and leverage blockchain data in this dynamic domain.
  </p>
  </div>
  </dd>
  <dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17583" title="Abstract">arXiv:2404.17583</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2404.17583" title="Download PDF">pdf</a>, <a href="/format/2404.17583" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Physically recurrent neural network for rate and path-dependent  heterogeneous materials in a finite strain framework
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cond-mat?searchtype=author&amp;query=Maia%2C+M+A">M. A. Maia</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Rocha%2C+I+B+C+M">I. B. C. M. Rocha</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Kova%C4%8Devi%C4%87%2C+D">D. Kovačević</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=van+der+Meer%2C+F+P">F. P. van der Meer</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 28 pages, 26 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)
  
  </div>
  <p class="mathjax">In this work, a hybrid physics-based data-driven surrogate model for the
  microscale analysis of heterogeneous material is investigated. The proposed
  model benefits from the physics-based knowledge contained in the constitutive
  models used in the full-order micromodel by embedding them in a neural network.
  Following previous developments, this paper extends the applicability of the
  physically recurrent neural network (PRNN) by introducing an architecture
  suitable for rate-dependent materials in a finite strain framework. In this
  model, the homogenized deformation gradient of the micromodel is encoded into a
  set of deformation gradients serving as input to the embedded constitutive
  models. These constitutive models compute stresses, which are combined in a
  decoder to predict the homogenized stress, such that the internal variables of
  the history-dependent constitutive models naturally provide physics-based
  memory for the network. To demonstrate the capabilities of the surrogate model,
  we consider a unidirectional composite micromodel with transversely isotropic
  elastic fibers and elasto-viscoplastic matrix material. The extrapolation
  properties of the surrogate model trained to replace such micromodel are tested
  on loading scenarios unseen during training, ranging from different
  strain-rates to cyclic loading and relaxation. Speed-ups of three orders of
  magnitude with respect to the runtime of the original micromodel are obtained.
  </p>
  </div>
  </dd>
  <dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17584" title="Abstract">arXiv:2404.17584</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2404.17584" title="Download PDF">pdf</a>, <a href="/format/2404.17584" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Equivariant graph convolutional neural networks for the representation  of homogenized anisotropic microstructural mechanical response
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cond-mat?searchtype=author&amp;query=Patel%2C+R">Ravi Patel</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Safta%2C+C">Cosmin Safta</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Jones%2C+R+E">Reese E. Jones</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 23 pages, 10 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Composite materials with different microstructural material symmetries are
  common in engineering applications where grain structure, alloying and
  particle/fiber packing are optimized via controlled manufacturing. In fact
  these microstructural tunings can be done throughout a part to achieve
  functional gradation and optimization at a structural level. To predict the
  performance of particular microstructural configuration and thereby overall
  performance, constitutive models of materials with microstructure are needed.
  <br>In this work we provide neural network architectures that provide effective
  homogenization models of materials with anisotropic components. These models
  satisfy equivariance and material symmetry principles inherently through a
  combination of equivariant and tensor basis operations. We demonstrate them on
  datasets of stochastic volume elements with different textures and phases where
  the material undergoes elastic and plastic deformation, and show that the these
  network architectures provide significant performance improvements.
  </p>
  </div>
  </dd>
  <dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17601" title="Abstract">arXiv:2404.17601</a> (cross-list from q-bio.PE) [<a href="/pdf/2404.17601" title="Download PDF">pdf</a>, <a href="/ps/2404.17601" title="Download PostScript">ps</a>, <a href="/format/2404.17601" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Nested Inheritance Dynamics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/q-bio?searchtype=author&amp;query=Moraffah%2C+B">Bahman Moraffah</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">The idea of the inheritance of biological processes, such as the
  developmental process or the life cycle of an organism, has been discussed in
  the biology literature, but formal mathematical descriptions and plausible data
  analysis frameworks are lacking. We introduce an extension of the nested
  Dirichlet Process (nDP) to a multiscale model to aid in understanding the
  mechanisms by which biological processes are inherited, remain stable, and are
  modified across generations. To address these issues, we introduce Nested
  Inheritance Dynamics Algorithm (NIDA). At its primary level, NIDA encompasses
  all processes unfolding within an individual organism's lifespan. The secondary
  level delineates the dynamics through which these processes evolve or remain
  stable over time. This framework allows for the specification of a physical
  system model at either scale, thus promoting seamless integration with
  established models of development and heredity.
  </p>
  </div>
  </dd>
  <dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17605" title="Abstract">arXiv:2404.17605</a> (cross-list from q-bio.OT) [<a href="/pdf/2404.17605" title="Download PDF">pdf</a>, <a href="/ps/2404.17605" title="Download PostScript">ps</a>, <a href="/format/2404.17605" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Autonomous LLM-driven research from data to human-verifiable research  papers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/q-bio?searchtype=author&amp;query=Ifargan%2C+T">Tal Ifargan</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Hafner%2C+L">Lukas Hafner</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Kern%2C+M">Maor Kern</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Alcalay%2C+O">Ori Alcalay</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Kishony%2C+R">Roy Kishony</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Other Quantitative Biology (q-bio.OT)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">As AI promises to accelerate scientific discovery, it remains unclear whether
  fully AI-driven research is possible and whether it can adhere to key
  scientific values, such as transparency, traceability and verifiability.
  Mimicking human scientific practices, we built data-to-paper, an automation
  platform that guides interacting LLM agents through a complete stepwise
  research process, while programmatically back-tracing information flow and
  allowing human oversight and interactions. In autopilot mode, provided with
  annotated data alone, data-to-paper raised hypotheses, designed research plans,
  wrote and debugged analysis codes, generated and interpreted results, and
  created complete and information-traceable research papers. Even though
  research novelty was relatively limited, the process demonstrated autonomous
  generation of de novo quantitative insights from data. For simple research
  goals, a fully-autonomous cycle can create manuscripts which recapitulate
  peer-reviewed publications without major errors in about 80-90%, yet as goal
  complexity increases, human co-piloting becomes critical for assuring accuracy.
  Beyond the process itself, created manuscripts too are inherently verifiable,
  as information-tracing allows to programmatically chain results, methods and
  data. Our work thereby demonstrates a potential for AI-driven acceleration of
  scientific discovery while enhancing, rather than jeopardizing, traceability,
  transparency and verifiability.
  </p>
  </div>
  </dd>
  <dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17611" title="Abstract">arXiv:2404.17611</a> (cross-list from physics.ao-ph) [<a href="/pdf/2404.17611" title="Download PDF">pdf</a>, <a href="/ps/2404.17611" title="Download PostScript">ps</a>, <a href="/format/2404.17611" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MetaSD: A Unified Framework for Scalable Downscaling of Meteorological  Variables in Diverse Situations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Hu%2C+J">Jing Hu</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Zhang%2C+H">Honghu Zhang</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Zheng%2C+P">Peng Zheng</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Mu%2C+J">Jialin Mu</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Huang%2C+X">Xiaomeng Huang</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Wu%2C+X">Xi Wu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Addressing complex meteorological processes at a fine spatial resolution
  requires substantial computational resources. To accelerate meteorological
  simulations, researchers have utilized neural networks to downscale
  meteorological variables from low-resolution simulations. Despite notable
  advancements, contemporary cutting-edge downscaling algorithms tailored to
  specific variables. Addressing meteorological variables in isolation overlooks
  their interconnectedness, leading to an incomplete understanding of atmospheric
  dynamics. Additionally, the laborious processes of data collection, annotation,
  and computational resources required for individual variable downscaling are
  significant hurdles. Given the limited versatility of existing models across
  different meteorological variables and their failure to account for
  inter-variable relationships, this paper proposes a unified downscaling
  approach leveraging meta-learning. This framework aims to facilitate the
  downscaling of diverse meteorological variables derived from various numerical
  models and spatiotemporal scales. Trained at variables consisted of
  temperature, wind, surface pressure and total precipitation from ERA5 and GFS,
  the proposed method can be extended to downscale convective precipitation,
  potential energy, height, humidity and ozone from CFS, S2S and CMIP6 at
  different spatiotemporal scales, which demonstrating its capability to capture
  the interconnections among diverse variables. Our approach represents the
  initial effort to create a generalized downscaling model. Experimental evidence
  demonstrates that the proposed model outperforms existing top downscaling
  methods in both quantitative and qualitative assessments.
  </p>
  </div>
  </dd>
  <dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17613" title="Abstract">arXiv:2404.17613</a> (cross-list from quant-ph) [<a href="/pdf/2404.17613" title="Download PDF">pdf</a>, <a href="/format/2404.17613" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quantum Patch-Based Autoencoder for Anomaly Segmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Madeira%2C+M+F">Maria Francisca Madeira</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Poggiali%2C+A">Alessandro Poggiali</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Lorenz%2C+J+M">Jeanette Miriam Lorenz</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Quantum Machine Learning investigates the possibility of quantum computers
  enhancing Machine Learning algorithms. Anomaly segmentation is a fundamental
  task in various domains to identify irregularities at sample level and can be
  addressed with both supervised and unsupervised methods. Autoencoders are
  commonly used in unsupervised tasks, where models are trained to reconstruct
  normal instances efficiently, allowing anomaly identification through high
  reconstruction errors. While quantum autoencoders have been proposed in the
  literature, their application to anomaly segmentation tasks remains unexplored.
  In this paper, we introduce a patch-based quantum autoencoder (QPB-AE) for
  image anomaly segmentation, with a number of parameters scaling logarithmically
  with patch size. QPB-AE reconstructs the quantum state of the embedded input
  patches, computing an anomaly map directly from measurement through a SWAP test
  without reconstructing the input image. We evaluate its performance across
  multiple datasets and parameter configurations and compare it against a
  classical counterpart.
  </p>
  </div>
  </dd>
  <dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17615" title="Abstract">arXiv:2404.17615</a> (cross-list from stat.ME) [<a href="/pdf/2404.17615" title="Download PDF">pdf</a>, <a href="/ps/2404.17615" title="Download PostScript">ps</a>, <a href="/format/2404.17615" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DeepVARMA: A Hybrid Deep Learning and VARMA Model for Chemical Industry  Index Forecasting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Yang%2C+H">Hu Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Computation (stat.CO); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">Since the chemical industry index is one of the important indicators to
  measure the development of the chemical industry, forecasting it is critical
  for understanding the economic situation and trends of the industry. Taking the
  multivariable nonstationary series-synthetic material index as the main
  research object, this paper proposes a new prediction model: DeepVARMA, and its
  variants Deep-VARMA-re and DeepVARMA-en, which combine LSTM and VARMAX models.
  The new model firstly uses the deep learning model such as the LSTM remove the
  trends of the target time series and also learn the representation of
  endogenous variables, and then uses the VARMAX model to predict the detrended
  target time series with the embeddings of endogenous variables, and finally
  combines the trend learned by the LSTM and dependency learned by the VARMAX
  model to obtain the final predictive values. The experimental results show that
  (1) the new model achieves the best prediction accuracy by combining the LSTM
  encoding of the exogenous variables and the VARMAX model. (2) In multivariate
  non-stationary series prediction, DeepVARMA uses a phased processing strategy
  to show higher adaptability and accuracy compared to the traditional VARMA
  model as well as the machine learning models LSTM, RF and XGBoost. (3) Compared
  with smooth sequence prediction, the traditional VARMA and VARMAX models
  fluctuate more in predicting non-smooth sequences, while DeepVARMA shows more
  flexibility and robustness. This study provides more accurate tools and methods
  for future development and scientific decision-making in the chemical industry.
  </p>
  </div>
  </dd>
  <dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17621" title="Abstract">arXiv:2404.17621</a> (cross-list from eess.IV) [<a href="/pdf/2404.17621" title="Download PDF">pdf</a>, <a href="/format/2404.17621" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Attention-aware non-rigid image registration for accelerated MR imaging
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Ghoul%2C+A">Aya Ghoul</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Pan%2C+J">Jiazhen Pan</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Lingg%2C+A">Andreas Lingg</a>, 
  <a href="/search/eess?searchtype=author&amp;query=K%C3%BCbler%2C+J">Jens Kübler</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Krumm%2C+P">Patrick Krumm</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Hammernik%2C+K">Kerstin Hammernik</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Rueckert%2C+D">Daniel Rueckert</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Gatidis%2C+S">Sergios Gatidis</a>, 
  <a href="/search/eess?searchtype=author&amp;query=K%C3%BCstner%2C+T">Thomas Küstner</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, 7 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Accurate motion estimation at high acceleration factors enables rapid
  motion-compensated reconstruction in Magnetic Resonance Imaging (MRI) without
  compromising the diagnostic image quality. In this work, we introduce an
  attention-aware deep learning-based framework that can perform non-rigid
  pairwise registration for fully sampled and accelerated MRI. We extract local
  visual representations to build similarity maps between the registered image
  pairs at multiple resolution levels and additionally leverage long-range
  contextual information using a transformer-based module to alleviate
  ambiguities in the presence of artifacts caused by undersampling. We combine
  local and global dependencies to perform simultaneous coarse and fine motion
  estimation. The proposed method was evaluated on in-house acquired fully
  sampled and accelerated data of 101 patients and 62 healthy subjects undergoing
  cardiac and thoracic MRI. The impact of motion estimation accuracy on the
  downstream task of motion-compensated reconstruction was analyzed. We
  demonstrate that our model derives reliable and consistent motion fields across
  different sampling trajectories (Cartesian and radial) and acceleration factors
  of up to 16x for cardiac motion and 30x for respiratory motion and achieves
  superior image quality in motion-compensated reconstruction qualitatively and
  quantitatively compared to conventional and recent deep learning-based
  approaches. The code is publicly available at
  https://github.com/lab-midas/GMARAFT.
  </p>
  </div>
  </dd>
  <dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17644" title="Abstract">arXiv:2404.17644</a> (cross-list from stat.ML) [<a href="/pdf/2404.17644" title="Download PDF">pdf</a>, <a href="/format/2404.17644" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Conditional Independence Test in the Presence of Discretization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Sun%2C+B">Boyang Sun</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Yao%2C+Y">Yu Yao</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Hao%2C+H">Huangyuan Hao</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Qiu%2C+Y">Yumou Qiu</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Zhang%2C+K">Kun Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Testing conditional independence has many applications, such as in Bayesian
  network learning and causal discovery. Different test methods have been
  proposed. However, existing methods generally can not work when only
  discretized observations are available. Specifically, consider <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-298-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1873" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1874"><span class="msubsup" id="MathJax-Span-1875"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1876" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.624em;"><span class="mn" id="MathJax-Span-1877" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-298">X_1</script>,
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-299-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1878" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1879"><span class="msubsup" id="MathJax-Span-1880"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(2.939em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1881"><span class="mrow" id="MathJax-Span-1882"><span class="munderover" id="MathJax-Span-1883"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1884" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.288em; left: 0.229em;"><span style="height: 0em; vertical-align: 0em; width: 0.398em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-1885" style="font-family: STIXGeneral-Regular;"><span style="margin-left: -0.392em;">̃</span><span style="height: 0em; vertical-align: 0em; margin-left: -0.054em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mn" id="MathJax-Span-1886" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-299">\tilde{X}_2</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-300-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1887" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1888"><span class="msubsup" id="MathJax-Span-1889"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1890" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.624em;"><span class="mn" id="MathJax-Span-1891" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-300">X_3</script> are observed variables, where <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-301-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1892" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1893"><span class="msubsup" id="MathJax-Span-1894"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(2.939em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1895"><span class="mrow" id="MathJax-Span-1896"><span class="munderover" id="MathJax-Span-1897"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1898" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.288em; left: 0.229em;"><span style="height: 0em; vertical-align: 0em; width: 0.398em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-1899" style="font-family: STIXGeneral-Regular;"><span style="margin-left: -0.392em;">̃</span><span style="height: 0em; vertical-align: 0em; margin-left: -0.054em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mn" id="MathJax-Span-1900" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-301">\tilde{X}_2</script> is a
  discretization of latent variables <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-302-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1901" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1902"><span class="msubsup" id="MathJax-Span-1903"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1904" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.624em;"><span class="mn" id="MathJax-Span-1905" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-302">X_2</script>. Applying existing test methods to the
  observations of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-303-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1906" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1907"><span class="msubsup" id="MathJax-Span-1908"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1909" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.624em;"><span class="mn" id="MathJax-Span-1910" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-303">X_1</script>, <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-304-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1911" style="width: 1.414em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1001.132em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1912"><span class="msubsup" id="MathJax-Span-1913"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px;"><span style="position: absolute; clip: rect(2.939em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-1914"><span class="mrow" id="MathJax-Span-1915"><span class="munderover" id="MathJax-Span-1916"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1917" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.288em; left: 0.229em;"><span style="height: 0em; vertical-align: 0em; width: 0.398em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-1918" style="font-family: STIXGeneral-Regular;"><span style="margin-left: -0.392em;">̃</span><span style="height: 0em; vertical-align: 0em; margin-left: -0.054em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.68em;"><span class="mn" id="MathJax-Span-1919" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-304">\tilde{X}_2</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-305-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1920" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1921"><span class="msubsup" id="MathJax-Span-1922"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1923" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.624em;"><span class="mn" id="MathJax-Span-1924" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-305">X_3</script> can lead to a false conclusion
  about the underlying conditional independence of variables <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-306-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1925" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1926"><span class="msubsup" id="MathJax-Span-1927"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1928" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.624em;"><span class="mn" id="MathJax-Span-1929" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-306">X_1</script>, <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-307-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1930" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1931"><span class="msubsup" id="MathJax-Span-1932"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1933" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.624em;"><span class="mn" id="MathJax-Span-1934" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-307">X_2</script> and
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-308-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1935" style="width: 1.358em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.076em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.076em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1936"><span class="msubsup" id="MathJax-Span-1937"><span style="display: inline-block; position: relative; width: 1.019em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1938" style="font-family: STIXGeneral-Italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.624em;"><span class="mn" id="MathJax-Span-1939" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.115em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-308">X_3</script>. Motivated by this, we propose a conditional independence test
  specifically designed to accommodate the presence of such discretization. To
  achieve this, we design the bridge equations to recover the parameter
  reflecting the statistical information of the underlying latent continuous
  variables. An appropriate test statistic and its asymptotic distribution under
  the null hypothesis of conditional independence have also been derived. Both
  theoretical results and empirical validation have been provided, demonstrating
  the effectiveness of our test methods.
  </p>
  </div>
  </dd>
  <dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17652" title="Abstract">arXiv:2404.17652</a> (cross-list from physics.ao-ph) [<a href="/pdf/2404.17652" title="Download PDF">pdf</a>, <a href="/format/2404.17652" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Validating Deep-Learning Weather Forecast Models on Recent High-Impact  Extreme Events
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Pasche%2C+O+C">Olivier C. Pasche</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Wider%2C+J">Jonathan Wider</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Zhang%2C+Z">Zhongwei Zhang</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Zscheischler%2C+J">Jakob Zscheischler</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Engelke%2C+S">Sebastian Engelke</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 37 pages, 20 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">The forecast accuracy of deep-learning-based weather prediction models is
  improving rapidly, leading many to speak of a "second revolution in weather
  forecasting". With numerous methods being developed, and limited physical
  guarantees offered by deep-learning models, there is a critical need for
  comprehensive evaluation of these emerging techniques. While this need has been
  partly fulfilled by benchmark datasets, they provide little information on rare
  and impactful extreme events, or on compound impact metrics, for which model
  accuracy might degrade due to misrepresented dependencies between variables. To
  address these issues, we compare deep-learning weather prediction models
  (GraphCast, PanguWeather, FourCastNet) and ECMWF's high-resolution forecast
  (HRES) system in three case studies: the 2021 Pacific Northwest heatwave, the
  2023 South Asian humid heatwave, and the North American winter storm in 2021.
  We find evidence that machine learning (ML) weather prediction models can
  locally achieve similar accuracy to HRES on record-shattering events such as
  the 2021 Pacific Northwest heatwave and even forecast the compound 2021 North
  American winter storm substantially better. However, extrapolating to extreme
  conditions may impact machine learning models more severely than HRES, as
  evidenced by the comparable or superior spatially- and temporally-aggregated
  forecast accuracy of HRES for the two heatwaves studied. The ML forecasts also
  lack variables required to assess the health risks of events such as the 2023
  South Asian humid heatwave. Generally, case-study-driven, impact-centric
  evaluation can complement existing research, increase public trust, and aid in
  developing reliable ML weather prediction models.
  </p>
  </div>
  </dd>
  <dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17667" title="Abstract">arXiv:2404.17667</a> (cross-list from eess.SP) [<a href="/pdf/2404.17667" title="Download PDF">pdf</a>, <a href="/format/2404.17667" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SiamQuality: A ConvNet-Based Foundation Model for Imperfect  Physiological Signals
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Ding%2C+C">Cheng Ding</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Guo%2C+Z">Zhicheng Guo</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Chen%2C+Z">Zhaoliang Chen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Lee%2C+R+J">Randall J Lee</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Rudin%2C+C">Cynthia Rudin</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Hu%2C+X">Xiao Hu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Foundation models, especially those using transformers as backbones, have
  gained significant popularity, particularly in language and language-vision
  tasks. However, large foundation models are typically trained on high-quality
  data, which poses a significant challenge, given the prevalence of poor-quality
  real-world data. This challenge is more pronounced for developing foundation
  models for physiological data; such data are often noisy, incomplete, or
  inconsistent. The present work aims to provide a toolset for developing
  foundation models on physiological data. We leverage a large dataset of
  photoplethysmography (PPG) signals from hospitalized intensive care patients.
  For this data, we propose SimQuality, a novel self-supervised learning task
  based on convolutional neural networks (CNNs) as the backbone to enforce
  representations to be similar for good and poor quality signals that are from
  similar physiological states. We pre-trained the SimQuality on over 36 million
  30-second PPG pairs and then fine-tuned and tested on six downstream tasks
  using external datasets. The results demonstrate the superiority of the
  proposed approach on all the downstream tasks, which are extremely important
  for heart monitoring on wearable devices. Our method indicates that CNNs can be
  an effective backbone for foundation models that are robust to training data
  quality.
  </p>
  </div>
  </dd>
  <dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17670" title="Abstract">arXiv:2404.17670</a> (cross-list from eess.IV) [<a href="/pdf/2404.17670" title="Download PDF">pdf</a>, <a href="/format/2404.17670" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Federated Learning for Blind Image Super-Resolution
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Moser%2C+B+B">Brian B. Moser</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Anwar%2C+A">Ahmed Anwar</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Raue%2C+F">Federico Raue</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Frolov%2C+S">Stanislav Frolov</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Dengel%2C+A">Andreas Dengel</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Emerging Technologies (cs.ET); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Traditional blind image SR methods need to model real-world degradations
  precisely. Consequently, current research struggles with this dilemma by
  assuming idealized degradations, which leads to limited applicability to actual
  user data. Moreover, the ideal scenario - training models on data from the
  targeted user base - presents significant privacy concerns. To address both
  challenges, we propose to fuse image SR with federated learning, allowing
  real-world degradations to be directly learned from users without invading
  their privacy. Furthermore, it enables optimization across many devices without
  data centralization. As this fusion is underexplored, we introduce new
  benchmarks specifically designed to evaluate new SR methods in this federated
  setting. By doing so, we employ known degradation modeling techniques from SR
  research. However, rather than aiming to mirror real degradations, our
  benchmarks use these degradation models to simulate the variety of degradations
  found across clients within a distributed user base. This distinction is
  crucial as it circumvents the need to precisely model real-world degradations,
  which limits contemporary blind image SR research. Our proposed benchmarks
  investigate blind image SR under new aspects, namely differently distributed
  degradation types among users and varying user numbers. We believe new methods
  tested within these benchmarks will perform more similarly in an application,
  as the simulated scenario addresses the variety while federated learning
  enables the training on actual degradations.
  </p>
  </div>
  </dd>
  <dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17683" title="Abstract">arXiv:2404.17683</a> (cross-list from math.OC) [<a href="/pdf/2404.17683" title="Download PDF">pdf</a>, <a href="/format/2404.17683" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Energy Storage Arbitrage in Two-settlement Markets: A Transformer-Based  Approach
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Alghumayjan%2C+S">Saud Alghumayjan</a>, 
  <a href="/search/math?searchtype=author&amp;query=Han%2C+J">Jiajun Han</a>, 
  <a href="/search/math?searchtype=author&amp;query=Zheng%2C+N">Ningkun Zheng</a>, 
  <a href="/search/math?searchtype=author&amp;query=Yi%2C+M">Ming Yi</a>, 
  <a href="/search/math?searchtype=author&amp;query=Xu%2C+B">Bolun Xu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Systems and Control (eess.SY)
  
  </div>
  <p class="mathjax">This paper presents an integrated model for bidding energy storage in
  day-ahead and real-time markets to maximize profits. We show that in integrated
  two-stage bidding, the real-time bids are independent of day-ahead settlements,
  while the day-ahead bids should be based on predicted real-time prices. We
  utilize a transformer-based model for real-time price prediction, which
  captures complex dynamical patterns of real-time prices, and use the result for
  day-ahead bidding design. For real-time bidding, we utilize a long short-term
  memory-dynamic programming hybrid real-time bidding model. We train and test
  our model with historical data from New York State, and our results showed that
  the integrated system achieved promising results of almost a 20\% increase in
  profit compared to only bidding in real-time markets, and at the same time
  reducing the risk in terms of the number of days with negative profits.
  </p>
  </div>
  </dd>
  <dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17704" title="Abstract">arXiv:2404.17704</a> (cross-list from eess.IV) [<a href="/pdf/2404.17704" title="Download PDF">pdf</a>, <a href="/format/2404.17704" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SPLICE -- Streamlining Digital Pathology Image Processing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Alsaafin%2C+A">Areej Alsaafin</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Nejat%2C+P">Peyman Nejat</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Shafique%2C+A">Abubakr Shafique</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Khan%2C+J">Jibran Khan</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Alfasly%2C+S">Saghir Alfasly</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Alabtah%2C+G">Ghazal Alabtah</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Tizhoosh%2C+H+R">H.R.Tizhoosh</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Under review for publication
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Digital pathology and the integration of artificial intelligence (AI) models
  have revolutionized histopathology, opening new opportunities. With the
  increasing availability of Whole Slide Images (WSIs), there's a growing demand
  for efficient retrieval, processing, and analysis of relevant images from vast
  biomedical archives. However, processing WSIs presents challenges due to their
  large size and content complexity. Full computer digestion of WSIs is
  impractical, and processing all patches individually is prohibitively
  expensive. In this paper, we propose an unsupervised patching algorithm,
  Sequential Patching Lattice for Image Classification and Enquiry (SPLICE). This
  novel approach condenses a histopathology WSI into a compact set of
  representative patches, forming a "collage" of WSI while minimizing redundancy.
  SPLICE prioritizes patch quality and uniqueness by sequentially analyzing a WSI
  and selecting non-redundant representative features. We evaluated SPLICE for
  search and match applications, demonstrating improved accuracy, reduced
  computation time, and storage requirements compared to existing
  state-of-the-art methods. As an unsupervised method, SPLICE effectively reduces
  storage requirements for representing tissue images by 50%. This reduction
  enables numerous algorithms in computational pathology to operate much more
  efficiently, paving the way for accelerated adoption of digital pathology.
  </p>
  </div>
  </dd>
  <dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17709" title="Abstract">arXiv:2404.17709</a> (cross-list from stat.ML) [<a href="/pdf/2404.17709" title="Download PDF">pdf</a>, <a href="/format/2404.17709" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Low-rank Matrix Bandits with Heavy-tailed Rewards
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Kang%2C+Y">Yue Kang</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Hsieh%2C+C">Cho-Jui Hsieh</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Lee%2C+T+C+M">Thomas C. M. Lee</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The 40th Conference on Uncertainty in Artificial Intelligence (UAI 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">In stochastic low-rank matrix bandit, the expected reward of an arm is equal
  to the inner product between its feature matrix and some unknown <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-309-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1940" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1941"><span class="msubsup" id="MathJax-Span-1942"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1943" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="mn" id="MathJax-Span-1944" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-309">d_1</script> by <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-310-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1945" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1946"><span class="msubsup" id="MathJax-Span-1947"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1948" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="mn" id="MathJax-Span-1949" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-310">d_2</script>
  low-rank parameter matrix <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-311-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1950" style="width: 1.527em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1001.245em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-1951"><span class="msubsup" id="MathJax-Span-1952"><span style="display: inline-block; position: relative; width: 1.188em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1953" style="font-family: STIXGeneral-Regular;">Θ</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.737em;"><span class="mo" id="MathJax-Span-1954" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∗</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.045em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-311">\Theta^*</script> with rank <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-312-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1955" style="width: 6.044em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.915em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1004.915em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1956"><span class="mi" id="MathJax-Span-1957" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1958" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≪</span><span class="msubsup" id="MathJax-Span-1959" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1960" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="mn" id="MathJax-Span-1961" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-1962" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">∧</span><span class="msubsup" id="MathJax-Span-1963" style="padding-left: 0.229em;"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1964" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="mn" id="MathJax-Span-1965" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-312">r \ll d_1\wedge d_2</script>. While all
  prior studies assume the payoffs are mixed with sub-Gaussian noises, in this
  work we loosen this strict assumption and consider the new problem of
  \underline{low}-rank matrix bandit with \underline{h}eavy-\underline{t}ailed
  \underline{r}ewards (LowHTR), where the rewards only have finite <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-313-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1966" style="width: 3.503em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.826em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.769em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1967"><span class="mo" id="MathJax-Span-1968" style="font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-1969" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1970" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">+</span><span class="mi" id="MathJax-Span-1971" style="font-family: STIXGeneral-Italic; padding-left: 0.229em;">δ</span><span class="mo" id="MathJax-Span-1972" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-313">(1+\delta)</script>
  moment for some <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-314-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1973" style="width: 4.858em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.955em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.842em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1974"><span class="mi" id="MathJax-Span-1975" style="font-family: STIXGeneral-Italic;">δ</span><span class="mo" id="MathJax-Span-1976" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="mo" id="MathJax-Span-1977" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">(</span><span class="mn" id="MathJax-Span-1978" style="font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-1979" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-1980" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">1</span><span class="mo" id="MathJax-Span-1981" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-314">\delta \in (0,1]</script>. By utilizing the truncation on observed
  payoffs and the dynamic exploration, we propose a novel algorithm called LOTUS
  attaining the regret bound of order <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-315-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1982" style="width: 9.093em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.399em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.245em, 1007.342em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-1983"><span class="texatom" id="MathJax-Span-1984"><span class="mrow" id="MathJax-Span-1985"><span class="munderover" id="MathJax-Span-1986"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1987" style="font-family: STIXGeneral-Italic;">O</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.288em; left: 0.172em;"><span style="height: 0em; vertical-align: 0em; width: 0.398em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-1988" style="font-family: STIXGeneral-Regular;"><span style="margin-left: -0.392em;">̃</span><span style="height: 0em; vertical-align: 0em; margin-left: -0.054em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-1989" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1990"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1991" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.567em;"><span class="mfrac" id="MathJax-Span-1992"><span style="display: inline-block; position: relative; width: 0.398em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.229em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.11em;"><span class="mn" id="MathJax-Span-1993" style="font-size: 50%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1000.229em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.11em;"><span class="mn" id="MathJax-Span-1994" style="font-size: 50%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.398em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.398em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-1995"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-1996" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.454em;"><span class="mfrac" id="MathJax-Span-1997"><span style="display: inline-block; position: relative; width: 0.398em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.172em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.11em;"><span class="mn" id="MathJax-Span-1998" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1000.229em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.11em;"><span class="mn" id="MathJax-Span-1999" style="font-size: 50%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.398em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.398em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-2000"><span style="display: inline-block; position: relative; width: 1.979em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.624em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2001" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.737em;"><span class="mfrac" id="MathJax-Span-2002"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.172em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.11em;"><span class="mn" id="MathJax-Span-2003" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1000.85em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.392em;"><span class="mrow" id="MathJax-Span-2004"><span class="mn" id="MathJax-Span-2005" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2006" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-2007" style="font-size: 50%; font-family: STIXGeneral-Italic;">δ</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.963em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.963em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="texatom" id="MathJax-Span-2008"><span class="mrow" id="MathJax-Span-2009"><span class="mo" id="MathJax-Span-2010" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="msubsup" id="MathJax-Span-2011"><span style="display: inline-block; position: relative; width: 1.358em; height: 0px;"><span style="position: absolute; clip: rect(2.939em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-2012"><span class="mrow" id="MathJax-Span-2013"><span class="munderover" id="MathJax-Span-2014"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2015" style="font-family: STIXGeneral-Italic;">D</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.288em; left: 0.172em;"><span style="height: 0em; vertical-align: 0em; width: 0.398em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-2016" style="font-family: STIXGeneral-Regular;"><span style="margin-left: -0.392em;">̃</span><span style="height: 0em; vertical-align: 0em; margin-left: -0.054em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.737em;"><span class="texatom" id="MathJax-Span-2017"><span class="mrow" id="MathJax-Span-2018"><span class="mi" id="MathJax-Span-2019" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-2020" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2021" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.74em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-315">\tilde
  O(d^\frac{3}{2}r^\frac{1}{2}T^\frac{1}{1+\delta}/\tilde{D}_{rr})</script> without
  knowing <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-316-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2022" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2023"><span class="mi" id="MathJax-Span-2024" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-316">T</script>, which matches the state-of-the-art regret bound under sub-Gaussian
  noises~\citep{lu2021low,kang2022efficient} with <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-317-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2025" style="width: 2.939em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.374em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.261em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2026"><span class="mi" id="MathJax-Span-2027" style="font-family: STIXGeneral-Italic;">δ</span><span class="mo" id="MathJax-Span-2028" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mn" id="MathJax-Span-2029" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-317">\delta = 1</script>. Moreover, we
  establish a lower bound of the order <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-318-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2030" style="width: 14.513em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.803em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.245em, 1011.746em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2031"><span class="mi" id="MathJax-Span-2032" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-2033" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-2034"><span style="display: inline-block; position: relative; width: 1.866em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2035" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.567em;"><span class="mfrac" id="MathJax-Span-2036"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.229em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.11em;"><span class="mi" id="MathJax-Span-2037" style="font-size: 50%; font-family: STIXGeneral-Italic;">δ</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1000.85em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.392em;"><span class="mrow" id="MathJax-Span-2038"><span class="mn" id="MathJax-Span-2039" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2040" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-2041" style="font-size: 50%; font-family: STIXGeneral-Italic;">δ</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.963em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.963em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-2042"><span style="display: inline-block; position: relative; width: 1.753em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2043" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.454em;"><span class="mfrac" id="MathJax-Span-2044"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.229em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.11em;"><span class="mi" id="MathJax-Span-2045" style="font-size: 50%; font-family: STIXGeneral-Italic;">δ</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1000.85em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.392em;"><span class="mrow" id="MathJax-Span-2046"><span class="mn" id="MathJax-Span-2047" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2048" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-2049" style="font-size: 50%; font-family: STIXGeneral-Italic;">δ</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.963em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.963em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-2050"><span style="display: inline-block; position: relative; width: 1.979em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.624em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2051" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.737em;"><span class="mfrac" id="MathJax-Span-2052"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.172em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.11em;"><span class="mn" id="MathJax-Span-2053" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1000.85em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.392em;"><span class="mrow" id="MathJax-Span-2054"><span class="mn" id="MathJax-Span-2055" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2056" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-2057" style="font-size: 50%; font-family: STIXGeneral-Italic;">δ</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.963em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.963em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2058" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-2059" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="mi" id="MathJax-Span-2060" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">Ω</span><span class="mo" id="MathJax-Span-2061" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-2062"><span style="display: inline-block; position: relative; width: 1.979em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.624em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2063" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.737em;"><span class="mfrac" id="MathJax-Span-2064"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.172em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.11em;"><span class="mn" id="MathJax-Span-2065" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1000.85em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.392em;"><span class="mrow" id="MathJax-Span-2066"><span class="mn" id="MathJax-Span-2067" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2068" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-2069" style="font-size: 50%; font-family: STIXGeneral-Italic;">δ</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.963em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.963em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2070" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.74em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-318">\Omega(d^\frac{\delta}{1+\delta}
  r^\frac{\delta}{1+\delta} T^\frac{1}{1+\delta}) = \Omega(T^\frac{1}{1+\delta})</script>
  for LowHTR, which indicates our LOTUS is nearly optimal in the order of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-319-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2071" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2072"><span class="mi" id="MathJax-Span-2073" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-319">T</script>. In
  addition, we improve LOTUS so that it does not require knowledge of the rank
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-320-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2074" style="width: 0.511em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.398em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.398em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2075"><span class="mi" id="MathJax-Span-2076" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-320">r</script> with <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-321-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2077" style="width: 6.496em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.254em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.245em, 1005.197em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2078"><span class="texatom" id="MathJax-Span-2079"><span class="mrow" id="MathJax-Span-2080"><span class="munderover" id="MathJax-Span-2081"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2082" style="font-family: STIXGeneral-Italic;">O</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.288em; left: 0.172em;"><span style="height: 0em; vertical-align: 0em; width: 0.398em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-2083" style="font-family: STIXGeneral-Regular;"><span style="margin-left: -0.392em;">̃</span><span style="height: 0em; vertical-align: 0em; margin-left: -0.054em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-2084" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-2085" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="msubsup" id="MathJax-Span-2086"><span style="display: inline-block; position: relative; width: 1.132em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2087" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.454em;"><span class="mfrac" id="MathJax-Span-2088"><span style="display: inline-block; position: relative; width: 0.398em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.229em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.11em;"><span class="mn" id="MathJax-Span-2089" style="font-size: 50%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1000.229em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.11em;"><span class="mn" id="MathJax-Span-2090" style="font-size: 50%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.398em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.398em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-2091"><span style="display: inline-block; position: relative; width: 2.205em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.624em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2092" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.737em;"><span class="mfrac" id="MathJax-Span-2093"><span style="display: inline-block; position: relative; width: 1.188em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.85em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.392em;"><span class="mrow" id="MathJax-Span-2094"><span class="mn" id="MathJax-Span-2095" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2096" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-2097" style="font-size: 50%; font-family: STIXGeneral-Italic;">δ</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1001.076em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.505em;"><span class="mrow" id="MathJax-Span-2098"><span class="mn" id="MathJax-Span-2099" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2100" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-2101" style="font-size: 50%; font-family: STIXGeneral-Regular;">2</span><span class="mi" id="MathJax-Span-2102" style="font-size: 50%; font-family: STIXGeneral-Italic;">δ</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1001.188em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 1.188em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2103" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.809em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-321">\tilde O(dr^\frac{3}{2}T^\frac{1+\delta}{1+2\delta})</script> regret bound,
  and it is efficient under the high-dimensional scenario. We also conduct
  simulations to demonstrate the practical superiority of our algorithm.
  </p>
  </div>
  </dd>
  <dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17736" title="Abstract">arXiv:2404.17736</a> (cross-list from eess.SP) [<a href="/pdf/2404.17736" title="Download PDF">pdf</a>, <a href="/format/2404.17736" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Diffusion-Aided Joint Source Channel Coding For High Realism Wireless  Image Transmission
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Yang%2C+M">Mingyu Yang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Liu%2C+B">Bowen Liu</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wang%2C+B">Boyang Wang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Kim%2C+H">Hun-Seok Kim</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Deep learning-based joint source-channel coding (deep JSCC) has been
  demonstrated as an effective approach for wireless image transmission.
  Nevertheless, current research has concentrated on minimizing a standard
  distortion metric such as Mean Squared Error (MSE), which does not necessarily
  improve the perceptual quality. To address this issue, we propose DiffJSCC, a
  novel framework that leverages pre-trained text-to-image diffusion models to
  enhance the realism of images transmitted over the channel. The proposed
  DiffJSCC utilizes prior deep JSCC frameworks to deliver an initial
  reconstructed image at the receiver. Then, the spatial and textual features are
  extracted from the initial reconstruction, which, together with the channel
  state information (e.g., signal-to-noise ratio, SNR), are passed to a control
  module to fine-tune the pre-trained Stable Diffusion model. Extensive
  experiments on the Kodak dataset reveal that our method significantly surpasses
  both conventional methods and prior deep JSCC approaches on perceptual metrics
  such as LPIPS and FID scores, especially with poor channel conditions and
  limited bandwidth. Notably, DiffJSCC can achieve highly realistic
  reconstructions for 768x512 pixel Kodak images with only 3072 symbols (&lt;0.008
  symbols per pixel) under 1dB SNR. Our code will be released in
  https://github.com/mingyuyng/DiffJSCC.
  </p>
  </div>
  </dd>
  <dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17742" title="Abstract">arXiv:2404.17742</a> (cross-list from eess.IV) [<a href="/pdf/2404.17742" title="Download PDF">pdf</a>, <a href="/format/2404.17742" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Segmentation Quality and Volumetric Accuracy in Medical Imaging
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+Z">Zheyuan Zhang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Bagci%2C+U">Ulas Bagci</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Current medical image segmentation relies on the region-based (Dice,
  F1-score) and boundary-based (Hausdorff distance, surface distance) metrics as
  the de-facto standard. While these metrics are widely used, they lack a unified
  interpretation, particularly regarding volume agreement. Clinicians often lack
  clear benchmarks to gauge the "goodness" of segmentation results based on these
  metrics. Recognizing the clinical relevance of volumetry, we utilize relative
  volume prediction error (vpe) to directly assess the accuracy of volume
  predictions derived from segmentation tasks. Our work integrates theoretical
  analysis and empirical validation across diverse datasets. We delve into the
  often-ambiguous relationship between segmentation quality (measured by Dice)
  and volumetric accuracy in clinical practice. Our findings highlight the
  critical role of incorporating volumetric prediction accuracy into segmentation
  evaluation. This approach empowers clinicians with a more nuanced understanding
  of segmentation performance, ultimately improving the interpretation and
  utility of these metrics in real-world healthcare settings.
  </p>
  </div>
  </dd>
  <dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17752" title="Abstract">arXiv:2404.17752</a> (cross-list from physics.ao-ph) [<a href="/pdf/2404.17752" title="Download PDF">pdf</a>, <a href="/format/2404.17752" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generative Diffusion-based Downscaling for Climate
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Watt%2C+R+A">Robbie A. Watt</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Mansfield%2C+L+A">Laura A. Mansfield</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Downscaling, or super-resolution, provides decision-makers with detailed,
  high-resolution information about the potential risks and impacts of climate
  change, based on climate model output. Machine learning algorithms are proving
  themselves to be efficient and accurate approaches to downscaling. Here, we
  show how a generative, diffusion-based approach to downscaling gives accurate
  downscaled results. We focus on an idealised setting where we recover ERA5 at
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-322-Frame" tabindex="0" style=""><span class="math" id="MathJax-Span-2104"><span class="noError" id="MathJax-Span-2105">$0.25\degree$</span></span></span><script type="math/tex" id="MathJax-Element-322">0.25\degree</script>~resolution from coarse grained version at <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-323-Frame" tabindex="0" style=""><span class="math" id="MathJax-Span-2106"><span class="noError" id="MathJax-Span-2107">$2\degree$</span></span></span><script type="math/tex" id="MathJax-Element-323">2\degree</script>~resolution.
  The diffusion-based method provides superior accuracy compared to a standard
  U-Net, particularly at the fine scales, as highlighted by a spectral
  decomposition. Additionally, the generative approach provides users with a
  probability distribution which can be used for risk assessment. This research
  highlights the potential of diffusion-based downscaling techniques in providing
  reliable and detailed climate predictions.
  </p>
  </div>
  </dd>
  <dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17856" title="Abstract">arXiv:2404.17856</a> (cross-list from stat.ML) [<a href="/pdf/2404.17856" title="Download PDF">pdf</a>, <a href="/format/2404.17856" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Uncertainty quantification for iterative algorithms in linear models  with application to early stopping
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Bellec%2C+P+C">Pierre C. Bellec</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Tan%2C+K">Kai Tan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Computation (stat.CO); Methodology (stat.ME)
  
  </div>
  <p class="mathjax">This paper investigates the iterates <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-324-Frame" tabindex="0" style=""><span class="math" id="MathJax-Span-2108"><span class="noError" id="MathJax-Span-2109">$\hbb^1,\dots,\hbb^T$</span></span></span><script type="math/tex" id="MathJax-Element-324">\hbb^1,\dots,\hbb^T</script> obtained from
  iterative algorithms in high-dimensional linear regression problems, in the
  regime where the feature dimension <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-325-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2110" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2111"><span class="mi" id="MathJax-Span-2112" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.906em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-325">p</script> is comparable with the sample size <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-326-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2113" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2114"><span class="mi" id="MathJax-Span-2115" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-326">n</script>,
  i.e., <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-327-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2116" style="width: 2.995em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.431em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.866em, 1002.431em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2117"><span class="mi" id="MathJax-Span-2118" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-2119" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">≍</span><span class="mi" id="MathJax-Span-2120" style="font-family: STIXGeneral-Italic; padding-left: 0.342em;">n</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-327">p \asymp n</script>. The analysis and proposed estimators are applicable to
  Gradient Descent (GD), proximal GD and their accelerated variants such as Fast
  Iterative Soft-Thresholding (FISTA). The paper proposes novel estimators for
  the generalization error of the iterate <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-328-Frame" tabindex="0" style=""><span class="math" id="MathJax-Span-2121"><span class="noError" id="MathJax-Span-2122">$\hbb^t$</span></span></span><script type="math/tex" id="MathJax-Element-328">\hbb^t</script> for any fixed iteration <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-329-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2123" style="width: 0.342em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.285em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.81em, 1000.285em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2124"><span class="mi" id="MathJax-Span-2125" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.837em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-329">t</script>
  along the trajectory. These estimators are proved to be <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-330-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2126" style="width: 1.64em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.301em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.116em, 1001.301em, 1.414em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2127"><span class="msqrt" id="MathJax-Span-2128"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0.737em;"><span class="mrow" id="MathJax-Span-2129"><span class="mi" id="MathJax-Span-2130" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(2.995em, 1000.511em, 3.39em, -999.997em); top: -3.893em; left: 0.737em;"><span style="font-family: STIXGeneral-Regular;">‾</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(2.882em, 1000.793em, 4.181em, -999.997em); top: -3.78em; left: 0em;"><span style="font-family: STIXVariants;">√</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.323em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-330">\sqrt n</script>-consistent
  under Gaussian designs. Applications to early-stopping are provided: when the
  generalization error of the iterates is a U-shape function of the iteration
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-331-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2131" style="width: 0.342em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.285em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.81em, 1000.285em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2132"><span class="mi" id="MathJax-Span-2133" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.837em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-331">t</script>, the estimates allow to select from the data an iteration <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-332-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2134" style="width: 0.511em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.398em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1000.342em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2135"><span class="texatom" id="MathJax-Span-2136"><span class="mrow" id="MathJax-Span-2137"><span class="munderover" id="MathJax-Span-2138"><span style="display: inline-block; position: relative; width: 0.342em; height: 0px;"><span style="position: absolute; clip: rect(3.277em, 1000.285em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2139" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.175em; left: 0.059em;"><span style="height: 0em; vertical-align: 0em; width: 0.398em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-2140" style="font-family: STIXGeneral-Regular;"><span style="margin-left: -0.392em;">̂</span><span style="height: 0em; vertical-align: 0em; width: 0em; display: inline-block; overflow: hidden;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-332">\hat t</script> that
  achieves the smallest generalization error along the trajectory. Additionally,
  we provide a technique for developing debiasing corrections and valid
  confidence intervals for the components of the true coefficient vector from the
  iterate <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-333-Frame" tabindex="0" style=""><span class="math" id="MathJax-Span-2141"><span class="noError" id="MathJax-Span-2142">$\hbb^t$</span></span></span><script type="math/tex" id="MathJax-Element-333">\hbb^t</script> at any finite iteration <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-334-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2143" style="width: 0.342em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.285em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.81em, 1000.285em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2144"><span class="mi" id="MathJax-Span-2145" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.837em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-334">t</script>. Extensive simulations on
  synthetic data illustrate the theoretical results.
  </p>
  </div>
  </dd>
  <dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17878" title="Abstract">arXiv:2404.17878</a> (cross-list from eess.IV) [<a href="/pdf/2404.17878" title="Download PDF">pdf</a>, <a href="/ps/2404.17878" title="Download PostScript">ps</a>, <a href="/format/2404.17878" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Processing HSV Colored Medical Images and Adapting Color Thresholds for  Computational Image Analysis: a Practical Introduction to an open-source tool
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Cai%2C+L">Lie Cai</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Pfob%2C+A">Andre Pfob</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> An open-source tool that can adapt different color thresholds of HSV-colored medical images. The newly developed pre-processing Matlab function successfully works on multi-center, international shear wave elastography data (NCT 02638935). Step-by-step instructions with accompanying code lines were provided, easy to follow and reproduce
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)
  
  </div>
  <p class="mathjax">Background: Using artificial intelligence (AI) techniques for computational
  medical image analysis has shown promising results. However, colored images are
  often not readily available for AI analysis because of different coloring
  thresholds used across centers and physicians as well as the removal of
  clinical annotations. We aimed to develop an open-source tool that can adapt
  different color thresholds of HSV-colored medical images and remove annotations
  with a simple click.
  <br>Materials and Methods: We built a function using MATLAB and used multi-center
  international shear wave elastography data (NCT 02638935) to test the function.
  We provide step-by-step instructions with accompanying code lines.
  <br>Results: We demonstrate that the newly developed pre-processing function
  successfully removed letters and adapted different color thresholds of
  HSV-colored medical images.
  <br>Conclusion: We developed an open-source tool for removing letters and
  adapting different color thresholds in HSV-colored medical images. We hope this
  contributes to advancing medical image processing for developing robust
  computational imaging algorithms using diverse multi-center big data. The
  open-source Matlab tool is available at
  https://github.com/cailiemed/image-threshold-adapting.
  </p>
  </div>
  </dd>
  <dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17884" title="Abstract">arXiv:2404.17884</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2404.17884" title="Download PDF">pdf</a>, <a href="/format/2404.17884" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring the efficacy of a hybrid approach with modal decomposition  over fully deep learning models for flow dynamics forecasting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Abad%C3%ADa-Heredia%2C+R">Rodrigo Abadía-Heredia</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Corrochano%2C+A">Adrián Corrochano</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Lopez-Martin%2C+M">Manuel Lopez-Martin</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Clainche%2C+S+L">Soledad Le Clainche</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 37 pages, 17 figures and 9 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Fluid dynamics problems are characterized by being multidimensional and
  nonlinear, causing the experiments and numerical simulations being complex,
  time-consuming and monetarily expensive. In this sense, there is a need to find
  new ways to obtain data in a more economical manner. Thus, in this work we
  study the application of time series forecasting to fluid dynamics problems,
  where the aim is to predict the flow dynamics using only past information. We
  focus our study on models based on deep learning that do not require a high
  amount of data for training, as this is the problem we are trying to address.
  Specifically in this work we have tested three autoregressive models where two
  of them are fully based on deep learning and the other one is a hybrid model
  that combines modal decomposition with deep learning. We ask these models to
  generate <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-335-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2146" style="width: 1.922em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.527em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1001.527em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2147"><span class="mn" id="MathJax-Span-2148" style="font-family: STIXGeneral-Regular;">200</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-335">200</script> time-ahead predictions of two datasets coming from a numerical
  simulation and experimental measurements, where the latter is characterized by
  being turbulent. We show how the hybrid model generates more reliable
  predictions in the experimental case, as it is physics-informed in the sense
  that the modal decomposition extracts the physics in a way that allows us to
  predict it.
  </p>
  </div>
  </dd>
  <dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17890" title="Abstract">arXiv:2404.17890</a> (cross-list from eess.IV) [<a href="/pdf/2404.17890" title="Download PDF">pdf</a>, <a href="/format/2404.17890" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DPER: Diffusion Prior Driven Neural Representation for Limited Angle and  Sparse View CT Reconstruction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Du%2C+C">Chenhe Du</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Lin%2C+X">Xiyue Lin</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wu%2C+Q">Qing Wu</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Tian%2C+X">Xuanyu Tian</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Su%2C+Y">Ying Su</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Luo%2C+Z">Zhe Luo</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wei%2C+H">Hongjiang Wei</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zhou%2C+S+K">S. Kevin Zhou</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Yu%2C+J">Jingyi Yu</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+Y">Yuyao Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages, 10 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Limited-angle and sparse-view computed tomography (LACT and SVCT) are crucial
  for expanding the scope of X-ray CT applications. However, they face challenges
  due to incomplete data acquisition, resulting in diverse artifacts in the
  reconstructed CT images. Emerging implicit neural representation (INR)
  techniques, such as NeRF, NeAT, and NeRP, have shown promise in
  under-determined CT imaging reconstruction tasks. However, the unsupervised
  nature of INR architecture imposes limited constraints on the solution space,
  particularly for the highly ill-posed reconstruction task posed by LACT and
  ultra-SVCT. In this study, we introduce the Diffusion Prior Driven Neural
  Representation (DPER), an advanced unsupervised framework designed to address
  the exceptionally ill-posed CT reconstruction inverse problems. DPER adopts the
  Half Quadratic Splitting (HQS) algorithm to decompose the inverse problem into
  data fidelity and distribution prior sub-problems. The two sub-problems are
  respectively addressed by INR reconstruction scheme and pre-trained score-based
  diffusion model. This combination initially preserves the implicit image local
  consistency prior from INR. Additionally, it effectively augments the
  feasibility of the solution space for the inverse problem through the
  generative diffusion model, resulting in increased stability and precision in
  the solutions. We conduct comprehensive experiments to evaluate the performance
  of DPER on LACT and ultra-SVCT reconstruction with two public datasets (AAPM
  and LIDC). The results show that our method outperforms the state-of-the-art
  reconstruction methods on in-domain datasets, while achieving significant
  performance improvements on out-of-domain datasets.
  </p>
  </div>
  </dd>
  <dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17926" title="Abstract">arXiv:2404.17926</a> (cross-list from eess.IV) [<a href="/pdf/2404.17926" title="Download PDF">pdf</a>, <a href="/format/2404.17926" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Pre-training on High Definition X-ray Images: An Experimental Study
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Li%2C+Y">Yuehang Li</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wu%2C+W">Wentao Wu</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Jin%2C+J">Jiandong Jin</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Rong%2C+Y">Yao Rong</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Jiang%2C+B">Bo Jiang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Li%2C+C">Chuanfu Li</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Tang%2C+J">Jin Tang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Technology Report
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Existing X-ray based pre-trained vision models are usually conducted on a
  relatively small-scale dataset (less than 500k samples) with limited resolution
  (e.g., 224 <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-336-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2149" style="width: 0.85em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.866em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2150"><span class="mo" id="MathJax-Span-2151" style="font-family: STIXGeneral-Regular;">×</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.837em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-336">\times</script> 224). However, the key to the success of self-supervised
  pre-training large models lies in massive training data, and maintaining high
  resolution in the field of X-ray images is the guarantee of effective solutions
  to difficult miscellaneous diseases. In this paper, we address these issues by
  proposing the first high-definition (1280 <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-337-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2152" style="width: 0.85em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.866em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2153"><span class="mo" id="MathJax-Span-2154" style="font-family: STIXGeneral-Regular;">×</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.837em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-337">\times</script> 1280) X-ray based
  pre-trained foundation vision model on our newly collected large-scale dataset
  which contains more than 1 million X-ray images. Our model follows the masked
  auto-encoder framework which takes the tokens after mask processing (with a
  high rate) is used as input, and the masked image patches are reconstructed by
  the Transformer encoder-decoder network. More importantly, we introduce a novel
  context-aware masking strategy that utilizes the chest contour as a boundary
  for adaptive masking operations. We validate the effectiveness of our model on
  two downstream tasks, including X-ray report generation and disease
  recognition. Extensive experiments demonstrate that our pre-trained medical
  foundation vision model achieves comparable or even new state-of-the-art
  performance on downstream benchmark datasets. The source code and pre-trained
  models of this paper will be released on
  https://github.com/Event-AHU/Medical_Image_Analysis.
  </p>
  </div>
  </dd>
  <dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17933" title="Abstract">arXiv:2404.17933</a> (cross-list from math.CO) [<a href="/pdf/2404.17933" title="Download PDF">pdf</a>, <a href="/ps/2404.17933" title="Download PostScript">ps</a>, <a href="/format/2404.17933" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Stability for binary scalar products
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Kupavskii%2C+A">Andrey Kupavskii</a>, 
  <a href="/search/math?searchtype=author&amp;query=Tsarev%2C+D">Dmitry Tsarev</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
  
  </div>
  <p class="mathjax">Bohn, Faenza, Fiorini, Fisikopoulos, Macchia, and Pashkovich (2015)
  conjectured that 2-level polytopes cannot simultaneously have many vertices and
  many facets, namely, that the maximum of the product of the number of vertices
  and facets is attained on the cube and cross-polytope. This was proved in a
  recent work by Kupavskii and Weltge. In this paper, we resolve a strong version
  of the conjecture by Bohn et al., and find the maximum possible product of the
  number of vertices and the number of facets in a 2-level polytope that is not
  affinely isomorphic to the cube or the cross-polytope. To do this, we get a
  sharp stability result of Kupavskii and Weltge's upper bound on <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-338-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2155" style="width: 4.463em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.616em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(2.205em, 1003.503em, 3.39em, -999.997em); top: -3.046em; left: 0em;"><span class="mrow" id="MathJax-Span-2156"><span class="mrow" id="MathJax-Span-2157"><span class="mo" id="MathJax-Span-2158" style="font-family: STIXVariants;">|</span><span class="texatom" id="MathJax-Span-2159"><span class="mrow" id="MathJax-Span-2160"><span class="mi" id="MathJax-Span-2161" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-2162" style="font-family: STIXVariants;">|</span></span><span class="mo" id="MathJax-Span-2163" style="font-family: STIXGeneral-Regular; padding-left: 0.229em;">⋅</span><span class="mrow" id="MathJax-Span-2164" style="padding-left: 0.229em;"><span class="mo" id="MathJax-Span-2165" style="font-family: STIXVariants;">|</span><span class="texatom" id="MathJax-Span-2166"><span class="mrow" id="MathJax-Span-2167"><span class="mi" id="MathJax-Span-2168" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-2169" style="font-family: STIXVariants;">|</span></span></span><span style="display: inline-block; width: 0px; height: 3.052em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-338">\left|\mathcal
  A\right|\cdot\left|\mathcal B\right|</script> for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-339-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2170" style="width: 5.649em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.576em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(2.035em, 1004.576em, 3.334em, -999.997em); top: -3.046em; left: 0em;"><span class="mrow" id="MathJax-Span-2171"><span class="texatom" id="MathJax-Span-2172"><span class="mrow" id="MathJax-Span-2173"><span class="mi" id="MathJax-Span-2174" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-2175" style="font-family: STIXGeneral-Regular;">,</span><span class="texatom" id="MathJax-Span-2176" style="padding-left: 0.172em;"><span class="mrow" id="MathJax-Span-2177"><span class="mi" id="MathJax-Span-2178" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-2179" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">⊆</span><span class="msubsup" id="MathJax-Span-2180" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 1.188em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.737em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-2181"><span class="mrow" id="MathJax-Span-2182"><span class="mi" id="MathJax-Span-2183" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.737em;"><span class="mi" id="MathJax-Span-2184" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.052em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-339">\mathcal A,\mathcal B \subseteq
  \mathbb R^d</script> with a property that <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-340-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2185" style="width: 7.794em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.326em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(2.205em, 1006.326em, 3.334em, -999.997em); top: -3.046em; left: 0em;"><span class="mrow" id="MathJax-Span-2186"><span class="mi" id="MathJax-Span-2187" style="font-family: STIXGeneral-Regular;">∀</span><span class="mi" id="MathJax-Span-2188" style="font-family: STIXGeneral-Italic;">a</span><span class="mo" id="MathJax-Span-2189" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="texatom" id="MathJax-Span-2190" style="padding-left: 0.342em;"><span class="mrow" id="MathJax-Span-2191"><span class="mi" id="MathJax-Span-2192" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-2193" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-2194" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">b</span><span class="mo" id="MathJax-Span-2195" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="texatom" id="MathJax-Span-2196" style="padding-left: 0.342em;"><span class="mrow" id="MathJax-Span-2197"><span class="mi" id="MathJax-Span-2198" style="font-family: STIXNonUnicode-Italic;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.052em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-340">\forall a \in \mathcal A, b \in \mathcal B</script>
  the scalar product <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-341-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2199" style="width: 7.399em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.987em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.64em, 1005.875em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2200"><span class="mo" id="MathJax-Span-2201" style="font-family: STIXGeneral-Regular;">⟨</span><span class="mi" id="MathJax-Span-2202" style="font-family: STIXGeneral-Italic;">a</span><span class="mo" id="MathJax-Span-2203" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-2204" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">b</span><span class="mo" id="MathJax-Span-2205" style="font-family: STIXGeneral-Regular;">⟩</span><span class="mo" id="MathJax-Span-2206" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="mo" id="MathJax-Span-2207" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">{</span><span class="mn" id="MathJax-Span-2208" style="font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-2209" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-2210" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">1</span><span class="mo" id="MathJax-Span-2211" style="font-family: STIXGeneral-Regular;">}</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-341">\langle a, b\rangle \in\{0,1\}</script>.
  </p>
  </div>
  </dd>
  <dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17959" title="Abstract">arXiv:2404.17959</a> (cross-list from quant-ph) [<a href="/pdf/2404.17959" title="Download PDF">pdf</a>, <a href="/ps/2404.17959" title="Download PostScript">ps</a>, <a href="/format/2404.17959" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On Quantum Algorithms for Efficient Solutions of General Classes of  Structured Markov Processes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Kalantzis%2C+V">Vasileios Kalantzis</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Squillante%2C+M+S">Mark S. Squillante</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Ubaru%2C+S">Shashanka Ubaru</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Numerical Analysis (math.NA); Probability (math.PR)
  
  </div>
  <p class="mathjax">We study the fundamental problem of efficiently computing the stationary
  distribution of general classes of structured Markov processes. In strong
  contrast with previous work, we consider this problem within the context of
  quantum computational environments from a mathematical perspective and devise
  the first quantum algorithms for computing the stationary distribution of
  structured Markov processes. We derive a mathematical analysis of the
  computational properties of our quantum algorithms together with related
  theoretical results, establishing that our quantum algorithms provide the
  potential for significant computational improvements over that of the
  best-known classical algorithms in various settings of both theoretical and
  practical importance. Although motivated by structured Markov processes, our
  quantum algorithms have the potential for being exploited to address a much
  larger class of numerical computation problems.
  </p>
  </div>
  </dd>
  <dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17962" title="Abstract">arXiv:2404.17962</a> (cross-list from quant-ph) [<a href="/pdf/2404.17962" title="Download PDF">pdf</a>, <a href="/format/2404.17962" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Deep Learning for Low-Latency, Quantum-Ready RF Sensing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Gokhale%2C+P">Pranav Gokhale</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Carnahan%2C+C">Caitlin Carnahan</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Clark%2C+W">William Clark</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Chong%2C+F+T">Frederic T. Chong</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Performance (cs.PF); Systems and Control (eess.SY)
  
  </div>
  <p class="mathjax">Recent work has shown the promise of applying deep learning to enhance
  software processing of radio frequency (RF) signals. In parallel, hardware
  developments with quantum RF sensors based on Rydberg atoms are breaking
  longstanding barriers in frequency range, resolution, and sensitivity. In this
  paper, we describe our implementations of quantum-ready machine learning
  approaches for RF signal classification. Our primary objective is latency:
  while deep learning offers a more powerful computational paradigm, it also
  traditionally incurs latency overheads that hinder wider scale deployment. Our
  work spans three axes. (1) A novel continuous wavelet transform (CWT) based
  recurrent neural network (RNN) architecture that enables flexible online
  classification of RF signals on-the-fly with reduced sampling time. (2)
  Low-latency inference techniques for both GPU and CPU that span over 100x
  reductions in inference time, enabling real-time operation with sub-millisecond
  inference. (3) Quantum-readiness validated through application of our models to
  physics-based simulation of Rydberg atom QRF sensors. Altogether, our work
  bridges towards next-generation RF sensors that use quantum technology to
  surpass previous physical limits, paired with latency-optimized AI/ML software
  that is suitable for real-time deployment.
  </p>
  </div>
  </dd>
  <dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17969" title="Abstract">arXiv:2404.17969</a> (cross-list from math.CO) [<a href="/pdf/2404.17969" title="Download PDF">pdf</a>, <a href="/ps/2404.17969" title="Download PostScript">ps</a>, <a href="/format/2404.17969" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> From the Lyndon factorization to the Canonical Inverse Lyndon  factorization: back and forth
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Bonizzoni%2C+P">Paola Bonizzoni</a>, 
  <a href="/search/math?searchtype=author&amp;query=De+Felice%2C+C">Clelia De Felice</a>, 
  <a href="/search/math?searchtype=author&amp;query=Zaccagnino%2C+R">Rocco Zaccagnino</a>, 
  <a href="/search/math?searchtype=author&amp;query=Zizza%2C+R">Rosalba Zizza</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/1911.01851">arXiv:1911.01851</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Formal Languages and Automata Theory (cs.FL)
  
  </div>
  <p class="mathjax">The notion of inverse Lyndon word is related to the classical notion of
  Lyndon word. More precisely, inverse Lyndon words are all and only the nonempty
  prefixes of the powers of the anti-Lyndon words, where an anti-Lyndon word with
  respect to a lexicographical order is a classical Lyndon word with respect to
  the inverse lexicographic order. Each word <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-342-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2212" style="width: 0.85em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.68em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2213"><span class="mi" id="MathJax-Span-2214" style="font-family: STIXGeneral-Italic;">w</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-342">w</script> admits a factorization in
  inverse Lyndon words, named the canonical inverse Lyndon factorization
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-343-Frame" tabindex="0" style=""><span class="math" id="MathJax-Span-2215"><span class="noError" id="MathJax-Span-2216">$\ICFL(w)$</span></span></span><script type="math/tex" id="MathJax-Element-343">\ICFL(w)</script>, which maintains the main properties of the Lyndon factorization of
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-344-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2217" style="width: 0.85em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.68em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2218"><span class="mi" id="MathJax-Span-2219" style="font-family: STIXGeneral-Italic;">w</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-344">w</script>. Although there is a huge literature on the Lyndon factorization, the
  relation between the Lyndon factorization <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-345-Frame" tabindex="0" style=""><span class="math" id="MathJax-Span-2220"><span class="noError" id="MathJax-Span-2221">$\CFL_{in}$</span></span></span><script type="math/tex" id="MathJax-Element-345">\CFL_{in}</script> with respect to the
  inverse order and the canonical inverse Lyndon factorization <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-346-Frame" tabindex="0" style=""><span class="math" id="MathJax-Span-2222"><span class="noError" id="MathJax-Span-2223">$\ICFL$</span></span></span><script type="math/tex" id="MathJax-Element-346">\ICFL</script> has not
  been thoroughly investigated. In this paper, we address this question and we
  show how to obtain one factorization from the other via the notion of grouping.
  This result naturally opens new insights in the investigation of the
  relationship between <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-347-Frame" tabindex="0" style=""><span class="math" id="MathJax-Span-2224"><span class="noError" id="MathJax-Span-2225">$\ICFL$</span></span></span><script type="math/tex" id="MathJax-Element-347">\ICFL</script> and other notions, e.g., variants of Burrows
  Wheeler Transform, as already done for the Lyndon factorization.
  </p>
  </div>
  </dd>
  <dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18015" title="Abstract">arXiv:2404.18015</a> (cross-list from math.OC) [<a href="/pdf/2404.18015" title="Download PDF">pdf</a>, <a href="/format/2404.18015" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Swarm-based gradient descent meets simulated annealing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Ding%2C+Z">Zhiyan Ding</a>, 
  <a href="/search/math?searchtype=author&amp;query=Guerra%2C+M">Martin Guerra</a>, 
  <a href="/search/math?searchtype=author&amp;query=Li%2C+Q">Qin Li</a>, 
  <a href="/search/math?searchtype=author&amp;query=Tadmor%2C+E">Eitan Tadmor</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)
  
  </div>
  <p class="mathjax">We introduce a novel method for non-convex optimization which is at the
  interface between the swarm-based gradient-descent (SBGD) [J. Lu et. al.,
  ArXiv:<a href="/abs/2211.17157">2211.17157</a>; E.Tadmor and A. Zenginoglu, Acta Applicandae Math., 190,
  2024] and Simulated Annealing (SA) [V. Cerny, J. optimization theory and appl.,
  45:41-51, 1985; S.Kirkpatrick et. al., Science, 220(4598):671-680, 1983; S.
  Geman and C.-R. Hwang, SIAM J. Control and Optimization, 24(5):1031-1043,
  1986]. We follow the methodology of SBGD in which a swarm of agents, each
  identified with a position, <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-348-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2226" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2227"><span class="texatom" id="MathJax-Span-2228"><span class="mrow" id="MathJax-Span-2229"><span class="texatom" id="MathJax-Span-2230"><span class="mrow" id="MathJax-Span-2231"><span class="mi" id="MathJax-Span-2232" style="font-family: STIXGeneral; font-weight: bold;">x</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-348">{\mathbf x}</script> and mass <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-349-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2233" style="width: 0.906em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.737em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.737em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2234"><span class="mi" id="MathJax-Span-2235" style="font-family: STIXGeneral-Italic;">m</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-349">m</script>, explores the ambient
  space. The agents proceed in gradient descent direction, and are subject to
  Brownian motion with annealing-rate dictated by a decreasing function of their
  mass. Thus, instead of the SA protocol for time-decreasing temperature, we let
  the swarm decide how to `cool down' agents, depending on their accumulated mass
  over time. The dynamics of masses is coupled with the dynamics of positions:
  agents at higher ground transfer (part of) their mass to those at lower ground.
  Consequently, the swarm is dynamically divided between heavier, cooler agents
  viewed as `leaders' and lighter, warmer agents viewed as `explorers'.
  Mean-field convergence analysis and benchmark optimizations demonstrate the
  effectiveness of the swarm-based method as a multi-dimensional global
  optimizer.
  </p>
  </div>
  </dd>
  <dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18017" title="Abstract">arXiv:2404.18017</a> (cross-list from q-fin.PM) [<a href="/pdf/2404.18017" title="Download PDF">pdf</a>, <a href="/ps/2404.18017" title="Download PostScript">ps</a>, <a href="/format/2404.18017" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Application of Deep Learning for Factor Timing in Asset Management
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/q-fin?searchtype=author&amp;query=Panda%2C+P+P">Prabhu Prasad Panda</a>, 
  <a href="/search/q-fin?searchtype=author&amp;query=Gharanchaei%2C+M+K">Maysam Khodayari Gharanchaei</a>, 
  <a href="/search/q-fin?searchtype=author&amp;query=Chen%2C+X">Xilin Chen</a>, 
  <a href="/search/q-fin?searchtype=author&amp;query=Lyu%2C+H">Haoshu Lyu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Machine Learning (cs.LG); Computational Finance (q-fin.CP)
  
  </div>
  <p class="mathjax">The paper examines the performance of regression models (OLS linear
  regression, Ridge regression, Random Forest, and Fully-connected Neural
  Network) on the prediction of CMA (Conservative Minus Aggressive) factor
  premium and the performance of factor timing investment with them.
  Out-of-sample R-squared shows that more flexible models have better performance
  in explaining the variance in factor premium of the unseen period, and the back
  testing affirms that the factor timing based on more flexible models tends to
  over perform the ones with linear models. However, for flexible models like
  neural networks, the optimal weights based on their prediction tend to be
  unstable, which can lead to high transaction costs and market impacts. We
  verify that tilting down the rebalance frequency according to the historical
  optimal rebalancing scheme can help reduce the transaction costs.
  </p>
  </div>
  </dd>
  <dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18041" title="Abstract">arXiv:2404.18041</a> (cross-list from quant-ph) [<a href="/pdf/2404.18041" title="Download PDF">pdf</a>, <a href="/format/2404.18041" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Variational Optimization for Quantum Problems using Deep Generative  Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Zhang%2C+L">Lingxia Zhang</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Lin%2C+X">Xiaodie Lin</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Wang%2C+P">Peidong Wang</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Yang%2C+K">Kaiyan Yang</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Zeng%2C+X">Xiao Zeng</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Wei%2C+Z">Zhaohui Wei</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Wang%2C+Z">Zizhu Wang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 17 pages, 13 figures, comments welcome
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)
  
  </div>
  <p class="mathjax">Optimization is one of the keystones of modern science and engineering. Its
  applications in quantum technology and machine learning helped nurture
  variational quantum algorithms and generative AI respectively. We propose a
  general approach to design variational optimization algorithms based on
  generative models: the Variational Generative Optimization Network (VGON). To
  demonstrate its broad applicability, we apply VGON to three quantum tasks:
  finding the best state in an entanglement-detection protocol, finding the
  ground state of a 1D quantum spin model with variational quantum circuits, and
  generating degenerate ground states of many-body quantum Hamiltonians. For the
  first task, VGON greatly reduces the optimization time compared to stochastic
  gradient descent while generating nearly optimal quantum states. For the second
  task, VGON alleviates the barren plateau problem in variational quantum
  circuits. For the final task, VGON can identify the degenerate ground state
  spaces after a single stage of training and generate a variety of states
  therein.
  </p>
  </div>
  </dd>
  <dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18058" title="Abstract">arXiv:2404.18058</a> (cross-list from eess.IV) [<a href="/pdf/2404.18058" title="Download PDF">pdf</a>, <a href="/format/2404.18058" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Joint Reference Frame Synthesis and Post Filter Enhancement for  Versatile Video Coding
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Bao%2C+W">Weijie Bao</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+Y">Yuantong Zhang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Jia%2C+J">Jianghao Jia</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Chen%2C+Z">Zhenzhong Chen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Liu%2C+S">Shan Liu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">This paper presents the joint reference frame synthesis (RFS) and
  post-processing filter enhancement (PFE) for Versatile Video Coding (VVC),
  aiming to explore the combination of different neural network-based video
  coding (NNVC) tools to better utilize the hierarchical bi-directional coding
  structure of VVC. Both RFS and PFE utilize the Space-Time Enhancement Network
  (STENet), which receives two input frames with artifacts and produces two
  enhanced frames with suppressed artifacts, along with an intermediate
  synthesized frame. STENet comprises two pipelines, the synthesis pipeline and
  the enhancement pipeline, tailored for different purposes. During RFS, two
  reconstructed frames are sent into STENet's synthesis pipeline to synthesize a
  virtual reference frame, similar to the current to-be-coded frame. The
  synthesized frame serves as an additional reference frame inserted into the
  reference picture list (RPL). During PFE, two reconstructed frames are fed into
  STENet's enhancement pipeline to alleviate their artifacts and distortions,
  resulting in enhanced frames with reduced artifacts and distortions. To reduce
  inference complexity, we propose joint inference of RFS and PFE (JISE),
  achieved through a single execution of STENet. Integrated into the VVC
  reference software VTM-15.0, RFS, PFE, and JISE are coordinated within a novel
  Space-Time Enhancement Window (STEW) under Random Access (RA) configuration.
  The proposed method could achieve -7.34%/-17.21%/-16.65% PSNR-based BD-rate on
  average for three components under RA configuration.
  </p>
  </div>
  </dd>
  <dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18096" title="Abstract">arXiv:2404.18096</a> (cross-list from eess.IV) [<a href="/pdf/2404.18096" title="Download PDF">pdf</a>, <a href="/format/2404.18096" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Snake with Shifted Window: Learning to Adapt Vessel Pattern for OCTA  Segmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Chen%2C+X">Xinrun Chen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Shen%2C+M">Mei Shen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Ning%2C+H">Haojian Ning</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+M">Mengzhan Zhang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wang%2C+C">Chengliang Wang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Li%2C+S">Shiying Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Segmenting specific targets or structures in optical coherence tomography
  angiography (OCTA) images is fundamental for conducting further pathological
  studies. The retinal vascular layers are rich and intricate, and such vascular
  with complex shapes can be captured by the widely-studied OCTA images. In this
  paper, we thus study how to use OCTA images with projection vascular layers to
  segment retinal structures. To this end, we propose the SSW-OCTA model, which
  integrates the advantages of deformable convolutions suited for tubular
  structures and the swin-transformer for global feature extraction, adapting to
  the characteristics of OCTA modality images. Our model underwent testing and
  comparison on the OCTA-500 dataset, achieving state-of-the-art performance. The
  code is available at: https://github.com/ShellRedia/Snake-SWin-OCTA.
  </p>
  </div>
  </dd>
  <dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18104" title="Abstract">arXiv:2404.18104</a> (cross-list from quant-ph) [<a href="/pdf/2404.18104" title="Download PDF">pdf</a>, <a href="/format/2404.18104" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The power of shallow-depth Toffoli and qudit quantum circuits
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Grilo%2C+A+B">Alex Bredariol Grilo</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Kashefi%2C+E">Elham Kashefi</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Markham%2C+D">Damian Markham</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=de+Oliveira%2C+M">Michael de Oliveira</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)
  
  </div>
  <p class="mathjax">The relevance of shallow-depth quantum circuits has recently increased,
  mainly due to their applicability to near-term devices. In this context, one of
  the main goals of quantum circuit complexity is to find problems that can be
  solved by quantum shallow circuits but require more computational resources
  classically.
  <br>Our first contribution in this work is to prove new separations between
  classical and quantum constant-depth circuits. Firstly, we show a separation
  between constant-depth quantum circuits with quantum advice
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-350-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2236" style="width: 6.157em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.971em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.471em, 1004.915em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2237"><span class="msubsup" id="MathJax-Span-2238"><span style="display: inline-block; position: relative; width: 2.487em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1002.035em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-2239"><span class="mrow" id="MathJax-Span-2240"><span class="mi" id="MathJax-Span-2241" style="font-family: STIXGeneral-Regular;">𝖰</span><span class="mi" id="MathJax-Span-2242" style="font-family: STIXGeneral-Regular;">𝖭</span><span class="mi" id="MathJax-Span-2243" style="font-family: STIXGeneral-Regular;">𝖢</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 2.092em;"><span class="mn" id="MathJax-Span-2244" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="texatom" id="MathJax-Span-2245"><span class="mrow" id="MathJax-Span-2246"><span class="mo" id="MathJax-Span-2247" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="texatom" id="MathJax-Span-2248"><span class="mrow" id="MathJax-Span-2249"><span class="mi" id="MathJax-Span-2250" style="font-family: STIXGeneral-Regular;">𝗊</span><span class="mi" id="MathJax-Span-2251" style="font-family: STIXGeneral-Regular;">𝗉</span><span class="mi" id="MathJax-Span-2252" style="font-family: STIXGeneral-Regular;">𝗈</span><span class="mi" id="MathJax-Span-2253" style="font-family: STIXGeneral-Regular;">𝗅</span><span class="mi" id="MathJax-Span-2254" style="font-family: STIXGeneral-Regular;">𝗒</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-350">\mathsf{QNC}^0/\mathsf{qpoly}</script>, and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-351-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2255" style="width: 3.616em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.939em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.471em, 1002.826em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2256"><span class="msubsup" id="MathJax-Span-2257"><span style="display: inline-block; position: relative; width: 1.753em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1001.301em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-2258"><span class="mrow" id="MathJax-Span-2259"><span class="mi" id="MathJax-Span-2260" style="font-family: STIXGeneral-Regular;">𝖠</span><span class="mi" id="MathJax-Span-2261" style="font-family: STIXGeneral-Regular;">𝖢</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.358em;"><span class="mn" id="MathJax-Span-2262" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2263" style="font-family: STIXGeneral-Regular;">[</span><span class="mi" id="MathJax-Span-2264" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-2265" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-351">\mathsf{AC}^0[p]</script>, which is the class of
  classical constant-depth circuits with unbounded-fan in and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-352-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2266" style="width: 5.028em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.068em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1004.011em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2267"><span class="TeXmathchoice" id="MathJax-Span-2268"><span class="mspace" id="MathJax-Span-2269" style="height: 0em; vertical-align: 0em; width: 0.511em; display: inline-block; overflow: hidden;"></span></span><span class="mo" id="MathJax-Span-2270" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-2271" style="font-family: STIXGeneral-Regular;">mod</span><span class="mspace" id="MathJax-Span-2272" style="height: 0em; vertical-align: 0em; width: 0.398em; display: inline-block; overflow: hidden;"></span><span class="mi" id="MathJax-Span-2273" style="font-family: STIXGeneral-Italic; padding-left: 0.172em;">p</span><span class="mo" id="MathJax-Span-2274" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-352">\pmod{p}</script> gates.
  In addition, we show a separation between <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-353-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2275" style="width: 3.165em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.543em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1002.543em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2276"><span class="msubsup" id="MathJax-Span-2277"><span style="display: inline-block; position: relative; width: 2.487em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1002.035em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-2278"><span class="mrow" id="MathJax-Span-2279"><span class="mi" id="MathJax-Span-2280" style="font-family: STIXGeneral-Regular;">𝖰</span><span class="mi" id="MathJax-Span-2281" style="font-family: STIXGeneral-Regular;">𝖠</span><span class="mi" id="MathJax-Span-2282" style="font-family: STIXGeneral-Regular;">𝖢</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 2.035em;"><span class="mn" id="MathJax-Span-2283" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-353">\mathsf{QAC}^0</script>, which additionally
  has Toffoli gates with unbounded control, and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-354-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2284" style="width: 3.616em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.939em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.471em, 1002.826em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2285"><span class="msubsup" id="MathJax-Span-2286"><span style="display: inline-block; position: relative; width: 1.753em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1001.301em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-2287"><span class="mrow" id="MathJax-Span-2288"><span class="mi" id="MathJax-Span-2289" style="font-family: STIXGeneral-Regular;">𝖠</span><span class="mi" id="MathJax-Span-2290" style="font-family: STIXGeneral-Regular;">𝖢</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.358em;"><span class="mn" id="MathJax-Span-2291" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2292" style="font-family: STIXGeneral-Regular;">[</span><span class="mi" id="MathJax-Span-2293" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-2294" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-354">\mathsf{AC}^0[p]</script>. This
  establishes the first such separation for a shallow-depth quantum class that
  does not involve quantum fan-out gates.
  <br>Secondly, we consider <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-355-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2295" style="width: 3.165em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.543em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(-0.054em, 1002.543em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2296"><span class="msubsup" id="MathJax-Span-2297"><span style="display: inline-block; position: relative; width: 2.487em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1002.035em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-2298"><span class="mrow" id="MathJax-Span-2299"><span class="mi" id="MathJax-Span-2300" style="font-family: STIXGeneral-Regular;">𝖰</span><span class="mi" id="MathJax-Span-2301" style="font-family: STIXGeneral-Regular;">𝖭</span><span class="mi" id="MathJax-Span-2302" style="font-family: STIXGeneral-Regular;">𝖢</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 2.092em;"><span class="mn" id="MathJax-Span-2303" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-355">\mathsf{QNC}^0</script> circuits with infinite-size gate sets.
  We show that these circuits, along with (classical or quantum) prime modular
  gates, can implement threshold gates, showing that
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-356-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2304" style="width: 9.262em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.512em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.471em, 1007.512em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2305"><span class="msubsup" id="MathJax-Span-2306"><span style="display: inline-block; position: relative; width: 2.487em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1002.035em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-2307"><span class="mrow" id="MathJax-Span-2308"><span class="mi" id="MathJax-Span-2309" style="font-family: STIXGeneral-Regular;">𝖰</span><span class="mi" id="MathJax-Span-2310" style="font-family: STIXGeneral-Regular;">𝖭</span><span class="mi" id="MathJax-Span-2311" style="font-family: STIXGeneral-Regular;">𝖢</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 2.092em;"><span class="mn" id="MathJax-Span-2312" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2313" style="font-family: STIXGeneral-Regular;">[</span><span class="mi" id="MathJax-Span-2314" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-2315" style="font-family: STIXGeneral-Regular;">]</span><span class="mo" id="MathJax-Span-2316" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">=</span><span class="msubsup" id="MathJax-Span-2317" style="padding-left: 0.342em;"><span style="display: inline-block; position: relative; width: 2.431em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1001.979em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="texatom" id="MathJax-Span-2318"><span class="mrow" id="MathJax-Span-2319"><span class="mi" id="MathJax-Span-2320" style="font-family: STIXGeneral-Regular;">𝖰</span><span class="mi" id="MathJax-Span-2321" style="font-family: STIXGeneral-Regular;">𝖳</span><span class="mi" id="MathJax-Span-2322" style="font-family: STIXGeneral-Regular;">𝖢</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.401em; left: 1.979em;"><span class="mn" id="MathJax-Span-2323" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.462em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-356">\mathsf{QNC}^0[p]=\mathsf{QTC}^0</script>. Finally, we also show that in the
  infinite-size gateset case, these quantum circuit classes for
  higher-dimensional Hilbert spaces do not offer any advantage to standard qubit
  implementations.
  </p>
  </div>
  </dd>
  <dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18142" title="Abstract">arXiv:2404.18142</a> (cross-list from quant-ph) [<a href="/pdf/2404.18142" title="Download PDF">pdf</a>, <a href="/format/2404.18142" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Revisiting Majumdar-Ghosh spin chain model and Max-cut problem using  variational quantum algorithms
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Britant">Britant</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Pathak%2C+A">Anirban Pathak</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Merits and demerits of using different variational quantum algorithms have been studied for Majumdar-Ghosh model and Max-cut problem
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)
  
  </div>
  <p class="mathjax">In this work, energy levels of the Majumdar-Ghosh model (MGM) are analyzed up
  to 15 spins chain in the noisy intermediate-scale quantum framework using noisy
  simulations. This is a useful model whose exact solution is known for a
  particular choice of interaction coefficients. We have solved this model for
  interaction coefficients other than that required for the exactly solvable
  conditions as this solution can be of help in understanding the quantum phase
  transitions in complex spin chain models. The solutions are obtained using
  quantum approximate optimization algorithms (QAOA), and variational quantum
  eigensolver (VQE). To obtain the solutions, the one-dimensional lattice network
  is mapped to a Hamiltonian that corresponds to the required interaction
  coefficients among spins. Then, the ground states energy eigenvalue of this
  Hamiltonian is found using QAOA and VQE. Further, the validity of the
  Lieb-Schultz-Mattis theorem in the context of MGM is established by employing
  variational quantum deflation to find the first excited energy of MGM. Solution
  for an unweighted Max-cut graph for 17 nodes is also obtained using QAOA and
  VQE to know which one of these two techniques performs better in a
  combinatorial optimization problem. Since the variational quantum algorithms
  used here to revisit the Max-cut problem and MGM are hybrid algorithms, they
  require classical optimization. Consequently, the results obtained using
  different types of classical optimizers are compared to reveal that the QNSPSA
  optimizer improves the convergence of QAOA in comparison to the SPSA optimizer.
  However, VQE with EfficientSU2 ansatz using the SPSA optimizer yields the best
  results.
  </p>
  </div>
  </dd>
  <dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18178" title="Abstract">arXiv:2404.18178</a> (cross-list from eess.IV) [<a href="/pdf/2404.18178" title="Download PDF">pdf</a>, <a href="/format/2404.18178" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Assessing Image Quality Using a Simple Generative Representation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Raviv%2C+S">Simon Raviv</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Chechik%2C+G">Gal Chechik</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Perceptual image quality assessment (IQA) is the task of predicting the
  visual quality of an image as perceived by a human observer. Current
  state-of-the-art techniques are based on deep representations trained in
  discriminative manner. Such representations may ignore visually important
  features, if they are not predictive of class labels. Recent generative models
  successfully learn low-dimensional representations using auto-encoding and have
  been argued to preserve better visual features. Here we leverage existing
  auto-encoders and propose VAE-QA, a simple and efficient method for predicting
  image quality in the presence of a full-reference. We evaluate our approach on
  four standard benchmarks and find that it significantly improves generalization
  across datasets, has fewer trainable parameters, a smaller memory footprint and
  faster run time.
  </p>
  </div>
  </dd>
  <dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18183" title="Abstract">arXiv:2404.18183</a> (cross-list from q-fin.RM) [<a href="/pdf/2404.18183" title="Download PDF">pdf</a>, <a href="/ps/2404.18183" title="Download PostScript">ps</a>, <a href="/format/2404.18183" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Innovative Application of Artificial Intelligence Technology in Bank  Credit Risk Management
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/q-fin?searchtype=author&amp;query=Bi%2C+S">Shuochen Bi</a>, 
  <a href="/search/q-fin?searchtype=author&amp;query=Bao%2C+W">Wenqing Bao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages, 1 figure, 2 tables
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> International Journal of Global Economics and Management ISSN:
    3005-9690 (Print), ISSN: 3005-8090 (Online) | Volume 2, Number 3, Year 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Risk Management (q-fin.RM)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">With the rapid growth of technology, especially the widespread application of
  artificial intelligence (AI) technology, the risk management level of
  commercial banks is constantly reaching new heights. In the current wave of
  digitalization, AI has become a key driving force for the strategic
  transformation of financial institutions, especially the banking industry. For
  commercial banks, the stability and safety of asset quality are crucial, which
  directly relates to the long-term stable growth of the bank. Among them, credit
  risk management is particularly core because it involves the flow of a large
  amount of funds and the accuracy of credit decisions. Therefore, establishing a
  scientific and effective credit risk decision-making mechanism is of great
  strategic significance for commercial banks. In this context, the innovative
  application of AI technology has brought revolutionary changes to bank credit
  risk management. Through deep learning and big data analysis, AI can accurately
  evaluate the credit status of borrowers, timely identify potential risks, and
  provide banks with more accurate and comprehensive credit decision support. At
  the same time, AI can also achieve realtime monitoring and early warning,
  helping banks intervene before risks occur and reduce losses.
  </p>
  </div>
  </dd>
  <dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18197" title="Abstract">arXiv:2404.18197</a> (cross-list from stat.ME) [<a href="/pdf/2404.18197" title="Download PDF">pdf</a>, <a href="/format/2404.18197" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A General Causal Inference Framework for Cross-Sectional Observational  Data
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Zhao%2C+Y">Yonghe Zhao</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Sun%2C+H">Huiyan Sun</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 19 pages, 7 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Causal inference methods for observational data are highly regarded due to
  their wide applicability. While there are already numerous methods available
  for de-confounding bias, these methods generally assume that covariates consist
  solely of confounders or make naive assumptions about the covariates. Such
  assumptions face challenges in both theory and practice, particularly when
  dealing with high-dimensional covariates. Relaxing these naive assumptions and
  identifying the confounding covariates that truly require correction can
  effectively enhance the practical significance of these methods. Therefore,
  this paper proposes a General Causal Inference (GCI) framework specifically
  designed for cross-sectional observational data, which precisely identifies the
  key confounding covariates and provides corresponding identification algorithm.
  Specifically, based on progressive derivations of the Markov property on
  Directed Acyclic Graph, we conclude that the key confounding covariates are
  equivalent to the common root ancestors of the treatment and the outcome
  variable. Building upon this conclusion, the GCI framework is composed of a
  novel Ancestor Set Identification (ASI) algorithm and de-confounding inference
  methods. Firstly, the ASI algorithm is theoretically supported by the
  conditional independence properties and causal asymmetry between variables,
  enabling the identification of key confounding covariates. Subsequently, the
  identified confounding covariates are used in the de-confounding inference
  methods to obtain unbiased causal effect estimation, which can support informed
  decision-making. Extensive experiments on synthetic datasets demonstrate that
  the GCI framework can effectively identify the critical confounding covariates
  and significantly improve the precision, stability, and interpretability of
  causal inference in observational studies.
  </p>
  </div>
  </dd>
  <dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18198" title="Abstract">arXiv:2404.18198</a> (cross-list from quant-ph) [<a href="/pdf/2404.18198" title="Download PDF">pdf</a>, <a href="/format/2404.18198" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Permutation-equivariant quantum convolutional neural networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Das%2C+S">Sreetama Das</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Caruso%2C+F">Filippo Caruso</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages, 10 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">The Symmetric group <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-357-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2324" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2325"><span class="msubsup" id="MathJax-Span-2326"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2327" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="texatom" id="MathJax-Span-2328"><span class="mrow" id="MathJax-Span-2329"><span class="mi" id="MathJax-Span-2330" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-357">S_{n}</script> manifests itself in large classes of quantum
  systems as the invariance of certain characteristics of a quantum state with
  respect to permuting the qubits. The subgroups of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-358-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2331" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2332"><span class="msubsup" id="MathJax-Span-2333"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2334" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="texatom" id="MathJax-Span-2335"><span class="mrow" id="MathJax-Span-2336"><span class="mi" id="MathJax-Span-2337" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-358">S_{n}</script> arise, among many
  other contexts, to describe label symmetry of classical images with respect to
  spatial transformations, e.g. reflection or rotation. Equipped with the
  formalism of geometric quantum machine learning, in this work we propose the
  architectures of equivariant quantum convolutional neural networks (EQCNNs)
  adherent to <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-359-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2338" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2339"><span class="msubsup" id="MathJax-Span-2340"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2341" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="texatom" id="MathJax-Span-2342"><span class="mrow" id="MathJax-Span-2343"><span class="mi" id="MathJax-Span-2344" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-359">S_{n}</script> and its subgroups. We demonstrate that a careful choice of
  pixel-to-qubit embedding order can facilitate easy construction of EQCNNs for
  small subgroups of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-360-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2345" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2346"><span class="msubsup" id="MathJax-Span-2347"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2348" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="texatom" id="MathJax-Span-2349"><span class="mrow" id="MathJax-Span-2350"><span class="mi" id="MathJax-Span-2351" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-360">S_{n}</script>. Our novel EQCNN architecture corresponding to the
  full permutation group <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-361-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2352" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2353"><span class="msubsup" id="MathJax-Span-2354"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2355" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="texatom" id="MathJax-Span-2356"><span class="mrow" id="MathJax-Span-2357"><span class="mi" id="MathJax-Span-2358" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-361">S_{n}</script> is built by applying all possible QCNNs with
  equal probability, which can also be conceptualized as a dropout strategy in
  quantum neural networks. For subgroups of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-362-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2359" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2360"><span class="msubsup" id="MathJax-Span-2361"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2362" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="texatom" id="MathJax-Span-2363"><span class="mrow" id="MathJax-Span-2364"><span class="mi" id="MathJax-Span-2365" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-362">S_{n}</script>, our numerical results using
  MNIST datasets show better classification accuracy than non-equivariant QCNNs.
  The <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-363-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2366" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2367"><span class="msubsup" id="MathJax-Span-2368"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2369" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="texatom" id="MathJax-Span-2370"><span class="mrow" id="MathJax-Span-2371"><span class="mi" id="MathJax-Span-2372" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-363">S_{n}</script>-equivariant QCNN architecture shows significantly improved training
  and test performance than non-equivariant QCNN for classification of connected
  and non-connected graphs. When trained with sufficiently large number of data,
  the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-364-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2373" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2374"><span class="msubsup" id="MathJax-Span-2375"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2376" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="texatom" id="MathJax-Span-2377"><span class="mrow" id="MathJax-Span-2378"><span class="mi" id="MathJax-Span-2379" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-364">S_{n}</script>-equivariant QCNN shows better average performance compared to
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-365-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2380" style="width: 1.188em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.172em, 1000.963em, 1.358em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2381"><span class="msubsup" id="MathJax-Span-2382"><span style="display: inline-block; position: relative; width: 0.906em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.511em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2383" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.511em;"><span class="texatom" id="MathJax-Span-2384"><span class="mrow" id="MathJax-Span-2385"><span class="mi" id="MathJax-Span-2386" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-365">S_{n}</script>-equivariant QNN . These results contribute towards building powerful
  quantum machine learning architectures in permutation-symmetric systems.
  </p>
  </div>
  </dd>
  <dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18219" title="Abstract">arXiv:2404.18219</a> (cross-list from physics.ins-det) [<a href="/pdf/2404.18219" title="Download PDF">pdf</a>, <a href="/format/2404.18219" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> BUFF: Boosted Decision Tree based Ultra-Fast Flow matching
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Jiang%2C+C">Cheng Jiang</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Qian%2C+S">Sitian Qian</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Qu%2C+H">Huilin Qu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 10 figures, 1 additional figure in appendix
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Detectors (physics.ins-det)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); Data Analysis, Statistics and Probability (physics.data-an)
  
  </div>
  <p class="mathjax">Tabular data stands out as one of the most frequently encountered types in
  high energy physics. Unlike commonly homogeneous data such as pixelated images,
  simulating high-dimensional tabular data and accurately capturing their
  correlations are often quite challenging, even with the most advanced
  architectures. Based on the findings that tree-based models surpass the
  performance of deep learning models for tasks specific to tabular data, we
  adopt the very recent generative modeling class named conditional flow matching
  and employ different techniques to integrate the usage of Gradient Boosted
  Trees. The performances are evaluated for various tasks on different analysis
  level with several public datasets. We demonstrate the training and inference
  time of most high-level simulation tasks can achieve speedup by orders of
  magnitude. The application can be extended to low-level feature simulation and
  conditioned generations with competitive performance.
  </p>
  </div>
  </dd>
  <dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18226" title="Abstract">arXiv:2404.18226</a> (cross-list from quant-ph) [<a href="/pdf/2404.18226" title="Download PDF">pdf</a>, <a href="/ps/2404.18226" title="Download PostScript">ps</a>, <a href="/format/2404.18226" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A quantum compiler design method by using linear combinations of  permutations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Daskin%2C+A">Ammar Daskin</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> related code <a href="https://github.com/adaskin/stochastic-matrix-into-permutations/">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Programming Languages (cs.PL)
  
  </div>
  <p class="mathjax">A matrix can be converted into a doubly stochastic matrix by using two
  diagonal matrices. And a doubly stochastic matrix can be written as a sum of
  permutation matrices. In this paper, we describe a method to write a given
  generic matrix in terms of quantum gates based on the block encoding.
  <br>In particular, we first show how to convert a matrix into doubly stochastic
  matrices and by using Birkhoff's algorithm, we express that matrix in terms of
  a linear combination of permutations which can be mapped to quantum circuits.
  We then discuss a few optimization techniques that can be applied in a possibly
  future quantum compiler software based on the method described here.
  </p>
  </div>
  </dd>
  <dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18233" title="Abstract">arXiv:2404.18233</a> (cross-list from stat.ML) [<a href="/pdf/2404.18233" title="Download PDF">pdf</a>, <a href="/ps/2404.18233" title="Download PostScript">ps</a>, <a href="/format/2404.18233" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Note on Asynchronous Challenges: Unveiling Formulaic Bias and Data  Loss in the Hayashi-Yoshida Estimator
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Georgiadis%2C+E">Evangelos Georgiadis</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> submitted. 15 pages, 1 appendix, 4 figures, 1 table, 1 algo
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Combinatorics (math.CO); Probability (math.PR)
  
  </div>
  <p class="mathjax">The Hayashi-Yoshida (\HY)-estimator exhibits an intrinsic, telescoping
  property that leads to an often overlooked computational bias, which we
  denote,formulaic or intrinsic bias. This formulaic bias results in data loss by
  cancelling out potentially relevant data points, the nonextant data points.
  This paper attempts to formalize and quantify the data loss arising from this
  bias. In particular, we highlight the existence of nonextant data points via a
  concrete example, and prove necessary and sufficient conditions for the
  telescoping property to induce this type of formulaic bias.Since this type of
  bias is nonexistent when inputs, i.e., observation times, <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-366-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2387" style="width: 9.601em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.794em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.414em, 1007.794em, 2.995em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2388"><span class="msubsup" id="MathJax-Span-2389"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2390" style="font-family: STIXGeneral-Regular;">Π</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.737em;"><span class="texatom" id="MathJax-Span-2391"><span class="mrow" id="MathJax-Span-2392"><span class="mo" id="MathJax-Span-2393" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-2394" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2395" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2396" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">:<span style="font-family: STIXGeneral-Regular; font-style: normal; font-weight: normal;">=</span></span><span class="mo" id="MathJax-Span-2397" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">(</span><span class="msubsup" id="MathJax-Span-2398"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px;"><span style="position: absolute; clip: rect(3.277em, 1000.285em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2399" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.39em, 1000.906em, 4.294em, -999.997em); top: -4.457em; left: 0.342em;"><span class="texatom" id="MathJax-Span-2400"><span class="mrow" id="MathJax-Span-2401"><span class="mo" id="MathJax-Span-2402" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-2403" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2404" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.39em, 1000.285em, 4.181em, -999.997em); top: -3.723em; left: 0.285em;"><span class="mi" id="MathJax-Span-2405" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-2406"><span style="display: inline-block; position: relative; width: 2.882em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.285em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="mo" id="MathJax-Span-2407" style="font-family: STIXGeneral-Regular;">)</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.342em;"><span class="texatom" id="MathJax-Span-2408"><span class="mrow" id="MathJax-Span-2409"><span class="mi" id="MathJax-Span-2410" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-2411" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">=</span><span class="mn" id="MathJax-Span-2412" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-2413" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-2414" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2415" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-2416" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">…</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.413em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.67em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-366">\Pi^{(1)}
  :=(t_i^{(1)})_{i=0,1,\ldots}</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-367-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2417" style="width: 9.601em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.794em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.414em, 1007.794em, 3.165em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2418"><span class="msubsup" id="MathJax-Span-2419"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2420" style="font-family: STIXGeneral-Regular;">Π</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.737em;"><span class="texatom" id="MathJax-Span-2421"><span class="mrow" id="MathJax-Span-2422"><span class="mo" id="MathJax-Span-2423" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-2424" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-2425" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2426" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">:<span style="font-family: STIXGeneral-Regular; font-style: normal; font-weight: normal;">=</span></span><span class="mo" id="MathJax-Span-2427" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">(</span><span class="msubsup" id="MathJax-Span-2428"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px;"><span style="position: absolute; clip: rect(3.277em, 1000.285em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2429" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.39em, 1000.906em, 4.294em, -999.997em); top: -4.457em; left: 0.342em;"><span class="texatom" id="MathJax-Span-2430"><span class="mrow" id="MathJax-Span-2431"><span class="mo" id="MathJax-Span-2432" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-2433" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-2434" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.39em, 1000.285em, 4.35em, -999.997em); top: -3.723em; left: 0.285em;"><span class="mi" id="MathJax-Span-2435" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-2436"><span style="display: inline-block; position: relative; width: 2.882em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.285em, 4.35em, -999.997em); top: -4.006em; left: 0em;"><span class="mo" id="MathJax-Span-2437" style="font-family: STIXGeneral-Regular;">)</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.342em;"><span class="texatom" id="MathJax-Span-2438"><span class="mrow" id="MathJax-Span-2439"><span class="mi" id="MathJax-Span-2440" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-2441" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">=</span><span class="mn" id="MathJax-Span-2442" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-2443" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-2444" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2445" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-2446" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">…</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.622em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.878em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-367">\Pi^{(2)} :=(t_j^{(2)})_{j=0,1,\ldots}</script>, are
  synchronous, we introduce the (a,b)-asynchronous adversary. This adversary
  generates inputs <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-368-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2447" style="width: 2.092em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.697em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.697em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2448"><span class="msubsup" id="MathJax-Span-2449"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2450" style="font-family: STIXGeneral-Regular;">Π</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.737em;"><span class="texatom" id="MathJax-Span-2451"><span class="mrow" id="MathJax-Span-2452"><span class="mo" id="MathJax-Span-2453" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-2454" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2455" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-368">\Pi^{(1)}</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-369-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2456" style="width: 2.092em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.697em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.697em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2457"><span class="msubsup" id="MathJax-Span-2458"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2459" style="font-family: STIXGeneral-Regular;">Π</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.737em;"><span class="texatom" id="MathJax-Span-2460"><span class="mrow" id="MathJax-Span-2461"><span class="mo" id="MathJax-Span-2462" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-2463" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-2464" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-369">\Pi^{(2)}</script> according to two independent
  homogenous Poisson processes with rates a&gt;0 and b&gt;0, respectively. We address
  the foundational questions regarding cumulative minimal (or least) average data
  point loss, and determine the values for a and b. We prove that for equal rates
  a=b, the minimal average cumulative data loss over both inputs is attained and
  amounts to 25\%. We present an algorithm, which is based on our theorem, for
  computing the exact number of nonextant data points given inputs <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-370-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2465" style="width: 2.092em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.697em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.697em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2466"><span class="msubsup" id="MathJax-Span-2467"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2468" style="font-family: STIXGeneral-Regular;">Π</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.737em;"><span class="texatom" id="MathJax-Span-2469"><span class="mrow" id="MathJax-Span-2470"><span class="mo" id="MathJax-Span-2471" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-2472" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2473" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-370">\Pi^{(1)}</script>
  and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-371-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2474" style="width: 2.092em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.697em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(0.003em, 1001.697em, 1.188em, -999.997em); top: -1.013em; left: 0em;"><span class="mrow" id="MathJax-Span-2475"><span class="msubsup" id="MathJax-Span-2476"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.165em, 1000.68em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2477" style="font-family: STIXGeneral-Regular;">Π</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.737em;"><span class="texatom" id="MathJax-Span-2478"><span class="mrow" id="MathJax-Span-2479"><span class="mo" id="MathJax-Span-2480" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-2481" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-2482" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 1.019em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-371">\Pi^{(2)}</script>, and suggest alternative methods. Finally, we use simulated
  data to empirically compare the (cumulative) average data loss of the
  (\HY)-estimator.
  </p>
  </div>
  </dd>
  <dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18297" title="Abstract">arXiv:2404.18297</a> (cross-list from quant-ph) [<a href="/pdf/2404.18297" title="Download PDF">pdf</a>, <a href="/format/2404.18297" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Coordination Capacity for Classical-Quantum Correlations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Nator%2C+H">Hosen Nator</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Pereg%2C+U">Uzi Pereg</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)
  
  </div>
  <p class="mathjax">Network coordination is considered in three basic settings, characterizing
  the generation of separable and classical-quantum correlations among multiple
  parties. First, we consider the simulation of a classical-quantum state between
  two nodes with rate-limited common randomness (CR) and communication.
  Furthermore, we study the preparation of a separable state between multiple
  nodes with rate-limited CR and no communication. At last, we consider a
  broadcast setting, where a sender and two receivers simulate a
  classical-quantum-quantum state using rate-limited CR and communication. We
  establish the optimal tradeoff between communication and CR rates in each
  setting.
  </p>
  </div>
  </dd>
  <dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18344" title="Abstract">arXiv:2404.18344</a> (cross-list from math.DG) [<a href="/pdf/2404.18344" title="Download PDF">pdf</a>, <a href="/ps/2404.18344" title="Download PostScript">ps</a>, <a href="/format/2404.18344" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Some Computational Results on Koszul-Vinberg Cochain Complexes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Liu%2C+H">Hanwen Liu</a>, 
  <a href="/search/math?searchtype=author&amp;query=Zhang%2C+J">Jun Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 0 figue
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Differential Geometry (math.DG)</span>; Information Theory (cs.IT)
  
  </div>
  <p class="mathjax">An affine connection is said to be flat if its curvature tensor vanishes
  identically. Koszul-Vinberg (KV for abbreviation) cohomology has been invoked
  to study the deformation theory of flat and torsion-free affine connections on
  tangent bundle. In this Note, we compute explicitly the differentials of
  various specific KV cochains, and study their relation to classical objects in
  information geometry, including deformations associated with projective and
  dual-projective transformations of a flat and torsion-free affine connection.
  As an application, we also give a simple yet non-trivial example of a KV
  algebra of which second cohomology group does not vanish.
  </p>
  </div>
  </dd>
  <dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18369" title="Abstract">arXiv:2404.18369</a> (cross-list from quant-ph) [<a href="/pdf/2404.18369" title="Download PDF">pdf</a>, <a href="/format/2404.18369" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A SAT Scalpel for Lattice Surgery: Representation and Synthesis of  Subroutines for Surface-Code Fault-Tolerant Quantum Computing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Tan%2C+D+B">Daniel Bochen Tan</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Niu%2C+M+Y">Murphy Yuezhen Niu</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Gidney%2C+C">Craig Gidney</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> To appear in 2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)
  
  </div>
  <p class="mathjax">Quantum error correction is necessary for large-scale quantum computing. A
  promising quantum error correcting code is the surface code. For this code,
  fault-tolerant quantum computing (FTQC) can be performed via lattice surgery,
  i.e., splitting and merging patches of code. Given the frequent use of certain
  lattice-surgery subroutines (LaS), it becomes crucial to optimize their design
  in order to minimize the overall spacetime volume of FTQC. In this study, we
  define the variables to represent LaS and the constraints on these variables.
  Leveraging this formulation, we develop a synthesizer for LaS, LaSsynth, that
  encodes a LaS construction problem into a SAT instance, subsequently querying
  SAT solvers for a solution. Starting from a baseline design, we can gradually
  invoke the solver with shrinking spacetime volume to derive more compact
  designs. Due to our foundational formulation and the use of SAT solvers,
  LaSsynth can exhaustively explore the design space, yielding optimal designs in
  volume. For example, it achieves 8% and 18% volume reduction respectively over
  two states-of-the-art human designs for the 15-to-1 T-factory, a bottleneck in
  FTQC.
  </p>
  </div>
  </dd>
  <dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18404" title="Abstract">arXiv:2404.18404</a> (cross-list from cond-mat.stat-mech) [<a href="/pdf/2404.18404" title="Download PDF">pdf</a>, <a href="/format/2404.18404" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Deep generative modelling of canonical ensemble with differentiable  thermal properties
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cond-mat?searchtype=author&amp;query=Li%2C+S">Shuo-Hui Li</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Zhang%2C+Y">Yao-Wen Zhang</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Pan%2C+D">Ding Pan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Main text: 4.5 pages, 2 figures. Supplement: 9 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">We propose a variational modelling method with differentiable temperature for
  canonical ensembles. Using a deep generative model, the free energy is
  estimated and minimized simultaneously in a continuous temperature range. At
  optimal, this generative model is a Boltzmann distribution with temperature
  dependence. The training process requires no dataset, and works with arbitrary
  explicit density generative models. We applied our method to study the phase
  transitions (PT) in the Ising and XY models, and showed that the
  direct-sampling simulation of our model is as accurate as the Markov Chain
  Monte Carlo (MCMC) simulation, but more efficient. Moreover, our method can
  give thermodynamic quantities as differentiable functions of temperature akin
  to an analytical solution. The free energy aligns closely with the exact one to
  the second-order derivative, so this inclusion of temperature dependence
  enables the otherwise biased variational model to capture the subtle thermal
  effects at the PTs. These findings shed light on the direct simulation of
  physical systems using deep generative models
  </p>
  </div>
  </dd>
  <dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18432" title="Abstract">arXiv:2404.18432</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2404.18432" title="Download PDF">pdf</a>, <a href="/ps/2404.18432" title="Download PostScript">ps</a>, <a href="/format/2404.18432" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Structure-preserving particle methods for the Landau collision operator  using the metriplectic framework
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Jeyakumar%2C+S">Sandra Jeyakumar</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Kraus%2C+M">Michael Kraus</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Hole%2C+M+J">Matthew J. Hole</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Pfefferl%C3%A9%2C+D">David Pfefferlé</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 17 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Numerical Analysis (math.NA)
  
  </div>
  <p class="mathjax">We present a novel family of particle discretisation methods for the
  nonlinear Landau collision operator. We exploit the metriplectic structure
  underlying the Vlasov-Maxwell-Landau system in order to obtain disretisation
  schemes that automatically preserve mass, momentum, and energy, warrant
  monotonic dissipation of entropy, and are thus guaranteed to respect the laws
  of thermodynamics. In contrast to recent works that used radial basis functions
  and similar methods for regularisation, here we use an auxiliary spline or
  finite element representation of the distribution function to this end.
  Discrete gradient methods are employed to guarantee the aforementioned
  properties in the time discrete domain as well.
  </p>
  </div>
  </dd>
  <dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18440" title="Abstract">arXiv:2404.18440</a> (cross-list from physics.ao-ph) [<a href="/pdf/2404.18440" title="Download PDF">pdf</a>, <a href="/format/2404.18440" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Potential Paradigm Shift in Hazard Risk Management: AI-Based Weather  Forecast for Tropical Cyclone Hazards
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Feng%2C+K">Kairui Feng</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Xi%2C+D">Dazhi Xi</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Ma%2C+W">Wei Ma</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Wang%2C+C">Cao Wang</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Li%2C+Y">Yuanlong Li</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Chen%2C+X">Xuanhong Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Earth and Planetary Astrophysics (astro-ph.EP); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)
  
  </div>
  <p class="mathjax">The advents of Artificial Intelligence (AI)-driven models marks a paradigm
  shift in risk management strategies for meteorological hazards. This study
  specifically employs tropical cyclones (TCs) as a focal example. We engineer a
  perturbation-based method to produce ensemble forecasts using the advanced
  Pangu AI weather model. Unlike traditional approaches that often generate fewer
  than 20 scenarios from Weather Research and Forecasting (WRF) simulations for
  one event, our method facilitates the rapid nature of AI-driven model to create
  thousands of scenarios. We offer open-source access to our model and evaluate
  its effectiveness through retrospective case studies of significant TC events:
  Hurricane Irma (2017), Typhoon Mangkhut (2018), and TC Debbie (2017), affecting
  regions across North America, East Asia, and Australia. Our findings indicate
  that the AI-generated ensemble forecasts align closely with the European Centre
  for Medium-Range Weather Forecasts (ECMWF) ensemble predictions up to seven
  days prior to landfall. This approach could substantially enhance the
  effectiveness of weather forecast-driven risk analysis and management,
  providing unprecedented operational speed, user-friendliness, and global
  applicability.
  </p>
  </div>
  </dd>
  <dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18445" title="Abstract">arXiv:2404.18445</a> (cross-list from econ.GN) [<a href="/pdf/2404.18445" title="Download PDF">pdf</a>, <a href="/format/2404.18445" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Strategic Behavior and AI Training Data
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/econ?searchtype=author&amp;query=Peukert%2C+C">Christian Peukert</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Abeillon%2C+F">Florian Abeillon</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Haese%2C+J">Jérémie Haese</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Kaiser%2C+F">Franziska Kaiser</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Staub%2C+A">Alexander Staub</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Human-created works represent critical data inputs to artificial intelligence
  (AI). Strategic behavior can play a major role for AI training datasets, be it
  in limiting access to existing works or in deciding which types of new works to
  create or whether to create new works at all. We examine creators' behavioral
  change when their works become training data for AI. Specifically, we focus on
  contributors on Unsplash, a popular stock image platform with about 6 million
  high-quality photos and illustrations. In the summer of 2020, Unsplash launched
  an AI research program by releasing a dataset of 25,000 images for commercial
  use. We study contributors' reactions, comparing contributors whose works were
  included in this dataset to contributors whose works were not included. Our
  results suggest that treated contributors left the platform at a
  higher-than-usual rate and substantially slowed down the rate of new uploads.
  Professional and more successful photographers react stronger than amateurs and
  less successful photographers. We also show that affected users changed the
  variety and novelty of contributions to the platform, with long-run
  implications for the stock of works potentially available for AI training.
  Taken together, our findings highlight the trade-off between interests of
  rightsholders and promoting innovation at the technological frontier. We
  discuss implications for copyright and AI policy.
  </p>
  </div>
  </dd>
  <dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18458" title="Abstract">arXiv:2404.18458</a> (cross-list from eess.IV) [<a href="/pdf/2404.18458" title="Download PDF">pdf</a>, <a href="/ps/2404.18458" title="Download PostScript">ps</a>, <a href="/format/2404.18458" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Autonomous Quality and Hallucination Assessment for Virtual Tissue  Staining and Digital Pathology
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Huang%2C+L">Luzhe Huang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Li%2C+Y">Yuzhu Li</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Pillar%2C+N">Nir Pillar</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Haran%2C+T+K">Tal Keidar Haran</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wallace%2C+W+D">William Dean Wallace</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Ozcan%2C+A">Aydogan Ozcan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 37 Pages, 7 Figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)
  
  </div>
  <p class="mathjax">Histopathological staining of human tissue is essential in the diagnosis of
  various diseases. The recent advances in virtual tissue staining technologies
  using AI alleviate some of the costly and tedious steps involved in the
  traditional histochemical staining process, permitting multiplexed rapid
  staining of label-free tissue without using staining reagents, while also
  preserving tissue. However, potential hallucinations and artifacts in these
  virtually stained tissue images pose concerns, especially for the clinical
  utility of these approaches. Quality assessment of histology images is
  generally performed by human experts, which can be subjective and depends on
  the training level of the expert. Here, we present an autonomous quality and
  hallucination assessment method (termed AQuA), mainly designed for virtual
  tissue staining, while also being applicable to histochemical staining. AQuA
  achieves 99.8% accuracy when detecting acceptable and unacceptable virtually
  stained tissue images without access to ground truth, also presenting an
  agreement of 98.5% with the manual assessments made by board-certified
  pathologists. Besides, AQuA achieves super-human performance in identifying
  realistic-looking, virtually stained hallucinatory images that would normally
  mislead human diagnosticians by deceiving them into diagnosing patients that
  never existed. We further demonstrate the wide adaptability of AQuA across
  various virtually and histochemically stained tissue images and showcase its
  strong external generalization to detect unseen hallucination patterns of
  virtual staining network models as well as artifacts observed in the
  traditional histochemical staining workflow. This framework creates new
  opportunities to enhance the reliability of virtual staining and will provide
  quality assurance for various image generation and transformation tasks in
  digital pathology and computational imaging.
  </p>
  </div>
  </dd>
  <dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18502" title="Abstract">arXiv:2404.18502</a> (cross-list from quant-ph) [<a href="/pdf/2404.18502" title="Download PDF">pdf</a>, <a href="/format/2404.18502" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Classical Software Verification using Quantum Computers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Issel%2C+S">Sebastian Issel</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Tscharke%2C+K">Kilian Tscharke</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Debus%2C+P">Pascal Debus</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Emerging Technologies (cs.ET)
  
  </div>
  <p class="mathjax">We explore the possibility of accelerating the formal verification of
  classical programs with a quantum computer.
  <br>A common source of security flaws stems from the existence of common
  programming errors like use after free, null-pointer dereference, or division
  by zero. To aid in the discovery of such errors, we try to verify that no such
  flaws exist.
  <br>In our approach, for some code snippet and undesired behaviour, a SAT
  instance is generated, which is satisfiable precisely if the behavior is
  present in the code. It is in turn converted to an optimization problem, that
  is solved on a quantum computer. This approach holds the potential of an
  asymptotically polynomial speedup.
  <br>Minimal examples of common errors, like out-of-bounds and overflows, but also
  synthetic instances with special properties, specific number of solutions, or
  structure, are tested with different solvers and tried on a quantum device.
  <br>We use the near-standard Quantum Approximation Optimisation Algorithm, an
  application of the Grover algorithm, and the Quantum Singular Value
  Transformation to find the optimal solution, and with it a satisfying
  assignment.
  </p>
  </div>
  </dd>
  <dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18516" title="Abstract">arXiv:2404.18516</a> (cross-list from eess.SP) [<a href="/pdf/2404.18516" title="Download PDF">pdf</a>, <a href="/ps/2404.18516" title="Download PostScript">ps</a>, <a href="/format/2404.18516" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Downlink Pilots are Essential for Cell-Free Massive MIMO with  Multi-Antenna Users
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Kama%2C+E+B">Eren Berk Kama</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Kim%2C+J">Junbeom Kim</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Bj%C3%B6rnson%2C+E">Emil Björnson</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> \c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)
  
  </div>
  <p class="mathjax">We consider a cell-free massive MIMO system with multiple antennas on the
  users and access points. In previous works, the downlink spectral efficiency
  (SE) has been evaluated using the hardening bound that requires no downlink
  pilots. This approach works well when having single-antenna users. In this
  paper, we show that much higher SEs can be achieved if downlink pilots are sent
  since the effective channel matrix does not harden when having multi-antenna
  users. We propose a pilot-based downlink estimation scheme and derive a new SE
  expression that utilizes zero-forcing combining. We show numerically how the
  number of users and user antennas affects the SE.
  </p>
  </div>
  </dd>
  <dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18521" title="Abstract">arXiv:2404.18521</a> (cross-list from quant-ph) [<a href="/pdf/2404.18521" title="Download PDF">pdf</a>, <a href="/format/2404.18521" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quantum Backbone Networks for Hybrid Quantum Dataframe Transmission
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Vista%2C+F">Francesco Vista</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Holme%2C+D">Daniel Holme</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=DiAdamo%2C+S">Stephen DiAdamo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted for publication in IEEE Communication Magazine
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Networking and Internet Architecture (cs.NI)
  
  </div>
  <p class="mathjax">To realize a global quantum Internet, there is a need for communication
  between quantum subnetworks. To accomplish this task, there have been multiple
  design proposals for a quantum backbone network and quantum subnetworks. In
  this work, we elaborate on the design that uses entanglement and quantum
  teleportation to build the quantum backbone between packetized quantum
  networks. We design a network interface to interconnect packetized quantum
  networks with entanglement-based quantum backbone networks and, moreover,
  design a scheme to accomplish data transmission over this hybrid quantum
  network model. We analyze the use of various implementations of the backbone
  network, focusing our study on backbone networks that use satellite links to
  continuously distribute entanglement resources. For feasibility, we analyze
  various system parameters via simulation to benchmark the performance of the
  overall network.
  </p>
  </div>
  </dd>
  <dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18555" title="Abstract">arXiv:2404.18555</a> (cross-list from quant-ph) [<a href="/pdf/2404.18555" title="Download PDF">pdf</a>, <a href="/format/2404.18555" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Machine Learning for Quantum Computing Specialists
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Goldsmith%2C+D">Daniel Goldsmith</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Mahmud%2C+M+M+H">M M Hassan Mahmud</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 32 pages, 21 figures, technical report
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Quantum machine learning (QML) is a promising early use case for quantum
  computing. There has been progress in the last five years from theoretical
  studies and numerical simulations to proof of concepts. Use cases demonstrated
  on contemporary quantum devices include classifying medical images and items
  from the Iris dataset, classifying and generating handwritten images, toxicity
  screening, and learning a probability distribution. Potential benefits of QML
  include faster training and identification of feature maps not found
  classically. Although, these examples lack the scale for commercial
  exploitation, and it may be several years before QML algorithms replace the
  classical solutions, QML is an exciting area.
  <br>This article is written for those who already have a sound knowledge of
  quantum computing and now wish to gain a basic overview of the terminology and
  some applications of classical machine learning ready to study quantum machine
  learning. The reader will already understand the relevant relevant linear
  algebra, including Hilbert spaces, a vector space with an inner product.
  </p>
  </div>
  </dd>
  <dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18560" title="Abstract">arXiv:2404.18560</a> (cross-list from math.OC) [<a href="/pdf/2404.18560" title="Download PDF">pdf</a>, <a href="/format/2404.18560" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Non-convex Pose Graph Optimization in SLAM via Proximal Linearized  Riemannian ADMM
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Chen%2C+X">Xin Chen</a>, 
  <a href="/search/math?searchtype=author&amp;query=Cui%2C+C">Chunfeng Cui</a>, 
  <a href="/search/math?searchtype=author&amp;query=Han%2C+D">Deren Han</a>, 
  <a href="/search/math?searchtype=author&amp;query=Qi%2C+L">Liqun Qi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)
  
  </div>
  <p class="mathjax">Pose graph optimization (PGO) is a well-known technique for solving the
  pose-based simultaneous localization and mapping (SLAM) problem. In this paper,
  we represent the rotation and translation by a unit quaternion and a
  three-dimensional vector, and propose a new PGO model based on the von
  Mises-Fisher distribution. The constraints derived from the unit quaternions
  are spherical manifolds, and the projection onto the constraints can be
  calculated by normalization. Then a proximal linearized Riemannian alternating
  direction method of multipliers (PieADMM) is developed to solve the proposed
  model, which not only has low memory requirements, but also can update the
  poses in parallel. Furthermore, we establish the iteration complexity of
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-372-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2483" style="width: 3.786em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.052em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1002.995em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2484"><span class="mi" id="MathJax-Span-2485" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-2486" style="font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-2487" style="font-family: STIXGeneral-Regular;">1</span><span class="texatom" id="MathJax-Span-2488"><span class="mrow" id="MathJax-Span-2489"><span class="mo" id="MathJax-Span-2490" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="msubsup" id="MathJax-Span-2491"><span style="display: inline-block; position: relative; width: 0.85em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2492" style="font-family: STIXGeneral-Italic;">ϵ</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.454em;"><span class="texatom" id="MathJax-Span-2493"><span class="mrow" id="MathJax-Span-2494"><span class="mn" id="MathJax-Span-2495" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2496" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-372">O(1/\epsilon^{2})</script> of PieADMM for finding an <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-373-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2497" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2498"><span class="mi" id="MathJax-Span-2499" style="font-family: STIXGeneral-Italic;">ϵ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-373">\epsilon</script>-stationary solution of
  our model. The efficiency of our proposed algorithm is demonstrated by
  numerical experiments on two synthetic and four 3D SLAM benchmark datasets.
  </p>
  </div>
  </dd>
  <dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18592" title="Abstract">arXiv:2404.18592</a> (cross-list from quant-ph) [<a href="/pdf/2404.18592" title="Download PDF">pdf</a>, <a href="/ps/2404.18592" title="Download PostScript">ps</a>, <a href="/format/2404.18592" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Atomicity in Distributed Quantum Computing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Zhang%2C+Z">Zhicheng Zhang</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Ying%2C+M">Mingsheng Ying</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 36 pages, 5 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
  
  </div>
  <p class="mathjax">Atomicity is a ubiquitous assumption in distributed computing, under which
  actions are indivisible and appear sequential. In classical computing, this
  assumption has several theoretical and practical guarantees. In quantum
  computing, although atomicity is still commonly assumed, it has not been
  seriously studied, and a rigorous basis for it is missing. Classical results on
  atomicity do not directly carry over to distributed quantum computing, due to
  new challenges caused by quantum entanglement and the measurement problem from
  the underlying quantum mechanics.
  <br>In this paper, we initiate the study of atomicity in distributed quantum
  computing. A formal model of (non-atomic) distributed quantum system is
  established. Based on the Dijkstra-Lamport condition, the system dynamics and
  observable dynamics of a distributed quantum system are defined, which
  correspond to the quantum state of and classically observable events in the
  system, respectively. Within this framework, we prove that local actions can be
  regarded as if they were atomic, up to the observable dynamics of the system.
  </p>
  </div>
  </dd>
  <dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18599" title="Abstract">arXiv:2404.18599</a> (cross-list from eess.IV) [<a href="/pdf/2404.18599" title="Download PDF">pdf</a>, <a href="/format/2404.18599" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Self-supervised learning for classifying paranasal anomalies in the  maxillary sinus
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Bhattacharya%2C+D">Debayan Bhattacharya</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Behrendt%2C+F">Finn Behrendt</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Becker%2C+B+T">Benjamin Tobias Becker</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Maack%2C+L">Lennart Maack</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Beyersdorff%2C+D">Dirk Beyersdorff</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Petersen%2C+E">Elina Petersen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Petersen%2C+M">Marvin Petersen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Cheng%2C+B">Bastian Cheng</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Eggert%2C+D">Dennis Eggert</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Betz%2C+C">Christian Betz</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Hoffmann%2C+A+S">Anna Sophie Hoffmann</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Schlaefer%2C+A">Alexander Schlaefer</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Purpose: Paranasal anomalies, frequently identified in routine radiological
  screenings, exhibit diverse morphological characteristics. Due to the diversity
  of anomalies, supervised learning methods require large labelled dataset
  exhibiting diverse anomaly morphology. Self-supervised learning (SSL) can be
  used to learn representations from unlabelled data. However, there are no SSL
  methods designed for the downstream task of classifying paranasal anomalies in
  the maxillary sinus (MS).
  <br>Methods: Our approach uses a 3D Convolutional Autoencoder (CAE) trained in an
  unsupervised anomaly detection (UAD) framework. Initially, we train the 3D CAE
  to reduce reconstruction errors when reconstructing normal maxillary sinus (MS)
  image. Then, this CAE is applied to an unlabelled dataset to generate coarse
  anomaly locations by creating residual MS images. Following this, a 3D
  Convolutional Neural Network (CNN) reconstructs these residual images, which
  forms our SSL task. Lastly, we fine-tune the encoder part of the 3D CNN on a
  labelled dataset of normal and anomalous MS images.
  <br>Results: The proposed SSL technique exhibits superior performance compared to
  existing generic self-supervised methods, especially in scenarios with limited
  annotated data. When trained on just 10% of the annotated dataset, our method
  achieves an Area Under the Precision-Recall Curve (AUPRC) of 0.79 for the
  downstream classification task. This performance surpasses other methods, with
  BYOL attaining an AUPRC of 0.75, SimSiam at 0.74, SimCLR at 0.73 and Masked
  Autoencoding using SparK at 0.75.
  <br>Conclusion: A self-supervised learning approach that inherently focuses on
  localizing paranasal anomalies proves to be advantageous, particularly when the
  subsequent task involves differentiating normal from anomalous maxillary
  sinuses. Access our code at
  https://github.com/mtec-tuhh/self-supervised-paranasal-anomaly
  </p>
  </div>
  </dd>
  <dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18654" title="Abstract">arXiv:2404.18654</a> (cross-list from math.OC) [<a href="/pdf/2404.18654" title="Download PDF">pdf</a>, <a href="/format/2404.18654" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Scoping Review on Simulation-based Design Optimization in Marine  Engineering: Trends, Best Practices, and Gaps
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Serani%2C+A">Andrea Serani</a>, 
  <a href="/search/math?searchtype=author&amp;query=Scholcz%2C+T">Thomas Scholcz</a>, 
  <a href="/search/math?searchtype=author&amp;query=Vanzi%2C+V">Valentina Vanzi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE)
  
  </div>
  <p class="mathjax">This scoping review assesses the current use of simulation-based design
  optimization (SBDO) in marine engineering, focusing on identifying research
  trends, methodologies, and application areas. Analyzing 277 studies from Scopus
  and Web of Science, the review finds that SBDO is predominantly applied to
  optimizing marine vessel hulls, including both surface and underwater types,
  and extends to key components like bows, sterns, propellers, and fins. It also
  covers marine structures and renewable energy systems. A notable trend is the
  preference for deterministic single-objective optimization methods, indicating
  potential growth areas in multi-objective and stochastic approaches. The review
  points out the necessity of integrating more comprehensive multidisciplinary
  optimization methods to address the complex challenges in marine environments.
  Despite the extensive application of SBDO in marine engineering, there remains
  a need for enhancing the methodologies' efficiency and robustness. This review
  offers a critical overview of SBDO's role in marine engineering and highlights
  opportunities for future research to advance the field.
  </p>
  </div>
  </dd>
  <dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18735" title="Abstract">arXiv:2404.18735</a> (cross-list from math.ST) [<a href="/pdf/2404.18735" title="Download PDF">pdf</a>, <a href="/format/2404.18735" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Tensor cumulants for statistical inference on invariant distributions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Kunisky%2C+D">Dmitriy Kunisky</a>, 
  <a href="/search/math?searchtype=author&amp;query=Moore%2C+C">Cristopher Moore</a>, 
  <a href="/search/math?searchtype=author&amp;query=Wein%2C+A+S">Alexander S. Wein</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 72 pages, 12 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Probability (math.PR); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">Many problems in high-dimensional statistics appear to have a
  statistical-computational gap: a range of values of the signal-to-noise ratio
  where inference is information-theoretically possible, but (conjecturally)
  computationally intractable. A canonical such problem is Tensor PCA, where we
  observe a tensor <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-374-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2500" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2501"><span class="mi" id="MathJax-Span-2502" style="font-family: STIXGeneral-Italic;">Y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-374">Y</script> consisting of a rank-one signal plus Gaussian noise.
  Multiple lines of work suggest that Tensor PCA becomes computationally hard at
  a critical value of the signal's magnitude. In particular, below this
  transition, no low-degree polynomial algorithm can detect the signal with high
  probability; conversely, various spectral algorithms are known to succeed above
  this transition. We unify and extend this work by considering tensor networks,
  orthogonally invariant polynomials where multiple copies of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-375-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2503" style="width: 0.793em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.624em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2504"><span class="mi" id="MathJax-Span-2505" style="font-family: STIXGeneral-Italic;">Y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.059em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-375">Y</script> are
  "contracted" to produce scalars, vectors, matrices, or other tensors. We define
  a new set of objects, tensor cumulants, which provide an explicit,
  near-orthogonal basis for invariant polynomials of a given degree. This basis
  lets us unify and strengthen previous results on low-degree hardness, giving a
  combinatorial explanation of the hardness transition and of a continuum of
  subexponential-time algorithms that work below it, and proving tight lower
  bounds against low-degree polynomials for recovering rather than just detecting
  the signal. It also lets us analyze a new problem of distinguishing between
  different tensor ensembles, such as Wigner and Wishart tensors, establishing a
  sharp computational threshold and giving evidence of a new
  statistical-computational gap in the Central Limit Theorem for random tensors.
  Finally, we believe these cumulants are valuable mathematical objects in their
  own right: they generalize the free cumulants of free probability theory from
  matrices to tensors, and share many of their properties, including additivity
  under additive free convolution.
  </p>
  </div>
  </dd>
  <dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18769" title="Abstract">arXiv:2404.18769</a> (cross-list from stat.ML) [<a href="/pdf/2404.18769" title="Download PDF">pdf</a>, <a href="/format/2404.18769" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning with Norm Constrained, Over-parameterized, Two-layer Neural  Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Liu%2C+F">Fanghui Liu</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Dadi%2C+L">Leello Dadi</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Cevher%2C+V">Volkan Cevher</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by JMLR
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Recent studies show that a reproducing kernel Hilbert space (RKHS) is not a
  suitable space to model functions by neural networks as the curse of
  dimensionality (CoD) cannot be evaded when trying to approximate even a single
  ReLU neuron (Bach, 2017). In this paper, we study a suitable function space for
  over-parameterized two-layer neural networks with bounded norms (e.g., the path
  norm, the Barron norm) in the perspective of sample complexity and
  generalization properties. First, we show that the path norm (as well as the
  Barron norm) is able to obtain width-independence sample complexity bounds,
  which allows for uniform convergence guarantees. Based on this result, we
  derive the improved result of metric entropy for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-376-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2506" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.454em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2507"><span class="mi" id="MathJax-Span-2508" style="font-family: STIXGeneral-Italic;">ϵ</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-376">\epsilon</script>-covering up to
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-377-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2509" style="width: 4.463em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.616em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.753em, 1003.56em, 3.39em, -999.997em); top: -3.046em; left: 0em;"><span class="mrow" id="MathJax-Span-2510"><span class="texatom" id="MathJax-Span-2511"><span class="mrow" id="MathJax-Span-2512"><span class="mi" id="MathJax-Span-2513" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-2514" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-2515"><span style="display: inline-block; position: relative; width: 2.205em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2516" style="font-family: STIXGeneral-Italic;">ϵ</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.454em;"><span class="texatom" id="MathJax-Span-2517"><span class="mrow" id="MathJax-Span-2518"><span class="mo" id="MathJax-Span-2519" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mfrac" id="MathJax-Span-2520"><span style="display: inline-block; position: relative; width: 0.963em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.511em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.279em;"><span class="mrow" id="MathJax-Span-2521"><span class="mn" id="MathJax-Span-2522" style="font-size: 50%; font-family: STIXGeneral-Regular;">2</span><span class="mi" id="MathJax-Span-2523" style="font-size: 50%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1000.85em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.449em;"><span class="mrow" id="MathJax-Span-2524"><span class="mi" id="MathJax-Span-2525" style="font-size: 50%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-2526" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-2527" style="font-size: 50%; font-family: STIXGeneral-Regular;">2</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1000.963em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 0.963em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2528" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 3.052em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.74em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-377">\mathcal{O}(\epsilon^{-\frac{2d}{d+2}})</script> (<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-378-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2529" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2530"><span class="mi" id="MathJax-Span-2531" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-378">d</script> is the input dimension and the
  depending constant is at most polynomial order of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-379-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2532" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2533"><span class="mi" id="MathJax-Span-2534" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-379">d</script>) via the convex hull
  technique, which demonstrates the separation with kernel methods with
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-380-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2535" style="width: 3.503em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.826em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.527em, 1002.769em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2536"><span class="mi" id="MathJax-Span-2537" style="font-family: STIXGeneral-Regular;">Ω</span><span class="mo" id="MathJax-Span-2538" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-2539"><span style="display: inline-block; position: relative; width: 1.358em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.398em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2540" style="font-family: STIXGeneral-Italic;">ϵ</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.454em;"><span class="texatom" id="MathJax-Span-2541"><span class="mrow" id="MathJax-Span-2542"><span class="mo" id="MathJax-Span-2543" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mi" id="MathJax-Span-2544" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2545" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.392em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-380">\Omega(\epsilon^{-d})</script> to learn the target function in a Barron space. Second,
  this metric entropy result allows for building a sharper generalization bound
  under a general moment hypothesis setting, achieving the rate at
  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-381-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2546" style="width: 4.858em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.955em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.898em, 3.39em, -999.997em); top: -3.046em; left: 0em;"><span class="mrow" id="MathJax-Span-2547"><span class="texatom" id="MathJax-Span-2548"><span class="mrow" id="MathJax-Span-2549"><span class="mi" id="MathJax-Span-2550" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-2551" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-2552"><span style="display: inline-block; position: relative; width: 2.543em; height: 0px;"><span style="position: absolute; clip: rect(3.39em, 1000.454em, 4.181em, -999.997em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-2553" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -4.457em; left: 0.511em;"><span class="texatom" id="MathJax-Span-2554"><span class="mrow" id="MathJax-Span-2555"><span class="mo" id="MathJax-Span-2556" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mfrac" id="MathJax-Span-2557"><span style="display: inline-block; position: relative; width: 1.245em; height: 0px; margin-right: 0.116em; margin-left: 0.116em;"><span style="position: absolute; clip: rect(3.503em, 1000.85em, 4.181em, -999.997em); top: -4.345em; left: 50%; margin-left: -0.449em;"><span class="mrow" id="MathJax-Span-2558"><span class="mi" id="MathJax-Span-2559" style="font-size: 50%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-2560" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-2561" style="font-size: 50%; font-family: STIXGeneral-Regular;">2</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(3.503em, 1001.076em, 4.181em, -999.997em); top: -3.667em; left: 50%; margin-left: -0.562em;"><span class="mrow" id="MathJax-Span-2562"><span class="mn" id="MathJax-Span-2563" style="font-size: 50%; font-family: STIXGeneral-Regular;">2</span><span class="mi" id="MathJax-Span-2564" style="font-size: 50%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-2565" style="font-size: 50%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-2566" style="font-size: 50%; font-family: STIXGeneral-Regular;">2</span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; clip: rect(0.85em, 1001.245em, 1.245em, -999.997em); top: -1.239em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top-width: 1.3px; border-top-style: solid; border-top-color: currentcolor; width: 1.245em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.076em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-2567" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 3.052em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.809em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-381">\mathcal{O}(n^{-\frac{d+2}{2d+2}})</script>. Our analysis is novel in that it offers a
  sharper and refined estimation for metric entropy (with a clear dependence
  relationship on the dimension <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-382-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2568" style="width: 0.624em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.511em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.511em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2569"><span class="mi" id="MathJax-Span-2570" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.976em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-382">d</script>) and unbounded sampling in the estimation of
  the sample error and the output error.
  </p>
  </div>
  </dd>
  <dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18774" title="Abstract">arXiv:2404.18774</a> (cross-list from cond-mat.supr-con) [<a href="/pdf/2404.18774" title="Download PDF">pdf</a>, <a href="/ps/2404.18774" title="Download PostScript">ps</a>, <a href="/format/2404.18774" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Self-training superconducting neuromorphic circuits using reinforcement  learning rules
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cond-mat?searchtype=author&amp;query=Schneider%2C+M+L">M. L. Schneider</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Ju%C3%A9%2C+E+M">E. M. Jué</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Pufall%2C+M+R">M. R. Pufall</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Segall%2C+K">K. Segall</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Anderson%2C+C+W">C. W. Anderson</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages, 6 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Superconductivity (cond-mat.supr-con)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  <p class="mathjax">Reinforcement learning algorithms are used in a wide range of applications,
  from gaming and robotics to autonomous vehicles. In this paper we describe a
  set of reinforcement learning-based local weight update rules and their
  implementation in superconducting hardware. Using SPICE circuit simulations, we
  implement a small-scale neural network with a learning time of order one
  nanosecond. This network can be trained to learn new functions simply by
  changing the target output for a given set of inputs, without the need for any
  external adjustments to the network. In this implementation the weights are
  adjusted based on the current state of the overall network response and locally
  stored information about the previous action. This removes the need to program
  explicit weight values in these networks, which is one of the primary
  challenges that analog hardware implementations of neural networks face. The
  adjustment of weights is based on a global reinforcement signal that obviates
  the need for circuitry to back-propagate errors.
  </p>
  </div>
  </dd>
  <dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18795" title="Abstract">arXiv:2404.18795</a> (cross-list from math.CT) [<a href="/pdf/2404.18795" title="Download PDF">pdf</a>, <a href="/format/2404.18795" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> When Lawvere meets Peirce: an equational presentation of boolean  hyperdoctrines
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Bonchi%2C+F">Filippo Bonchi</a>, 
  <a href="/search/math?searchtype=author&amp;query=Di+Giorgio%2C+A">Alessandro Di Giorgio</a>, 
  <a href="/search/math?searchtype=author&amp;query=Trotta%2C+D">Davide Trotta</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)
  
  </div>
  <p class="mathjax">Fo-bicategories are a categorification of Peirce's calculus of relations.
  Notably, their laws provide a proof system for first-order logic that is both
  purely equational and complete. This paper illustrates a correspondence between
  fo-bicategories and Lawvere's hyperdoctrines. To streamline our proof, we
  introduce peircean bicategories, which offer a more succinct characterization
  of fo-bicategories.
  </p>
  </div>
  </dd>
  <dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18802" title="Abstract">arXiv:2404.18802</a> (cross-list from math.CO) [<a href="/pdf/2404.18802" title="Download PDF">pdf</a>, <a href="/format/2404.18802" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Endhered patterns in matchings and RNA
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Biane%2C+C">Célia Biane</a>, 
  <a href="/search/math?searchtype=author&amp;query=Kirgizov%2C+S">Sergey Kirgizov</a>, 
  <a href="/search/math?searchtype=author&amp;query=Hampikian%2C+G">Greg Hampikian</a>, 
  <a href="/search/math?searchtype=author&amp;query=Nurligareev%2C+K">Khaydar Nurligareev</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 19 pages, 14 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Biomolecules (q-bio.BM)
  
  </div>
  <p class="mathjax">An endhered (end-adhered) pattern is a subset of arcs in matchings, such that
  the corresponding starting points are consecutive and the same holds for the
  ending points. Such patterns are in one-to-one correspondence with the
  permutations. We focus on the occurrence frequency of such patterns in
  matchings and real-world RNA structures with pseudoknots. We present
  combinatorial results related to the distribution and asymptotic behavior of
  the pattern 21, which corresponds to two consecutive stacked bonds frequently
  encountered in RNA, and the pattern 12, representing the archetypal minimal
  pseudoknot. We show that in matchings these two patterns are equidistributed,
  which is quite different from what we can find in real-world RNAs. We also
  examine the distribution of endhered patterns of size 3, showing how the
  patterns change under the transformation called endhered twist. Finally, we
  compute the distributions of endhered patterns of size 2 and 3 in real-world
  secondary RNA structures with pseudoknots and discuss possible outcomes of our
  study.
  </p>
  </div>
  </dd>
  <dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18807" title="Abstract">arXiv:2404.18807</a> (cross-list from hep-ph) [<a href="/pdf/2404.18807" title="Download PDF">pdf</a>, <a href="/format/2404.18807" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Landscape of Unfolding with Machine Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/hep-ph?searchtype=author&amp;query=Huetsch%2C+N">Nathan Huetsch</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Villadamigo%2C+J+M">Javier Mariño Villadamigo</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Shmakov%2C+A">Alexander Shmakov</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Diefenbacher%2C+S">Sascha Diefenbacher</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Mikuni%2C+V">Vinicius Mikuni</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Heimel%2C+T">Theo Heimel</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Fenton%2C+M">Michael Fenton</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Greif%2C+K">Kevin Greif</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Nachman%2C+B">Benjamin Nachman</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Whiteson%2C+D">Daniel Whiteson</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Butter%2C+A">Anja Butter</a>, 
  <a href="/search/hep-ph?searchtype=author&amp;query=Plehn%2C+T">Tilman Plehn</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)
  
  </div>
  <p class="mathjax">Recent innovations from machine learning allow for data unfolding, without
  binning and including correlations across many dimensions. We describe a set of
  known, upgraded, and new methods for ML-based unfolding. The performance of
  these approaches are evaluated on the same two datasets. We find that all
  techniques are capable of accurately reproducing the particle-level spectra
  across complex observables. Given that these approaches are conceptually
  diverse, they offer an exciting toolkit for a new class of measurements that
  can probe the Standard Model with an unprecedented level of detail and may
  enable sensitivity to new phenomena.
  </p>
  </div>
  </dd>
  <dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18820" title="Abstract">arXiv:2404.18820</a> (cross-list from eess.IV) [<a href="/pdf/2404.18820" title="Download PDF">pdf</a>, <a href="/format/2404.18820" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Extreme Image Compression with Latent Feature Guidance and  Diffusion Prior
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Li%2C+Z">Zhiyuan Li</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zhou%2C+Y">Yanhui Zhou</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wei%2C+H">Hao Wei</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Ge%2C+C">Chenyang Ge</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Jiang%2C+J">Jingwen Jiang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to IEEE TCSVT
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  <p class="mathjax">Compressing images at extremely low bitrates (below 0.1 bits per pixel (bpp))
  is a significant challenge due to substantial information loss. Existing
  extreme image compression methods generally suffer from heavy compression
  artifacts or low-fidelity reconstructions. To address this problem, we propose
  a novel extreme image compression framework that combines compressive VAEs and
  pre-trained text-to-image diffusion models in an end-to-end manner.
  Specifically, we introduce a latent feature-guided compression module based on
  compressive VAEs. This module compresses images and initially decodes the
  compressed information into content variables. To enhance the alignment between
  content variables and the diffusion space, we introduce external guidance to
  modulate intermediate feature maps. Subsequently, we develop a conditional
  diffusion decoding module that leverages pre-trained diffusion models to
  further decode these content variables. To preserve the generative capability
  of pre-trained diffusion models, we keep their parameters fixed and use a
  control module to inject content information. We also design a space alignment
  loss to provide sufficient constraints for the latent feature-guided
  compression module. Extensive experiments demonstrate that our method
  outperforms state-of-the-art approaches in terms of both visual performance and
  image fidelity at extremely low bitrates.
  </p>
  </div>
  </dd>
  <dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18833" title="Abstract">arXiv:2404.18833</a> (cross-list from physics.soc-ph) [<a href="/pdf/2404.18833" title="Download PDF">pdf</a>, <a href="/format/2404.18833" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The dynamics of leadership and success in software development teams
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Betti%2C+L">Lorenzo Betti</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Gallo%2C+L">Luca Gallo</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Wachs%2C+J">Johannes Wachs</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Battiston%2C+F">Federico Battiston</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)
  
  </div>
  <p class="mathjax">From science to industry, teamwork plays a crucial role in knowledge
  production and innovation. Most studies consider teams as static groups of
  individuals, thereby failing to capture how the micro-dynamics of collaborative
  processes and organizational changes determine team success. Here, we leverage
  fine-grained temporal data on software development teams to gain insights into
  the dynamics of online collaborative projects. Our analysis reveals an uneven
  workload distribution in teams, with stronger heterogeneity correlated with
  higher success, and the early emergence of a lead developer carrying out the
  majority of work. Moreover, we find that a sizeable fraction of projects
  experience a change of lead developer, with such a transition being more likely
  in projects led by inexperienced users. Finally, we show that leadership change
  is associated with faster success growth, in particular for the least
  successful projects. Our work contributes to a deeper understanding of the link
  between team evolution and success in collaborative processes.
  </p>
  </div>
  </dd>
  <dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18834" title="Abstract">arXiv:2404.18834</a> (cross-list from math.OC) [<a href="/pdf/2404.18834" title="Download PDF">pdf</a>, <a href="/format/2404.18834" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Interpolating between Optimal Transport and KL regularized Optimal  Transport using Rényi Divergences
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Bresch%2C+J">Jonas Bresch</a>, 
  <a href="/search/math?searchtype=author&amp;query=Stein%2C+V">Viktor Stein</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 40 pages, 9 figures, 3 tables, comments welcome
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Functional Analysis (math.FA); Numerical Analysis (math.NA)
  
  </div>
  <p class="mathjax">Regularized optimal transport (OT) has received much attention in recent
  years starting from Cuturi's paper with Kullback-Leibler (KL) divergence
  regularized OT. In this paper, we propose to regularize the OT problem using
  the family of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-383-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2571" style="width: 0.737em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.567em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.567em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2572"><span class="mi" id="MathJax-Span-2573" style="font-family: STIXGeneral-Italic;">α</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-383">\alpha</script>-R\'enyi divergences for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-384-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2574" style="width: 4.971em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.011em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1003.955em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2575"><span class="mi" id="MathJax-Span-2576" style="font-family: STIXGeneral-Italic;">α</span><span class="mo" id="MathJax-Span-2577" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">∈</span><span class="mo" id="MathJax-Span-2578" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">(</span><span class="mn" id="MathJax-Span-2579" style="font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-2580" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-2581" style="font-family: STIXGeneral-Regular; padding-left: 0.172em;">1</span><span class="mo" id="MathJax-Span-2582" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-384">\alpha \in (0, 1)</script>. R\'enyi
  divergences are neither <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-385-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2583" style="width: 0.567em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.454em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1000.454em, 2.939em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2584"><span class="mi" id="MathJax-Span-2585" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.172em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.253em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-385">f</script>-divergences nor Bregman distances, but they recover
  the KL divergence in the limit <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-386-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2586" style="width: 3.334em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.713em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.6em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2587"><span class="mi" id="MathJax-Span-2588" style="font-family: STIXGeneral-Italic;">α</span><span class="mo" id="MathJax-Span-2589" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">↗</span><span class="mn" id="MathJax-Span-2590" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-386">\alpha \nearrow 1</script>. The advantage of
  introducing the additional parameter <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-387-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2591" style="width: 0.737em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.567em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.922em, 1000.567em, 2.713em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2592"><span class="mi" id="MathJax-Span-2593" style="font-family: STIXGeneral-Italic;">α</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.698em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-387">\alpha</script> is that for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-388-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2594" style="width: 3.334em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.713em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.697em, 1002.713em, 2.882em, -999.997em); top: -2.538em; left: 0em;"><span class="mrow" id="MathJax-Span-2595"><span class="mi" id="MathJax-Span-2596" style="font-family: STIXGeneral-Italic;">α</span><span class="mo" id="MathJax-Span-2597" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">↘</span><span class="mn" id="MathJax-Span-2598" style="font-family: STIXGeneral-Regular; padding-left: 0.342em;">0</span></span><span style="display: inline-block; width: 0px; height: 2.543em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-388">\alpha \searrow 0</script>
  we obtain convergence to the unregularized OT problem. For the KL regularized
  OT problem, this was achieved by letting the regularization parameter tend to
  zero, which causes numerical instabilities. We present two different ways to
  obtain premetrics on probability measures, namely by R\'enyi divergence
  constraints and penalization. The latter premetric interpolates between the
  unregularized and KL regularized OT problem with weak convergence of the
  minimizer, generalizing the interpolating property of KL regularized OT. We use
  a nested mirror descent algorithm for solving the primal formulation. Both on
  real and synthetic data sets R\'enyi regularized OT plans outperform their KL
  and Tsallis counterparts in terms of being closer to the unregularized
  transport plans and recovering the ground truth in inference tasks better.
  </p>
  </div>
  </dd>
  <dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18840" title="Abstract">arXiv:2404.18840</a> (cross-list from quant-ph) [<a href="/pdf/2404.18840" title="Download PDF">pdf</a>, <a href="/format/2404.18840" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Fast Quantum Process Tomography via Riemannian Gradient Descent
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Volya%2C+D">Daniel Volya</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Nikitin%2C+A">Andrey Nikitin</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Mishra%2C+P">Prabhat Mishra</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)
  
  </div>
  <p class="mathjax">Constrained optimization plays a crucial role in the fields of quantum
  physics and quantum information science and becomes especially challenging for
  high-dimensional complex structure problems. One specific issue is that of
  quantum process tomography, in which the goal is to retrieve the underlying
  quantum process based on a given set of measurement data. In this paper, we
  introduce a modified version of stochastic gradient descent on a Riemannian
  manifold that integrates recent advancements in numerical methods for
  Riemannian optimization. This approach inherently supports the physically
  driven constraints of a quantum process, takes advantage of state-of-the-art
  large-scale stochastic objective optimization, and has superior performance to
  traditional approaches such as maximum likelihood estimation and projected
  least squares. The data-driven approach enables accurate, order-of-magnitude
  faster results, and works with incomplete data. We demonstrate our approach on
  simulations of quantum processes and in hardware by characterizing an
  engineered process on quantum computers.
  </p>
  </div>
  </dd>
  <dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.18905" title="Abstract">arXiv:2404.18905</a> (cross-list from stat.ME) [<a href="/pdf/2404.18905" title="Download PDF">pdf</a>, <a href="/format/2404.18905" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Detecting critical treatment effect bias in small subgroups
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=De+Bartolomeis%2C+P">Piersilvio De Bartolomeis</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Abad%2C+J">Javier Abad</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Donhauser%2C+K">Konstantin Donhauser</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Yang%2C+F">Fanny Yang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted for presentation at the Conference on Uncertainty in Artificial Intelligence (UAI) 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
  
  </div>
  <p class="mathjax">Randomized trials are considered the gold standard for making informed
  decisions in medicine, yet they often lack generalizability to the patient
  populations in clinical practice. Observational studies, on the other hand,
  cover a broader patient population but are prone to various biases. Thus,
  before using an observational study for decision-making, it is crucial to
  benchmark its treatment effect estimates against those derived from a
  randomized trial. We propose a novel strategy to benchmark observational
  studies beyond the average treatment effect. First, we design a statistical
  test for the null hypothesis that the treatment effects estimated from the two
  studies, conditioned on a set of relevant features, differ up to some
  tolerance. We then estimate an asymptotically valid lower bound on the maximum
  bias strength for any subgroup in the observational study. Finally, we validate
  our benchmarking strategy in a real-world setting and show that it leads to
  conclusions that align with established medical knowledge.
  </p>
  </div>
  </dd>
  </dl>
  <h3>Replacements for Tue, 30 Apr 24</h3>
  <dl>
  <dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1909.12656" title="Abstract">arXiv:1909.12656</a> (replaced) [<a href="/pdf/1909.12656" title="Download PDF">pdf</a>, <a href="/format/1909.12656" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards declarative comparabilities: application to functional  dependencies
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nourine%2C+L">Lhouari Nourine</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Petit%2C+J+M">Jean Marc Petit</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vilmin%2C+S">Simon Vilmin</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 45 pages, 14 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Databases (cs.DB); Information Theory (cs.IT)
  
  </div>
  </div>
  </dd>
  <dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2001.05535" title="Abstract">arXiv:2001.05535</a> (replaced) [<a href="/pdf/2001.05535" title="Download PDF">pdf</a>, <a href="/ps/2001.05535" title="Download PostScript">ps</a>, <a href="/format/2001.05535" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Bhargava greedoid as a Gaussian elimination greedoid
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Grinberg%2C+D">Darij Grinberg</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 71 pages. Pages 1-39 are the core; the rest proves the optimality of the bound (under certain conditions) and fills in some very basic details. See <a href="http://www.cip.ifi.lmu.de/~grinberg/algebra/fps20gfv.pdf">this http URL</a> for a streamlined survey. Comments are welcome! v5 corrects a few typos and adds Example 2.5. This is NOT the published version!
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
  
  </div>
  </div>
  </dd>
  <dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.10689" title="Abstract">arXiv:2007.10689</a> (replaced) [<a href="/pdf/2007.10689" title="Download PDF">pdf</a>, <a href="/format/2007.10689" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Deep Ordinal Distortion Estimation Approach for Distortion  Rectification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liao%2C+K">Kang Liao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+C">Chunyu Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yao Zhao</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.06701" title="Abstract">arXiv:2102.06701</a> (replaced) [<a href="/pdf/2102.06701" title="Download PDF">pdf</a>, <a href="/format/2102.06701" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Explaining Neural Scaling Laws
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bahri%2C+Y">Yasaman Bahri</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dyer%2C+E">Ethan Dyer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kaplan%2C+J">Jared Kaplan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Jaehoon Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sharma%2C+U">Utkarsh Sharma</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 11 pages, 3 figures + Supplement (expanded). This version to appear in PNAS
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.15416" title="Abstract">arXiv:2103.15416</a> (replaced) [<a href="/pdf/2103.15416" title="Download PDF">pdf</a>, <a href="/format/2103.15416" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Performance-based Trajectory Optimization for Path Following Control  Using Bayesian Optimization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Rupenyan%2C+A">Alisa Rupenyan</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Khosravi%2C+M">Mohammad Khosravi</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Lygeros%2C+J">John Lygeros</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, paper accepted at 2021 60th IEEE Conference on Decision and Control (CDC)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.13040" title="Abstract">arXiv:2104.13040</a> (replaced) [<a href="/pdf/2104.13040" title="Download PDF">pdf</a>, <a href="/format/2104.13040" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The music box operad: Random generation of musical phrases from patterns
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Giraudo%2C+S">Samuele Giraudo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 42 pages. Extended version of <a href="/abs/2104.12432">arXiv:2104.12432</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Journal of Creative Music Systems 8, Issue 1, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Combinatorics (math.CO); Quantum Algebra (math.QA)
  
  </div>
  </div>
  </dd>
  <dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.11190" title="Abstract">arXiv:2107.11190</a> (replaced) [<a href="/pdf/2107.11190" title="Download PDF">pdf</a>, <a href="/format/2107.11190" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Semantic Communications for Speech Recognition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Weng%2C+Z">Zhenzi Weng</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Qin%2C+Z">Zhijin Qin</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Li%2C+G+Y">Geoffrey Ye Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)
  
  </div>
  </div>
  </dd>
  <dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.12003" title="Abstract">arXiv:2108.12003</a> (replaced) [<a href="/pdf/2108.12003" title="Download PDF">pdf</a>, <a href="/ps/2108.12003" title="Download PostScript">ps</a>, <a href="/format/2108.12003" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Automata Linear Dynamic Logic on Finite Traces
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Smith%2C+K+W">Kevin W.Smith</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vardi%2C+M+Y">Moshe Y. Vardi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.08123" title="Abstract">arXiv:2109.08123</a> (replaced) [<a href="/pdf/2109.08123" title="Download PDF">pdf</a>, <a href="/format/2109.08123" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Neural Étendue Expander for Ultra-Wide-Angle High-Fidelity  Holographic Display
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Tseng%2C+E">Ethan Tseng</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Kuo%2C+G">Grace Kuo</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Baek%2C+S">Seung-Hwan Baek</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Matsuda%2C+N">Nathan Matsuda</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Maimone%2C+A">Andrew Maimone</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Schiffers%2C+F">Florian Schiffers</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Chakravarthula%2C+P">Praneeth Chakravarthula</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Fu%2C+Q">Qiang Fu</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Heidrich%2C+W">Wolfgang Heidrich</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Lanman%2C+D">Douglas Lanman</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Heide%2C+F">Felix Heide</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Optics (physics.optics)
  
  </div>
  </div>
  </dd>
  <dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.09138" title="Abstract">arXiv:2109.09138</a> (replaced) [<a href="/pdf/2109.09138" title="Download PDF">pdf</a>, <a href="/format/2109.09138" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-Task Learning in Natural Language Processing: An Overview
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Shijie Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qiang Yang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by ACM Computing Surveys
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.05388" title="Abstract">arXiv:2110.05388</a> (replaced) [<a href="/pdf/2110.05388" title="Download PDF">pdf</a>, <a href="/ps/2110.05388" title="Download PostScript">ps</a>, <a href="/format/2110.05388" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quantitative Equality in Substructural Logic via Lipschitz Doctrines
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dagnino%2C+F">Francesco Dagnino</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pasquali%2C+F">Fabio Pasquali</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)
  
  </div>
  </div>
  </dd>
  <dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.04597" title="Abstract">arXiv:2111.04597</a> (replaced) [<a href="/pdf/2111.04597" title="Download PDF">pdf</a>, <a href="/format/2111.04597" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Neyman-Pearson Multi-class Classification via Cost-sensitive Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Tian%2C+Y">Ye Tian</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Feng%2C+Y">Yang Feng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 117 pages, 18 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)
  
  </div>
  </div>
  </dd>
  <dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.04386" title="Abstract">arXiv:2112.04386</a> (replaced) [<a href="/pdf/2112.04386" title="Download PDF">pdf</a>, <a href="/format/2112.04386" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Which images to label for few-shot medical landmark detection?
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Quan%2C+Q">Quan Quan</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Yao%2C+Q">Qingsong Yao</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Li%2C+J">Jun Li</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zhou%2C+S+K">S. Kevin Zhou</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Proceedings of the Conference on Computer Vision and Pattern
    Recognition, 2022
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.11131" title="Abstract">arXiv:2112.11131</a> (replaced) [<a href="/pdf/2112.11131" title="Download PDF">pdf</a>, <a href="/format/2112.11131" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Omnisolver: an extensible interface to Ising spin glass solvers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ja%C5%82owiecki%2C+K">Konrad Jałowiecki</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pawela%2C+%C5%81">Łukasz Pawela</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> SoftwareX 24, 101559 (2023)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Quantum Physics (quant-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.13448" title="Abstract">arXiv:2201.13448</a> (replaced) [<a href="/pdf/2201.13448" title="Download PDF">pdf</a>, <a href="/format/2201.13448" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Warmth and competence in human-agent cooperation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=McKee%2C+K+R">Kevin R. McKee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bai%2C+X">Xuechunzi Bai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fiske%2C+S+T">Susan T. Fiske</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at Autonomous Agents and Multi-Agent Systems
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.05436" title="Abstract">arXiv:2204.05436</a> (replaced) [<a href="/pdf/2204.05436" title="Download PDF">pdf</a>, <a href="/format/2204.05436" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Heterogeneous Acceleration Pipeline for Recommendation System Training
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Adnan%2C+M">Muhammad Adnan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Maboud%2C+Y+E">Yassaman Ebrahimzadeh Maboud</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mahajan%2C+D">Divya Mahajan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nair%2C+P+J">Prashant J. Nair</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at The International Symposium on Computer Architecture (ISCA), 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.02422" title="Abstract">arXiv:2205.02422</a> (replaced) [<a href="/pdf/2205.02422" title="Download PDF">pdf</a>, <a href="/ps/2205.02422" title="Download PostScript">ps</a>, <a href="/format/2205.02422" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quantum Semantic Communications for Resource-Efficient Quantum  Networking
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chehimi%2C+M">Mahdi Chehimi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chaccour%2C+C">Christina Chaccour</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Thomas%2C+C+K">Christo Kurisummoottil Thomas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Saad%2C+W">Walid Saad</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 5 pages, 3 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Quantum Physics (quant-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.04287" title="Abstract">arXiv:2205.04287</a> (replaced) [<a href="/pdf/2205.04287" title="Download PDF">pdf</a>, <a href="/format/2205.04287" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Regular and Complete Notion of Delay for Streaming String Transducers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Filiot%2C+E">Emmanuel Filiot</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jecker%2C+I">Ismaël Jecker</a>, 
  <a href="/search/cs?searchtype=author&amp;query=L%C3%B6ding%2C+C">Christof Löding</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Winter%2C+S">Sarah Winter</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02386" title="Abstract">arXiv:2206.02386</a> (replaced) [<a href="/pdf/2206.02386" title="Download PDF">pdf</a>, <a href="/format/2206.02386" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Restructuring Graph for Higher Homophily via Adaptive Spectral  Clustering
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shouheng Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D">Dongwoo Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qing Wang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages, 9 figures, AAAI 2023
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02667" title="Abstract">arXiv:2206.02667</a> (replaced) [<a href="/pdf/2206.02667" title="Download PDF">pdf</a>, <a href="/format/2206.02667" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Emergent specialization from participation dynamics and multi-learner  retraining
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dean%2C+S">Sarah Dean</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Curmei%2C+M">Mihaela Curmei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ratliff%2C+L+J">Lillian J. Ratliff</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Morgenstern%2C+J">Jamie Morgenstern</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fazel%2C+M">Maryam Fazel</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> AISTATS 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10567" title="Abstract">arXiv:2206.10567</a> (replaced) [<a href="/pdf/2206.10567" title="Download PDF">pdf</a>, <a href="/format/2206.10567" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A nonconforming primal hybrid finite element method for the  two-dimensional vector Laplacian
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Barker%2C+M">Mary Barker</a>, 
  <a href="/search/math?searchtype=author&amp;query=Cao%2C+S">Shuhao Cao</a>, 
  <a href="/search/math?searchtype=author&amp;query=Stern%2C+A">Ari Stern</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 20 pages; v2: minor revisions and corrections
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11832" title="Abstract">arXiv:2206.11832</a> (replaced) [<a href="/pdf/2206.11832" title="Download PDF">pdf</a>, <a href="/format/2206.11832" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On the parameterized complexity of computing tree-partitions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bodlaender%2C+H+L">Hans L. Bodlaender</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Groenland%2C+C">Carla Groenland</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jacob%2C+H">Hugo Jacob</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.05275" title="Abstract">arXiv:2207.05275</a> (replaced) [<a href="/pdf/2207.05275" title="Download PDF">pdf</a>, <a href="/format/2207.05275" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Size and depth of monotone neural networks: interpolation and  approximation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mikulincer%2C+D">Dan Mikulincer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Reichman%2C+D">Daniel Reichman</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 25 pages, 1 Figure; improved inapproximability results and added general reduction results
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13261" title="Abstract">arXiv:2207.13261</a> (replaced) [<a href="/pdf/2207.13261" title="Download PDF">pdf</a>, <a href="/format/2207.13261" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On Error Correction for Nonvolatile Processing-In-Memory
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=C%C4%B1lasun%2C+H">Hüsrev Cılasun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Resch%2C+S">Salonik Resch</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chowdhury%2C+Z+I">Zamshed I. Chowdhury</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zabihi%2C+M">Masoud Zabihi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lv%2C+Y">Yang Lv</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zink%2C+B">Brandon Zink</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jian-Ping Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sapatnekar%2C+S+S">Sachin S. Sapatnekar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Karpuzcu%2C+U+R">Ulya R. Karpuzcu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.05853" title="Abstract">arXiv:2208.05853</a> (replaced) [<a href="/pdf/2208.05853" title="Download PDF">pdf</a>, <a href="/format/2208.05853" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MultiMatch: Multi-task Learning for Semi-supervised Domain  Generalization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Qi%2C+L">Lei Qi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+H">Hongpeng Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yinghuan Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Geng%2C+X">Xin Geng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by ACM TOMM
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.08882" title="Abstract">arXiv:2208.08882</a> (replaced) [<a href="/pdf/2208.08882" title="Download PDF">pdf</a>, <a href="/ps/2208.08882" title="Download PostScript">ps</a>, <a href="/format/2208.08882" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Heart Disease Detection using Quantum Computing and Partitioned Random  Forest Methods
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Heidari%2C+H">Hanif Heidari</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Hellstern%2C+G">Gerhard Hellstern</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Murugappan%2C+M">Murugappan Murugappan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03077" title="Abstract">arXiv:2209.03077</a> (replaced) [<a href="/pdf/2209.03077" title="Download PDF">pdf</a>, <a href="/ps/2209.03077" title="Download PostScript">ps</a>, <a href="/format/2209.03077" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On the Convergence of the ELBO to Entropy Sums
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=L%C3%BCcke%2C+J">Jörg Lücke</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Warnken%2C+J">Jan Warnken</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 50 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Probability (math.PR); Statistics Theory (math.ST)
  
  </div>
  </div>
  </dd>
  <dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08322" title="Abstract">arXiv:2209.08322</a> (replaced) [<a href="/pdf/2209.08322" title="Download PDF">pdf</a>, <a href="/format/2209.08322" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Feedback Stability Analysis via Dissipativity with Dynamic Supply Rates
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Khong%2C+S+Z">Sei Zhen Khong</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Chen%2C+C">Chao Chen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Lanzon%2C+A">Alexander Lanzon</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11745" title="Abstract">arXiv:2209.11745</a> (replaced) [<a href="/pdf/2209.11745" title="Download PDF">pdf</a>, <a href="/format/2209.11745" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Unified Algorithms for RL with Decision-Estimation Coefficients: PAC,  Reward-Free, Preference-Based Learning, and Beyond
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+F">Fan Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mei%2C+S">Song Mei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yu Bai</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Statistics Theory (math.ST); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01603" title="Abstract">arXiv:2210.01603</a> (replaced) [<a href="/pdf/2210.01603" title="Download PDF">pdf</a>, <a href="/format/2210.01603" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Neural-Symbolic Recursive Machine for Systematic Generalization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Q">Qing Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yixin Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yitao Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y+N">Ying Nian Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+S">Song-Chun Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+S">Siyuan Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICLR 2024. Project website: <a href="https://liqing-ustc.github.io/NSR/">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03921" title="Abstract">arXiv:2210.03921</a> (replaced) [<a href="/pdf/2210.03921" title="Download PDF">pdf</a>, <a href="/format/2210.03921" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Data Selection: A General Principle for Building Small Interpretable  Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ghose%2C+A">Abhishek Ghose</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04219" title="Abstract">arXiv:2210.04219</a> (replaced) [<a href="/pdf/2210.04219" title="Download PDF">pdf</a>, <a href="/ps/2210.04219" title="Download PostScript">ps</a>, <a href="/format/2210.04219" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Rational cross-sections, bounded generation and orders on groups
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Bodart%2C+C">Corentin Bodart</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Fixed a mistake in the proof of Proposition 7.4, and other minors changes
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Formal Languages and Automata Theory (cs.FL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05105" title="Abstract">arXiv:2210.05105</a> (replaced) [<a href="/pdf/2210.05105" title="Download PDF">pdf</a>, <a href="/format/2210.05105" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Distributed-Memory Randomized Algorithms for Sparse Tensor CP  Decomposition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Bharadwaj%2C+V">Vivek Bharadwaj</a>, 
  <a href="/search/math?searchtype=author&amp;query=Malik%2C+O+A">Osman Asif Malik</a>, 
  <a href="/search/math?searchtype=author&amp;query=Murray%2C+R">Riley Murray</a>, 
  <a href="/search/math?searchtype=author&amp;query=Bulu%C3%A7%2C+A">Aydin Buluç</a>, 
  <a href="/search/math?searchtype=author&amp;query=Demmel%2C+J">James Demmel</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> To appear in the Proceedings of the 36th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA'24). 14 pages, 13 figures, 5 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.17223" title="Abstract">arXiv:2210.17223</a> (replaced) [<a href="/pdf/2210.17223" title="Download PDF">pdf</a>, <a href="/format/2210.17223" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Accelerating Distributed MoE Training and Inference with Lina
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jiamin Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yimin Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yibo Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Cong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Hong Xu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01152" title="Abstract">arXiv:2211.01152</a> (replaced) [<a href="/pdf/2211.01152" title="Download PDF">pdf</a>, <a href="/format/2211.01152" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> New Tradeoffs for Decremental Approximate All-Pairs Shortest Paths
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dory%2C+M">Michal Dory</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Forster%2C+S">Sebastian Forster</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nazari%2C+Y">Yasamin Nazari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=de+Vos%2C+T">Tijn de Vos</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to ICALP 2024. Compared to the previous version, this manuscript contains an improved version of Theorem 1.1 and the new Theorem 1.3
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01939" title="Abstract">arXiv:2211.01939</a> (replaced) [<a href="/pdf/2211.01939" title="Download PDF">pdf</a>, <a href="/format/2211.01939" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Empirical Analysis of Model Selection for Heterogeneous Causal Effect  Estimation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mahajan%2C+D">Divyat Mahajan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mitliagkas%2C+I">Ioannis Mitliagkas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Neal%2C+B">Brady Neal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Proceedings of the 12th International Conference on Learning Representations (ICLR), 2024. (Spotlight)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)
  
  </div>
  </div>
  </dd>
  <dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08223" title="Abstract">arXiv:2211.08223</a> (replaced) [<a href="/pdf/2211.08223" title="Download PDF">pdf</a>, <a href="/format/2211.08223" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Jump-preserving polynomial interpolation in non-manifold polyhedra
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Averseng%2C+M">Martin Averseng</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)
  
  </div>
  </div>
  </dd>
  <dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11869" title="Abstract">arXiv:2211.11869</a> (replaced) [<a href="/pdf/2211.11869" title="Download PDF">pdf</a>, <a href="/format/2211.11869" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Examining Policy Entropy of Reinforcement Learning Agents for  Personalization Tasks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dereventsov%2C+A">Anton Dereventsov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Starnes%2C+A">Andrew Starnes</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Webster%2C+C+G">Clayton G. Webster</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA); Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01168" title="Abstract">arXiv:2212.01168</a> (replaced) [<a href="/pdf/2212.01168" title="Download PDF">pdf</a>, <a href="/format/2212.01168" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Cross Domain Generalization of Hamiltonian Representation via  Meta Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+Y">Yeongwoo Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jeong%2C+H">Hawoong Jeong</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Conference paper at ICLR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04672" title="Abstract">arXiv:2212.04672</a> (replaced) [<a href="/pdf/2212.04672" title="Download PDF">pdf</a>, <a href="/format/2212.04672" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Primal Dual Alternating Proximal Gradient Algorithms for Nonsmooth  Nonconvex Minimax Problems with Coupled Linear Constraints
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Zhang%2C+H">Huiling Zhang</a>, 
  <a href="/search/math?searchtype=author&amp;query=Wang%2C+J">Junlin Wang</a>, 
  <a href="/search/math?searchtype=author&amp;query=Xu%2C+Z">Zi Xu</a>, 
  <a href="/search/math?searchtype=author&amp;query=Dai%2C+Y">Yu-Hong Dai</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09298" title="Abstract">arXiv:2212.09298</a> (replaced) [<a href="/pdf/2212.09298" title="Download PDF">pdf</a>, <a href="/format/2212.09298" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> From a Bird's Eye View to See: Joint Camera and Subject Registration  without the Camera Calibration
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Qian%2C+Z">Zekun Qian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+R">Ruize Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+W">Wei Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+F">Feifan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Song Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09570" title="Abstract">arXiv:2212.09570</a> (replaced) [<a href="/pdf/2212.09570" title="Download PDF">pdf</a>, <a href="/format/2212.09570" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Solving Quantified Modal Logic Problems by Translation to Classical  Logics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Steen%2C+A">Alexander Steen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sutcliffe%2C+G">Geoff Sutcliffe</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Benzm%C3%BCller%2C+C">Christoph Benzmüller</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 23 pages, 1 figure; updated journal version of conference paper
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05350" title="Abstract">arXiv:2301.05350</a> (replaced) [<a href="/pdf/2301.05350" title="Download PDF">pdf</a>, <a href="/format/2301.05350" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Sublinear Algorithms for TSP via Path Covers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Behnezhad%2C+S">Soheil Behnezhad</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Roghani%2C+M">Mohammad Roghani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rubinstein%2C+A">Aviad Rubinstein</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Saberi%2C+A">Amin Saberi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06676" title="Abstract">arXiv:2301.06676</a> (replaced) [<a href="/pdf/2301.06676" title="Download PDF">pdf</a>, <a href="/format/2301.06676" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Explainable, Interpretable &amp; Trustworthy AI for Intelligent Digital  Twin: Case Study on Remaining Useful Life
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kobayashi%2C+K">Kazuma Kobayashi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Alam%2C+S+B">Syed Bahauddin Alam</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Engineering Applications of Artificial Intelligence 129 (2024):
    107620
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Computation (stat.CO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06701" title="Abstract">arXiv:2301.06701</a> (replaced) [<a href="/pdf/2301.06701" title="Download PDF">pdf</a>, <a href="/format/2301.06701" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Improved generalization with deep neural operators for engineering  systems: Path towards digital twin
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kobayashi%2C+K">Kazuma Kobayashi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Daniell%2C+J">James Daniell</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Alam%2C+S+B">Syed Bahauddin Alam</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Engineering Applications of Artificial Intelligence 131 (2024):
    107844
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Computation (stat.CO); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08970" title="Abstract">arXiv:2301.08970</a> (replaced) [<a href="/pdf/2301.08970" title="Download PDF">pdf</a>, <a href="/format/2301.08970" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Conditional Cauchy-Schwarz Divergence with Applications to  Time-Series Data and Sequential Decision Making
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+S">Shujian Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+H">Hongming Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=L%C3%B8kse%2C+S">Sigurd Løkse</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jenssen%2C+R">Robert Jenssen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pr%C3%ADncipe%2C+J+C">José C. Príncipe</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 27 pages, 10 figures, under 2nd round review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11580" title="Abstract">arXiv:2301.11580</a> (replaced) [<a href="/pdf/2301.11580" title="Download PDF">pdf</a>, <a href="/format/2301.11580" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Characterization of Complexity in Public Goods Games
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gilboa%2C+M">Matan Gilboa</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> To be published in ICALP'24
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12210" title="Abstract">arXiv:2301.12210</a> (replaced) [<a href="/pdf/2301.12210" title="Download PDF">pdf</a>, <a href="/format/2301.12210" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Neural Temporal Point Process for Forecasting Higher Order and  Directional Interactions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gracious%2C+T">Tony Gracious</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+A">Arman Gupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dukkipati%2C+A">Ambedkar Dukkipati</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 17 pages, 10 figures, 9 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00058" title="Abstract">arXiv:2302.00058</a> (replaced) [<a href="/pdf/2302.00058" title="Download PDF">pdf</a>, <a href="/format/2302.00058" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Graph Anomaly Detection in Time Series: A Survey
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ho%2C+T+K+K">Thi Kieu Khanh Ho</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Karami%2C+A">Ali Karami</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Armanfard%2C+N">Narges Armanfard</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 20 pages, 4 figures, 2 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00788" title="Abstract">arXiv:2302.00788</a> (replaced) [<a href="/pdf/2302.00788" title="Download PDF">pdf</a>, <a href="/format/2302.00788" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A supplemental investigation of non-linearity in quantum generative  models with respect to simulatability and optimization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Gili%2C+K">Kaitlin Gili</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Kumar%2C+R+S">Rohan S. Kumar</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Sveistrys%2C+M">Mykolas Sveistrys</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Ballance%2C+C+J">C. J. Ballance</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)
  
  </div>
  </div>
  </dd>
  <dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02399" title="Abstract">arXiv:2302.02399</a> (replaced) [<a href="/pdf/2302.02399" title="Download PDF">pdf</a>, <a href="/ps/2302.02399" title="Download PostScript">ps</a>, <a href="/format/2302.02399" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Latent Space Bayesian Optimization with Latent Data Augmentation for  Enhanced Exploration
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Boyar%2C+O">Onur Boyar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Takeuchi%2C+I">Ichiro Takeuchi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 figures, 6 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04783" title="Abstract">arXiv:2302.04783</a> (replaced) [<a href="/pdf/2302.04783" title="Download PDF">pdf</a>, <a href="/ps/2302.04783" title="Download PostScript">ps</a>, <a href="/format/2302.04783" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-389-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2599" style="width: 0.405em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.316em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.839em, 1000.316em, 2.646em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-2600"><span class="mi" id="MathJax-Span-2601" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.781em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-389">t</script>-sails and sparse hereditary classes of unbounded tree-width
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Cocks%2C+D">Daniel Cocks</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Data Structures and Algorithms (cs.DS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05030" title="Abstract">arXiv:2302.05030</a> (replaced) [<a href="/pdf/2302.05030" title="Download PDF">pdf</a>, <a href="/ps/2302.05030" title="Download PostScript">ps</a>, <a href="/format/2302.05030" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Dynamic <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-390-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2602" style="width: 3.586em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.87em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1002.825em, 2.825em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-2603"><span class="mo" id="MathJax-Span-2604" style="font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-2605" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-2606" style="font-family: STIXGeneral-Regular; padding-left: 0.271em;">+</span><span class="texatom" id="MathJax-Span-2607" style="padding-left: 0.271em;"><span class="mrow" id="MathJax-Span-2608"><span class="mo" id="MathJax-Span-2609" style="font-family: STIXGeneral-Regular;">ε</span></span></span><span class="mo" id="MathJax-Span-2610" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.275em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.169em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-390">(1+ε)</script>-Approximate Matching Size in Truly Sublinear  Update Time
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bhattacharya%2C+S">Sayan Bhattacharya</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kiss%2C+P">Peter Kiss</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Saranurak%2C+T">Thatchaphol Saranurak</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07491" title="Abstract">arXiv:2302.07491</a> (replaced) [<a href="/pdf/2302.07491" title="Download PDF">pdf</a>, <a href="/format/2302.07491" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Self-Supervised Temporal Graph learning with Temporal and Structural  Intensity Alignment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+M">Meng Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+K">Ke Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yawei Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tu%2C+W">Wenxuan Tu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+S">Sihang Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gan%2C+X">Xinbiao Gan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xinwang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kunlun He</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09832" title="Abstract">arXiv:2302.09832</a> (replaced) [<a href="/pdf/2302.09832" title="Download PDF">pdf</a>, <a href="/format/2302.09832" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> TAMUNA: Doubly Accelerated Distributed Optimization with Local Training,  Compression, and Partial Participation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Condat%2C+L">Laurent Condat</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agarsk%C3%BD%2C+I">Ivan Agarský</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Malinovsky%2C+G">Grigory Malinovsky</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Richt%C3%A1rik%2C+P">Peter Richtárik</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This work is a follow-up of our previous work introducing CompressedScaffnew in paper <a href="/abs/2210.13277">arXiv:2210.13277</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10753" title="Abstract">arXiv:2302.10753</a> (replaced) [<a href="/pdf/2302.10753" title="Download PDF">pdf</a>, <a href="/format/2302.10753" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DTAAD: Dual Tcn-Attention Networks for Anomaly Detection in Multivariate  Time Series Data
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+L">Lingrui Yu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10786" title="Abstract">arXiv:2302.10786</a> (replaced) [<a href="/pdf/2302.10786" title="Download PDF">pdf</a>, <a href="/format/2302.10786" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Real-World Deployment and Evaluation of Kwame for Science, An AI  Teaching Assistant for Science Education in West Africa
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Boateng%2C+G">George Boateng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=John%2C+S">Samuel John</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Boateng%2C+S">Samuel Boateng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Badu%2C+P">Philemon Badu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agyeman-Budu%2C+P">Patrick Agyeman-Budu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kumbol%2C+V">Victor Kumbol</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, Accepted for publication at the 25th International Conference on Artificial Intelligence in Education (AIED 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11419" title="Abstract">arXiv:2302.11419</a> (replaced) [<a href="/pdf/2302.11419" title="Download PDF">pdf</a>, <a href="/format/2302.11419" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Aligned Diffusion Schrödinger Bridges
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Somnath%2C+V+R">Vignesh Ram Somnath</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pariset%2C+M">Matteo Pariset</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hsieh%2C+Y">Ya-Ping Hsieh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Martinez%2C+M+R">Maria Rodriguez Martinez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Krause%2C+A">Andreas Krause</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bunne%2C+C">Charlotte Bunne</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)
  
  </div>
  </div>
  </dd>
  <dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00612" title="Abstract">arXiv:2303.00612</a> (replaced) [<a href="/pdf/2303.00612" title="Download PDF">pdf</a>, <a href="/format/2303.00612" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Has the Virtualization of the Face Changed Facial Perception? A Study of  the Impact of Photo Editing and Augmented Reality on Facial Perception
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Conwill%2C+L">Louisa Conwill</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Anthony%2C+S+E">Sam English Anthony</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Scheirer%2C+W+J">Walter J. Scheirer</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00935" title="Abstract">arXiv:2303.00935</a> (replaced) [<a href="/pdf/2303.00935" title="Download PDF">pdf</a>, <a href="/format/2303.00935" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning to Detect Slip through Tactile Estimation of the Contact Force  Field and its Entropy
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+X">Xiaohai Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Venkatesh%2C+A">Aparajit Venkatesh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wan%2C+Y">Yusen Wan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+G">Guiliang Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jawale%2C+N">Neel Jawale</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kaur%2C+N">Navneet Kaur</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xu Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Birkmeyer%2C+P">Paul Birkmeyer</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 7 figures, submitted
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00952" title="Abstract">arXiv:2303.00952</a> (replaced) [<a href="/pdf/2303.00952" title="Download PDF">pdf</a>, <a href="/format/2303.00952" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Activated Muscle Group Estimation in the Wild
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+K">Kunyu Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schneider%2C+D">David Schneider</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Roitberg%2C+A">Alina Roitberg</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+K">Kailun Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiaming Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Deng%2C+C">Chen Deng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kaiyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sarfraz%2C+M+S">M. Saquib Sarfraz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The contributed dataset and code will be publicly available at <a href="https://github.com/KPeng9510/MuscleMap">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09347" title="Abstract">arXiv:2303.09347</a> (replaced) [<a href="/e-print/2303.09347" title="Download source">src</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CSSL-MHTR: Continual Self-Supervised Learning for Scalable Multi-script  Handwritten Text Recognition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dhiaf%2C+M">Marwa Dhiaf</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Souibgui%2C+M+A">Mohamed Ali Souibgui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+K">Kai Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuyang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kessentini%2C+Y">Yousri Kessentini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Forn%C3%A9s%2C+A">Alicia Fornés</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rouhou%2C+A+C">Ahmed Cheikh Rouhou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Due to current company policy constraints, we are compelled to withdraw our paper. The organization's guidelines prohibit us from proceeding with the publication of this work at this time. We apologize for any inconvenience this may cause and appreciate your understanding in this matter
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11964" title="Abstract">arXiv:2303.11964</a> (replaced) [<a href="/pdf/2303.11964" title="Download PDF">pdf</a>, <a href="/format/2303.11964" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Fast exact simulation of the first passage of a tempered stable  subordinator across a non-increasing function
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=C%C3%A1zares%2C+J+I+G">Jorge Ignacio González Cázares</a>, 
  <a href="/search/math?searchtype=author&amp;query=Lin%2C+F">Feng Lin</a>, 
  <a href="/search/math?searchtype=author&amp;query=Mijatovi%C4%87%2C+A">Aleksandar Mijatović</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 51 pages, 8 figures, 12 algorithms, final version, to appear in Stochastic Systems. Short YouTube presentation on the algorithm: <a href="https://www.youtube.com/watch?v=dO-cQeABHdM">this https URL</a> and on applications: <a href="https://www.youtube.com/watch?v=e38c1LmrzfA">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA)
  
  </div>
  </div>
  </dd>
  <dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13935" title="Abstract">arXiv:2303.13935</a> (replaced) [<a href="/pdf/2303.13935" title="Download PDF">pdf</a>, <a href="/format/2303.13935" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-Task Reinforcement Learning in Continuous Control with Successor  Feature-Based Concurrent Composition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y+T">Yu Tang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ahmad%2C+A">Aamir Ahmad</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05229" title="Abstract">arXiv:2304.05229</a> (replaced) [<a href="/pdf/2304.05229" title="Download PDF">pdf</a>, <a href="/format/2304.05229" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Big-O Problem for Max-Plus Automata is Decidable (PSPACE-Complete)
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Daviaud%2C+L">Laure Daviaud</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Purser%2C+D">David Purser</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tcheng%2C+M">Marie Tcheng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Version 2: adds section on Max-Plus automata with increasingly complex witnesses
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06565" title="Abstract">arXiv:2304.06565</a> (replaced) [<a href="/pdf/2304.06565" title="Download PDF">pdf</a>, <a href="/format/2304.06565" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> List Update with Delays or Time Windows
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Azar%2C+Y">Yossi Azar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lewkowicz%2C+S">Shahar Lewkowicz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vainstein%2C+D">Danny Vainstein</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06911" title="Abstract">arXiv:2304.06911</a> (replaced) [<a href="/pdf/2304.06911" title="Download PDF">pdf</a>, <a href="/format/2304.06911" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> 3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud  Pretraining
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+S">Siming Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yuqi Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yuxiao Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+H">Hao Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+P">Peng-shuai Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tong%2C+X">Xin Tong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Q">Qixing Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Published in ICLR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12310" title="Abstract">arXiv:2304.12310</a> (replaced) [<a href="/pdf/2304.12310" title="Download PDF">pdf</a>, <a href="/format/2304.12310" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Fully Sparse Fusion for 3D Object Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yingyan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+L">Lue Fan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zehao Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuntao Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+N">Naiyan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoxiang Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> TPMAI 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08420" title="Abstract">arXiv:2305.08420</a> (replaced) [<a href="/pdf/2305.08420" title="Download PDF">pdf</a>, <a href="/format/2305.08420" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring Few-Shot Adaptation for Activity Recognition on Diverse  Domains
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+K">Kunyu Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wen%2C+D">Di Wen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schneider%2C+D">David Schneider</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiaming Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+K">Kailun Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sarfraz%2C+M+S">M. Saquib Sarfraz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Roitberg%2C+A">Alina Roitberg</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The benchmark and source code will be publicly available at <a href="https://github.com/KPeng9510/RelaMiX">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Image and Video Processing (eess.IV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10672" title="Abstract">arXiv:2305.10672</a> (replaced) [<a href="/pdf/2305.10672" title="Download PDF">pdf</a>, <a href="/format/2305.10672" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Relay Mining: Incentivizing Full Non-Validating Nodes Servicing All RPC  Types
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Olshansky%2C+D">Daniel Olshansky</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Colmeiro%2C+R+R">Ramiro Rodríguez Colmeiro</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 18 pages, 4 tables, 5 figures, 2 appendices with 8 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR); Systems and Control (eess.SY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12081" title="Abstract">arXiv:2305.12081</a> (replaced) [<a href="/pdf/2305.12081" title="Download PDF">pdf</a>, <a href="/format/2305.12081" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MediTab: Scaling Medical Tabular Data Predictors via Data Consolidation,  Enrichment, and Refinement
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zifeng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+C">Chufan Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+C">Cao Xiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jimeng Sun</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> IJCAI 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13882" title="Abstract">arXiv:2305.13882</a> (replaced) [<a href="/pdf/2305.13882" title="Download PDF">pdf</a>, <a href="/format/2305.13882" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Subsampling Error in Stochastic Gradient Langevin Diffusions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Jin%2C+K">Kexin Jin</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Liu%2C+C">Chenguang Liu</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Latz%2C+J">Jonas Latz</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> AISTATS 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18584" title="Abstract">arXiv:2305.18584</a> (replaced) [<a href="/pdf/2305.18584" title="Download PDF">pdf</a>, <a href="/format/2305.18584" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Coeditor: Leveraging Contextual Changes for Multi-round Code  Auto-editing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+J">Jiayi Wei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Durrett%2C+G">Greg Durrett</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dillig%2C+I">Isil Dillig</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The Twelfth International Conference on Learning Representations (2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18829" title="Abstract">arXiv:2305.18829</a> (replaced) [<a href="/pdf/2305.18829" title="Download PDF">pdf</a>, <a href="/format/2305.18829" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> UniScene: Multi-Camera Unified Pre-training via 3D Scene Reconstruction  for Autonomous Driving
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Min%2C+C">Chen Min</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+L">Liang Xiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+D">Dawei Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nie%2C+Y">Yiming Nie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dai%2C+B">Bin Dai</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by RAL2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Robotics (cs.RO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19480" title="Abstract">arXiv:2305.19480</a> (replaced) [<a href="/pdf/2305.19480" title="Download PDF">pdf</a>, <a href="/format/2305.19480" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning by Aligning 2D Skeleton Sequences and Multi-Modality Fusion
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tran%2C+Q">Quoc-Huy Tran</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ahmed%2C+M">Muhammad Ahmed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Popattia%2C+M">Murad Popattia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ahmed%2C+M+H">M. Hassan Ahmed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Konin%2C+A">Andrey Konin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zia%2C+M+Z">M. Zeeshan Zia</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01198" title="Abstract">arXiv:2306.01198</a> (replaced) [<a href="/pdf/2306.01198" title="Download PDF">pdf</a>, <a href="/format/2306.01198" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Confidence Intervals for Error Rates in 1:1 Matching Tasks: Critical  Statistical Analysis and Recommendations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Fogliato%2C+R">Riccardo Fogliato</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Patil%2C+P">Pratik Patil</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Perona%2C+P">Pietro Perona</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02558" title="Abstract">arXiv:2306.02558</a> (replaced) [<a href="/pdf/2306.02558" title="Download PDF">pdf</a>, <a href="/format/2306.02558" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-View Representation is What You Need for Point-Cloud Pre-Training
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+S">Siming Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+C">Chen Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kong%2C+Y">Youkang Kong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Q">Qixing Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Published in ICLR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05208" title="Abstract">arXiv:2306.05208</a> (replaced) [<a href="/pdf/2306.05208" title="Download PDF">pdf</a>, <a href="/format/2306.05208" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PriSampler: Mitigating Property Inference of Diffusion Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">Hailong Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pang%2C+J">Jun Pang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05806" title="Abstract">arXiv:2306.05806</a> (replaced) [<a href="/pdf/2306.05806" title="Download PDF">pdf</a>, <a href="/ps/2306.05806" title="Download PostScript">ps</a>, <a href="/format/2306.05806" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Robust Probabilistic Temporal Logics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zimmermann%2C+M">Martin Zimmermann</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07544" title="Abstract">arXiv:2306.07544</a> (replaced) [<a href="/pdf/2306.07544" title="Download PDF">pdf</a>, <a href="/format/2306.07544" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On Achieving Optimal Adversarial Test Error
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J+D">Justin D. Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Telgarsky%2C+M">Matus Telgarsky</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICLR 2023; bugs fixed
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08157" title="Abstract">arXiv:2306.08157</a> (replaced) [<a href="/pdf/2306.08157" title="Download PDF">pdf</a>, <a href="/format/2306.08157" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Causal Feature Engineering of Price Directions of Cryptocurrencies using  Dynamic Bayesian Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Amirzadeh%2C+R">Rasoul Amirzadeh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nazari%2C+A">Asef Nazari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Thiruvady%2C+D">Dhananjay Thiruvady</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ee%2C+M+S">Mong Shan Ee</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 32 pages, 8 figures, 6 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Statistical Finance (q-fin.ST)
  
  </div>
  </div>
  </dd>
  <dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08616" title="Abstract">arXiv:2306.08616</a> (replaced) [<a href="/pdf/2306.08616" title="Download PDF">pdf</a>, <a href="/format/2306.08616" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Automated Identification of Violation Symptoms of Architecture  Erosion
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+R">Ruiyin Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+P">Peng Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Avgeriou%2C+P">Paris Avgeriou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 21 pages, 4 images, 7 tables, Revision submitted to TSE (2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09278" title="Abstract">arXiv:2306.09278</a> (replaced) [<a href="/pdf/2306.09278" title="Download PDF">pdf</a>, <a href="/format/2306.09278" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Robustness Analysis on Foundational Segmentation Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Schiappa%2C+M+C">Madeline Chantry Schiappa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Azad%2C+S">Shehreen Azad</a>, 
  <a href="/search/cs?searchtype=author&amp;query=VS%2C+S">Sachidanand VS</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ge%2C+Y">Yunhao Ge</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Miksik%2C+O">Ondrej Miksik</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rawat%2C+Y+S">Yogesh S. Rawat</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vineet%2C+V">Vibhav Vineet</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This benchmark along with the code and datasets is available at: <a href="https://tinyurl.com/fm-robust.">this https URL</a> Accepted at CVPRW 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10648" title="Abstract">arXiv:2306.10648</a> (replaced) [<a href="/pdf/2306.10648" title="Download PDF">pdf</a>, <a href="/format/2306.10648" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bidder Selection Problem in Position Auctions: A Fast and Simple  Algorithm via Poisson Approximation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gravin%2C+N">Nickolai Gravin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Y+E">Yixuan Even Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+R">Renfei Zhou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 19 pages; in WWW 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10784" title="Abstract">arXiv:2306.10784</a> (replaced) [<a href="/pdf/2306.10784" title="Download PDF">pdf</a>, <a href="/ps/2306.10784" title="Download PostScript">ps</a>, <a href="/format/2306.10784" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On the minimum number of arcs in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-391-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2611" style="width: 0.674em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.54em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1000.495em, 2.646em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-2612"><span class="mn" id="MathJax-Span-2613" style="font-family: STIXGeneral-Regular;">4</span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.947em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-391">4</script>-dicritical oriented graphs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Havet%2C+F">Frédéric Havet</a>, 
  <a href="/search/math?searchtype=author&amp;query=Picasarri-Arrieta%2C+L">Lucas Picasarri-Arrieta</a>, 
  <a href="/search/math?searchtype=author&amp;query=Rambaud%2C+C">Clément Rambaud</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 31 pages, 6 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
  
  </div>
  </div>
  </dd>
  <dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10947" title="Abstract">arXiv:2306.10947</a> (replaced) [<a href="/pdf/2306.10947" title="Download PDF">pdf</a>, <a href="/format/2306.10947" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PAC-Chernoff Bounds: Understanding Generalization in the Interpolation  Regime
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Masegosa%2C+A+R">Andrés R. Masegosa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ortega%2C+L+A">Luis A. Ortega</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 56 pages, 11 figures, Pre-print
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11876" title="Abstract">arXiv:2306.11876</a> (replaced) [<a href="/pdf/2306.11876" title="Download PDF">pdf</a>, <a href="/format/2306.11876" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> BMAD: Benchmarks for Medical Anomaly Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Bao%2C+J">Jinan Bao</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Sun%2C+H">Hanshi Sun</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Deng%2C+H">Hanqiu Deng</a>, 
  <a href="/search/eess?searchtype=author&amp;query=He%2C+Y">Yinsheng He</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+Z">Zhaoxiang Zhang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Li%2C+X">Xingyu Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11991" title="Abstract">arXiv:2306.11991</a> (replaced) [<a href="/pdf/2306.11991" title="Download PDF">pdf</a>, <a href="/format/2306.11991" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generalizable Metric Network for Cross-domain Person Re-identification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Qi%2C+L">Lei Qi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yinghuan Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Geng%2C+X">Xin Geng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by IEEE TCSVT
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12189" title="Abstract">arXiv:2306.12189</a> (replaced) [<a href="/pdf/2306.12189" title="Download PDF">pdf</a>, <a href="/format/2306.12189" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Annotating Ambiguous Images: General Annotation Strategy for  High-Quality Data with Real-World Biomedical Validation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Schmarje%2C+L">Lars Schmarje</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Grossmann%2C+V">Vasco Grossmann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zelenka%2C+C">Claudius Zelenka</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Br%C3%BCnger%2C+J">Johannes Brünger</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Koch%2C+R">Reinhard Koch</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at ICLR 2024, DMLR Workshop
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00827" title="Abstract">arXiv:2307.00827</a> (replaced) [<a href="/pdf/2307.00827" title="Download PDF">pdf</a>, <a href="/ps/2307.00827" title="Download PostScript">ps</a>, <a href="/format/2307.00827" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Toward a Mapping of Capability and Skill Models using Asset  Administration Shells and Ontologies
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=da+Silva%2C+L+M+V">Luis Miguel Vieira da Silva</a>, 
  <a href="/search/cs?searchtype=author&amp;query=K%C3%B6cher%2C+A">Aljosha Köcher</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gill%2C+M+S">Milapji Singh Gill</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Weiss%2C+M">Marco Weiss</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fay%2C+A">Alexander Fay</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> \c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computational Engineering, Finance, and Science (cs.CE)
  
  </div>
  </div>
  </dd>
  <dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03571" title="Abstract">arXiv:2307.03571</a> (replaced) [<a href="/pdf/2307.03571" title="Download PDF">pdf</a>, <a href="/format/2307.03571" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Smoothing the Edges: Smooth Optimization for Sparse Regularization using  Hadamard Overparametrization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kolb%2C+C">Chris Kolb</a>, 
  <a href="/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+C+L">Christian L. Müller</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bischl%2C+B">Bernd Bischl</a>, 
  <a href="/search/cs?searchtype=author&amp;query=R%C3%BCgamer%2C+D">David Rügamer</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04050" title="Abstract">arXiv:2307.04050</a> (replaced) [<a href="/pdf/2307.04050" title="Download PDF">pdf</a>, <a href="/format/2307.04050" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Optimization-based Learning for Dynamic Load Planning in Trucking  Service Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ojha%2C+R">Ritesh Ojha</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+W">Wenbo Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hanyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khir%2C+R">Reem Khir</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Erera%2C+A">Alan Erera</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Van+Hentenryck%2C+P">Pascal Van Hentenryck</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05370" title="Abstract">arXiv:2307.05370</a> (replaced) [<a href="/pdf/2307.05370" title="Download PDF">pdf</a>, <a href="/format/2307.05370" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Origami Single-end Capacitive Sensing for Continuous Shape Estimation of  Morphing Structures
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ray%2C+L+S+S">Lala Shakti Swarup Ray</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gei%C3%9Fler%2C+D">Daniel Geißler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+B">Bo Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lukowicz%2C+P">Paul Lukowicz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Greinke%2C+B">Berit Greinke</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Signal Processing (eess.SP)
  
  </div>
  </div>
  </dd>
  <dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05415" title="Abstract">arXiv:2307.05415</a> (replaced) [<a href="/pdf/2307.05415" title="Download PDF">pdf</a>, <a href="/format/2307.05415" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Reliable optimal controls for SEIR models in epidemiology
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Cacace%2C+S">Simone Cacace</a>, 
  <a href="/search/math?searchtype=author&amp;query=Oliviero%2C+A">Alessio Oliviero</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)
  
  </div>
  </div>
  </dd>
  <dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06281" title="Abstract">arXiv:2307.06281</a> (replaced) [<a href="/pdf/2307.06281" title="Download PDF">pdf</a>, <a href="/format/2307.06281" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MMBench: Is Your Multi-modal Model an All-around Player?
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Duan%2C+H">Haodong Duan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuanhan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bo Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Songyang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+W">Wangbo Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yike Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaqi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+C">Conghui He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziwei Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+K">Kai Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+D">Dahua Lin</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08529" title="Abstract">arXiv:2307.08529</a> (replaced) [<a href="/pdf/2307.08529" title="Download PDF">pdf</a>, <a href="/format/2307.08529" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Synthetic Lagrangian Turbulence by Generative Diffusion Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Li%2C+T">Tianyi Li</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Biferale%2C+L">Luca Biferale</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Bonaccorso%2C+F">Fabio Bonaccorso</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Scarpolini%2C+M+A">Martino Andrea Scarpolini</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Buzzicotti%2C+M">Michele Buzzicotti</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> We include Supplementary Information as a separate PDF file available in the Tex Source download area
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Nat Mach Intell 6, 393-403 (2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Statistical Mechanics (cond-mat.stat-mech); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Chaotic Dynamics (nlin.CD)
  
  </div>
  </div>
  </dd>
  <dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08874" title="Abstract">arXiv:2307.08874</a> (replaced) [<a href="/pdf/2307.08874" title="Download PDF">pdf</a>, <a href="/format/2307.08874" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Latent Space Representations of Neural Algorithmic Reasoners
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mirjani%C4%87%2C+V+V">Vladimir V. Mirjanić</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pascanu%2C+R">Razvan Pascanu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Veli%C4%8Dkovi%C4%87%2C+P">Petar Veličković</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 24 pages, 19 figures; Accepted at the Second Learning on Graphs Conference (LoG 2023); updated layout, reorganized content, added journal reference
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> PMLR 231:10:1-10:24, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10700" title="Abstract">arXiv:2307.10700</a> (replaced) [<a href="/pdf/2307.10700" title="Download PDF">pdf</a>, <a href="/format/2307.10700" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Topics, Authors, and Institutions in Large Language Model Research:  Trends from 17K arXiv Papers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Movva%2C+R">Rajiv Movva</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Balachandar%2C+S">Sidhika Balachandar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+K">Kenny Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agostini%2C+G">Gabriel Agostini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Garg%2C+N">Nikhil Garg</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pierson%2C+E">Emma Pierson</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> NAACL 2024. Data &amp; code available at <a href="https://github.com/rmovva/LLM-publication-patterns-public">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11470" title="Abstract">arXiv:2307.11470</a> (replaced) [<a href="/pdf/2307.11470" title="Download PDF">pdf</a>, <a href="/format/2307.11470" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Physics-Aware Semi-Supervised Underwater Image Enhancement
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Qi%2C+H">Hao Qi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+X">Xinghui Dong</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages, 5 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12114" title="Abstract">arXiv:2307.12114</a> (replaced) [<a href="/pdf/2307.12114" title="Download PDF">pdf</a>, <a href="/ps/2307.12114" title="Download PostScript">ps</a>, <a href="/format/2307.12114" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language  Models Applied to Clinical and Biomedical Tasks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Labrak%2C+Y">Yanis Labrak</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rouvier%2C+M">Mickael Rouvier</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dufour%2C+R">Richard Dufour</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Under review process
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> The 2024 Joint International Conference on Computational
    Linguistics, Language Resources and Evaluation (LREC-COLING 2024), May 2024,
    Torino, Italy
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14566" title="Abstract">arXiv:2307.14566</a> (replaced) [<a href="/pdf/2307.14566" title="Download PDF">pdf</a>, <a href="/ps/2307.14566" title="Download PostScript">ps</a>, <a href="/format/2307.14566" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Limiting Moments of Autocorrelation Demerit Factors of Binary Sequences
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Katz%2C+D+J">Daniel J. Katz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ramirez%2C+M+E">Miriam E. Ramirez</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 27 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Signal Processing (eess.SP); Combinatorics (math.CO); Probability (math.PR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15051" title="Abstract">arXiv:2307.15051</a> (replaced) [<a href="/pdf/2307.15051" title="Download PDF">pdf</a>, <a href="/ps/2307.15051" title="Download PostScript">ps</a>, <a href="/format/2307.15051" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Matching Patients to Clinical Trials with Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jin%2C+Q">Qiao Jin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zifeng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Floudas%2C+C+S">Charalampos S. Floudas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+F">Fangyuan Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gong%2C+C">Changlin Gong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bracken-Clarke%2C+D">Dara Bracken-Clarke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+E">Elisabetta Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yifan Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jimeng Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhiyong Lu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Under review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00964" title="Abstract">arXiv:2308.00964</a> (replaced) [<a href="/pdf/2308.00964" title="Download PDF">pdf</a>, <a href="/format/2308.00964" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ForensicsForest Family: A Series of Multi-scale Hierarchical Cascade  Forests for Detecting GAN-generated Faces
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+J">Jiucui Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jiaran Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+J">Junyu Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bin Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lyu%2C+S">Siwei Lyu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuezun Li</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> To Appear in IEEE TIFS 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01286" title="Abstract">arXiv:2308.01286</a> (replaced) [<a href="/pdf/2308.01286" title="Download PDF">pdf</a>, <a href="/ps/2308.01286" title="Download PostScript">ps</a>, <a href="/format/2308.01286" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enumeration Kernels of Polynomial Size for Cuts of Bounded Degree
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Majumdar%2C+D">Diptapriyo Majumdar</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> There have been major revision in the technicalities and proofs of the paper
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)
  
  </div>
  </div>
  </dd>
  <dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01917" title="Abstract">arXiv:2308.01917</a> (replaced) [<a href="/pdf/2308.01917" title="Download PDF">pdf</a>, <a href="/format/2308.01917" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PePNet: A Periodicity-Perceived Workload Prediction Network Supporting  Rare Occurrence of Heavy Workload
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+F">Feiyi Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qin%2C+Z">Zhen Qin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hailiang Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Deng%2C+S">Shuiguang Deng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to TKDE 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02194" title="Abstract">arXiv:2308.02194</a> (replaced) [<a href="/pdf/2308.02194" title="Download PDF">pdf</a>, <a href="/format/2308.02194" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Paired Competing Neurons Improving STDP Supervised Local Learning In  Spiking Neural Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Goupy%2C+G">Gaspard Goupy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tirilly%2C+P">Pierre Tirilly</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bilasco%2C+I+M">Ioan Marius Bilasco</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04103" title="Abstract">arXiv:2308.04103</a> (replaced) [<a href="/pdf/2308.04103" title="Download PDF">pdf</a>, <a href="/ps/2308.04103" title="Download PostScript">ps</a>, <a href="/format/2308.04103" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Explainable machine learning to enable high-throughput electrical  conductivity optimization and discovery of doped conjugated polymers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Yoon%2C+J+W">Ji Wei Yoon</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Kumar%2C+A">Adithya Kumar</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Kumar%2C+P">Pawan Kumar</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Hippalgaonkar%2C+K">Kedar Hippalgaonkar</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Senthilnath%2C+J">J Senthilnath</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Chellappan%2C+V">Vijila Chellappan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 33 Pages, 17 figures
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Knowledge-Based Systems 295C (2024) 111812
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05459" title="Abstract">arXiv:2308.05459</a> (replaced) [<a href="/pdf/2308.05459" title="Download PDF">pdf</a>, <a href="/format/2308.05459" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> KS-APR: Keyframe Selection for Robust Absolute Pose Regression
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Changkun Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yukun Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Braud%2C+T">Tristan Braud</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05593" title="Abstract">arXiv:2308.05593</a> (replaced) [<a href="/pdf/2308.05593" title="Download PDF">pdf</a>, <a href="/format/2308.05593" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Robust Lifelong Indoor LiDAR Localization using the Area Graph
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+F">Fujing Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schwertfeger%2C+S">Sören Schwertfeger</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07523" title="Abstract">arXiv:2308.07523</a> (replaced) [<a href="/pdf/2308.07523" title="Download PDF">pdf</a>, <a href="/format/2308.07523" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Deep Neural Operator Driven Real Time Inference for Nuclear Systems to  Enable Digital Twin Solutions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Kobayashi%2C+K">Kazuma Kobayashi</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Alam%2C+S+B">Syed Bahauddin Alam</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Sci Rep 14, 2101 (2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07821" title="Abstract">arXiv:2308.07821</a> (replaced) [<a href="/pdf/2308.07821" title="Download PDF">pdf</a>, <a href="/ps/2308.07821" title="Download PostScript">ps</a>, <a href="/format/2308.07821" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Nearly Quadratic-Time FPTAS for Knapsack
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Lin Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lian%2C+J">Jiayi Lian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mao%2C+Y">Yuchen Mao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guochuan Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09474" title="Abstract">arXiv:2308.09474</a> (replaced) [<a href="/pdf/2308.09474" title="Download PDF">pdf</a>, <a href="/format/2308.09474" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Evolving Scientific Discovery by Unifying Data and Background Knowledge  with AI Hilbert
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cory-Wright%2C+R">Ryan Cory-Wright</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cornelio%2C+C">Cristina Cornelio</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dash%2C+S">Sanjeeb Dash</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khadir%2C+B+E">Bachir El Khadir</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Horesh%2C+L">Lior Horesh</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Revised version, including a significant number of new experiments+supplementary material in appendix, and a title change
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Symbolic Computation (cs.SC); Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11228" title="Abstract">arXiv:2308.11228</a> (replaced) [<a href="/pdf/2308.11228" title="Download PDF">pdf</a>, <a href="/format/2308.11228" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> VIO-DualProNet: Visual-Inertial Odometry with Learning Based Process  Noise Covariance
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Solodar%2C+D">Dan Solodar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Klein%2C+I">Itzik Klein</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 15 figures, bib file
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Engineering Applications of Artificial Intelligence, 133, (2024)
    108466
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11738" title="Abstract">arXiv:2308.11738</a> (replaced) [<a href="/pdf/2308.11738" title="Download PDF">pdf</a>, <a href="/ps/2308.11738" title="Download PostScript">ps</a>, <a href="/format/2308.11738" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Lifted Inference beyond First-Order Logic
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Malhotra%2C+S">Sagar Malhotra</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bizzaro%2C+D">Davide Bizzaro</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Serafini%2C+L">Luciano Serafini</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Under Review at the Artificial Intelligence Journal. arXiv admin note: text overlap with <a href="/abs/2302.09830">arXiv:2302.09830</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12066" title="Abstract">arXiv:2308.12066</a> (replaced) [<a href="/pdf/2308.12066" title="Download PDF">pdf</a>, <a href="/format/2308.12066" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Pre-gated MoE: An Algorithm-System Co-Design for Fast and Scalable  Mixture-of-Expert Inference
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hwang%2C+R">Ranggi Hwang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+J">Jianyu Wei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+S">Shijie Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hwang%2C+C">Changho Hwang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+X">Xiaohu Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+T">Ting Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+M">Mao Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13222" title="Abstract">arXiv:2308.13222</a> (replaced) [<a href="/pdf/2308.13222" title="Download PDF">pdf</a>, <a href="/ps/2308.13222" title="Download PostScript">ps</a>, <a href="/format/2308.13222" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bayesian Reasoning for Physics Informed Neural Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Graczyk%2C+K+M">Krzysztof M. Graczyk</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Witkowski%2C+K">Kornel Witkowski</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 22 pages, 12 figures, the description of the method extended, one more example added, improved the numerical analysis
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Fluid Dynamics (physics.flu-dyn); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00848" title="Abstract">arXiv:2309.00848</a> (replaced) [<a href="/e-print/2309.00848" title="Download source">src</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bengali Document Layout Analysis -- A YOLOV8 Based Ensembling Approach
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ahmed%2C+N+S">Nazmus Sakib Ahmed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Noor%2C+S+S">Saad Sakib Noor</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sikder%2C+A+I+S">Ashraful Islam Shanto Sikder</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Paul%2C+A">Abhijit Paul</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Need to review and rework this
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02072" title="Abstract">arXiv:2309.02072</a> (replaced) [<a href="/pdf/2309.02072" title="Download PDF">pdf</a>, <a href="/format/2309.02072" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Data Scaling Effect of Deep Learning in Financial Time Series  Forecasting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/econ?searchtype=author&amp;query=Liu%2C+C">Chen Liu</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Tran%2C+M">Minh-Ngoc Tran</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Wang%2C+C">Chao Wang</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Gerlach%2C+R">Richard Gerlach</a>, 
  <a href="/search/econ?searchtype=author&amp;query=Kohn%2C+R">Robert Kohn</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Artificial Intelligence (cs.AI); Computational Finance (q-fin.CP)
  
  </div>
  </div>
  </dd>
  <dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04160" title="Abstract">arXiv:2309.04160</a> (replaced) [<a href="/pdf/2309.04160" title="Download PDF">pdf</a>, <a href="/format/2309.04160" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PRISM: Leveraging Prototype Patient Representations with  Feature-Missing-Aware Calibration for EHR Data Sparsity Mitigation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yinghao Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zixiang Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+L">Long He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+S">Shiyun Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+L">Liantao Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+C">Chengwei Pan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05273" title="Abstract">arXiv:2309.05273</a> (replaced) [<a href="/pdf/2309.05273" title="Download PDF">pdf</a>, <a href="/format/2309.05273" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Formalizing Multimedia Recommendation through Multimodal Deep Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Malitesta%2C+D">Daniele Malitesta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cornacchia%2C+G">Giandomenico Cornacchia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pomo%2C+C">Claudio Pomo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Merra%2C+F+A">Felice Antonio Merra</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Di+Noia%2C+T">Tommaso Di Noia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Di+Sciascio%2C+E">Eugenio Di Sciascio</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted in the Special Issue on Knowledge Transferring for Recommender Systems (KT4Rec) in ACM Transactions on Recommender Systems
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07384" title="Abstract">arXiv:2309.07384</a> (replaced) [<a href="/pdf/2309.07384" title="Download PDF">pdf</a>, <a href="/format/2309.07384" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An Interactive Framework for Profiling News Media Sources
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mehta%2C+N">Nikhil Mehta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Goldwasser%2C+D">Dan Goldwasser</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> NAACL 2024 Main Conference
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07447" title="Abstract">arXiv:2309.07447</a> (replaced) [<a href="/pdf/2309.07447" title="Download PDF">pdf</a>, <a href="/format/2309.07447" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Commercial Anti-Smishing Tools and Their Comparative Effectiveness  Against Modern Threats
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Timko%2C+D">Daniel Timko</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rahman%2C+M+L">Muhammad Lutfor Rahman</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Proceedings of the 16th ACM Conference on Security and Privacy in
    Wireless and Mobile Networks, 1-12, 2023
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07672" title="Abstract">arXiv:2309.07672</a> (replaced) [<a href="/pdf/2309.07672" title="Download PDF">pdf</a>, <a href="/ps/2309.07672" title="Download PostScript">ps</a>, <a href="/format/2309.07672" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Physics-constrained robust learning of open-form partial differential  equations from limited and noisy data
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Du%2C+M">Mengge Du</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuntian Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nie%2C+L">Longfeng Nie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lou%2C+S">Siyu Lou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+D">Dongxiao Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Applications (stat.AP)
  
  </div>
  </div>
  </dd>
  <dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07779" title="Abstract">arXiv:2309.07779</a> (replaced) [<a href="/pdf/2309.07779" title="Download PDF">pdf</a>, <a href="/ps/2309.07779" title="Download PostScript">ps</a>, <a href="/format/2309.07779" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Convergence analysis of online algorithms for vector-valued kernel  regression
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Griebel%2C+M">Michael Griebel</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Oswald%2C+P">Peter Oswald</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 18 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Numerical Analysis (math.NA)
  
  </div>
  </div>
  </dd>
  <dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08415" title="Abstract">arXiv:2309.08415</a> (replaced) [<a href="/pdf/2309.08415" title="Download PDF">pdf</a>, <a href="/ps/2309.08415" title="Download PostScript">ps</a>, <a href="/format/2309.08415" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A new method of modeling the multi-stage decision-making process of CRT  using machine learning with uncertainty quantification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Larsen%2C+K">Kristoffer Larsen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+C">Chen Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Keyak%2C+J">Joyce Keyak</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sha%2C+Q">Qiuying Sha</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Paez%2C+D">Diana Paez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xinwei Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hung%2C+G">Guang-Uei Hung</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zou%2C+J">Jiangang Zou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peix%2C+A">Amalia Peix</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+W">Weihua Zhou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 30 pages,6 figures. arXiv admin note: text overlap with <a href="/abs/2305.02475">arXiv:2305.02475</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Medical Physics (physics.med-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08513" title="Abstract">arXiv:2309.08513</a> (replaced) [<a href="/pdf/2309.08513" title="Download PDF">pdf</a>, <a href="/format/2309.08513" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SCT: A Simple Baseline for Parameter-Efficient Fine-Tuning via Salient  Channels
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H+H">Henry Hengyuan Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+P">Pichao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yuyang Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+H">Hao Luo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+F">Fan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shou%2C+M+Z">Mike Zheng Shou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This work has been accepted by IJCV
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08849" title="Abstract">arXiv:2309.08849</a> (replaced) [<a href="/pdf/2309.08849" title="Download PDF">pdf</a>, <a href="/ps/2309.08849" title="Download PostScript">ps</a>, <a href="/format/2309.08849" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning a Stable Dynamic System with a Lyapunov Energy Function for  Demonstratives Using Neural Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zou%2C+Y">Yongxiang Zou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Haoyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xia%2C+X">Xiuze Xia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+L">Long Cheng</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08891" title="Abstract">arXiv:2309.08891</a> (replaced) [<a href="/pdf/2309.08891" title="Download PDF">pdf</a>, <a href="/format/2309.08891" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> V2CE: Video to Continuous Events Simulator
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhongyang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cui%2C+S">Shuyang Cui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chai%2C+K">Kaidong Chai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Haowen Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dasgupta%2C+S">Subhasis Dasgupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mahbub%2C+U">Upal Mahbub</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rahman%2C+T">Tauhidur Rahman</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages, 7 figures, IEEE International Conference on Robotics and Automation (ICRA) 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09007" title="Abstract">arXiv:2309.09007</a> (replaced) [<a href="/pdf/2309.09007" title="Download PDF">pdf</a>, <a href="/format/2309.09007" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MonoForce: Self-supervised Learning of Physics-aware Model for  Predicting Robot-terrain Interaction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Agishev%2C+R">Ruslan Agishev</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zimmermann%2C+K">Karel Zimmermann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kubelka%2C+V">Vladimír Kubelka</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pecka%2C+M">Martin Pecka</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Svoboda%2C+T">Tomáš Svoboda</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10511" title="Abstract">arXiv:2309.10511</a> (replaced) [<a href="/pdf/2309.10511" title="Download PDF">pdf</a>, <a href="/ps/2309.10511" title="Download PostScript">ps</a>, <a href="/format/2309.10511" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Self2Seg: Single-Image Self-Supervised Joint Segmentation and Denoising
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gruber%2C+N">Nadja Gruber</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schwab%2C+J">Johannes Schwab</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Debroux%2C+N">Noémie Debroux</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Papadakis%2C+N">Nicolas Papadakis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Haltmeier%2C+M">Markus Haltmeier</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12019" title="Abstract">arXiv:2309.12019</a> (replaced) [<a href="/pdf/2309.12019" title="Download PDF">pdf</a>, <a href="/format/2309.12019" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Dissipative WENO stabilization of high-order discontinuous Galerkin  methods for hyperbolic problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Vedral%2C+J">Joshua Vedral</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Added more benchmark results. Solution to Woodward-Colella blast wave problem is displayed on finer mesh
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12245" title="Abstract">arXiv:2309.12245</a> (replaced) [<a href="/pdf/2309.12245" title="Download PDF">pdf</a>, <a href="/format/2309.12245" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Adaptive Input-image Normalization for Solving the Mode Collapse Problem  in GAN-based X-ray Images
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Saad%2C+M+M">Muhammad Muneeb Saad</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Rehmani%2C+M+H">Mubashir Husain Rehmani</a>, 
  <a href="/search/eess?searchtype=author&amp;query=O%27Reilly%2C+R">Ruairi O'Reilly</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to the Elsevier Journal
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12766" title="Abstract">arXiv:2309.12766</a> (replaced) [<a href="/pdf/2309.12766" title="Download PDF">pdf</a>, <a href="/format/2309.12766" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Study on Incorporating Whisper for Robust Speech Assessment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Zezario%2C+R+E">Ryandhimas E. Zezario</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Chen%2C+Y">Yu-Wen Chen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Fu%2C+S">Szu-Wei Fu</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Tsao%2C+Y">Yu Tsao</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wang%2C+H">Hsin-Min Wang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Fuh%2C+C">Chiou-Shann Fuh</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to IEEE ICME 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
  
  </div>
  </div>
  </dd>
  <dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14085" title="Abstract">arXiv:2309.14085</a> (replaced) [<a href="/pdf/2309.14085" title="Download PDF">pdf</a>, <a href="/format/2309.14085" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> New algebraic fast algorithms for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-392-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2614" style="width: 0.898em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.719em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1000.719em, 2.646em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-2615"><span class="mi" id="MathJax-Span-2616" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.047em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.947em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-392">N</script>-body problems in two and three  dimensions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Khan%2C+R">Ritesh Khan</a>, 
  <a href="/search/math?searchtype=author&amp;query=Ambikasaran%2C+S">Sivaram Ambikasaran</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 41 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14162" title="Abstract">arXiv:2309.14162</a> (replaced) [<a href="/pdf/2309.14162" title="Download PDF">pdf</a>, <a href="/format/2309.14162" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Data Upcycling Knowledge Distillation for Image Super-Resolution
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yun Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Wei Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Simiao Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hanting Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tu%2C+Z">Zhijun Tu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenjia Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jing%2C+B">Bingyi Jing</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+S">Shaohui Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Jie Hu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16937" title="Abstract">arXiv:2309.16937</a> (replaced) [<a href="/pdf/2309.16937" title="Download PDF">pdf</a>, <a href="/format/2309.16937" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SSHR: Leveraging Self-supervised Hierarchical Representations for  Multilingual Automatic Speech Recognition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+H">Hongfei Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shao%2C+Q">Qijie Shao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+K">Kaixun Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+P">Peikun Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jie Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+L">Lei Xie</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 5 pages, 2 figures. Accepted by ICME 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17196" title="Abstract">arXiv:2309.17196</a> (replaced) [<a href="/pdf/2309.17196" title="Download PDF">pdf</a>, <a href="/format/2309.17196" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ResBit: Residual Bit Vector for Categorical Values
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fuchi%2C+M">Masane Fuchi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zanashir%2C+A">Amar Zanashir</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Minami%2C+H">Hiroto Minami</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Takagi%2C+T">Tomohiro Takagi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 24pages, 8 figures, 29 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02075" title="Abstract">arXiv:2310.02075</a> (replaced) [<a href="/pdf/2310.02075" title="Download PDF">pdf</a>, <a href="/format/2310.02075" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning Quantum Processes with Quantum Statistical Queries
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Wadhwa%2C+C">Chirag Wadhwa</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Doosti%2C+M">Mina Doosti</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 46 pages, 3 figures. v2: Added lower bounds (Section 6)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02980" title="Abstract">arXiv:2310.02980</a> (replaced) [<a href="/pdf/2310.02980" title="Download PDF">pdf</a>, <a href="/format/2310.02980" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Never Train from Scratch: Fair Comparison of Long-Sequence Models  Requires Data-Driven Priors
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Amos%2C+I">Ido Amos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Berant%2C+J">Jonathan Berant</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+A">Ankit Gupta</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03584" title="Abstract">arXiv:2310.03584</a> (replaced) [<a href="/pdf/2310.03584" title="Download PDF">pdf</a>, <a href="/ps/2310.03584" title="Download PostScript">ps</a>, <a href="/format/2310.03584" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Minimum number of arcs in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-393-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2617" style="width: 0.585em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.45em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1000.45em, 2.646em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-2618"><span class="mi" id="MathJax-Span-2619" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.947em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-393">k</script>-critical digraphs with order at most  <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-394-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2620" style="width: 3.362em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.69em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1002.601em, 2.78em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-2621"><span class="mn" id="MathJax-Span-2622" style="font-family: STIXGeneral-Regular;">2</span><span class="mi" id="MathJax-Span-2623" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-2624" style="font-family: STIXGeneral-Regular; padding-left: 0.271em;">−</span><span class="mn" id="MathJax-Span-2625" style="font-family: STIXGeneral-Regular; padding-left: 0.271em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.219em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.114em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-394">2k-1</script>
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Picasarri-Arrieta%2C+L">Lucas Picasarri-Arrieta</a>, 
  <a href="/search/math?searchtype=author&amp;query=Stiebitz%2C+M">Michael Stiebitz</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
  
  </div>
  </div>
  </dd>
  <dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04063" title="Abstract">arXiv:2310.04063</a> (replaced) [<a href="/pdf/2310.04063" title="Download PDF">pdf</a>, <a href="/format/2310.04063" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Globally Optimal Resource Allocation Design for Discrete Phase Shift  IRS-Assisted Multiuser Networks with Perfect and Imperfect CSI
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yifei Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+D">Dongfang Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schober%2C+R">Robert Schober</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gerstacker%2C+W">Wolfgang Gerstacker</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05765" title="Abstract">arXiv:2310.05765</a> (replaced) [<a href="/pdf/2310.05765" title="Download PDF">pdf</a>, <a href="/format/2310.05765" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Examining the simulation-to-reality gap of a wheel loader digging in  deformable terrain
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Aoshima%2C+K">Koji Aoshima</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Servin%2C+M">Martin Servin</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 22 pages, 15 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Robotics (cs.RO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07418" title="Abstract">arXiv:2310.07418</a> (replaced) [<a href="/pdf/2310.07418" title="Download PDF">pdf</a>, <a href="/format/2310.07418" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules  and Training Stages
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+G">Guozheng Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Lu Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Sen Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zixuan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhen Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yixin Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shen%2C+L">Li Shen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xueqian Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tao%2C+D">Dacheng Tao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICLR 2024 poster
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07545" title="Abstract">arXiv:2310.07545</a> (replaced) [<a href="/pdf/2310.07545" title="Download PDF">pdf</a>, <a href="/format/2310.07545" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Large-Language-Model-Powered Agent-Based Framework for Misinformation  and Disinformation Research: Opportunities and Open Challenges
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pastor-Galindo%2C+J">Javier Pastor-Galindo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nespoli%2C+P">Pantaleone Nespoli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ruip%C3%A9rez-Valiente%2C+J+A">José A. Ruipérez-Valiente</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> IEEE Security &amp; Privacy, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Multiagent Systems (cs.MA)
  
  </div>
  </div>
  </dd>
  <dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07805" title="Abstract">arXiv:2310.07805</a> (replaced) [<a href="/pdf/2310.07805" title="Download PDF">pdf</a>, <a href="/format/2310.07805" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generative Modeling with Phase Stochastic Bridges
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Tianrong Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gu%2C+J">Jiatao Gu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dinh%2C+L">Laurent Dinh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Theodorou%2C+E+A">Evangelos A. Theodorou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Susskind%2C+J">Joshua Susskind</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+S">Shuangfei Zhai</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07902" title="Abstract">arXiv:2310.07902</a> (replaced) [<a href="/pdf/2310.07902" title="Download PDF">pdf</a>, <a href="/format/2310.07902" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Unraveling the Single Tangent Space Fallacy: An Analysis and  Clarification for Applying Riemannian Geometry in Robot Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jaquier%2C+N">Noémie Jaquier</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rozo%2C+L">Leonel Rozo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Asfour%2C+T">Tamim Asfour</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted for publication in ICRA'24. 8 pages, 5 figures, 3 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08383" title="Abstract">arXiv:2310.08383</a> (replaced) [<a href="/pdf/2310.08383" title="Download PDF">pdf</a>, <a href="/format/2310.08383" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Reconstructing Materials Tetrahedron: Challenges in Materials  Information Extraction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hira%2C+K">Kausik Hira</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zaki%2C+M">Mohd Zaki</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sheth%2C+D">Dhruvil Sheth</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mausam">Mausam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Krishnan%2C+N+M+A">N M Anoop Krishnan</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Digital Discovery, 2024, Advance Article
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Materials Science (cond-mat.mtrl-sci)
  
  </div>
  </div>
  </dd>
  <dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08602" title="Abstract">arXiv:2310.08602</a> (replaced) [<a href="/pdf/2310.08602" title="Download PDF">pdf</a>, <a href="/format/2310.08602" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Safe Deep Policy Adaptation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+W">Wenli Xiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+T">Tairan He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dolan%2C+J">John Dolan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+G">Guanya Shi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICRA 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09413" title="Abstract">arXiv:2310.09413</a> (replaced) [<a href="/pdf/2310.09413" title="Download PDF">pdf</a>, <a href="/format/2310.09413" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ZeroSwap: Data-driven Optimal Market Making in DeFi
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nadkarni%2C+V">Viraj Nadkarni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Jiachen Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rana%2C+R">Ranvir Rana</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jin%2C+C">Chi Jin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kulkarni%2C+S">Sanjeev Kulkarni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Viswanath%2C+P">Pramod Viswanath</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)
  
  </div>
  </div>
  </dd>
  <dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10586" title="Abstract">arXiv:2310.10586</a> (replaced) [<a href="/pdf/2310.10586" title="Download PDF">pdf</a>, <a href="/format/2310.10586" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> VidCoM: Fast Video Comprehension through Large Language Models with  Multimodal Tools
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Qi%2C+J">Ji Qi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ji%2C+K">Kaixuan Ji</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Jifan Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+D">Duokang Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+B">Bin Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hou%2C+L">Lei Hou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Juanzi Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11401" title="Abstract">arXiv:2310.11401</a> (replaced) [<a href="/pdf/2310.11401" title="Download PDF">pdf</a>, <a href="/format/2310.11401" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhancing Group Fairness in Online Settings Using Oblique Decision  Forests
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chowdhury%2C+S+B+R">Somnath Basu Roy Chowdhury</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Monath%2C+N">Nicholas Monath</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Beirami%2C+A">Ahmad Beirami</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kidambi%2C+R">Rahul Kidambi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dubey%2C+A">Avinava Dubey</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ahmed%2C+A">Amr Ahmed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chaturvedi%2C+S">Snigdha Chaturvedi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICLR 2024 (Spotlight)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11684" title="Abstract">arXiv:2310.11684</a> (replaced) [<a href="/pdf/2310.11684" title="Download PDF">pdf</a>, <a href="/format/2310.11684" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quantum Speedups in Regret Analysis of Infinite Horizon Average-Reward  Markov Decision Processes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ganguly%2C+B">Bhargav Ganguly</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yang Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aggarwal%2C+V">Vaneet Aggarwal</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantum Physics (quant-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13193" title="Abstract">arXiv:2310.13193</a> (replaced) [<a href="/pdf/2310.13193" title="Download PDF">pdf</a>, <a href="/format/2310.13193" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Heterogeneous Graph Neural Networks for End-to-End Traffic Assignment  and Traffic Flow Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+T">Tong Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Meidani%2C+H">Hadi Meidani</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 16 pages, 8 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13219" title="Abstract">arXiv:2310.13219</a> (replaced) [<a href="/pdf/2310.13219" title="Download PDF">pdf</a>, <a href="/format/2310.13219" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> HierCas: Hierarchical Temporal Graph Attention Networks for Popularity  Prediction in Information Cascades
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhizhen Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+X">Xiaohui Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yishuo Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lanshan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yong Jiang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by IJCNN'24
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13828" title="Abstract">arXiv:2310.13828</a> (replaced) [<a href="/pdf/2310.13828" title="Download PDF">pdf</a>, <a href="/format/2310.13828" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Nightshade: Prompt-Specific Poisoning Attacks on Text-to-Image  Generative Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shan%2C+S">Shawn Shan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+W">Wenxin Ding</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Passananti%2C+J">Josephine Passananti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+S">Stanley Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+H">Haitao Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+B+Y">Ben Y. Zhao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> IEEE Security and Privacy 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14278" title="Abstract">arXiv:2310.14278</a> (replaced) [<a href="/pdf/2310.14278" title="Download PDF">pdf</a>, <a href="/format/2310.14278" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Conversational Speech Recognition by Learning Audio-textual Cross-modal  Contextual Representation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+K">Kun Wei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bei Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lv%2C+H">Hang Lv</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Q">Quan Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+N">Ning Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+L">Lei Xie</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> TASLP
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> IEEE/ACM Transactions on Audio, Speech, and Language Processing,
    2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16588" title="Abstract">arXiv:2310.16588</a> (replaced) [<a href="/pdf/2310.16588" title="Download PDF">pdf</a>, <a href="/format/2310.16588" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-Task Wavelength-Multiplexed Reservoir Computing Using a Silicon  Microring Resonator
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Castro%2C+B+J+G">Bernard J. Giron Castro</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peucheret%2C+C">Christophe Peucheret</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zibar%2C+D">Darko Zibar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Da+Ros%2C+F">Francesco Da Ros</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 7 figures, Accepted for presentation at The International Joint Conference on Neural Networks (IJCNN), part of IEEE WCCI 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Optics (physics.optics)
  
  </div>
  </div>
  </dd>
  <dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20225" title="Abstract">arXiv:2310.20225</a> (replaced) [<a href="/pdf/2310.20225" title="Download PDF">pdf</a>, <a href="/format/2310.20225" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Multi-Modal Foundation Model to Assist People with Blindness and Low  Vision in Environmental Interaction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hao%2C+Y">Yu Hao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+F">Fan Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+H">Hao Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+S">Shuaihang Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rangan%2C+S">Sundeep Rangan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rizzo%2C+J">John-Ross Rizzo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+Y">Yi Fang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20426" title="Abstract">arXiv:2310.20426</a> (replaced) [<a href="/pdf/2310.20426" title="Download PDF">pdf</a>, <a href="/format/2310.20426" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Dealing with Structure Constraints in Evolutionary Pareto Set Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+X">Xi Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaoyuan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhiyuan Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qingfu Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20581" title="Abstract">arXiv:2310.20581</a> (replaced) [<a href="/pdf/2310.20581" title="Download PDF">pdf</a>, <a href="/format/2310.20581" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Stochastic Gradient Descent for Gaussian Processes Done Right
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J+A">Jihao Andreas Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Padhy%2C+S">Shreyas Padhy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Antor%C3%A1n%2C+J">Javier Antorán</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tripp%2C+A">Austin Tripp</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Terenin%2C+A">Alexander Terenin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Szepesv%C3%A1ri%2C+C">Csaba Szepesvári</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hern%C3%A1ndez-Lobato%2C+J+M">José Miguel Hernández-Lobato</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Janz%2C+D">David Janz</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00696" title="Abstract">arXiv:2311.00696</a> (replaced) [<a href="/pdf/2311.00696" title="Download PDF">pdf</a>, <a href="/format/2311.00696" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Decision Support Framework for Home Health Caregiver Allocation Using  Optimally Tuned Spectral Clustering and Genetic Algorithm
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sharifnia%2C+S+M+E">Seyed Mohammad Ebrahim Sharifnia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bagheri%2C+F">Faezeh Bagheri</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sawhney%2C+R">Rupy Sawhney</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kobza%2C+J+E">John E. Kobza</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Anda%2C+E+M">Enrique Macias De Anda</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hajiaghaei-Keshteli%2C+M">Mostafa Hajiaghaei-Keshteli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mirrielees%2C+M">Michael Mirrielees</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The document is written in the Elsevier LaTeX format
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01020" title="Abstract">arXiv:2311.01020</a> (replaced) [<a href="/pdf/2311.01020" title="Download PDF">pdf</a>, <a href="/format/2311.01020" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring the Problems, their Causes and Solutions of AI Pair  Programming: A Study with Practitioners of GitHub Copilot
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiyu Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+P">Peng Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+B">Beiqi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zengyang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ahmad%2C+A">Aakash Ahmad</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shahin%2C+M">Mojtaba Shahin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Waseem%2C+M">Muhammad Waseem</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01553" title="Abstract">arXiv:2311.01553</a> (replaced) [<a href="/pdf/2311.01553" title="Download PDF">pdf</a>, <a href="/format/2311.01553" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Total Variation Meets Differential Privacy
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ghazi%2C+E">Elena Ghazi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Issa%2C+I">Ibrahim Issa</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, 7 figures, partially published at 2023 IEEE ISIT and partially published at IEEE Journal on Selected Areas in Information Theory
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02766" title="Abstract">arXiv:2311.02766</a> (replaced) [<a href="/pdf/2311.02766" title="Download PDF">pdf</a>, <a href="/format/2311.02766" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Riemannian Laplace Approximation with the Fisher Metric
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Hanlin Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hartmann%2C+M">Marcelo Hartmann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Williams%2C+B">Bernardo Williams</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Girolami%2C+M">Mark Girolami</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Klami%2C+A">Arto Klami</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> AISTATS 2024, with additional fixes and improvements
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02865" title="Abstract">arXiv:2311.02865</a> (replaced) [<a href="/pdf/2311.02865" title="Download PDF">pdf</a>, <a href="/format/2311.02865" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Geometrically-Shaped Constellation for Visible Light Communications at  Short Blocklength
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+J">Jia-Ning Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+R">Ru-Han Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jian Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Longguang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+X">Xu Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jing Zhou</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
  
  </div>
  </div>
  </dd>
  <dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06031" title="Abstract">arXiv:2311.06031</a> (replaced) [<a href="/pdf/2311.06031" title="Download PDF">pdf</a>, <a href="/format/2311.06031" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Diagonal Hierarchical Consistency Learning for Semi-supervised Medical  Image Segmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Koo%2C+H">Heejoon Koo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to IEEE EMBC 2024 (46th Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06243" title="Abstract">arXiv:2311.06243</a> (replaced) [<a href="/pdf/2311.06243" title="Download PDF">pdf</a>, <a href="/format/2311.06243" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+W">Weiyang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+Z">Zeju Qiu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yao Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiu%2C+Y">Yuliang Xiu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+Y">Yuxuan Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+L">Longhui Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+H">Haiwen Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhen Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Heo%2C+J">Juyeon Heo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+S">Songyou Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wen%2C+Y">Yandong Wen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Black%2C+M+J">Michael J. Black</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Weller%2C+A">Adrian Weller</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sch%C3%B6lkopf%2C+B">Bernhard Schölkopf</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICLR 2024 (v2: 34 pages, 19 figures)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07064" title="Abstract">arXiv:2311.07064</a> (replaced) [<a href="/pdf/2311.07064" title="Download PDF">pdf</a>, <a href="/format/2311.07064" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Prompt have evil twins
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Melamed%2C+R">Rimon Melamed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McCabe%2C+L+H">Lucas H. McCabe</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wakhare%2C+T">Tanay Wakhare</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+Y">Yejin Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+H+H">H. Howie Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Boix-Adsera%2C+E">Enric Boix-Adsera</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Preprint. Under review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07125" title="Abstract">arXiv:2311.07125</a> (replaced) [<a href="/pdf/2311.07125" title="Download PDF">pdf</a>, <a href="/format/2311.07125" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Attention-Challenging Multiple Instance Learning for Whole Slide Image  Classification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yunlong Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+H">Honglin Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuxuan Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+S">Sunyi Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+C">Chenglu Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+L">Lin Yang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Under review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07129" title="Abstract">arXiv:2311.07129</a> (replaced) [<a href="/pdf/2311.07129" title="Download PDF">pdf</a>, <a href="/ps/2311.07129" title="Download PostScript">ps</a>, <a href="/format/2311.07129" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-Point Method using Effective Demodulation and Decomposition  Techniques allowing Identification of Disturbing Loads in Power Grids
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Kuwa%C5%82ek%2C+P">Piotr Kuwałek</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wiczy%C5%84ski%2C+G">Grzegorz Wiczyński</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 10 figures, accepted and published article
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Kuwalek P., Wiczynski G., Multi-point method using effective
    demodulation and decomposition techniques allowing identification of
    disturbing loads in power grids, Electric Power Systems Research, vol. 231,
    art. no. 110335, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Numerical Analysis (math.NA)
  
  </div>
  </div>
  </dd>
  <dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07338" title="Abstract">arXiv:2311.07338</a> (replaced) [<a href="/pdf/2311.07338" title="Download PDF">pdf</a>, <a href="/format/2311.07338" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A mathematical model of the visual MacKay effect
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Tamekue%2C+C">Cyprien Tamekue</a>, 
  <a href="/search/math?searchtype=author&amp;query=Prandi%2C+D">Dario Prandi</a>, 
  <a href="/search/math?searchtype=author&amp;query=Chitour%2C+Y">Yacine Chitour</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Neurons and Cognition (q-bio.NC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07439" title="Abstract">arXiv:2311.07439</a> (replaced) [<a href="/pdf/2311.07439" title="Download PDF">pdf</a>, <a href="/format/2311.07439" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Investigating Multi-Pivot Ensembling with Massively Multilingual Machine  Translation Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mohammadshahi%2C+A">Alireza Mohammadshahi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vamvas%2C+J">Jannis Vamvas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sennrich%2C+R">Rico Sennrich</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to Insights at NAACL 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07609" title="Abstract">arXiv:2311.07609</a> (replaced) [<a href="/pdf/2311.07609" title="Download PDF">pdf</a>, <a href="/ps/2311.07609" title="Download PostScript">ps</a>, <a href="/format/2311.07609" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Artificial Intelligence in Assessing Cardiovascular Diseases and Risk  Factors via Retinal Fundus Images: A Review of the Last Decade
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/q-bio?searchtype=author&amp;query=Abdollahi%2C+M">Mirsaeed Abdollahi</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Jafarizadeh%2C+A">Ali Jafarizadeh</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Asbagh%2C+A+G">Amirhosein Ghafouri Asbagh</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Sobhi%2C+N">Navid Sobhi</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Pourmoghtader%2C+K">Keysan Pourmoghtader</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Pedrammehr%2C+S">Siamak Pedrammehr</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Asadi%2C+H">Houshyar Asadi</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Alizadehsani%2C+R">Roohallah Alizadehsani</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Tan%2C+R">Ru-San Tan</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Acharya%2C+U+R">U. Rajendra Acharya</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 41 pages, 5 figures, 3 tables, 114 references
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Medical Physics (physics.med-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07614" title="Abstract">arXiv:2311.07614</a> (replaced) [<a href="/e-print/2311.07614" title="Download source">src</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Application of a Dense Fusion Attention Network in Fault Diagnosis of  Centrifugal Fan
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+R">Ruijun Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+Z">Zhixia Fan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+X">Xiaogang Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Huijie Wang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Authors request the withdrawal of this preprint for internal team reasons, and because of the need to adjust the direction of their research between authors
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07907" title="Abstract">arXiv:2311.07907</a> (replaced) [<a href="/pdf/2311.07907" title="Download PDF">pdf</a>, <a href="/ps/2311.07907" title="Download PostScript">ps</a>, <a href="/format/2311.07907" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Curve Stabbing Depth: Data Depth for Plane Curves
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Durocher%2C+S">Stephane Durocher</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Leblanc%2C+A">Alexandre Leblanc</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Szabados%2C+S">Spencer Szabados</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Preprint
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07986" title="Abstract">arXiv:2311.07986</a> (replaced) [<a href="/pdf/2311.07986" title="Download PDF">pdf</a>, <a href="/format/2311.07986" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On the View-and-Channel Aggregation Gain in Integrated Sensing and Edge  AI
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xu Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Letaief%2C+K+B">Khaled B. Letaief</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+K">Kaibin Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 34 pages, 8 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
  
  </div>
  </div>
  </dd>
  <dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08274" title="Abstract">arXiv:2311.08274</a> (replaced) [<a href="/pdf/2311.08274" title="Download PDF">pdf</a>, <a href="/format/2311.08274" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Laccolith: Hypervisor-Based Adversary Emulation with Anti-Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Orbinato%2C+V">Vittorio Orbinato</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feliciano%2C+M+C">Marco Carlo Feliciano</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cotroneo%2C+D">Domenico Cotroneo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Natella%2C+R">Roberto Natella</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Operating Systems (cs.OS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08403" title="Abstract">arXiv:2311.08403</a> (replaced) [<a href="/pdf/2311.08403" title="Download PDF">pdf</a>, <a href="/format/2311.08403" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Instant3D: Instant Text-to-3D Generation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Ming Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+P">Pan Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jia-Wei Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Keppo%2C+J">Jussi Keppo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+M">Min Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+S">Shuicheng Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+X">Xiangyu Xu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Project page: <a href="https://ming1993li.github.io/Instant3DProj">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Multimedia (cs.MM)
  
  </div>
  </div>
  </dd>
  <dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08502" title="Abstract">arXiv:2311.08502</a> (replaced) [<a href="/pdf/2311.08502" title="Download PDF">pdf</a>, <a href="/format/2311.08502" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Variational Quantum Eigensolver with Constraints (VQEC): Solving  Constrained Optimization Problems via VQE
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Le%2C+T+V">Thinh Viet Le</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Kekatos%2C+V">Vassilis Kekatos</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 22 pages, 13 figures, 1 table
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08896" title="Abstract">arXiv:2311.08896</a> (replaced) [<a href="/pdf/2311.08896" title="Download PDF">pdf</a>, <a href="/format/2311.08896" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> HeLM: Highlighted Evidence augmented Language Model for Enhanced  Table-to-Text Generation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bian%2C+J">Junyi Bian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qin%2C+X">Xiaolei Qin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zou%2C+W">Wuhe Zou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+M">Mengzuo Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+C">Congyi Luo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+K">Ke Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weidong Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09410" title="Abstract">arXiv:2311.09410</a> (replaced) [<a href="/pdf/2311.09410" title="Download PDF">pdf</a>, <a href="/format/2311.09410" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> When Large Language Models contradict humans? Large Language Models'  Sycophantic Behaviour
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ranaldi%2C+L">Leonardo Ranaldi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pucci%2C+G">Giulia Pucci</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09483" title="Abstract">arXiv:2311.09483</a> (replaced) [<a href="/pdf/2311.09483" title="Download PDF">pdf</a>, <a href="/format/2311.09483" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Adaptive Interventions with User-Defined Goals for Health Behavior  Change
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mandyam%2C+A">Aishwarya Mandyam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=J%C3%B6rke%2C+M">Matthew Jörke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Denton%2C+W">William Denton</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Engelhardt%2C+B+E">Barbara E. Engelhardt</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Brunskill%2C+E">Emma Brunskill</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 5 pages Full paper to be presented at Conference on Health Inference and Learning (CHIL) 2024, June 27th, 2024, New York City, United States, 11 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09709" title="Abstract">arXiv:2311.09709</a> (replaced) [<a href="/pdf/2311.09709" title="Download PDF">pdf</a>, <a href="/format/2311.09709" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Ups and Downs of Large Language Model Inference with Vocabulary  Trimming by Language Heuristics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bogoychev%2C+N">Nikolay Bogoychev</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+P">Pinzhen Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Haddow%2C+B">Barry Haddow</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Birch%2C+A">Alexandra Birch</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Versions 2, accepted at Insights from negative results 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11260" title="Abstract">arXiv:2311.11260</a> (replaced) [<a href="/pdf/2311.11260" title="Download PDF">pdf</a>, <a href="/format/2311.11260" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Radarize: Enhancing Radar SLAM with Generalizable Doppler-Based Odometry
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sie%2C+E">Emerson Sie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xinyu Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+H">Heyu Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vasisht%2C+D">Deepak Vasisht</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)
  
  </div>
  </div>
  </dd>
  <dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11313" title="Abstract">arXiv:2311.11313</a> (replaced) [<a href="/pdf/2311.11313" title="Download PDF">pdf</a>, <a href="/format/2311.11313" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Symbolic Execution for Quantum Error Correction Programs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Fang%2C+W">Wang Fang</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Ying%2C+M">Mingsheng Ying</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 41pages, 11 figures. v2: fix inappropriate use of Stim. v3: Extended version of PLDI 2024 publication
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Programming Languages (cs.PL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12970" title="Abstract">arXiv:2311.12970</a> (replaced) [<a href="/pdf/2311.12970" title="Download PDF">pdf</a>, <a href="/format/2311.12970" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Clustered Policy Decision Ranking
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Levin%2C+M">Mark Levin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chockler%2C+H">Hana Chockler</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 4 pages, 4 figures. arXiv admin note: text overlap with <a href="/abs/2111.08415">arXiv:2111.08415</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13127" title="Abstract">arXiv:2311.13127</a> (replaced) [<a href="/pdf/2311.13127" title="Download PDF">pdf</a>, <a href="/format/2311.13127" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MetaCloak: Preventing Unauthorized Subject-driven Text-to-image  Diffusion-based Synthesis via Meta-learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yixin Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+C">Chenrui Fan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dai%2C+Y">Yutong Dai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xun Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+P">Pan Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+L">Lichao Sun</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to CVPR 2024 (Oral)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13852" title="Abstract">arXiv:2311.13852</a> (replaced) [<a href="/pdf/2311.13852" title="Download PDF">pdf</a>, <a href="/format/2311.13852" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Cross Attention Approach to Diagnostic Explainability using Clinical  Practice Guidelines for Depression
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dalal%2C+S">Sumit Dalal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tilwani%2C+D">Deepa Tilwani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Roy%2C+K">Kaushik Roy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gaur%2C+M">Manas Gaur</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jain%2C+S">Sarika Jain</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shalin%2C+V">Valerie Shalin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sheth%2C+A">Amit Sheth</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13951" title="Abstract">arXiv:2311.13951</a> (replaced) [<a href="/pdf/2311.13951" title="Download PDF">pdf</a>, <a href="/format/2311.13951" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MLLM-Bench: Evaluating Multimodal LLMs with Per-sample Criteria
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ge%2C+W">Wentao Ge</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Shunian Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+G+H">Guiming Hardy Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhihong Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Junying Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+S">Shuo Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+C">Chenghao Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Z">Ziyue Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+W">Wenya Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xinyi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chai%2C+Y">Yichen Chai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaoyu Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+D">Dingjie Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xidong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+A">Anningzhe Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhiyi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jianquan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wan%2C+X">Xiang Wan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Benyou Wang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 23 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14455" title="Abstract">arXiv:2311.14455</a> (replaced) [<a href="/pdf/2311.14455" title="Download PDF">pdf</a>, <a href="/format/2311.14455" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Universal Jailbreak Backdoors from Poisoned Human Feedback
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rando%2C+J">Javier Rando</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tram%C3%A8r%2C+F">Florian Tramèr</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted as conference paper in ICLR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15675" title="Abstract">arXiv:2311.15675</a> (replaced) [<a href="/pdf/2311.15675" title="Download PDF">pdf</a>, <a href="/ps/2311.15675" title="Download PostScript">ps</a>, <a href="/format/2311.15675" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Complexity of Second-order HyperLTL
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Frenkel%2C+H">Hadar Frenkel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zimmermann%2C+M">Martin Zimmermann</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16445" title="Abstract">arXiv:2311.16445</a> (replaced) [<a href="/pdf/2311.16445" title="Download PDF">pdf</a>, <a href="/format/2311.16445" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CLAP: Isolating Content from Style through Contrastive Learning with  Augmented Prompts
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cai%2C+Y">Yichao Cai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuhang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhen Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+J+Q">Javen Qinfeng Shi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16681" title="Abstract">arXiv:2311.16681</a> (replaced) [<a href="/pdf/2311.16681" title="Download PDF">pdf</a>, <a href="/format/2311.16681" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Understanding the (Extra-)Ordinary: Validating Deep Model Decisions with  Prototypical Concept-based Explanations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dreyer%2C+M">Maximilian Dreyer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Achtibat%2C+R">Reduan Achtibat</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Samek%2C+W">Wojciech Samek</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lapuschkin%2C+S">Sebastian Lapuschkin</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 39 pages (8 pages manuscript, 3 pages references, 28 pages appendix)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16759" title="Abstract">arXiv:2311.16759</a> (replaced) [<a href="/pdf/2311.16759" title="Download PDF">pdf</a>, <a href="/format/2311.16759" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Gradient-based Local Next-best-view Planning for Improved Perception of  Targeted Plant Nodes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Burusa%2C+A+K">Akshay K. Burusa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=van+Henten%2C+E+J">Eldert J. van Henten</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kootstra%2C+G">Gert Kootstra</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This work has been accepted for the 2024 International Conference on Robotics and Automation (ICRA 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16806" title="Abstract">arXiv:2311.16806</a> (replaced) [<a href="/pdf/2311.16806" title="Download PDF">pdf</a>, <a href="/ps/2311.16806" title="Download PostScript">ps</a>, <a href="/format/2311.16806" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Summing the sum of digits
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Allouche%2C+J">Jean-Paul Allouche</a>, 
  <a href="/search/math?searchtype=author&amp;query=Stipulanti%2C+M">Manon Stipulanti</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages; this is a revised version to appear in Communications in Mathematics
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17347" title="Abstract">arXiv:2311.17347</a> (replaced) [<a href="/pdf/2311.17347" title="Download PDF">pdf</a>, <a href="/format/2311.17347" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Data-driven Bandwidth Adaptation for Radio Access Network Slices
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nikolaidis%2C+P">Panagiotis Nikolaidis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zoulkarni%2C+A">Asim Zoulkarni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Baras%2C+J">John Baras</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17528" title="Abstract">arXiv:2311.17528</a> (replaced) [<a href="/pdf/2311.17528" title="Download PDF">pdf</a>, <a href="/format/2311.17528" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> HiDiffusion: Unlocking Higher-Resolution Creativity and Efficiency in  Pretrained Diffusion Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shen Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhaowei Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhenyu Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuhao Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yao Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+J">Jiajun Liang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17590" title="Abstract">arXiv:2311.17590</a> (replaced) [<a href="/pdf/2311.17590" title="Download PDF">pdf</a>, <a href="/format/2311.17590" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+Z">Ziqiao Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+W">Wentao Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yue Shi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xiangyu Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaomei Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hao Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+J">Jun He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Hongyan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+Z">Zhaoxin Fan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by CVPR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18072" title="Abstract">arXiv:2311.18072</a> (replaced) [<a href="/pdf/2311.18072" title="Download PDF">pdf</a>, <a href="/format/2311.18072" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Self-Supervised Learning for Large-Scale Preventive Security Constrained  DC Optimal Power Flow
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Park%2C+S">Seonho Park</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Van+Hentenryck%2C+P">Pascal Van Hentenryck</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Revision to IEEE Transactions on Power Systems
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18259" title="Abstract">arXiv:2311.18259</a> (replaced) [<a href="/pdf/2311.18259" title="Download PDF">pdf</a>, <a href="/format/2311.18259" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Ego-Exo4D: Understanding Skilled Human Activity from First- and  Third-Person Perspectives
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Grauman%2C+K">Kristen Grauman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Westbury%2C+A">Andrew Westbury</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Torresani%2C+L">Lorenzo Torresani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kitani%2C+K">Kris Kitani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Malik%2C+J">Jitendra Malik</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Afouras%2C+T">Triantafyllos Afouras</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ashutosh%2C+K">Kumar Ashutosh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Baiyya%2C+V">Vijay Baiyya</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bansal%2C+S">Siddhant Bansal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Boote%2C+B">Bikram Boote</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Byrne%2C+E">Eugene Byrne</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chavis%2C+Z">Zach Chavis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Joya Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+F">Feng Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chu%2C+F">Fu-Jen Chu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Crane%2C+S">Sean Crane</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dasgupta%2C+A">Avijit Dasgupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+J">Jing Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Escobar%2C+M">Maria Escobar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Forigua%2C+C">Cristhian Forigua</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gebreselasie%2C+A">Abrham Gebreselasie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Haresh%2C+S">Sanjay Haresh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jing Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Islam%2C+M+M">Md Mohaiminul Islam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jain%2C+S">Suyog Jain</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khirodkar%2C+R">Rawal Khirodkar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kukreja%2C+D">Devansh Kukreja</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+K+J">Kevin J Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jia-Wei Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Majumder%2C+S">Sagnik Majumder</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mao%2C+Y">Yongsen Mao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Martin%2C+M">Miguel Martin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mavroudi%2C+E">Effrosyni Mavroudi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nagarajan%2C+T">Tushar Nagarajan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ragusa%2C+F">Francesco Ragusa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ramakrishnan%2C+S+K">Santhosh Kumar Ramakrishnan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Seminara%2C+L">Luigi Seminara</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Somayazulu%2C+A">Arjun Somayazulu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+Y">Yale Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Su%2C+S">Shan Su</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+Z">Zihui Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+E">Edward Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jinxu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Castillo%2C+A">Angela Castillo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C">Changan Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fu%2C+X">Xinzhu Fu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Furuta%2C+R">Ryosuke Furuta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gonzalez%2C+C">Cristina Gonzalez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+P">Prince Gupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Jiabo Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yifei Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yiming Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khoo%2C+W">Weslie Khoo</a>,  et al. (48 additional authors not shown)
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> updated baseline results and dataset statistics to match the released v2 data; added table to appendix comparing stats of Ego-Exo4D alongside other datasets
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00028" title="Abstract">arXiv:2312.00028</a> (replaced) [<a href="/pdf/2312.00028" title="Download PDF">pdf</a>, <a href="/format/2312.00028" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Constructive Representation of Functions in <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-395-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2626" style="width: 0.898em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.719em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1000.719em, 2.646em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-2627"><span class="mi" id="MathJax-Span-2628" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.047em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.947em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-395">N</script>-Dimensional Sobolev  Space
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Jagt%2C+D+S">Declan S. Jagt</a>, 
  <a href="/search/math?searchtype=author&amp;query=Peet%2C+M+M">Matthew M. Peet</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00195" title="Abstract">arXiv:2312.00195</a> (replaced) [<a href="/pdf/2312.00195" title="Download PDF">pdf</a>, <a href="/format/2312.00195" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Raising the Bar of AI-generated Image Detection with CLIP
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cozzolino%2C+D">Davide Cozzolino</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Poggi%2C+G">Giovanni Poggi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Corvi%2C+R">Riccardo Corvi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nie%C3%9Fner%2C+M">Matthias Nießner</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Verdoliva%2C+L">Luisa Verdoliva</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00516" title="Abstract">arXiv:2312.00516</a> (replaced) [<a href="/pdf/2312.00516" title="Download PDF">pdf</a>, <a href="/format/2312.00516" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Spatial-Temporal-Decoupled Masked Pre-training for Spatiotemporal  Forecasting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+H">Haotian Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+R">Renhe Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+Z">Zheng Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Deng%2C+J">Jinliang Deng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yuxin Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+X">Xuan Song</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at IJCAI-2024 Main Track
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00784" title="Abstract">arXiv:2312.00784</a> (replaced) [<a href="/pdf/2312.00784" title="Download PDF">pdf</a>, <a href="/format/2312.00784" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ViP-LLaVA: Making Large Multimodal Models Understand Arbitrary Visual  Prompts
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cai%2C+M">Mu Cai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Haotian Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Park%2C+D">Dennis Park</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mustikovela%2C+S+K">Siva Karthik Mustikovela</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Meyer%2C+G+P">Gregory P. Meyer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chai%2C+Y">Yuning Chai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+Y+J">Yong Jae Lee</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to CVPR2024. Project page: <a href="https://vip-llava.github.io/">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02731" title="Abstract">arXiv:2312.02731</a> (replaced) [<a href="/pdf/2312.02731" title="Download PDF">pdf</a>, <a href="/format/2312.02731" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> D-LGP: Dynamic Logic-Geometric Program for Reactive Task and Motion  Planning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+T">Teng Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Razmjoo%2C+A">Amirreza Razmjoo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Calinon%2C+S">Sylvain Calinon</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 2024 IEEE International Conference on Robotics and Automation (ICRA)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02974" title="Abstract">arXiv:2312.02974</a> (replaced) [<a href="/pdf/2312.02974" title="Download PDF">pdf</a>, <a href="/format/2312.02974" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Describing Differences in Image Sets with Natural Language
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dunlap%2C+L">Lisa Dunlap</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuhui Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaohan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+R">Ruiqi Zhong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Darrell%2C+T">Trevor Darrell</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Steinhardt%2C+J">Jacob Steinhardt</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yeung-Levy%2C+S">Serena Yeung-Levy</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> CVPR 2024 Oral
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03549" title="Abstract">arXiv:2312.03549</a> (replaced) [<a href="/pdf/2312.03549" title="Download PDF">pdf</a>, <a href="/format/2312.03549" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Holmes: Towards Distributed Training Across Clusters with Heterogeneous  NIC Environment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+F">Fei Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+S">Shuang Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+N">Ning Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+F">Fangyu Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuanyuan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+F">Fu Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+J">Jiezhong Qiu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+A">Aimin Pan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05632" title="Abstract">arXiv:2312.05632</a> (replaced) [<a href="/pdf/2312.05632" title="Download PDF">pdf</a>, <a href="/format/2312.05632" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Subject-Based Domain Adaptation for Facial Expression Recognition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zeeshan%2C+M+O">Muhammad Osama Zeeshan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aslam%2C+M+H">Muhammad Haseeb Aslam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Belharbi%2C+S">Soufiane Belharbi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Koerich%2C+A+L">Alessandro Lameiras Koerich</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pedersoli%2C+M">Marco Pedersoli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bacon%2C+S">Simon Bacon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Granger%2C+E">Eric Granger</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06050" title="Abstract">arXiv:2312.06050</a> (replaced) [<a href="/pdf/2312.06050" title="Download PDF">pdf</a>, <a href="/format/2312.06050" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Federated Multilinear Principal Component Analysis with Applications in  Prognostics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chengyu Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Su%2C+Y">Yuqi Su</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xia%2C+T">Tangbin Xia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+X">Xiaolei Fang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV); Machine Learning (stat.ML)
  
  </div>
  </div>
  </dd>
  <dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06947" title="Abstract">arXiv:2312.06947</a> (replaced) [<a href="/pdf/2312.06947" title="Download PDF">pdf</a>, <a href="/format/2312.06947" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MaTe3D: Mask-guided Text-based 3D-aware Portrait Editing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+K">Kangneng Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+D">Daiheng Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xuan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jie Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+P">Peng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+X">Xusen Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Longhao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+S">Shiqi Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+B">Bang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bo%2C+L">Liefeng Bo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yaxing Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+M">Ming-Ming Cheng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages, 13 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08367" title="Abstract">arXiv:2312.08367</a> (replaced) [<a href="/pdf/2312.08367" title="Download PDF">pdf</a>, <a href="/format/2312.08367" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ViLA: Efficient Video-Language Alignment for Video Question Answering
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xijun Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+J">Junbang Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chun-Kai Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Deng%2C+K">Kenan Deng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lou%2C+Y">Yu Lou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+M">Ming Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+S">Shan Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09658" title="Abstract">arXiv:2312.09658</a> (replaced) [<a href="/pdf/2312.09658" title="Download PDF">pdf</a>, <a href="/ps/2312.09658" title="Download PostScript">ps</a>, <a href="/format/2312.09658" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Algorithms for automatic intents extraction and utterances  classification for goal-oriented dialogue systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Legashev%2C+L">Leonid Legashev</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shukhman%2C+A">Alexander Shukhman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Badikov%2C+V">Vadim Badikov</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> in Russian language This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10349" title="Abstract">arXiv:2312.10349</a> (replaced) [<a href="/pdf/2312.10349" title="Download PDF">pdf</a>, <a href="/format/2312.10349" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Comparative Analysis of Large Language Models for Code Documentation  Generation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dvivedi%2C+S+S">Shubhang Shekhar Dvivedi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vijay%2C+V">Vyshnav Vijay</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pujari%2C+S+L+R">Sai Leela Rahul Pujari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lodh%2C+S">Shoumik Lodh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+D">Dhruv Kumar</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Under review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11459" title="Abstract">arXiv:2312.11459</a> (replaced) [<a href="/pdf/2312.11459" title="Download PDF">pdf</a>, <a href="/format/2312.11459" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> VolumeDiffusion: Flexible Text-to-3D Generation with Efficient  Volumetric Encoder
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+Z">Zhicong Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gu%2C+S">Shuyang Gu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chunyu Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Ting Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bao%2C+J">Jianmin Bao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+D">Dong Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+B">Baining Guo</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11489" title="Abstract">arXiv:2312.11489</a> (replaced) [<a href="/pdf/2312.11489" title="Download PDF">pdf</a>, <a href="/format/2312.11489" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Agglomerative Federated Learning: Empowering Larger Model Training via  End-Edge-Cloud Collaboration
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhiyuan Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+S">Sheng Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuwei Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+M">Min Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+B">Bo Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+Q">Quyang Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+T">Tianliu He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xuefeng Jiang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by IEEE International Conference on Computer Communications (INFOCOM), 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12891" title="Abstract">arXiv:2312.12891</a> (replaced) [<a href="/pdf/2312.12891" title="Download PDF">pdf</a>, <a href="/format/2312.12891" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MinePlanner: A Benchmark for Long-Horizon Planning in Large Minecraft  Worlds
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hill%2C+W">William Hill</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+I">Ireton Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Mello+Koch%2C+A">Anita De Mello Koch</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Harvey%2C+D">Damion Harvey</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+N">Nishanth Kumar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Konidaris%2C+G">George Konidaris</a>, 
  <a href="/search/cs?searchtype=author&amp;query=James%2C+S">Steven James</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the 6th ICAPS Workshop on the International Planning Competition (WIPC 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14259" title="Abstract">arXiv:2312.14259</a> (replaced) [<a href="/pdf/2312.14259" title="Download PDF">pdf</a>, <a href="/format/2312.14259" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-Agent Bandit Learning through Heterogeneous Action Erasure  Channels
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hanna%2C+O+A">Osama A. Hanna</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Karakas%2C+M">Merve Karakas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+L+F">Lin F. Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fragouli%2C+C">Christina Fragouli</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA)
  
  </div>
  </div>
  </dd>
  <dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15138" title="Abstract">arXiv:2312.15138</a> (replaced) [<a href="/pdf/2312.15138" title="Download PDF">pdf</a>, <a href="/format/2312.15138" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An FPGA-Based Accelerator for Graph Embedding using Sequential Training  Algorithm
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sunaga%2C+K">Kazuki Sunaga</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sugiura%2C+K">Keisuke Sugiura</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Matsutani%2C+H">Hiroki Matsutani</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> RAW'24
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15569" title="Abstract">arXiv:2312.15569</a> (replaced) [<a href="/pdf/2312.15569" title="Download PDF">pdf</a>, <a href="/format/2312.15569" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Globally Optimal Inverse Kinematics as a Quadratic Program
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Votroubek%2C+T">Tomáš Votroubek</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kroupa%2C+T">Tomáš Kroupa</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16020" title="Abstract">arXiv:2312.16020</a> (replaced) [<a href="/pdf/2312.16020" title="Download PDF">pdf</a>, <a href="/format/2312.16020" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Robust Neural Pruning with Gradient Sampling Optimization for Residual  Neural Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yun%2C+J">Juyoung Yun</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17247" title="Abstract">arXiv:2312.17247</a> (replaced) [<a href="/pdf/2312.17247" title="Download PDF">pdf</a>, <a href="/format/2312.17247" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Amodal Ground Truth and Completion in the Wild
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhan%2C+G">Guanqi Zhan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+C">Chuanxia Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+W">Weidi Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zisserman%2C+A">Andrew Zisserman</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> CVPR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17670" title="Abstract">arXiv:2312.17670</a> (replaced) [<a href="/pdf/2312.17670" title="Download PDF">pdf</a>, <a href="/format/2312.17670" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Benchmarking the CoW with the TopCoW Challenge: Topology-Aware  Anatomical Segmentation of the Circle of Willis for CTA and MRA
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+K">Kaiyuan Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Musio%2C+F">Fabio Musio</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yihui Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Juchler%2C+N">Norman Juchler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Paetzold%2C+J+C">Johannes C. Paetzold</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Al-Maskari%2C+R">Rami Al-Maskari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=H%C3%B6her%2C+L">Luciano Höher</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+H+B">Hongwei Bran Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hamamci%2C+I+E">Ibrahim Ethem Hamamci</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sekuboyina%2C+A">Anjany Sekuboyina</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shit%2C+S">Suprosanna Shit</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+H">Houjing Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Prabhakar%2C+C">Chinmay Prabhakar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=de+la+Rosa%2C+E">Ezequiel de la Rosa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Waldmannstetter%2C+D">Diana Waldmannstetter</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kofler%2C+F">Florian Kofler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Navarro%2C+F">Fernando Navarro</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Menten%2C+M">Martin Menten</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ezhov%2C+I">Ivan Ezhov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rueckert%2C+D">Daniel Rueckert</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vos%2C+I">Iris Vos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ruigrok%2C+Y">Ynte Ruigrok</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Velthuis%2C+B">Birgitta Velthuis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kuijf%2C+H">Hugo Kuijf</a>, 
  <a href="/search/cs?searchtype=author&amp;query=H%C3%A4mmerli%2C+J">Julien Hämmerli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wurster%2C+C">Catherine Wurster</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bijlenga%2C+P">Philippe Bijlenga</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Westphal%2C+L">Laura Westphal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bisschop%2C+J">Jeroen Bisschop</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Colombo%2C+E">Elisa Colombo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Baazaoui%2C+H">Hakim Baazaoui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Makmur%2C+A">Andrew Makmur</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hallinan%2C+J">James Hallinan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wiestler%2C+B">Bene Wiestler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kirschke%2C+J+S">Jan S. Kirschke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wiest%2C+R">Roland Wiest</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Montagnon%2C+E">Emmanuel Montagnon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Letourneau-Guillon%2C+L">Laurent Letourneau-Guillon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Galdran%2C+A">Adrian Galdran</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Galati%2C+F">Francesco Galati</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Falcetta%2C+D">Daniele Falcetta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zuluaga%2C+M+A">Maria A. Zuluaga</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+C">Chaolong Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Haoran Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zehan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ra%2C+S">Sinyoung Ra</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hwang%2C+J">Jongyun Hwang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Park%2C+H">Hyunjin Park</a>,  et al. (36 additional authors not shown)
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 24 pages, 11 figures, 9 tables. Summary Paper for the MICCAI TopCoW 2023 Challenge
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Tissues and Organs (q-bio.TO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00766" title="Abstract">arXiv:2401.00766</a> (replaced) [<a href="/pdf/2401.00766" title="Download PDF">pdf</a>, <a href="/format/2401.00766" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exposure Bracketing is All You Need for Unifying Image Restoration and  Enhancement Tasks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhilu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shuohao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+R">Renlong Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Z">Zifei Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zuo%2C+W">Wangmeng Zuo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 29 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02254" title="Abstract">arXiv:2401.02254</a> (replaced) [<a href="/pdf/2401.02254" title="Download PDF">pdf</a>, <a href="/format/2401.02254" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> L3Cube-IndicNews: News-based Short Text and Long Document Classification  Datasets in Indic Languages
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mirashi%2C+A">Aishwarya Mirashi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sonavane%2C+S">Srushti Sonavane</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lingayat%2C+P">Purva Lingayat</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Padhiyar%2C+T">Tejas Padhiyar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Joshi%2C+R">Raviraj Joshi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at the International Conference on Natural Language Processing (ICON 2023)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03412" title="Abstract">arXiv:2401.03412</a> (replaced) [<a href="/pdf/2401.03412" title="Download PDF">pdf</a>, <a href="/format/2401.03412" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> N<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-396-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2629" style="width: 0.629em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.495em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(0.002em, 1000.495em, 1.122em, -999.998em); top: -0.983em; left: 0em;"><span class="mrow" id="MathJax-Span-2630"><span class="msubsup" id="MathJax-Span-2631"><span style="display: inline-block; position: relative; width: 0.45em; height: 0px;"><span style="position: absolute; clip: rect(3.855em, 1000.002em, 4.124em, -999.998em); top: -3.985em; left: 0em;"><span class="mi" id="MathJax-Span-2632"></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -4.344em; left: 0em;"><span class="texatom" id="MathJax-Span-2633"><span class="mrow" id="MathJax-Span-2634"><span class="mn" id="MathJax-Span-2635" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 0.988em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.169em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-396">^{3}</script>-Mapping: Normal Guided Neural Non-Projective Signed Distance  Fields for Large-scale 3D Mapping
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+S">Shuangfu Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+J">Junqiao Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+K">Kai Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J">Jiaye Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+C">Chen Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+T">Tiantian Feng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 10 figures. Accepted by RAL2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04068" title="Abstract">arXiv:2401.04068</a> (replaced) [<a href="/pdf/2401.04068" title="Download PDF">pdf</a>, <a href="/format/2401.04068" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> IntervalMDP.jl: Accelerated Value Iteration for Interval Markov Decision  Processes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Mathiesen%2C+F+B">Frederik Baymler Mathiesen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Lahijanian%2C+M">Morteza Lahijanian</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Laurenti%2C+L">Luca Laurenti</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Logic in Computer Science (cs.LO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04312" title="Abstract">arXiv:2401.04312</a> (replaced) [<a href="/pdf/2401.04312" title="Download PDF">pdf</a>, <a href="/format/2401.04312" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Prompt-based Multi-interest Learning Method for Sequential  Recommendation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+X">Xue Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+X">Xuemeng Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+T">Tongliang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guan%2C+W">Weili Guan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05609" title="Abstract">arXiv:2401.05609</a> (replaced) [<a href="/pdf/2401.05609" title="Download PDF">pdf</a>, <a href="/ps/2401.05609" title="Download PostScript">ps</a>, <a href="/format/2401.05609" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A cable finite element formulation based on exact tension field for  static nonlinear analysis of cable structures
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Wenxiong Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Q">Qikun Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Suiyin Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06166" title="Abstract">arXiv:2401.06166</a> (replaced) [<a href="/pdf/2401.06166" title="Download PDF">pdf</a>, <a href="/ps/2401.06166" title="Download PostScript">ps</a>, <a href="/format/2401.06166" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> AdaMR: Adaptable Molecular Representation for Unified Pre-training  Strategy
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/q-bio?searchtype=author&amp;query=Ding%2C+Y">Yan Ding</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Cheng%2C+H">Hao Cheng</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Ye%2C+Z">Ziliang Ye</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Feng%2C+R">Ruyi Feng</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Tian%2C+W">Wei Tian</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Xie%2C+P">Peng Xie</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Zhang%2C+J">Juan Zhang</a>, 
  <a href="/search/q-bio?searchtype=author&amp;query=Gu%2C+Z">Zhongze Gu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06561" title="Abstract">arXiv:2401.06561</a> (replaced) [<a href="/pdf/2401.06561" title="Download PDF">pdf</a>, <a href="/format/2401.06561" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Intention Analysis Makes LLMs A Good Jailbreak Defender
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuqi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+L">Liang Ding</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lefei Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tao%2C+D">Dacheng Tao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 20 pages, 16 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06721" title="Abstract">arXiv:2401.06721</a> (replaced) [<a href="/pdf/2401.06721" title="Download PDF">pdf</a>, <a href="/ps/2401.06721" title="Download PostScript">ps</a>, <a href="/format/2401.06721" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Role of Identification in Data-driven Policy Iteration: A System  Theoretic Study
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Song%2C+B">Bowen Song</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Iannelli%2C+A">Andrea Iannelli</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06866" title="Abstract">arXiv:2401.06866</a> (replaced) [<a href="/pdf/2401.06866" title="Download PDF">pdf</a>, <a href="/format/2401.06866" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Health-LLM: Large Language Models for Health Prediction via Wearable  Sensor Data
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+Y">Yubin Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+X">Xuhai Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McDuff%2C+D">Daniel McDuff</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Breazeal%2C+C">Cynthia Breazeal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Park%2C+H+W">Hae Won Park</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07844" title="Abstract">arXiv:2401.07844</a> (replaced) [<a href="/pdf/2401.07844" title="Download PDF">pdf</a>, <a href="/ps/2401.07844" title="Download PostScript">ps</a>, <a href="/format/2401.07844" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The ODE Method for Stochastic Approximation and Reinforcement Learning  with Markovian Noise
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shuze Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Shuhang Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shangtong Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10862" title="Abstract">arXiv:2401.10862</a> (replaced) [<a href="/pdf/2401.10862" title="Download PDF">pdf</a>, <a href="/format/2401.10862" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs  Without Fine-Tuning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hasan%2C+A">Adib Hasan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rugina%2C+I">Ileana Rugina</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+A">Alex Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11183" title="Abstract">arXiv:2401.11183</a> (replaced) [<a href="/pdf/2401.11183" title="Download PDF">pdf</a>, <a href="/format/2401.11183" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Predictive stability filters for nonlinear dynamical systems affected by  disturbances
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Didier%2C+A">Alexandre Didier</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zanelli%2C+A">Andrea Zanelli</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wabersich%2C+K+P">Kim P. Wabersich</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted at NMPC'24
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11592" title="Abstract">arXiv:2401.11592</a> (replaced) [<a href="/pdf/2401.11592" title="Download PDF">pdf</a>, <a href="/format/2401.11592" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Differentially-Private Hierarchical Federated Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+F+P">Frank Po-Chen Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Brinton%2C+C">Christopher Brinton</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11671" title="Abstract">arXiv:2401.11671</a> (replaced) [<a href="/pdf/2401.11671" title="Download PDF">pdf</a>, <a href="/format/2401.11671" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> RTA-Former: Reverse Transformer Attention for Polyp Segmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Li%2C+Z">Zhikai Li</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Yi%2C+M">Murong Yi</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Uneri%2C+A">Ali Uneri</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Niu%2C+S">Sihan Niu</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Jones%2C+C">Craig Jones</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The paper has been accepted by EMBC 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11824" title="Abstract">arXiv:2401.11824</a> (replaced) [<a href="/pdf/2401.11824" title="Download PDF">pdf</a>, <a href="/format/2401.11824" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Rethinking Centered Kernel Alignment in Knowledge Distillation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zikai Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yunhang Shen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shao%2C+S">Shitong Shao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gong%2C+L">Linrui Gong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+S">Shaohui Lin</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11901" title="Abstract">arXiv:2401.11901</a> (replaced) [<a href="/pdf/2401.11901" title="Download PDF">pdf</a>, <a href="/format/2401.11901" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ORBGRAND: Achievable Rate for General Bit Channels and Application in  BICM
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenyi Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12422" title="Abstract">arXiv:2401.12422</a> (replaced) [<a href="/pdf/2401.12422" title="Download PDF">pdf</a>, <a href="/format/2401.12422" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> InverseMatrixVT3D: An Efficient Projection Matrix-Based Approach for 3D  Occupancy Prediction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ming%2C+Z">Zhenxing Ming</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Berrio%2C+J+S">Julie Stephany Berrio</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shan%2C+M">Mao Shan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Worrall%2C+S">Stewart Worrall</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13100" title="Abstract">arXiv:2401.13100</a> (replaced) [<a href="/pdf/2401.13100" title="Download PDF">pdf</a>, <a href="/format/2401.13100" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Bayesian sampling using interacting particles
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Chen%2C+S">Shi Chen</a>, 
  <a href="/search/math?searchtype=author&amp;query=Ding%2C+Z">Zhiyan Ding</a>, 
  <a href="/search/math?searchtype=author&amp;query=Li%2C+Q">Qin Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)
  
  </div>
  </div>
  </dd>
  <dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14040" title="Abstract">arXiv:2401.14040</a> (replaced) [<a href="/pdf/2401.14040" title="Download PDF">pdf</a>, <a href="/format/2401.14040" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> (Chat)GPT v BERT: Dawn of Justice for Semantic Change Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Periti%2C+F">Francesco Periti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dubossarsky%2C+H">Haim Dubossarsky</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tahmasebi%2C+N">Nina Tahmasebi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the Findings of EACL 2024 (<a href="https://aclanthology.org/2024.findings-eacl.29.pdf">this https URL</a>)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14505" title="Abstract">arXiv:2401.14505</a> (replaced) [<a href="/pdf/2401.14505" title="Download PDF">pdf</a>, <a href="/ps/2401.14505" title="Download PostScript">ps</a>, <a href="/format/2401.14505" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Unified KKL-based Interval Observer for Nonlinear Discrete-time  Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Dinh%2C+T+N">Thach Ngoc Dinh</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Tran%2C+G+Q+B">Gia Quoc Bao Tran</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 1 figure, IEEE Control Systems Letters with 63rd IEEE Conference on Decision and Control
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15182" title="Abstract">arXiv:2401.15182</a> (replaced) [<a href="/pdf/2401.15182" title="Download PDF">pdf</a>, <a href="/format/2401.15182" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> App Planner: Utilizing Generative AI in K-12 Mobile App Development  Education
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D">David Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ravi%2C+P">Prerna Ravi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Williams%2C+R">Randi Williams</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yoo%2C+D">Daeun Yoo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages, 3 figure, 1 table
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15489" title="Abstract">arXiv:2401.15489</a> (replaced) [<a href="/pdf/2401.15489" title="Download PDF">pdf</a>, <a href="/format/2401.15489" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Distilling Privileged Multimodal Information for Expression Recognition  using Optimal Transport
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Aslam%2C+M+H">Muhammad Haseeb Aslam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zeeshan%2C+M+O">Muhammad Osama Zeeshan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Belharbi%2C+S">Soufiane Belharbi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pedersoli%2C+M">Marco Pedersoli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Koerich%2C+A">Alessandro Koerich</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bacon%2C+S">Simon Bacon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Granger%2C+E">Eric Granger</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15946" title="Abstract">arXiv:2401.15946</a> (replaced) [<a href="/pdf/2401.15946" title="Download PDF">pdf</a>, <a href="/ps/2401.15946" title="Download PostScript">ps</a>, <a href="/format/2401.15946" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Approaching Maximum Likelihood Decoding Performance via Reshuffling  ORBGRAND
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wan%2C+L">Li Wan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenyi Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16025" title="Abstract">arXiv:2401.16025</a> (replaced) [<a href="/pdf/2401.16025" title="Download PDF">pdf</a>, <a href="/format/2401.16025" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Simple Policy Optimization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+Z">Zhengpeng Xie</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16465" title="Abstract">arXiv:2401.16465</a> (replaced) [<a href="/pdf/2401.16465" title="Download PDF">pdf</a>, <a href="/format/2401.16465" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DressCode: Autoregressively Sewing and Generating Garments from Text  Guidance
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kai He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yao%2C+K">Kaixin Yao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qixuan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Jingyi Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+L">Lingjie Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+L">Lan Xu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Project page: <a href="https://IHe-KaiI.github.io/DressCode/">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16719" title="Abstract">arXiv:2401.16719</a> (replaced) [<a href="/pdf/2401.16719" title="Download PDF">pdf</a>, <a href="/format/2401.16719" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> OptiState: State Estimation of Legged Robots using Gated Networks with  Transformer-based Vision and Kalman Filtering
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Schperberg%2C+A">Alexander Schperberg</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tanaka%2C+Y">Yusuke Tanaka</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mowlavi%2C+S">Saviz Mowlavi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+F">Feng Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Balaji%2C+B">Bharathan Balaji</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hong%2C+D">Dennis Hong</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to the 2024 IEEE International Conference on Robotics and Automation (ICRA), May 13-17, in Yokohama, Japan. 7 pages, 5 figures, 1 table
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17793" title="Abstract">arXiv:2401.17793</a> (replaced) [<a href="/pdf/2401.17793" title="Download PDF">pdf</a>, <a href="/format/2401.17793" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Optimal Dynamic Ancillary Services Provision Based on Local Power Grid  Perception
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=H%C3%A4berle%2C+V">Verena Häberle</a>, 
  <a href="/search/eess?searchtype=author&amp;query=He%2C+X">Xiuqiang He</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Huang%2C+L">Linbin Huang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Prieto-Araujo%2C+E">Eduardo Prieto-Araujo</a>, 
  <a href="/search/eess?searchtype=author&amp;query=D%C3%B6rfler%2C+F">Florian Dörfler</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 18 Figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00205" title="Abstract">arXiv:2402.00205</a> (replaced) [<a href="/pdf/2402.00205" title="Download PDF">pdf</a>, <a href="/format/2402.00205" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Decentralised, Collaborative, and Privacy-preserving Machine Learning  for Multi-Hospital Data
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+C">Congyu Fang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dziedzic%2C+A">Adam Dziedzic</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lin Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oliva%2C+L">Laura Oliva</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Verma%2C+A">Amol Verma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Razak%2C+F">Fahad Razak</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Papernot%2C+N">Nicolas Papernot</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bo Wang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> page 6 and 12, typos corrected. Results unchanged
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> eBioMedicine, vol. 101, p. 105006, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00711" title="Abstract">arXiv:2402.00711</a> (replaced) [<a href="/pdf/2402.00711" title="Download PDF">pdf</a>, <a href="/format/2402.00711" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Explaining Text Classifiers with Counterfactual Representations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lemberger%2C+P">Pirmin Lemberger</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Saillenfest%2C+A">Antoine Saillenfest</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 24 pages, 4 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01074" title="Abstract">arXiv:2402.01074</a> (replaced) [<a href="/pdf/2402.01074" title="Download PDF">pdf</a>, <a href="/format/2402.01074" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Neural Models and Algorithms for Sensorimotor Control of an Octopus Arm
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Wang%2C+T">Tixian Wang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Halder%2C+U">Udit Halder</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Gribkova%2C+E">Ekaterina Gribkova</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Gillette%2C+R">Rhanor Gillette</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Gazzola%2C+M">Mattia Gazzola</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Mehta%2C+P+G">Prashant G. Mehta</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO); Biological Physics (physics.bio-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01292" title="Abstract">arXiv:2402.01292</a> (replaced) [<a href="/pdf/2402.01292" title="Download PDF">pdf</a>, <a href="/format/2402.01292" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards the New XAI: A Hypothesis-Driven Approach to Decision Support  Using Evidence
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Le%2C+T">Thao Le</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Miller%2C+T">Tim Miller</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sonenberg%2C+L">Liz Sonenberg</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Singh%2C+R">Ronal Singh</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 26 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01895" title="Abstract">arXiv:2402.01895</a> (replaced) [<a href="/pdf/2402.01895" title="Download PDF">pdf</a>, <a href="/ps/2402.01895" title="Download PostScript">ps</a>, <a href="/format/2402.01895" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-397-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2636" style="width: 1.302em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.033em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(0.181em, 1001.033em, 1.436em, -999.998em); top: -0.983em; left: 0em;"><span class="mrow" id="MathJax-Span-2637"><span class="msubsup" id="MathJax-Span-2638"><span style="display: inline-block; position: relative; width: 0.988em; height: 0px;"><span style="position: absolute; clip: rect(3.183em, 1000.54em, 4.124em, -999.998em); top: -3.985em; left: 0em;"><span class="mi" id="MathJax-Span-2639" style="font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.54em;"><span class="mi" id="MathJax-Span-2640" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 0.988em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.442em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.281em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-397">L_q</script> Lower Bounds on Distributed Estimation via Fisher Information
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+W">Wei-Ning Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=%C3%96zg%C3%BCr%2C+A">Ayfer Özgür</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Statistics Theory (math.ST)
  
  </div>
  </div>
  </dd>
  <dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02352" title="Abstract">arXiv:2402.02352</a> (replaced) [<a href="/pdf/2402.02352" title="Download PDF">pdf</a>, <a href="/format/2402.02352" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Region-Based Representations Revisited
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shlapentokh-Rothman%2C+M">Michal Shlapentokh-Rothman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Blume%2C+A">Ansel Blume</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+Y">Yao Xiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuqun Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=V%2C+S+T">Sethuraman T V</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tao%2C+H">Heyi Tao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J+Y">Jae Yong Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Torres%2C+W">Wilfredo Torres</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yu-Xiong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hoiem%2C+D">Derek Hoiem</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> CVPR 2024 Camera Ready
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02367" title="Abstract">arXiv:2402.02367</a> (replaced) [<a href="/pdf/2402.02367" title="Download PDF">pdf</a>, <a href="/format/2402.02367" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring Intrinsic Properties of Medical Images for Self-Supervised  Binary Semantic Segmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Singh%2C+P">Pranav Singh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cirrone%2C+J">Jacopo Cirrone</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 30 pages, 10 figures, and 10 tables. Under Review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02678" title="Abstract">arXiv:2402.02678</a> (replaced) [<a href="/pdf/2402.02678" title="Download PDF">pdf</a>, <a href="/format/2402.02678" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Counterfactual Explanations of Black-box Machine Learning Models using  Causal Discovery with Applications to Credit Rating
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Takahashi%2C+D">Daisuke Takahashi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shimizu%2C+S">Shohei Shimizu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tanaka%2C+T">Takuma Tanaka</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02985" title="Abstract">arXiv:2402.02985</a> (replaced) [<a href="/pdf/2402.02985" title="Download PDF">pdf</a>, <a href="/format/2402.02985" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Applying Unsupervised Semantic Segmentation to High-Resolution UAV  Imagery for Enhanced Road Scene Parsing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zihan Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yongshang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+R">Ronggui Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+C">Chen Liang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03300" title="Abstract">arXiv:2402.03300</a> (replaced) [<a href="/pdf/2402.03300" title="Download PDF">pdf</a>, <a href="/format/2402.03300" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open  Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shao%2C+Z">Zhihong Shao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+P">Peiyi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qihao Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+R">Runxin Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+J">Junxiao Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bi%2C+X">Xiao Bi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Haowei Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Mingchuan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y+K">Y.K. Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Y. Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+D">Daya Guo</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03375" title="Abstract">arXiv:2402.03375</a> (replaced) [<a href="/pdf/2402.03375" title="Download PDF">pdf</a>, <a href="/format/2402.03375" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> BetterV: Controlled Verilog Generation with Discriminative Guidance
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pei%2C+Z">Zehua Pei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhen%2C+H">Hui-Ling Zhen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+M">Mingxuan Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yu Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+B">Bei Yu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Programming Languages (cs.PL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03469" title="Abstract">arXiv:2402.03469</a> (replaced) [<a href="/pdf/2402.03469" title="Download PDF">pdf</a>, <a href="/format/2402.03469" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Rethinking the Role of Proxy Rewards in Language Model Alignment
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+S">Sungdong Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Seo%2C+M">Minjoon Seo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Under review; Preprint
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03479" title="Abstract">arXiv:2402.03479</a> (replaced) [<a href="/pdf/2402.03479" title="Download PDF">pdf</a>, <a href="/format/2402.03479" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DRED: Zero-Shot Transfer in Reinforcement Learning via Data-Regularised  Environment Design
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Garcin%2C+S">Samuel Garcin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Doran%2C+J">James Doran</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+S">Shangmin Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lucas%2C+C+G">Christopher G. Lucas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Albrecht%2C+S+V">Stefano V. Albrecht</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> A preliminary version of this work (<a href="/abs/2310.03494">arXiv:2310.03494</a>) was presented at the ALOE workshop, NeurIPS 2023
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03690" title="Abstract">arXiv:2402.03690</a> (replaced) [<a href="/pdf/2402.03690" title="Download PDF">pdf</a>, <a href="/format/2402.03690" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> 3Doodle: Compact Abstraction of Objects with 3D Strokes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Choi%2C+C">Changwoon Choi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Jaeah Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Park%2C+J">Jaesik Park</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+Y+M">Young Min Kim</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> SIGGRAPH 2024 (Transactions on Graphics)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04718" title="Abstract">arXiv:2402.04718</a> (replaced) [<a href="/pdf/2402.04718" title="Download PDF">pdf</a>, <a href="/format/2402.04718" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Adaptive Smooth Control via Nonsingular Fast Terminal Sliding Mode for  Distributed Space Telescope Demonstration Mission by CubeSat Formation Flying
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Jeon%2C+S">Soobin Jeon</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Cho%2C+H">Hancheol Cho</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Park%2C+S">Sang-Young Park</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05625" title="Abstract">arXiv:2402.05625</a> (replaced) [<a href="/pdf/2402.05625" title="Download PDF">pdf</a>, <a href="/format/2402.05625" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Coded Many-User Multiple Access via Approximate Message Passing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaoqi Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hsieh%2C+K">Kuan Hsieh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Venkataramanan%2C+R">Ramji Venkataramanan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages, 4 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
  
  </div>
  </div>
  </dd>
  <dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06986" title="Abstract">arXiv:2402.06986</a> (replaced) [<a href="/pdf/2402.06986" title="Download PDF">pdf</a>, <a href="/format/2402.06986" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Cacophony: An Improved Contrastive Audio-Text Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+G">Ge Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Darefsky%2C+J">Jordan Darefsky</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Duan%2C+Z">Zhiyao Duan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Work in Progress
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07397" title="Abstract">arXiv:2402.07397</a> (replaced) [<a href="/pdf/2402.07397" title="Download PDF">pdf</a>, <a href="/format/2402.07397" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Leveraging AI to Advance Science and Computing Education across Africa:  Challenges, Progress and Opportunities
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Boateng%2C+G">George Boateng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Book chapter for the book: "Artificial Intelligence in Education: The Intersection of Technology and Pedagogy"
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07596" title="Abstract">arXiv:2402.07596</a> (replaced) [<a href="/pdf/2402.07596" title="Download PDF">pdf</a>, <a href="/format/2402.07596" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Sheet Music Transformer: End-To-End Optical Music Recognition Beyond  Monophonic Transcription
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=R%C3%ADos-Vila%2C+A">Antonio Ríos-Vila</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Calvo-Zaragoza%2C+J">Jorge Calvo-Zaragoza</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Paquet%2C+T">Thierry Paquet</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to the International Conference on Document Analysis and Recognition 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07696" title="Abstract">arXiv:2402.07696</a> (replaced) [<a href="/pdf/2402.07696" title="Download PDF">pdf</a>, <a href="/format/2402.07696" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Synthesizing Strongly Equivalent Logic Programs: Beth Definability for  Answer Set Programs via Craig Interpolation in First-Order Logic
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Heuer%2C+J">Jan Heuer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wernhard%2C+C">Christoph Wernhard</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Preprint version of the IJCAR 2024 contribution
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08015" title="Abstract">arXiv:2402.08015</a> (replaced) [<a href="/pdf/2402.08015" title="Download PDF">pdf</a>, <a href="/format/2402.08015" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and  Generative Datasets
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Azime%2C+I+A">Israel Abebe Azime</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tonja%2C+A+L">Atnafu Lambebo Tonja</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Belay%2C+T+D">Tadesse Destaw Belay</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fuge%2C+M+Y">Mitiku Yohannes Fuge</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wassie%2C+A+K">Aman Kassahun Wassie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jada%2C+E+S">Eyasu Shiferaw Jada</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chanie%2C+Y">Yonas Chanie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sewunetie%2C+W+T">Walelign Tewabe Sewunetie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yimam%2C+S+M">Seid Muhie Yimam</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08367" title="Abstract">arXiv:2402.08367</a> (replaced) [<a href="/pdf/2402.08367" title="Download PDF">pdf</a>, <a href="/format/2402.08367" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> RBF-PINN: Non-Fourier Positional Embedding in Physics-Informed Neural  Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+C">Chengxi Zeng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Burghardt%2C+T">Tilo Burghardt</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gambaruto%2C+A+M">Alberto M Gambaruto</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2402.06955">arXiv:2402.06955</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08439" title="Abstract">arXiv:2402.08439</a> (replaced) [<a href="/pdf/2402.08439" title="Download PDF">pdf</a>, <a href="/format/2402.08439" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> JeFaPaTo -- A joint toolbox for blinking analysis and facial features  extraction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=B%C3%BCchner%2C+T">Tim Büchner</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mothes%2C+O">Oliver Mothes</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guntinas-Lichius%2C+O">Orlando Guntinas-Lichius</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Denzler%2C+J">Joachim Denzler</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> A Preprint - Submitted to the Journal of Open Source Software; 7 pages, 3 figures, 3 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08698" title="Abstract">arXiv:2402.08698</a> (replaced) [<a href="/pdf/2402.08698" title="Download PDF">pdf</a>, <a href="/format/2402.08698" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> AMEND: A Mixture of Experts Framework for Long-tailed Trajectory  Prediction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mercurius%2C+R+C">Ray Coden Mercurius</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ahmadi%2C+E">Ehsan Ahmadi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shabestary%2C+S+M+A">Soheil Mohamad Alizadeh Shabestary</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rasouli%2C+A">Amir Rasouli</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09085" title="Abstract">arXiv:2402.09085</a> (replaced) [<a href="/pdf/2402.09085" title="Download PDF">pdf</a>, <a href="/format/2402.09085" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Polynomial Semantics of Tractable Probabilistic Circuits
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Broadrick%2C+O">Oliver Broadrick</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Honghua Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Van+den+Broeck%2C+G">Guy Van den Broeck</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09246" title="Abstract">arXiv:2402.09246</a> (replaced) [<a href="/pdf/2402.09246" title="Download PDF">pdf</a>, <a href="/format/2402.09246" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Who Plays First? Optimizing the Order of Play in Stackelberg Games with  Many Robots
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">Haimin Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dragotto%2C+G">Gabriele Dragotto</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zixu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+K">Kaiqu Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stellato%2C+B">Bartolomeo Stellato</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fisac%2C+J+F">Jaime F. Fisac</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY); Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09353" title="Abstract">arXiv:2402.09353</a> (replaced) [<a href="/pdf/2402.09353" title="Download PDF">pdf</a>, <a href="/format/2402.09353" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DoRA: Weight-Decomposed Low-Rank Adaptation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shih-Yang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chien-Yi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yin%2C+H">Hongxu Yin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Molchanov%2C+P">Pavlo Molchanov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+K">Kwang-Ting Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Min-Hung Chen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Code available at <a href="https://github.com/NVlabs/DoRA">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09474" title="Abstract">arXiv:2402.09474</a> (replaced) [<a href="/pdf/2402.09474" title="Download PDF">pdf</a>, <a href="/format/2402.09474" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Deciphering Heartbeat Signatures: A Vision Transformer Approach to  Explainable Atrial Fibrillation Detection from ECG Signals
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Mohan%2C+A">Aruna Mohan</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Elbers%2C+D">Danne Elbers</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zilbershot%2C+O">Or Zilbershot</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Afghah%2C+F">Fatemeh Afghah</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Vorchheimer%2C+D">David Vorchheimer</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted for publication at the 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, IEEE EMBC 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10494" title="Abstract">arXiv:2402.10494</a> (replaced) [<a href="/pdf/2402.10494" title="Download PDF">pdf</a>, <a href="/format/2402.10494" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mechanised uniform interpolation for modal logics K, GL, and iSL
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=F%C3%A9r%C3%A9e%2C+H">Hugo Férée</a>, 
  <a href="/search/cs?searchtype=author&amp;query=van+der+Giessen%2C+I">Iris van der Giessen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=van+Gool%2C+S">Sam van Gool</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shillito%2C+I">Ian Shillito</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 18 pages, to appear in IJCAR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10862" title="Abstract">arXiv:2402.10862</a> (replaced) [<a href="/pdf/2402.10862" title="Download PDF">pdf</a>, <a href="/format/2402.10862" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Differential Private Federated Transfer Learning for Mental Health  Monitoring in Everyday Settings: A Case Study on Stress Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyu Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhongqi Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Azimi%2C+I">Iman Azimi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rahmani%2C+A+M">Amir M. Rahmani</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 5 pages, 2 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11515" title="Abstract">arXiv:2402.11515</a> (replaced) [<a href="/pdf/2402.11515" title="Download PDF">pdf</a>, <a href="/format/2402.11515" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Optimal Parallelization Strategies for Active Flow Control in Deep  Reinforcement Learning-Based Computational Fluid Dynamics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jia%2C+W">Wang Jia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Hang Xu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Fluid Dynamics (physics.flu-dyn)
  
  </div>
  </div>
  </dd>
  <dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11567" title="Abstract">arXiv:2402.11567</a> (replaced) [<a href="/pdf/2402.11567" title="Download PDF">pdf</a>, <a href="/ps/2402.11567" title="Download PostScript">ps</a>, <a href="/format/2402.11567" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Saturability of the Quantum Cramér-Rao Bound in Multiparameter  Quantum Estimation at the Single-Copy Level
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Nurdin%2C+H+I">Hendra I. Nurdin</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, no figures. Minor typos corrected and numbering now follows the published version
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> IEEE Control Systems Lett., vol. 8, pp. 376-381, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12147" title="Abstract">arXiv:2402.12147</a> (replaced) [<a href="/pdf/2402.12147" title="Download PDF">pdf</a>, <a href="/format/2402.12147" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Surprising Efficacy of Fine-Tuned Transformers for Fact-Checking over  Larger Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Setty%2C+V">Vinay Setty</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted in SIGIR 2024 (industry track)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12208" title="Abstract">arXiv:2402.12208</a> (replaced) [<a href="/pdf/2402.12208" title="Download PDF">pdf</a>, <a href="/format/2402.12208" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Language-Codec: Reducing the Gaps Between Discrete Codec Representation  and Speech Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Ji%2C+S">Shengpeng Ji</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Fang%2C+M">Minghui Fang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Jiang%2C+Z">Ziyue Jiang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zheng%2C+S">Siqi Zheng</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Chen%2C+Q">Qian Chen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Huang%2C+R">Rongjie Huang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zuo%2C+J">Jialung Zuo</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wang%2C+S">Shulei Wang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Zhao%2C+Z">Zhou Zhao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> We release a more powerful checkpoint in Language-Codec v3
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
  
  </div>
  </div>
  </dd>
  <dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14083" title="Abstract">arXiv:2402.14083</a> (replaced) [<a href="/pdf/2402.14083" title="Download PDF">pdf</a>, <a href="/format/2402.14083" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Beyond A*: Better Planning with Transformers via Search Dynamics  Bootstrapping
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lehnert%2C+L">Lucas Lehnert</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sukhbaatar%2C+S">Sainbayar Sukhbaatar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Su%2C+D">DiJia Su</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+Q">Qinqing Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mcvay%2C+P">Paul Mcvay</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rabbat%2C+M">Michael Rabbat</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yuandong Tian</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14297" title="Abstract">arXiv:2402.14297</a> (replaced) [<a href="/pdf/2402.14297" title="Download PDF">pdf</a>, <a href="/format/2402.14297" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Semantics-Empowered Space-Air-Ground-Sea Integrated Network: New  Paradigm, Frameworks, and Challenges
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Meng%2C+S">Siqi Meng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+S">Shaohua Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiaming Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+J">Junlan Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+H">Haibo Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qinyu Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14313" title="Abstract">arXiv:2402.14313</a> (replaced) [<a href="/pdf/2402.14313" title="Download PDF">pdf</a>, <a href="/format/2402.14313" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning to Kern: Set-wise Estimation of Optimal Letter Space
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Nakatsuru%2C+K">Kei Nakatsuru</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Uchida%2C+S">Seiichi Uchida</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14846" title="Abstract">arXiv:2402.14846</a> (replaced) [<a href="/pdf/2402.14846" title="Download PDF">pdf</a>, <a href="/format/2402.14846" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Stick to your Role! Context-dependence and Stability of Personal Values  Expression in Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kova%C4%8D%2C+G">Grgur Kovač</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Portelas%2C+R">Rémy Portelas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sawayama%2C+M">Masataka Sawayama</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dominey%2C+P+F">Peter Ford Dominey</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oudeyer%2C+P">Pierre-Yves Oudeyer</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The project website and code are available at <a href="https://sites.google.com/view/llmvaluestability">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15164" title="Abstract">arXiv:2402.15164</a> (replaced) [<a href="/pdf/2402.15164" title="Download PDF">pdf</a>, <a href="/ps/2402.15164" title="Download PostScript">ps</a>, <a href="/format/2402.15164" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> EasyRL4Rec: An Easy-to-use Library for Reinforcement Learning Based  Recommender Systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yuanqing Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+C">Chongming Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiawei Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+H">Heng Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuefeng Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qian Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+W">Weizhi Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Min Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by SIGIR2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15340" title="Abstract">arXiv:2402.15340</a> (replaced) [<a href="/pdf/2402.15340" title="Download PDF">pdf</a>, <a href="/ps/2402.15340" title="Download PostScript">ps</a>, <a href="/format/2402.15340" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MetaStates: An Approach for Representing Human Workers'  Psychophysiological States in the Industrial Metaverse
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Eyam%2C+A+T">Aitor Toichoa Eyam</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lastra%2C+J+L+M">Jose L. Martinez Lastra</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 6 figures, 4 tables, journal
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15659" title="Abstract">arXiv:2402.15659</a> (replaced) [<a href="/pdf/2402.15659" title="Download PDF">pdf</a>, <a href="/format/2402.15659" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DeepLight: Reconstructing High-Resolution Observations of Nighttime  Light With Multi-Modal Remote Sensing Data
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lixian Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+R">Runmin Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+S">Shuai Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jinxiao Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Mengxuan Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+J">Juepeng Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fu%2C+H">Haohuan Fu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15761" title="Abstract">arXiv:2402.15761</a> (replaced) [<a href="/pdf/2402.15761" title="Download PDF">pdf</a>, <a href="/format/2402.15761" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Res-VMamba: Fine-Grained Food Category Visual Classification Using  Selective State Space Models with Deep Residual Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C">Chi-Sheng Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+G">Guan-Ying Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+D">Dong Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+D">Di Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+D">Dai-Shi Chen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages, 3 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16123" title="Abstract">arXiv:2402.16123</a> (replaced) [<a href="/pdf/2402.16123" title="Download PDF">pdf</a>, <a href="/format/2402.16123" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> InstructEdit: Instruction-based Knowledge Editing for Large Language  Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+N">Ningyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tian%2C+B">Bozhong Tian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+S">Siyuan Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+X">Xiaozhuan Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yi Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+K">Kouying Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gou%2C+Y">Yanjie Gou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xi Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Huajun Chen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> IJCAI 2024; the project website is at <a href="https://www.zjukg.org/project/InstructEdit/">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16839" title="Abstract">arXiv:2402.16839</a> (replaced) [<a href="/pdf/2402.16839" title="Download PDF">pdf</a>, <a href="/ps/2402.16839" title="Download PostScript">ps</a>, <a href="/format/2402.16839" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Displacing Science
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Linzhuo Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yiling Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+L">Lingfei Wu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 1 figure
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Social and Information Networks (cs.SI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16906" title="Abstract">arXiv:2402.16906</a> (replaced) [<a href="/pdf/2402.16906" title="Download PDF">pdf</a>, <a href="/format/2402.16906" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LDB: A Large Language Model Debugger via Verifying Runtime Execution  Step-by-step
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+L">Lily Zhong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zilong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shang%2C+J">Jingbo Shang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Preprint
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17151" title="Abstract">arXiv:2402.17151</a> (replaced) [<a href="/pdf/2402.17151" title="Download PDF">pdf</a>, <a href="/format/2402.17151" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Clustering Document Parts: Detecting and Characterizing Influence  Campaigns from Documents
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhengxiang Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rambow%2C+O">Owen Rambow</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages, 2 figures, 5 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17743" title="Abstract">arXiv:2402.17743</a> (replaced) [<a href="/pdf/2402.17743" title="Download PDF">pdf</a>, <a href="/format/2402.17743" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Rose: Composable Autodiff for the Interactive Web
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Estep%2C+S">Sam Estep</a> (Carnegie Mellon University), 
  <a href="/search/cs?searchtype=author&amp;query=Ni%2C+W">Wode Ni</a> (Carnegie Mellon University), 
  <a href="/search/cs?searchtype=author&amp;query=Rothkopf%2C+R">Raven Rothkopf</a> (Barnard College, Columbia University), 
  <a href="/search/cs?searchtype=author&amp;query=Sunshine%2C+J">Joshua Sunshine</a> (Carnegie Mellon University)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17927" title="Abstract">arXiv:2402.17927</a> (replaced) [<a href="/pdf/2402.17927" title="Download PDF">pdf</a>, <a href="/ps/2402.17927" title="Download PostScript">ps</a>, <a href="/format/2402.17927" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MCSat-based Finite Field Reasoning in the Yices2 SMT Solver
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hader%2C+T">Thomas Hader</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kaufmann%2C+D">Daniela Kaufmann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Irfan%2C+A">Ahmed Irfan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Graham-Lengrand%2C+S">Stéphane Graham-Lengrand</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kov%C3%A1cs%2C+L">Laura Kovács</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17992" title="Abstract">arXiv:2402.17992</a> (replaced) [<a href="/pdf/2402.17992" title="Download PDF">pdf</a>, <a href="/ps/2402.17992" title="Download PostScript">ps</a>, <a href="/format/2402.17992" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Physics-Informed Machine Learning for Seismic Response Prediction OF  Nonlinear Steel Moment Resisting Frame Structures
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Bond%2C+R+B">R. Bailey Bond</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Ren%2C+P">Pu Ren</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Hajjar%2C+J+F">Jerome F. Hajjar</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Sun%2C+H">Hao Sun</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 34 pages, 12 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18090" title="Abstract">arXiv:2402.18090</a> (replaced) [<a href="/pdf/2402.18090" title="Download PDF">pdf</a>, <a href="/format/2402.18090" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Computing Minimal Absent Words and Extended Bispecial Factors with CDAWG  Space
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Inenaga%2C+S">Shunsuke Inenaga</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mieno%2C+T">Takuya Mieno</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Arimura%2C+H">Hiroki Arimura</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Funakoshi%2C+M">Mitsuru Funakoshi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fujishige%2C+Y">Yuta Fujishige</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted for IWOCA 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Formal Languages and Automata Theory (cs.FL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18430" title="Abstract">arXiv:2402.18430</a> (replaced) [<a href="/pdf/2402.18430" title="Download PDF">pdf</a>, <a href="/ps/2402.18430" title="Download PostScript">ps</a>, <a href="/format/2402.18430" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Smishing Dataset I: Phishing SMS Dataset from Smishtank.com
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Timko%2C+D">Daniel Timko</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rahman%2C+M+L">Muhammad Lutfor Rahman</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18598" title="Abstract">arXiv:2402.18598</a> (replaced) [<a href="/pdf/2402.18598" title="Download PDF">pdf</a>, <a href="/ps/2402.18598" title="Download PostScript">ps</a>, <a href="/format/2402.18598" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Note: Evolutionary Game Theory Focus Informational Health: The Cocktail  Party Effect Through Werewolfgame under Incomplete Information and ESS Search  Method Using Expected Gains of Repeated Dilemmas
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Kawahata%2C+Y">Yasuko Kawahata</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Werewolf Games, Evolutionary Game Theory, Non-Complete Information Games, Expanding Form Games, Cocktail Party Effect, Fake News, Evolutionary Stability Strategy (ESS), Information Pollution Risk, Numerical Simulation, Strategic Interaction, Replicator Equation
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18705" title="Abstract">arXiv:2402.18705</a> (replaced) [<a href="/pdf/2402.18705" title="Download PDF">pdf</a>, <a href="/ps/2402.18705" title="Download PostScript">ps</a>, <a href="/format/2402.18705" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> How Platform Exchange and Safeguards Matter: The Case of Sexual Risk in  Airbnb and Couchsurfing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Skyler Wang</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Proc. ACM Hum.-Comput. Interact., 8, CSCW1, Article 204 (April
    2024), 23 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00127" title="Abstract">arXiv:2403.00127</a> (replaced) [<a href="/pdf/2403.00127" title="Download PDF">pdf</a>, <a href="/ps/2403.00127" title="Download PostScript">ps</a>, <a href="/format/2403.00127" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Prompting ChatGPT for Translation: A Comparative Analysis of Translation  Brief and Persona Prompts
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+S">Sui He</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00372" title="Abstract">arXiv:2403.00372</a> (replaced) [<a href="/pdf/2403.00372" title="Download PDF">pdf</a>, <a href="/format/2403.00372" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> HyperSDFusion: Bridging Hierarchical Structures in Language and Geometry  for Enhanced 3D Text2Shape Generation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Leng%2C+Z">Zhiying Leng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Birdal%2C+T">Tolga Birdal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+X">Xiaohui Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tombari%2C+F">Federico Tombari</a>
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> IEEE/CVF conference on computer vision and pattern recognition
    2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00399" title="Abstract">arXiv:2403.00399</a> (replaced) [<a href="/pdf/2403.00399" title="Download PDF">pdf</a>, <a href="/format/2403.00399" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> As Soon as Possible but Rationally
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bruy%C3%A8re%2C+V">Véronique Bruyère</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Grandmont%2C+C">Christophe Grandmont</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Raskin%2C+J">Jean-François Raskin</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01197" title="Abstract">arXiv:2403.01197</a> (replaced) [<a href="/pdf/2403.01197" title="Download PDF">pdf</a>, <a href="/format/2403.01197" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Quan%2C+S">Shanghaoran Quan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 23 pages, 8 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01632" title="Abstract">arXiv:2403.01632</a> (replaced) [<a href="/pdf/2403.01632" title="Download PDF">pdf</a>, <a href="/format/2403.01632" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SynCode: LLM Generation with Grammar Augmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ugare%2C+S">Shubham Ugare</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Suresh%2C+T">Tarun Suresh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kang%2C+H">Hangoo Kang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Misailovic%2C+S">Sasa Misailovic</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Singh%2C+G">Gagandeep Singh</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Formal Languages and Automata Theory (cs.FL); Programming Languages (cs.PL); Software Engineering (cs.SE)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01699" title="Abstract">arXiv:2403.01699</a> (replaced) [<a href="/pdf/2403.01699" title="Download PDF">pdf</a>, <a href="/format/2403.01699" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Brilla AI: AI Contestant for the National Science and Maths Quiz
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Boateng%2C+G">George Boateng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mensah%2C+J+A">Jonathan Abrefah Mensah</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yeboah%2C+K+T">Kevin Takyi Yeboah</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Edor%2C+W">William Edor</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mensah-Onumah%2C+A+K">Andrew Kojo Mensah-Onumah</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ibrahim%2C+N+D">Naafi Dasana Ibrahim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yeboah%2C+N+S">Nana Sam Yeboah</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 14 pages. Accepted for the WideAIED track at the 25th International Conference on AI in Education (AIED 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Sound (cs.SD); Audio and Speech Processing (eess.AS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02090" title="Abstract">arXiv:2403.02090</a> (replaced) [<a href="/pdf/2403.02090" title="Download PDF">pdf</a>, <a href="/format/2403.02090" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Modeling Multimodal Social Interactions: New Challenges and Baselines  with Densely Aligned Representations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+S">Sangmin Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lai%2C+B">Bolin Lai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ryan%2C+F">Fiona Ryan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Boote%2C+B">Bikram Boote</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rehg%2C+J+M">James M. Rehg</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> CVPR 2024 Oral
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02342" title="Abstract">arXiv:2403.02342</a> (replaced) [<a href="/pdf/2403.02342" title="Download PDF">pdf</a>, <a href="/ps/2403.02342" title="Download PostScript">ps</a>, <a href="/format/2403.02342" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Entanglement: Balancing Punishment and Compensation, Repeated Dilemma  Game-Theoretic Analysis of Maximum Compensation Problem for Bypass and Least  Cost Paths in Fact-Checking, Case of Fake News with Weak Wallace's Law
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Kawahata%2C+Y">Yasuko Kawahata</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Recurring Dilemma, Wallace's Law, Entanglement, Detour Path, Least Cost Path, Metzler Function, Metzler Matrix, Fake News, Fact-Checking, Punitive Dominance Problem, Maximum Compensation Problem, Informational health
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI); Theoretical Economics (econ.TH)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02687" title="Abstract">arXiv:2403.02687</a> (replaced) [<a href="/e-print/2403.02687" title="Download source">src</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhanced DareFightingICE Competitions: Sound Design and AI Competitions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Khan%2C+I">Ibrahim Khan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nimpattanavong%2C+C">Chollakorn Nimpattanavong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Van+Nguyen%2C+T">Thai Van Nguyen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Plupattanakit%2C+K">Kantinan Plupattanakit</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Thawonmas%2C+R">Ruck Thawonmas</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This paper describes a new competition platform using Unity for our competitions at the 2024 IEEE Conference on Games (CoG 2024). It was accepted for presentation at CoG 2024. However, we recently discovered a much more effective way to do this task without using Unity, leading to our decision to withdraw the paper from CoG 2024 and ArXiv
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02751" title="Abstract">arXiv:2403.02751</a> (replaced) [<a href="/pdf/2403.02751" title="Download PDF">pdf</a>, <a href="/format/2403.02751" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Splat-Nav: Safe Real-Time Robot Navigation in Gaussian Splatting Maps
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Timothy Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shorinwa%2C+O">Ola Shorinwa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bruno%2C+J">Joseph Bruno</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Javier Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+W">Weijia Zeng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nagami%2C+K">Keiko Nagami</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dames%2C+P">Philip Dames</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schwager%2C+M">Mac Schwager</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03218" title="Abstract">arXiv:2403.03218</a> (replaced) [<a href="/pdf/2403.03218" title="Download PDF">pdf</a>, <a href="/format/2403.03218" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+N">Nathaniel Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+A">Alexander Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gopal%2C+A">Anjali Gopal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yue%2C+S">Summer Yue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Berrios%2C+D">Daniel Berrios</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gatti%2C+A">Alice Gatti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J+D">Justin D. Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dombrowski%2C+A">Ann-Kathrin Dombrowski</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shashwat Goel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Phan%2C+L">Long Phan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mukobi%2C+G">Gabriel Mukobi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Helm-Burger%2C+N">Nathan Helm-Burger</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lababidi%2C+R">Rassin Lababidi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Justen%2C+L">Lennart Justen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+A+B">Andrew B. Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Michael Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Barrass%2C+I">Isabelle Barrass</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+O">Oliver Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xiaoyuan Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tamirisa%2C+R">Rishub Tamirisa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bharathi%2C+B">Bhrugu Bharathi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khoja%2C+A">Adam Khoja</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhenqi Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Herbert-Voss%2C+A">Ariel Herbert-Voss</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Breuer%2C+C+B">Cort B. Breuer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Marks%2C+S">Samuel Marks</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Patel%2C+O">Oam Patel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zou%2C+A">Andy Zou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mazeika%2C+M">Mantas Mazeika</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zifan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oswal%2C+P">Palash Oswal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+W">Weiran Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hunt%2C+A+A">Adam A. Hunt</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tienken-Harder%2C+J">Justin Tienken-Harder</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shih%2C+K+Y">Kevin Y. Shih</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Talley%2C+K">Kemper Talley</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guan%2C+J">John Guan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kaplan%2C+R">Russell Kaplan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Steneker%2C+I">Ian Steneker</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Campbell%2C+D">David Campbell</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jokubaitis%2C+B">Brad Jokubaitis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Levinson%2C+A">Alex Levinson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jean Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qian%2C+W">William Qian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Karmakar%2C+K+K">Kallol Krishna Karmakar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Basart%2C+S">Steven Basart</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fitz%2C+S">Stephen Fitz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Levine%2C+M">Mindy Levine</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kumaraguru%2C+P">Ponnurangam Kumaraguru</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tupakula%2C+U">Uday Tupakula</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Varadharajan%2C+V">Vijay Varadharajan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shoshitaishvili%2C+Y">Yan Shoshitaishvili</a>,  et al. (4 additional authors not shown)
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> See the project page at <a href="https://wmdp.ai">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03473" title="Abstract">arXiv:2403.03473</a> (replaced) [<a href="/pdf/2403.03473" title="Download PDF">pdf</a>, <a href="/format/2403.03473" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Inverse-Free Fast Natural Gradient Descent Method for Deep Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ou%2C+X">Xinwei Ou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+C">Ce Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+X">Xiaolin Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yipeng Liu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04327" title="Abstract">arXiv:2403.04327</a> (replaced) [<a href="/pdf/2403.04327" title="Download PDF">pdf</a>, <a href="/format/2403.04327" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ProMoAI: Process Modeling with Generative AI
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kourani%2C+H">Humam Kourani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Berti%2C+A">Alessandro Berti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schuster%2C+D">Daniel Schuster</a>, 
  <a href="/search/cs?searchtype=author&amp;query=van+der+Aalst%2C+W+M+P">Wil M. P. van der Aalst</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04618" title="Abstract">arXiv:2403.04618</a> (replaced) [<a href="/pdf/2403.04618" title="Download PDF">pdf</a>, <a href="/format/2403.04618" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Strong Priority and Determinacy in Timed CCS
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liquori%2C+L">Luigi Liquori</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mendler%2C+M">Michael Mendler</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.05370" title="Abstract">arXiv:2403.05370</a> (replaced) [<a href="/pdf/2403.05370" title="Download PDF">pdf</a>, <a href="/ps/2403.05370" title="Download PostScript">ps</a>, <a href="/format/2403.05370" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On a Software Joint Velocity Limitation of a Spherical Parallel  Manipulator with Coaxial Input Shafts
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=L%C3%AA%2C+A">Alexandre Lê</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rance%2C+G">Guillaume Rance</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rouillier%2C+F">Fabrice Rouillier</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Quadrat%2C+A">Arnaud Quadrat</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chablat%2C+D">Damien Chablat</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages, 8 figures, 19th International Symposium on Advances in Robot Kinematics, Ljubljana, June 30 - July 4, 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.06285" title="Abstract">arXiv:2403.06285</a> (replaced) [<a href="/pdf/2403.06285" title="Download PDF">pdf</a>, <a href="/format/2403.06285" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Tunable Universal Formula for Safety-Critical Control
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Li%2C+M">Ming Li</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Sun%2C+Z">Zhiyong Sun</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Koelewijn%2C+P+J+W">Patrick J. W. Koelewijn</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Weiland%2C+S">Siep Weiland</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.06694" title="Abstract">arXiv:2403.06694</a> (replaced) [<a href="/pdf/2403.06694" title="Download PDF">pdf</a>, <a href="/ps/2403.06694" title="Download PostScript">ps</a>, <a href="/format/2403.06694" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-398-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2641" style="width: 2.87em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.287em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(0.181em, 1002.287em, 1.302em, -999.998em); top: -0.983em; left: 0em;"><span class="mrow" id="MathJax-Span-2642"><span class="msubsup" id="MathJax-Span-2643"><span style="display: inline-block; position: relative; width: 2.242em; height: 0px;"><span style="position: absolute; clip: rect(3.183em, 1000.674em, 4.124em, -999.998em); top: -3.985em; left: 0em;"><span class="mi" id="MathJax-Span-2644" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.674em;"><span class="texatom" id="MathJax-Span-2645"><span class="mrow" id="MathJax-Span-2646"><span class="mn" id="MathJax-Span-2647" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mi" id="MathJax-Span-2648" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-2649" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-2650" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 0.988em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.275em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.169em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-398">C_{2k+1}</script>-coloring of bounded-diameter graphs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Piecyk%2C+M">Marta Piecyk</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.06915" title="Abstract">arXiv:2403.06915</a> (replaced) [<a href="/pdf/2403.06915" title="Download PDF">pdf</a>, <a href="/format/2403.06915" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Monitoring the Venice Lagoon: an IoT Cloud-Based Sensor Nerwork Approach
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Campagnaro%2C+F">Filippo Campagnaro</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ghalkhani%2C+M">Matin Ghalkhani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tumiati%2C+R">Riccardo Tumiati</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Marin%2C+F">Federico Marin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Del+Grande%2C+M">Matteo Del Grande</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pozzebon%2C+A">Alessandro Pozzebon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Battisti%2C+D">Davide De Battisti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Francescon%2C+R">Roberto Francescon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zorzi%2C+M">Michele Zorzi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.07928" title="Abstract">arXiv:2403.07928</a> (replaced) [<a href="/pdf/2403.07928" title="Download PDF">pdf</a>, <a href="/format/2403.07928" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Strategic Bidding in Knapsack Auctions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Khezr%2C+P">Peyman Khezr</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mohan%2C+V">Vijay Mohan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Page%2C+L">Lionel Page</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.08058" title="Abstract">arXiv:2403.08058</a> (replaced) [<a href="/pdf/2403.08058" title="Download PDF">pdf</a>, <a href="/format/2403.08058" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CHAI: Clustered Head Attention for Efficient LLM Inference
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+S">Saurabh Agarwal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Acun%2C+B">Bilge Acun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hosmer%2C+B">Basil Hosmer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Elhoushi%2C+M">Mostafa Elhoushi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+Y">Yejin Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Venkataraman%2C+S">Shivaram Venkataraman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Papailiopoulos%2C+D">Dimitris Papailiopoulos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+C">Carole-Jean Wu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.08748" title="Abstract">arXiv:2403.08748</a> (replaced) [<a href="/pdf/2403.08748" title="Download PDF">pdf</a>, <a href="/format/2403.08748" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Real-time 3D semantic occupancy prediction for autonomous vehicles using  memory-efficient sparse convolution
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sze%2C+S">Samuel Sze</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kunze%2C+L">Lars Kunze</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 7 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.08774" title="Abstract">arXiv:2403.08774</a> (replaced) [<a href="/pdf/2403.08774" title="Download PDF">pdf</a>, <a href="/ps/2403.08774" title="Download PostScript">ps</a>, <a href="/format/2403.08774" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Discussion of Loop Expansion and Introduction of Series Cutting  Functions to Local Potential Approximation: Complexity Analysis Using Green's  Functions, Cutting Of Nth-Order Social Interactions For Progressive Safety
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Kawahata%2C+Y">Yasuko Kawahata</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> In this study, we focus on the aforementioned paper, "Examination Kubo-Matsubara Green's Function Of The Edwards-Anderson Model: Extreme Value Information Flow Of Nth-Order Interpolated Extrapolation Of Zero Phenomena Using The Replica Method (2024)"
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.09880" title="Abstract">arXiv:2403.09880</a> (replaced) [<a href="/pdf/2403.09880" title="Download PDF">pdf</a>, <a href="/format/2403.09880" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> How To Save Fees in Bitcoin Smart Contracts: a Simple Optimistic  Off-chain Protocol
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Maddaloni%2C+D">Dario Maddaloni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Marchesin%2C+R">Riccardo Marchesin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zunino%2C+R">Roberto Zunino</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.09993" title="Abstract">arXiv:2403.09993</a> (replaced) [<a href="/pdf/2403.09993" title="Download PDF">pdf</a>, <a href="/format/2403.09993" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> TRG-Net: An Interpretable and Controllable Rain Generator
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pang%2C+Z">Zhiqiang Pang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+Q">Qi Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Meng%2C+D">Deyu Meng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zongben Xu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.10063" title="Abstract">arXiv:2403.10063</a> (replaced) [<a href="/pdf/2403.10063" title="Download PDF">pdf</a>, <a href="/format/2403.10063" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Unified Projection-Free Algorithms for Adversarial DR-Submodular  Optimization
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Pedramfar%2C+M">Mohammad Pedramfar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nadew%2C+Y+Y">Yididiya Y. Nadew</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Quinn%2C+C+J">Christopher J. Quinn</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aggarwal%2C+V">Vaneet Aggarwal</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This paper is published in ICLR 2024. This version includes a correction for regret bounds in the full-information zeroth order feedback setting (see the footnote on page 1 for details)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.11144" title="Abstract">arXiv:2403.11144</a> (replaced) [<a href="/pdf/2403.11144" title="Download PDF">pdf</a>, <a href="/format/2403.11144" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Is Mamba Effective for Time Series Forecasting?
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zihan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kong%2C+F">Fanheng Kong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+S">Shi Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M">Ming Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiaocui Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Han Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+D">Daling Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yifei Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.12229" title="Abstract">arXiv:2403.12229</a> (replaced) [<a href="/pdf/2403.12229" title="Download PDF">pdf</a>, <a href="/format/2403.12229" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Fusion Transformer with Object Mask Guidance for Image Forgery Analysis
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Karageorgiou%2C+D">Dimitrios Karageorgiou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kordopatis-Zilos%2C+G">Giorgos Kordopatis-Zilos</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Papadopoulos%2C+S">Symeon Papadopoulos</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.13241" title="Abstract">arXiv:2403.13241</a> (replaced) [<a href="/pdf/2403.13241" title="Download PDF">pdf</a>, <a href="/format/2403.13241" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Tackling Noisy Labels with Network Parameter Additive Decomposition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jingyi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xia%2C+X">Xiaobo Xia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lan%2C+L">Long Lan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xinghao Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Jun Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+W">Wenjing Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+B">Bo Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+T">Tongliang Liu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by IEEE T-PAMI
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1036">[1036]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.14353" title="Abstract">arXiv:2403.14353</a> (replaced) [<a href="/pdf/2403.14353" title="Download PDF">pdf</a>, <a href="/format/2403.14353" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DaCapo: Accelerating Continuous Learning in Autonomous Systems for Video  Analytics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+Y">Yoonsung Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oh%2C+C">Changhun Oh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hwang%2C+J">Jinwoo Hwang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+W">Wonung Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Oh%2C+S">Seongryong Oh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+Y">Yubin Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sharma%2C+H">Hardik Sharma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yazdanbakhsh%2C+A">Amir Yazdanbakhsh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Park%2C+J">Jongse Park</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Robotics (cs.RO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1037">[1037]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.14608" title="Abstract">arXiv:2403.14608</a> (replaced) [<a href="/pdf/2403.14608" title="Download PDF">pdf</a>, <a href="/format/2403.14608" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+Z">Zeyu Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+C">Chao Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jinyang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jeff Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S+Q">Sai Qian Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 24 pages, 12 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1038">[1038]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.15412" title="Abstract">arXiv:2403.15412</a> (replaced) [<a href="/pdf/2403.15412" title="Download PDF">pdf</a>, <a href="/format/2403.15412" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Measuring and Modeling "Culture" in LLMs: A Survey
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Adilazuarda%2C+M+F">Muhammad Farid Adilazuarda</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mukherjee%2C+S">Sagnik Mukherjee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lavania%2C+P">Pradhyumna Lavania</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Singh%2C+S">Siddhant Singh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dwivedi%2C+A">Ashutosh Dwivedi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aji%2C+A+F">Alham Fikri Aji</a>, 
  <a href="/search/cs?searchtype=author&amp;query=O%27Neill%2C+J">Jacki O'Neill</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Modi%2C+A">Ashutosh Modi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Choudhury%2C+M">Monojit Choudhury</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1039">[1039]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.15638" title="Abstract">arXiv:2403.15638</a> (replaced) [<a href="/pdf/2403.15638" title="Download PDF">pdf</a>, <a href="/format/2403.15638" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Differentially Private Next-Token Prediction of Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Flemings%2C+J">James Flemings</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Razaviyayn%2C+M">Meisam Razaviyayn</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Annavaram%2C+M">Murali Annavaram</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1040">[1040]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.16418" title="Abstract">arXiv:2403.16418</a> (replaced) [<a href="/pdf/2403.16418" title="Download PDF">pdf</a>, <a href="/ps/2403.16418" title="Download PostScript">ps</a>, <a href="/format/2403.16418" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An Incremental MaxSAT-based Model to Learn Interpretable and Balanced  Classification Rules
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=J%C3%BAnior%2C+A+C+S+F">Antônio Carlos Souza Ferreira Júnior</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rocha%2C+T+A">Thiago Alves Rocha</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 16 pages, 5 tables, submitted to BRACIS 2023 (Brazilian Conference on Intelligent Systems), accepted version published in Intelligent Systems, LNCS, vol 14195
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Intelligent Systems (2023), LNCS, vol 14195 (pp. 227-242),
    Springer Nature
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1041">[1041]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.17124" title="Abstract">arXiv:2403.17124</a> (replaced) [<a href="/pdf/2403.17124" title="Download PDF">pdf</a>, <a href="/format/2403.17124" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Grounding Language Plans in Demonstrations Through Counterfactual  Perturbations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanwei Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Tsun-Hsuan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mao%2C+J">Jiayuan Mao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hagenow%2C+M">Michael Hagenow</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shah%2C+J">Julie Shah</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> ICLR 2024 Spotlight
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1042">[1042]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.17868" title="Abstract">arXiv:2403.17868</a> (replaced) [<a href="/pdf/2403.17868" title="Download PDF">pdf</a>, <a href="/format/2403.17868" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> An invitation to the sample complexity of quantum hypothesis testing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Cheng%2C+H">Hao-Chung Cheng</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Datta%2C+N">Nilanjana Datta</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Liu%2C+N">Nana Liu</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Nuradha%2C+T">Theshani Nuradha</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Salzmann%2C+R">Robert Salzmann</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Wilde%2C+M+M">Mark M. Wilde</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> v2: 52 pages, 1 figure, title modified and now includes Section V on applications and further avenues of research; see independent and concurrent work of Pensia, Jog, Loh at <a href="/abs/2403.16981">arXiv:2403.16981</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1043">[1043]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.18643" title="Abstract">arXiv:2403.18643</a> (replaced) [<a href="/pdf/2403.18643" title="Download PDF">pdf</a>, <a href="/format/2403.18643" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Sampling-Based Motion Planning with Online Racing Line Generation for  Autonomous Driving on Three-Dimensional Race Tracks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=%C3%96gretmen%2C+L">Levent Ögretmen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rowold%2C+M">Matthias Rowold</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Langmann%2C+A">Alexander Langmann</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lohmann%2C+B">Boris Lohmann</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, accepted to be published at the 35th IEEE Intelligent Vehicles Symposium, June 2 - 5, 2024, Jeju Shinhwa World, Jeju Island, Korea
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1044">[1044]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.18837" title="Abstract">arXiv:2403.18837</a> (replaced) [<a href="/pdf/2403.18837" title="Download PDF">pdf</a>, <a href="/ps/2403.18837" title="Download PostScript">ps</a>, <a href="/format/2403.18837" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Repetitive Dilemma Games in Distribution Information Using Interplay of  Droop Quota: Meek's Method in Impact of Maximum Compensation and Minimum Cost  Routes in Information Role of Marginal Contribution in Two-Sided Matching  Markets
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/econ?searchtype=author&amp;query=Kawahata%2C+Y">Yasuko Kawahata</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Wallace's Law, Droop Quota, Meek's Method, Marginal Contribution, Two-Sided Matching Market, Repetitive Dilemma Game, Maximum Compensation Problem, Minimum Cost Pathways, Fake News, Fact-Checking, Information Market Equilibrium
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH); Physics and Society (physics.soc-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1045">[1045]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.19043" title="Abstract">arXiv:2403.19043</a> (replaced) [<a href="/pdf/2403.19043" title="Download PDF">pdf</a>, <a href="/format/2403.19043" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Illicit object detection in X-ray images using Vision Transformers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cani%2C+J">Jorgen Cani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mademlis%2C+I">Ioannis Mademlis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chrysochoou%2C+A+A+R">Adamantia Anna Rebolledo Chrysochoou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Papadopoulos%2C+G+T">Georgios Th. Papadopoulos</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1046">[1046]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.19758" title="Abstract">arXiv:2403.19758</a> (replaced) [<a href="/pdf/2403.19758" title="Download PDF">pdf</a>, <a href="/format/2403.19758" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quantum Natural Language Processing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Widdows%2C+D">Dominic Widdows</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Aboumrad%2C+W">Willie Aboumrad</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Kim%2C+D">Dohun Kim</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Ray%2C+S">Sayonee Ray</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Mei%2C+J">Jonathan Mei</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1047">[1047]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.19862" title="Abstract">arXiv:2403.19862</a> (replaced) [<a href="/pdf/2403.19862" title="Download PDF">pdf</a>, <a href="/format/2403.19862" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PACC: A Passive-Arm Approach for High-Payload Collaborative Carrying  with Quadruped Robots Using Model Predictive Control
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Turrisi%2C+G">Giulio Turrisi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schulze%2C+L">Lucas Schulze</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Medeiros%2C+V+S">Vivian S. Medeiros</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Semini%2C+C">Claudio Semini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Barasuol%2C+V">Victor Barasuol</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The paper has 8 pages and 9 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1048">[1048]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.19871" title="Abstract">arXiv:2403.19871</a> (replaced) [<a href="/pdf/2403.19871" title="Download PDF">pdf</a>, <a href="/format/2403.19871" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Stable Machine Learning Model Retraining via Slowly Varying  Sequences
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bertsimas%2C+D">Dimitris Bertsimas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Digalakis%2C+V">Vassilis Digalakis Jr</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yu Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Paschalidis%2C+P">Phevos Paschalidis</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1049">[1049]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.19924" title="Abstract">arXiv:2403.19924</a> (replaced) [<a href="/pdf/2403.19924" title="Download PDF">pdf</a>, <a href="/format/2403.19924" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SceneTracker: Long-term Scene Flow Estimation Network
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bo Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jian Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yang Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+L">Li Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhenping Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+D">Dewen Hu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1050">[1050]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.00650" title="Abstract">arXiv:2404.00650</a> (replaced) [<a href="/pdf/2404.00650" title="Download PDF">pdf</a>, <a href="/format/2404.00650" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Deep Instruction Tuning for Segment Anything Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+X">Xiaorui Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+G">Gen Luo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+C">Chaoyang Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tong%2C+B">Bo Tong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yiyi Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+X">Xiaoshuai Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ji%2C+R">Rongrong Ji</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1051">[1051]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.01224" title="Abstract">arXiv:2404.01224</a> (replaced) [<a href="/pdf/2404.01224" title="Download PDF">pdf</a>, <a href="/format/2404.01224" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Collaborative Pareto Set Learning in Multiple Multi-Objective  Optimization Problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shang%2C+C">Chikai Shang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ye%2C+R">Rongguang Ye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+J">Jiaqi Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gu%2C+F">Fangqing Gu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by IJCNN 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1052">[1052]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.01336" title="Abstract">arXiv:2404.01336</a> (replaced) [<a href="/pdf/2404.01336" title="Download PDF">pdf</a>, <a href="/format/2404.01336" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FineFake: A Knowledge-Enriched Dataset for Fine-Grained Multi-Domain  Fake News Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Ziyi Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaoming Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Litian Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiacheng Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chaozhuo Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1053">[1053]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.01341" title="Abstract">arXiv:2404.01341</a> (replaced) [<a href="/pdf/2404.01341" title="Download PDF">pdf</a>, <a href="/format/2404.01341" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Block-Diagonal Guided DBSCAN Clustering
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+W">Weibing Zhao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2009.04552">arXiv:2009.04552</a> by other authors
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1054">[1054]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.01630" title="Abstract">arXiv:2404.01630</a> (replaced) [<a href="/pdf/2404.01630" title="Download PDF">pdf</a>, <a href="/format/2404.01630" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SMaRTT-REPS: Sender-based Marked Rapidly-adapting Trimmed &amp; Timed  Transport with Recycled Entropies
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bonato%2C+T">Tommaso Bonato</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kabbani%2C+A">Abdul Kabbani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Sensi%2C+D">Daniele De Sensi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+R">Rong Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Le%2C+Y">Yanfang Le</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Raiciu%2C+C">Costin Raiciu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Handley%2C+M">Mark Handley</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schneider%2C+T">Timo Schneider</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Blach%2C+N">Nils Blach</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ghalayini%2C+A">Ahmad Ghalayini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Alves%2C+D">Daniel Alves</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Papamichael%2C+M">Michael Papamichael</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Caulfield%2C+A">Adrian Caulfield</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hoefler%2C+T">Torsten Hoefler</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Fixed typo and wrong y axis of one plot
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1055">[1055]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.01673" title="Abstract">arXiv:2404.01673</a> (replaced) [<a href="/pdf/2404.01673" title="Download PDF">pdf</a>, <a href="/format/2404.01673" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Universal Knowledge Embedded Contrastive Learning Framework for  Hyperspectral Image Classification
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Q">Quanwei Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+Y">Yanni Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+T">Tao Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lefei Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Du%2C+B">Bo Du</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1056">[1056]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.01741" title="Abstract">arXiv:2404.01741</a> (replaced) [<a href="/pdf/2404.01741" title="Download PDF">pdf</a>, <a href="/format/2404.01741" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Intrusion Tolerance for Networked Systems through Two-Level Feedback  Control
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hammar%2C+K">Kim Hammar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Stadler%2C+R">Rolf Stadler</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Preprint to appear in the conference proceedings of the 54th IEEE/IFIP Dependable Systems and Networks Conference (DSN'24)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computer Science and Game Theory (cs.GT); Systems and Control (eess.SY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1057">[1057]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.02538" title="Abstract">arXiv:2404.02538</a> (replaced) [<a href="/pdf/2404.02538" title="Download PDF">pdf</a>, <a href="/format/2404.02538" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Convergence Analysis of Flow Matching in Latent Space with Transformers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/stat?searchtype=author&amp;query=Jiao%2C+Y">Yuling Jiao</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Lai%2C+Y">Yanming Lai</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Wang%2C+Y">Yang Wang</a>, 
  <a href="/search/stat?searchtype=author&amp;query=Yan%2C+B">Bokai Yan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1058">[1058]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.03147" title="Abstract">arXiv:2404.03147</a> (replaced) [<a href="/pdf/2404.03147" title="Download PDF">pdf</a>, <a href="/format/2404.03147" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Eigenpruning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Vergara-Browne%2C+T">Tomás Vergara-Browne</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Soto%2C+%C3%81">Álvaro Soto</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aizawa%2C+A">Akiko Aizawa</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Extended abstract accepted to LatinX at NAACL 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1059">[1059]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.03892" title="Abstract">arXiv:2404.03892</a> (replaced) [<a href="/pdf/2404.03892" title="Download PDF">pdf</a>, <a href="/format/2404.03892" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and  Integration of Convolutional Neural Networks and Explainable AI
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ahmed%2C+M">Maryam Ahmed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bibi%2C+T">Tooba Bibi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khan%2C+R+A">Rizwan Ahmed Khan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nasir%2C+S">Sidra Nasir</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1060">[1060]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.04292" title="Abstract">arXiv:2404.04292</a> (replaced) [<a href="/pdf/2404.04292" title="Download PDF">pdf</a>, <a href="/format/2404.04292" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Conversational Disease Diagnosis via External Planner-Controlled Large  Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhoujian Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+C">Cheng Luo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhengxing Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Work in Progress
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1061">[1061]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.04496" title="Abstract">arXiv:2404.04496</a> (replaced) [<a href="/pdf/2404.04496" title="Download PDF">pdf</a>, <a href="/format/2404.04496" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Better Graph Neural Neural Network-based Fault Localization  Through Enhanced Code Representation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rafi%2C+M+N">Md Nakhla Rafi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D+J">Dong Jae Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+A+R">An Ran Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Tse-Hsun Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shaowei Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1062">[1062]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.04599" title="Abstract">arXiv:2404.04599</a> (replaced) [<a href="/pdf/2404.04599" title="Download PDF">pdf</a>, <a href="/ps/2404.04599" title="Download PostScript">ps</a>, <a href="/format/2404.04599" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Local Test for Unitarily Invariant Properties of Bipartite Quantum  States
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Chen%2C+K">Kean Chen</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Wang%2C+Q">Qisheng Wang</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Zhang%2C+Z">Zhicheng Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 51 pages. Compared to [v1], we (i) extended testers with parameterized completeness and soundness, (ii) added new lower bounds for testing the bond dimension of matrix product states (MPS), and (iii) improved the lower bounds for testing Schmidt rank
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1063">[1063]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.04739" title="Abstract">arXiv:2404.04739</a> (replaced) [<a href="/pdf/2404.04739" title="Download PDF">pdf</a>, <a href="/format/2404.04739" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mathematics of the MML functional quantizer modules for VCV Rack  software synthesizer
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Schneider%2C+M">Maxwell Schneider</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McCarthy%2C+C">Cody McCarthy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Maxwell%2C+M+G">Michael G. Maxwell</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pfeffer%2C+J">Joshua Pfeffer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schneider%2C+R">Robert Schneider</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sills%2C+A+V">Andrew V. Sills</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 4 pages, published in Infinite Loop: an online journal for undergraduate research and applied computing projects (2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); History and Overview (math.HO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1064">[1064]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.04956" title="Abstract">arXiv:2404.04956</a> (replaced) [<a href="/pdf/2404.04956" title="Download PDF">pdf</a>, <a href="/format/2404.04956" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Gaussian Shading: Provable Performance-Lossless Image Watermarking for  Diffusion Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zijin Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+K">Kai Zeng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+K">Kejiang Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+H">Han Fang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weiming Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+N">Nenghai Yu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 17 pages, 11 figures, accepted by CVPR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1065">[1065]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.05386" title="Abstract">arXiv:2404.05386</a> (replaced) [<a href="/pdf/2404.05386" title="Download PDF">pdf</a>, <a href="/format/2404.05386" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MealRec<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-399-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2651" style="width: 0.719em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.585em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(0.092em, 1000.585em, 1.122em, -999.998em); top: -0.983em; left: 0em;"><span class="mrow" id="MathJax-Span-2652"><span class="msubsup" id="MathJax-Span-2653"><span style="display: inline-block; position: relative; width: 0.54em; height: 0px;"><span style="position: absolute; clip: rect(3.855em, 1000.002em, 4.124em, -999.998em); top: -3.985em; left: 0em;"><span class="mi" id="MathJax-Span-2654"></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -4.344em; left: 0em;"><span class="mo" id="MathJax-Span-2655" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 0.988em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 1.058em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-399">^+</script>: A Meal Recommendation Dataset with Meal-Course Affiliation  for Personalization and Healthiness
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Ming Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Lin Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tao%2C+X">Xiaohui Tao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J+X">Jimmy Xiangji Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by SIGIR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1066">[1066]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.05576" title="Abstract">arXiv:2404.05576</a> (replaced) [<a href="/pdf/2404.05576" title="Download PDF">pdf</a>, <a href="/format/2404.05576" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Dynamic Backtracking in GFlowNets: Enhancing Decision Steps with  Reward-Dependent Adjustment Mechanisms
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+S">Shuai Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chu%2C+J">Jielei Chu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+L">Lei Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+T">Tianrui Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1067">[1067]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.05635" title="Abstract">arXiv:2404.05635</a> (replaced) [<a href="/pdf/2404.05635" title="Download PDF">pdf</a>, <a href="/ps/2404.05635" title="Download PostScript">ps</a>, <a href="/format/2404.05635" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Semi-Infinite Programs for Robust Control and Optimization: Efficient  Solutions and Extensions to Existence Constraints
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Wehbeh%2C+J">Jad Wehbeh</a> (1), 
  <a href="/search/math?searchtype=author&amp;query=Kerrigan%2C+E+C">Eric C. Kerrigan</a> (1 and 2) ((1) Department of Electrical and Electronic Engineering, Imperial College London, (2) Department of Aeronautics, Imperial College London)
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 6 pages, 1 figure. To be published in the proceedings of the 8th IFAC Conference on Nonlinear Model Predictive Control (NMPC 2024)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1068">[1068]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.05843" title="Abstract">arXiv:2404.05843</a> (replaced) [<a href="/pdf/2404.05843" title="Download PDF">pdf</a>, <a href="/ps/2404.05843" title="Download PostScript">ps</a>, <a href="/format/2404.05843" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Softmax Attention with Constant Cost per Token
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Heinsen%2C+F+A">Franz A. Heinsen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Source code and instructions for replicating our results are online at <a href="https://github.com/glassroom/heinsen_attention">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1069">[1069]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.06075" title="Abstract">arXiv:2404.06075</a> (replaced) [<a href="/pdf/2404.06075" title="Download PDF">pdf</a>, <a href="/format/2404.06075" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LIPT: Latency-aware Image Processing Transformer
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Qiao%2C+J">Junbo Qiao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Wei Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+H">Haizhen Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hanting Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yunshuai Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tu%2C+Z">Zhijun Tu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Jie Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+S">Shaohui Lin</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1070">[1070]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.06484" title="Abstract">arXiv:2404.06484</a> (replaced) [<a href="/pdf/2404.06484" title="Download PDF">pdf</a>, <a href="/format/2404.06484" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Public-private funding models in open source software development: A  case study on scikit-learn
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Osborne%2C+C">Cailean Osborne</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 16 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1071">[1071]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.06495" title="Abstract">arXiv:2404.06495</a> (replaced) [<a href="/pdf/2404.06495" title="Download PDF">pdf</a>, <a href="/format/2404.06495" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mechanism Design for ZK-Rollup Prover Markets
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenhao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+L">Lulu Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yaish%2C+A">Aviv Yaish</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+F">Fan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fisch%2C+B">Ben Fisch</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Livshits%2C+B">Benjamin Livshits</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1072">[1072]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.06895" title="Abstract">arXiv:2404.06895</a> (replaced) [<a href="/pdf/2404.06895" title="Download PDF">pdf</a>, <a href="/format/2404.06895" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CaDRec: Contextualized and Debiased Recommender Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinfeng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fukumoto%2C+F">Fumiyo Fukumoto</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cui%2C+J">Jin Cui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Suzuki%2C+Y">Yoshimi Suzuki</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jiyi Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+D">Dongjin Yu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to SIGIR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1073">[1073]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.06900" title="Abstract">arXiv:2404.06900</a> (replaced) [<a href="/pdf/2404.06900" title="Download PDF">pdf</a>, <a href="/format/2404.06900" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> NFARec: A Negative Feedback-Aware Recommender Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinfeng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fukumoto%2C+F">Fumiyo Fukumoto</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cui%2C+J">Jin Cui</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Suzuki%2C+Y">Yoshimi Suzuki</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+D">Dongjin Yu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted to SIGIR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1074">[1074]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.07037" title="Abstract">arXiv:2404.07037</a> (replaced) [<a href="/pdf/2404.07037" title="Download PDF">pdf</a>, <a href="/format/2404.07037" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Computing the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-400-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2656" style="width: 0.943em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.764em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1000.764em, 2.646em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-2657"><span class="mi" id="MathJax-Span-2658" style="font-family: STIXGeneral-Italic;">D</span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.947em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-400">D</script>-base and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax" id="MathJax-Element-401-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-2659" style="width: 0.943em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.764em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.705em, 1000.764em, 2.646em, -999.998em); top: -2.507em; left: 0em;"><span class="mrow" id="MathJax-Span-2660"><span class="mi" id="MathJax-Span-2661" style="font-family: STIXGeneral-Italic;">D</span></span><span style="display: inline-block; width: 0px; height: 2.511em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left-width: 0px; border-left-style: solid; border-left-color: currentcolor; width: 0px; height: 0.947em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-401">D</script>-relation in finite closure systems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Adaricheva%2C+K">Kira Adaricheva</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nourine%2C+L">Lhouari Nourine</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vilmin%2C+S">Simon Vilmin</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 34 pages (with appendices), 11 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1075">[1075]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.07072" title="Abstract">arXiv:2404.07072</a> (replaced) [<a href="/pdf/2404.07072" title="Download PDF">pdf</a>, <a href="/format/2404.07072" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Implicit Multi-Spectral Transformer: An Lightweight and Effective  Visible to Infrared Image Translation Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yijia Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+P">Pinghua Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiangxin Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lei%2C+Y">Yingtie Lei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Ziyang Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Mingxian Li</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by IJCNN 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1076">[1076]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.07227" title="Abstract">arXiv:2404.07227</a> (replaced) [<a href="/pdf/2404.07227" title="Download PDF">pdf</a>, <a href="/ps/2404.07227" title="Download PostScript">ps</a>, <a href="/format/2404.07227" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Is Complexity an Illusion?
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bennett%2C+M+T">Michael Timothy Bennett</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Definitions shared with <a href="/abs/2302.00843">arXiv:2302.00843</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1077">[1077]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.07857" title="Abstract">arXiv:2404.07857</a> (replaced) [<a href="/pdf/2404.07857" title="Download PDF">pdf</a>, <a href="/format/2404.07857" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Optical next generation reservoir computing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/physics?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Hu%2C+J">Jianqi Hu</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Baek%2C+Y">YoonSeok Baek</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Tsuchiyama%2C+K">Kohei Tsuchiyama</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Joly%2C+M">Malo Joly</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Liu%2C+Q">Qiang Liu</a>, 
  <a href="/search/physics?searchtype=author&amp;query=Gigan%2C+S">Sylvain Gigan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET); Chaotic Dynamics (nlin.CD)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1078">[1078]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.08763" title="Abstract">arXiv:2404.08763</a> (replaced) [<a href="/pdf/2404.08763" title="Download PDF">pdf</a>, <a href="/format/2404.08763" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CATS: Contextually-Aware Thresholding for Sparsity in Large Language  Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Je-Yong Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lee%2C+D">Donghyun Lee</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Genghan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tiwari%2C+M">Mo Tiwari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mirhoseini%2C+A">Azalia Mirhoseini</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1079">[1079]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.08995" title="Abstract">arXiv:2404.08995</a> (replaced) [<a href="/pdf/2404.08995" title="Download PDF">pdf</a>, <a href="/format/2404.08995" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Beyond Known Clusters: Probe New Prototypes for Efficient Generalized  Class Discovery
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Ye Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yaxiong Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yujiao Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+B">Bingchen Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qian%2C+X">Xueming Qian</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 7 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1080">[1080]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.09005" title="Abstract">arXiv:2404.09005</a> (replaced) [<a href="/pdf/2404.09005" title="Download PDF">pdf</a>, <a href="/format/2404.09005" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Proof-of-Learning with Incentive Security
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zishuo Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+Z">Zhixuan Fang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xuechao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xi Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yuan Zhou</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 17 pages, 5 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1081">[1081]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.09173" title="Abstract">arXiv:2404.09173</a> (replaced) [<a href="/pdf/2404.09173" title="Download PDF">pdf</a>, <a href="/format/2404.09173" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> TransformerFAM: Feedback attention is working memory
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hwang%2C+D">Dongseong Hwang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Weiran Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huo%2C+Z">Zhuoyuan Huo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sim%2C+K+C">Khe Chai Sim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mengibar%2C+P+M">Pedro Moreno Mengibar</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 24 pages, 12 figures, 14 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1082">[1082]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.09405" title="Abstract">arXiv:2404.09405</a> (replaced) [<a href="/pdf/2404.09405" title="Download PDF">pdf</a>, <a href="/format/2404.09405" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Few-shot Name Entity Recognition on StackOverflow
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xinwei Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+K">Kun Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+T">Tianyou Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+J">Jiangjian Guo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 5 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1083">[1083]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.09479" title="Abstract">arXiv:2404.09479</a> (replaced) [<a href="/pdf/2404.09479" title="Download PDF">pdf</a>, <a href="/ps/2404.09479" title="Download PostScript">ps</a>, <a href="/format/2404.09479" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Legal Risk Taxonomy for Generative Artificial Intelligence
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Atkinson%2C+D">David Atkinson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Morrison%2C+J">Jacob Morrison</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 28 pages, 2 tables, preprint
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1084">[1084]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.09533" title="Abstract">arXiv:2404.09533</a> (replaced) [<a href="/pdf/2404.09533" title="Download PDF">pdf</a>, <a href="/format/2404.09533" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> WiTUnet: A U-Shaped Architecture Integrating CNN and Transformer for  Improved Feature Alignment and Local Information Fusion
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bin Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Deng%2C+F">Fei Deng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+P">Peifan Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuang Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Han%2C+X">Xiao Han</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhixuan Zhang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1085">[1085]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.09586" title="Abstract">arXiv:2404.09586</a> (replaced) [<a href="/pdf/2404.09586" title="Download PDF">pdf</a>, <a href="/format/2404.09586" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Mitigating the Curse of Dimensionality for Certified Robustness via Dual  Randomized Smoothing
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xia%2C+S">Song Xia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yi%2C+Y">Yu Yi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xudong Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+H">Henghui Ding</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by ICLR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1086">[1086]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.09709" title="Abstract">arXiv:2404.09709</a> (replaced) [<a href="/pdf/2404.09709" title="Download PDF">pdf</a>, <a href="/format/2404.09709" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Scenario-Adaptive Fine-Grained Personalization Network: Tailoring User  Behavior Representation to the Scenario Context
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Moyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yongxiang Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Jinxin Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yu Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by SIGIR 2024, 10 pages, 5 figures, 5 tables
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> SIGIR 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1087">[1087]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.10160" title="Abstract">arXiv:2404.10160</a> (replaced) [<a href="/pdf/2404.10160" title="Download PDF">pdf</a>, <a href="/format/2404.10160" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> RLRF:Reinforcement Learning from Reflection through Debates as Feedback  for Bias Mitigation in LLMs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+R">Ruoxi Cheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+H">Haoxuan Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+S">Shuirong Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shi%2C+T">Tianyu Shi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1088">[1088]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.10172" title="Abstract">arXiv:2404.10172</a> (replaced) [<a href="/pdf/2404.10172" title="Download PDF">pdf</a>, <a href="/format/2404.10172" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Forensic Iris Image-Based Post-Mortem Interval Estimation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bhuiyan%2C+R+A">Rasel Ahmed Bhuiyan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Czajka%2C+A">Adam Czajka</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1089">[1089]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.10199" title="Abstract">arXiv:2404.10199</a> (replaced) [<a href="/pdf/2404.10199" title="Download PDF">pdf</a>, <a href="/format/2404.10199" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CULTURE-GEN: Revealing Global Cultural Perception in Language Models  through Natural Language Prompting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+H">Huihan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+L">Liwei Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J+D">Jena D. Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+H">Hyunwoo Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Santy%2C+S">Sebastin Santy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sorensen%2C+T">Taylor Sorensen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+B+Y">Bill Yuchen Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dziri%2C+N">Nouha Dziri</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+X">Xiang Ren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Choi%2C+Y">Yejin Choi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1090">[1090]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.10255" title="Abstract">arXiv:2404.10255</a> (replaced) [<a href="/pdf/2404.10255" title="Download PDF">pdf</a>, <a href="/format/2404.10255" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Privacy-Enhanced Training-as-a-Service for On-Device Intelligence:  Concept, Architectural Scheme, and Open Problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhiyuan Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+S">Sheng Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuwei Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+M">Min Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+B">Bo Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=He%2C+T">Tianliu He</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wen Wang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 3 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1091">[1091]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.10306" title="Abstract">arXiv:2404.10306</a> (replaced) [<a href="/pdf/2404.10306" title="Download PDF">pdf</a>, <a href="/format/2404.10306" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Balancing Speciality and Versatility: a Coarse to Fine Framework for  Supervised Fine-tuning Large Language Model
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hengyuan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yanru Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Dawei Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zacc Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+R">Rui Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yong Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tan%2C+F">Fei Tan</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 43 pages, 10 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1092">[1092]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.10616" title="Abstract">arXiv:2404.10616</a> (replaced) [<a href="/pdf/2404.10616" title="Download PDF">pdf</a>, <a href="/ps/2404.10616" title="Download PostScript">ps</a>, <a href="/format/2404.10616" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> One is all you need: Second-order Unification without First-order  Variables
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cerna%2C+D+M">David M. Cerna</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Parsert%2C+J">Julian Parsert</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Under review
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1093">[1093]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.10665" title="Abstract">arXiv:2404.10665</a> (replaced) [<a href="/pdf/2404.10665" title="Download PDF">pdf</a>, <a href="/format/2404.10665" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Iterated Invariant Extended Kalman Filter (IIEKF)
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Goffin%2C+S">Sven Goffin</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Barrau%2C+A">Axel Barrau</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Bonnabel%2C+S">Silvère Bonnabel</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Br%C3%BCls%2C+O">Olivier Brüls</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Sacr%C3%A9%2C+P">Pierre Sacré</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1094">[1094]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.10746" title="Abstract">arXiv:2404.10746</a> (replaced) [<a href="/pdf/2404.10746" title="Download PDF">pdf</a>, <a href="/format/2404.10746" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Interpolation and differentiation of alchemical degrees of freedom in  machine learning interatomic potentials
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cond-mat?searchtype=author&amp;query=Nam%2C+J">Juno Nam</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=G%C3%B3mez-Bombarelli%2C+R">Rafael Gómez-Bombarelli</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1095">[1095]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.10942" title="Abstract">arXiv:2404.10942</a> (replaced) [<a href="/pdf/2404.10942" title="Download PDF">pdf</a>, <a href="/format/2404.10942" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> What Hides behind Unfairness? Exploring Dynamics Fairness in  Reinforcement Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Deng%2C+Z">Zhihong Deng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+J">Jing Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Long%2C+G">Guodong Long</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chengqi Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages, 9 figures, accepted by IJCAI 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Methodology (stat.ME)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1096">[1096]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.11107" title="Abstract">arXiv:2404.11107</a> (replaced) [<a href="/pdf/2404.11107" title="Download PDF">pdf</a>, <a href="/format/2404.11107" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> KernJC: Automated Vulnerable Environment Generation for Linux Kernel  Vulnerabilities
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ruan%2C+B">Bonan Ruan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiahao Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chuqi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+Z">Zhenkai Liang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1097">[1097]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.11130" title="Abstract">arXiv:2404.11130</a> (replaced) [<a href="/pdf/2404.11130" title="Download PDF">pdf</a>, <a href="/format/2404.11130" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Learning epidemic trajectories through Kernel Operator Learning: from  modelling to optimal control
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Ziarelli%2C+G">Giovanni Ziarelli</a>, 
  <a href="/search/math?searchtype=author&amp;query=Parolini%2C+N">Nicola Parolini</a>, 
  <a href="/search/math?searchtype=author&amp;query=Verani%2C+M">Marco Verani</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 38 pages, 13 figures
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Populations and Evolution (q-bio.PE)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1098">[1098]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.11474" title="Abstract">arXiv:2404.11474</a> (replaced) [<a href="/pdf/2404.11474" title="Download PDF">pdf</a>, <a href="/format/2404.11474" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Highly Realistic Artistic Style Transfer via Stable Diffusion  with Step-aware and Layer-aware Prompt
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhanjie Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Quanwei Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+H">Huaizhong Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xing%2C+W">Wei Xing</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mo%2C+J">Juncheng Mo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+S">Shuaicheng Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+J">Jinheng Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Guangyuan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luan%2C+J">Junsheng Luan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+L">Lei Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+D">Dalong Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Lixia Chen</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by IJCAI2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1099">[1099]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.11536" title="Abstract">arXiv:2404.11536</a> (replaced) [<a href="/pdf/2404.11536" title="Download PDF">pdf</a>, <a href="/format/2404.11536" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FedPFT: Federated Proxy Fine-Tuning of Foundation Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+Z">Zhaopeng Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fan%2C+X">Xiaoliang Fan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yufan Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zheng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pan%2C+S">Shirui Pan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wen%2C+C">Chenglu Wen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruisheng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Cheng Wang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by IJCAI'24
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1100">[1100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.11766" title="Abstract">arXiv:2404.11766</a> (replaced) [<a href="/pdf/2404.11766" title="Download PDF">pdf</a>, <a href="/format/2404.11766" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> End-to-End Mesh Optimization of a Hybrid Deep Learning Black-Box PDE  Solver
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+S">Shaocong Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Diffenderfer%2C+J">James Diffenderfer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kailkhura%2C+B">Bhavya Kailkhura</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yi Zhou</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1101">[1101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.12674" title="Abstract">arXiv:2404.12674</a> (replaced) [<a href="/pdf/2404.12674" title="Download PDF">pdf</a>, <a href="/format/2404.12674" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards Universal Performance Modeling for Machine Learning Training on  Multi-GPU Platforms
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhongyi Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+N">Ning Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bhattacharya%2C+P">Pallab Bhattacharya</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+X">Xizhou Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+L">Louis Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Owens%2C+J+D">John D. Owens</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages, 11 figures, 4 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Performance (cs.PF)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1102">[1102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.12739" title="Abstract">arXiv:2404.12739</a> (replaced) [<a href="/pdf/2404.12739" title="Download PDF">pdf</a>, <a href="/format/2404.12739" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Solution for the CVPR2024 NICE Image Captioning Challenge
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+L">Longfei Huang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+S">Shupeng Zhong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiangyu Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+R">Ruoxuan Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1103">[1103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.12901" title="Abstract">arXiv:2404.12901</a> (replaced) [<a href="/pdf/2404.12901" title="Download PDF">pdf</a>, <a href="/format/2404.12901" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Large Language Models for Networking: Workflow, Advances and Challenges
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+X">Xiaohui Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xinggong Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cui%2C+Y">Yong Cui</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1104">[1104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13195" title="Abstract">arXiv:2404.13195</a> (replaced) [<a href="/pdf/2404.13195" title="Download PDF">pdf</a>, <a href="/ps/2404.13195" title="Download PostScript">ps</a>, <a href="/format/2404.13195" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Automatic BLAS Offloading on Unified Memory Architecture: A Study on  NVIDIA Grace-Hopper
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Junjie Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yinzhi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+X">Xiao Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Hang Liu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1105">[1105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13443" title="Abstract">arXiv:2404.13443</a> (replaced) [<a href="/pdf/2404.13443" title="Download PDF">pdf</a>, <a href="/format/2404.13443" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> FisheyeDetNet: 360° Surround view Fisheye Camera based Object  Detection System for Autonomous Driving
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sistu%2C+G">Ganesh Sistu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yogamani%2C+S">Senthil Yogamani</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2206.05542">arXiv:2206.05542</a> by other authors
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1106">[1106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13573" title="Abstract">arXiv:2404.13573</a> (replaced) [<a href="/pdf/2404.13573" title="Download PDF">pdf</a>, <a href="/format/2404.13573" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring AIGC Video Quality: A Focus on Visual Harmony, Video-Text  Consistency and Domain Distribution Gap
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Qu%2C+B">Bowen Qu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+X">Xiaoyu Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+S">Shangkun Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+W">Wei Gao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 3 figures, 3 tables. Accepted by CVPR2024 Workshop (3rd place winner of NTIRE2024 Quality Assessment for AI-Generated Content - Track 2 Video)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1107">[1107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13621" title="Abstract">arXiv:2404.13621</a> (replaced) [<a href="/pdf/2404.13621" title="Download PDF">pdf</a>, <a href="/format/2404.13621" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Attack on Scene Flow using Point Clouds
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Oskouie%2C+H+E">Haniyeh Ehsani Oskouie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Moin%2C+M">Mohammad-Shahram Moin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kasaei%2C+S">Shohreh Kasaei</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1108">[1108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13624" title="Abstract">arXiv:2404.13624</a> (replaced) [<a href="/pdf/2404.13624" title="Download PDF">pdf</a>, <a href="/ps/2404.13624" title="Download PostScript">ps</a>, <a href="/format/2404.13624" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Necessary and Sufficient Conditions for Capacity-Achieving Private  Information Retrieval with Non-Colluding and Colluding Servers
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Miki%2C+A">Atsushi Miki</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Morishita%2C+Y">Yusuke Morishita</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Matsushima%2C+T">Toshiyasu Matsushima</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 16 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1109">[1109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13655" title="Abstract">arXiv:2404.13655</a> (replaced) [<a href="/pdf/2404.13655" title="Download PDF">pdf</a>, <a href="/format/2404.13655" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SPGNN: Recognizing Salient Subgraph Patterns via Enhanced Graph  Convolution and Pooling
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+Z">Zehao Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Muhan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yixin Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1110">[1110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13685" title="Abstract">arXiv:2404.13685</a> (replaced) [<a href="/pdf/2404.13685" title="Download PDF">pdf</a>, <a href="/format/2404.13685" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Second-Order Identification Capacity of AWGN Channels
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhicheng Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuan Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Huazi Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jun Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+G">Guiying Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zhiming Ma</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 3 figures, 1 table. This paper has been accepted by IEEE ISIT 2024. In response to the reviewer's feedback, we have incorporated additional references and refined the content in the introduction section and we update some references
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1111">[1111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13696" title="Abstract">arXiv:2404.13696</a> (replaced) [<a href="/pdf/2404.13696" title="Download PDF">pdf</a>, <a href="/format/2404.13696" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Clio: Real-time Task-Driven Open-Set 3D Scene Graphs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Maggio%2C+D">Dominic Maggio</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chang%2C+Y">Yun Chang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hughes%2C+N">Nathan Hughes</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Trang%2C+M">Matthew Trang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Griffith%2C+D">Dan Griffith</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dougherty%2C+C">Carlyn Dougherty</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cristofalo%2C+E">Eric Cristofalo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schmid%2C+L">Lukas Schmid</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Carlone%2C+L">Luca Carlone</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1112">[1112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13788" title="Abstract">arXiv:2404.13788</a> (replaced) [<a href="/pdf/2404.13788" title="Download PDF">pdf</a>, <a href="/format/2404.13788" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> AnyPattern: Towards In-context Image Copy Detection
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenhao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yifan Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tan%2C+Z">Zhentao Tan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yi Yang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> The project is publicly available at <a href="https://anypattern.github.io.">this https URL</a> arXiv admin note: text overlap with <a href="/abs/2403.06098">arXiv:2403.06098</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1113">[1113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13812" title="Abstract">arXiv:2404.13812</a> (replaced) [<a href="/pdf/2404.13812" title="Download PDF">pdf</a>, <a href="/format/2404.13812" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Comparative Study on Enhancing Prediction in Social Network  Advertisement through Data Augmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qikai Yang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+P">Panfeng Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+X">Xinhe Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+Z">Zhicheng Ding</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+W">Wenjing Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nian%2C+Y">Yi Nian</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Accepted by 2024 4th International Conference on Machine Learning and Intelligent Systems Engineering (MLISE)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1114">[1114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.13909" title="Abstract">arXiv:2404.13909</a> (replaced) [<a href="/pdf/2404.13909" title="Download PDF">pdf</a>, <a href="/ps/2404.13909" title="Download PostScript">ps</a>, <a href="/format/2404.13909" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Physics-informed neural networks with curriculum training for  poroelastic flow and deformation processes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Bekele%2C+Y+W">Yared W. Bekele</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages, 11 figures, Paper submitted to NGM2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1115">[1115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14025" title="Abstract">arXiv:2404.14025</a> (replaced) [<a href="/pdf/2404.14025" title="Download PDF">pdf</a>, <a href="/format/2404.14025" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> DHRNet: A Dual-Path Hierarchical Relation Network for Multi-Person Pose  Estimation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dang%2C+Y">Yonghao Dang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yin%2C+J">Jianqin Yin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+L">Liyuan Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+P">Pengxiang Ding</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuan Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yanzhu Hu</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1116">[1116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14037" title="Abstract">arXiv:2404.14037</a> (replaced) [<a href="/pdf/2404.14037" title="Download PDF">pdf</a>, <a href="/format/2404.14037" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> GaussianTalker: Speaker-specific Talking Head Synthesis via 3D Gaussian  Splatting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Hongyun Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qu%2C+Z">Zhan Qu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Q">Qihang Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jianchuan Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Zhonghua Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhiwen Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shengyu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Jimin Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+F">Fei Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lv%2C+C">Chengfei Lv</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+G">Gang Yu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> <a href="https://yuhongyun777.github.io/GaussianTalker/">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1117">[1117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14165" title="Abstract">arXiv:2404.14165</a> (replaced) [<a href="/pdf/2404.14165" title="Download PDF">pdf</a>, <a href="/format/2404.14165" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Sliding window-aided ordered statistics decoding for short LDPC codes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Guangwen Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+X">Xiao Yu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 7 pages, 6 figures, 1 table
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1118">[1118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14192" title="Abstract">arXiv:2404.14192</a> (replaced) [<a href="/pdf/2404.14192" title="Download PDF">pdf</a>, <a href="/format/2404.14192" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Swap distance minimization beyond entropy minimization in word order  variation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Franco-S%C3%A1nchez%2C+V">Víctor Franco-Sánchez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mart%C3%AD-Llobet%2C+A">Arnau Martí-Llobet</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ferrer-i-Cancho%2C+R">Ramon Ferrer-i-Cancho</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Discussion expanded; many typos corrected
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Physics and Society (physics.soc-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1119">[1119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14250" title="Abstract">arXiv:2404.14250</a> (replaced) [<a href="/pdf/2404.14250" title="Download PDF">pdf</a>, <a href="/ps/2404.14250" title="Download PostScript">ps</a>, <a href="/format/2404.14250" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Frosty: Bringing strong liveness guarantees to the Snow family of  consensus protocols
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Buchwald%2C+A">Aaron Buchwald</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Buttolph%2C+S">Stephen Buttolph</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lewis-Pye%2C+A">Andrew Lewis-Pye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=O%27Grady%2C+P">Patrick O'Grady</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sekniqi%2C+K">Kevin Sekniqi</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1120">[1120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14312" title="Abstract">arXiv:2404.14312</a> (replaced) [<a href="/pdf/2404.14312" title="Download PDF">pdf</a>, <a href="/format/2404.14312" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Structure-preserving neural networks for the regularized entropy-based  closure of the Boltzmann moment system
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/math?searchtype=author&amp;query=Schotth%C3%B6fer%2C+S">Steffen Schotthöfer</a>, 
  <a href="/search/math?searchtype=author&amp;query=Laiu%2C+M+P">M. Paul Laiu</a>, 
  <a href="/search/math?searchtype=author&amp;query=Frank%2C+M">Martin Frank</a>, 
  <a href="/search/math?searchtype=author&amp;query=Hauck%2C+C+D">Cory D. Hauck</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1121">[1121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14355" title="Abstract">arXiv:2404.14355</a> (replaced) [<a href="/pdf/2404.14355" title="Download PDF">pdf</a>, <a href="/format/2404.14355" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Calc-CMU at SemEval-2024 Task 7: Pre-Calc -- Learning to Use the  Calculator Improves Numeracy in Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Veerendranath%2C+V">Vishruth Veerendranath</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shah%2C+V">Vishwa Shah</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ghate%2C+K">Kshitish Ghate</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> NumEval (Task 7) at SemEval, NAACL 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1122">[1122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14361" title="Abstract">arXiv:2404.14361</a> (replaced) [<a href="/pdf/2404.14361" title="Download PDF">pdf</a>, <a href="/format/2404.14361" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Better Synthetic Data by Retrieving and Transforming Existing Datasets
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gandhi%2C+S">Saumya Gandhi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gala%2C+R">Ritu Gala</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Viswanathan%2C+V">Vijay Viswanathan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+T">Tongshuang Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Neubig%2C+G">Graham Neubig</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> PDF fixed in v3
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1123">[1123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14399" title="Abstract">arXiv:2404.14399</a> (replaced) [<a href="/pdf/2404.14399" title="Download PDF">pdf</a>, <a href="/format/2404.14399" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MLQAOA: Graph Learning Accelerated Hybrid Quantum-Classical Multilevel  QAOA
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/quant-ph?searchtype=author&amp;query=Bach%2C+B">Bao Bach</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Falla%2C+J">Jose Falla</a>, 
  <a href="/search/quant-ph?searchtype=author&amp;query=Safro%2C+I">Ilya Safro</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 11 pages, 3 figures, 4 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Engineering, Finance, and Science (cs.CE); Computational Physics (physics.comp-ph)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1124">[1124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14542" title="Abstract">arXiv:2404.14542</a> (replaced) [<a href="/pdf/2404.14542" title="Download PDF">pdf</a>, <a href="/format/2404.14542" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> UVEB: A Large-scale Benchmark and Baseline Towards Real-World Underwater  Video Enhancement
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xie%2C+Y">Yaofeng Xie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kong%2C+L">Lingwei Kong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+K">Kai Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+Z">Ziqiang Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+X">Xiao Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhibin Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+B">Bing Zheng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 10 pages,CVPR2024 accept
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1125">[1125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14563" title="Abstract">arXiv:2404.14563</a> (replaced) [<a href="/pdf/2404.14563" title="Download PDF">pdf</a>, <a href="/format/2404.14563" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Exploring Algorithmic Explainability: Generating Explainable AI Insights  for Personalized Clinical Decision Support Focused on Cannabis Intoxication  in Young Adults
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tongze Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chung%2C+T">Tammy Chung</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dey%2C+A">Anind Dey</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bae%2C+S+W">Sang Won Bae</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 2024 International Conference on Activity and Behavior Computing
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1126">[1126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14749" title="Abstract">arXiv:2404.14749</a> (replaced) [<a href="/pdf/2404.14749" title="Download PDF">pdf</a>, <a href="/ps/2404.14749" title="Download PostScript">ps</a>, <a href="/format/2404.14749" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Semantic Cells: Evolutional Process to Acquire Sense Diversity of Items
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ohsawa%2C+Y">Yukio Ohsawa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xue%2C+D">Dingming Xue</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sekiguchi%2C+K">Kaira Sekiguchi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 18 pages, 3 figures, 1 table
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1127">[1127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14763" title="Abstract">arXiv:2404.14763</a> (replaced) [<a href="/pdf/2404.14763" title="Download PDF">pdf</a>, <a href="/format/2404.14763" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Evolutionary Reinforcement Learning via Cooperative Coevolution
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+C">Chengpeng Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jialin Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yao%2C+X">Xin Yao</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1128">[1128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14817" title="Abstract">arXiv:2404.14817</a> (replaced) [<a href="/pdf/2404.14817" title="Download PDF">pdf</a>, <a href="/format/2404.14817" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Quantitative Evaluation of driver's situation awareness in virtual  driving through Eye tracking analysis
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yunxiang Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Q">Qing Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhen%2C+K">Kai Zhen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yu Chen</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1129">[1129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14829" title="Abstract">arXiv:2404.14829</a> (replaced) [<a href="/pdf/2404.14829" title="Download PDF">pdf</a>, <a href="/format/2404.14829" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Revisiting Neural Networks for Continual Learning: An Architectural  Perspective
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+A">Aojun Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+T">Tao Feng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+H">Hangjie Yuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Song%2C+X">Xiaotian Song</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yanan Sun</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1130">[1130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14846" title="Abstract">arXiv:2404.14846</a> (replaced) [<a href="/pdf/2404.14846" title="Download PDF">pdf</a>, <a href="/format/2404.14846" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Beyond Trial-and-Error: Predicting User Abandonment After a Moderation  Intervention
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tessa%2C+B">Benedetta Tessa</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cima%2C+L">Lorenzo Cima</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Trujillo%2C+A">Amaury Trujillo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Avvenuti%2C+M">Marco Avvenuti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cresci%2C+S">Stefano Cresci</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1131">[1131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14926" title="Abstract">arXiv:2404.14926</a> (replaced) [<a href="/pdf/2404.14926" title="Download PDF">pdf</a>, <a href="/ps/2404.14926" title="Download PostScript">ps</a>, <a href="/format/2404.14926" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Towards self-optimization of publish/subscribe IoT systems using  continuous performance monitoring
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Djahafi%2C+M">Mohammed Djahafi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Salmi%2C+N">Nabila Salmi</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages, 7 figures. Conference: 5th International Conference on Networks, Blockchain and Internet of Things (NBIoT 2024). Published by Computer Science Conference Proceedings in Computer Science &amp; Information Technology (CS &amp; IT)
  </div>
  <div class="list-journal-ref">
  <span class="descriptor">Journal-ref:</span> Computer Science &amp; Information Technology (CS &amp; IT) 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1132">[1132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.14963" title="Abstract">arXiv:2404.14963</a> (replaced) [<a href="/pdf/2404.14963" title="Download PDF">pdf</a>, <a href="/format/2404.14963" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Achieving &gt;97% on GSM8K: Deeply Understanding the Problems Makes LLMs  Better Reasoners
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+Q">Qihuang Zhong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+K">Kang Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Ziyang Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Juhua Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ding%2C+L">Liang Ding</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Du%2C+B">Bo Du</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tao%2C+D">Dacheng Tao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Work in progress
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1133">[1133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15009" title="Abstract">arXiv:2404.15009</a> (replaced) [<a href="/pdf/2404.15009" title="Download PDF">pdf</a>, <a href="/format/2404.15009" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Brain Tumor Segmentation in Pediatrics (BraTS-PEDs) Challenge: Focus  on Pediatrics (CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs)
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kazerooni%2C+A+F">Anahita Fathi Kazerooni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khalili%2C+N">Nastaran Khalili</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gandhi%2C+D">Deep Gandhi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xinyang Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Zhifan Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Anwar%2C+S+M">Syed Muhammed Anwar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Albrecht%2C+J">Jake Albrecht</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Adewole%2C+M">Maruf Adewole</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Anazodo%2C+U">Udunna Anazodo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Anderson%2C+H">Hannah Anderson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bagheri%2C+S">Sina Bagheri</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Baid%2C+U">Ujjwal Baid</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bergquist%2C+T">Timothy Bergquist</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Borja%2C+A+J">Austin J. Borja</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Calabrese%2C+E">Evan Calabrese</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chung%2C+V">Verena Chung</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Conte%2C+G">Gian-Marco Conte</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dako%2C+F">Farouk Dako</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Eddy%2C+J">James Eddy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ezhov%2C+I">Ivan Ezhov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Familiar%2C+A">Ariana Familiar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Farahani%2C+K">Keyvan Farahani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gottipati%2C+A">Anurag Gottipati</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Haldar%2C+D">Debanjan Haldar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Haldar%2C+S">Shuvanjan Haldar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Iglesias%2C+J+E">Juan Eugenio Iglesias</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Janas%2C+A">Anastasia Janas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Johansen%2C+E">Elaine Johansen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jones%2C+B+V">Blaise V Jones</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Khalili%2C+N">Neda Khalili</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kofler%2C+F">Florian Kofler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=LaBella%2C+D">Dominic LaBella</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lai%2C+H+A">Hollie Anne Lai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Van+Leemput%2C+K">Koen Van Leemput</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+H+B">Hongwei Bran Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Maleki%2C+N">Nazanin Maleki</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McAllister%2C+A+S">Aaron S McAllister</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Meier%2C+Z">Zeke Meier</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Menze%2C+B">Bjoern Menze</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Moawad%2C+A+W">Ahmed W Moawad</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nandolia%2C+K+K">Khanak K Nandolia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pavaine%2C+J">Julija Pavaine</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Piraud%2C+M">Marie Piraud</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Poussaint%2C+T">Tina Poussaint</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Prabhu%2C+S+P">Sanjay P Prabhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Reitman%2C+Z">Zachary Reitman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rodriguez%2C+A">Andres Rodriguez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rudie%2C+J+D">Jeffrey D Rudie</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sanchez-Montano%2C+M">Mariana Sanchez-Montano</a>,  et al. (27 additional authors not shown)
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2305.17033">arXiv:2305.17033</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1134">[1134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15143" title="Abstract">arXiv:2404.15143</a> (replaced) [<a href="/pdf/2404.15143" title="Download PDF">pdf</a>, <a href="/format/2404.15143" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Every Breath You Don't Take: Deepfake Speech Detection Using Breath
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Layton%2C+S">Seth Layton</a>, 
  <a href="/search/cs?searchtype=author&amp;query=De+Andrade%2C+T">Thiago De Andrade</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Olszewski%2C+D">Daniel Olszewski</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Warren%2C+K">Kevin Warren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Butler%2C+K">Kevin Butler</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Traynor%2C+P">Patrick Traynor</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Submitted to ACM journal -- Digital Threats: Research and Practice
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Cryptography and Security (cs.CR); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1135">[1135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15272" title="Abstract">arXiv:2404.15272</a> (replaced) [<a href="/pdf/2404.15272" title="Download PDF">pdf</a>, <a href="/format/2404.15272" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and  Radiology Reports for Full-Body Scenarios
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J">Jingyang Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xia%2C+Y">Yingda Xia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jianpeng Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yan%2C+K">Ke Yan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+L">Le Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luo%2C+J">Jiebo Luo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Ling Zhang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages, 5 figures, 3 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1136">[1136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15297" title="Abstract">arXiv:2404.15297</a> (replaced) [<a href="/pdf/2404.15297" title="Download PDF">pdf</a>, <a href="/ps/2404.15297" title="Download PostScript">ps</a>, <a href="/format/2404.15297" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-stream Transmission for Directional Modulation Network via  Distributed Multi-UAV-aided Multi-active-IRS
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Yang%2C+K">Ke Yang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Dong%2C+R">Rongen Dong</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Gao%2C+W">Wei Gao</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Shu%2C+F">Feng Shu</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Shi%2C+W">Weiping Shi</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yan Wang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wang%2C+X">Xuehui Wang</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wang%2C+J">Jiangzhou Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1137">[1137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15381" title="Abstract">arXiv:2404.15381</a> (replaced) [<a href="/pdf/2404.15381" title="Download PDF">pdf</a>, <a href="/format/2404.15381" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Advances and Open Challenges in Federated Learning with Foundation  Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ren%2C+C">Chao Ren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Han Yu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+H">Hongyi Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tang%2C+X">Xiaoli Tang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+A">Anran Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yulan Gao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tan%2C+A+Z">Alysa Ziying Tan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+B">Bo Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaoxiao Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zengxiang Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qiang Yang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Survey of Federated Foundation Models (FedFM)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1138">[1138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15497" title="Abstract">arXiv:2404.15497</a> (replaced) [<a href="/pdf/2404.15497" title="Download PDF">pdf</a>, <a href="/format/2404.15497" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Deep-learning Optical Flow Outperforms PIV in Obtaining Velocity Fields  from Active Nematics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cond-mat?searchtype=author&amp;query=Tran%2C+P+N">Phu N. Tran</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Ray%2C+S">Sattvic Ray</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Lemma%2C+L">Linnea Lemma</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Li%2C+Y">Yunrui Li</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Sweeney%2C+R">Reef Sweeney</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Baskaran%2C+A">Aparna Baskaran</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Dogic%2C+Z">Zvonimir Dogic</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Hong%2C+P">Pengyu Hong</a>, 
  <a href="/search/cond-mat?searchtype=author&amp;query=Hagan%2C+M+F">Michael F. Hagan</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1139">[1139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15510" title="Abstract">arXiv:2404.15510</a> (replaced) [<a href="/pdf/2404.15510" title="Download PDF">pdf</a>, <a href="/format/2404.15510" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> NeuraChip: Accelerating GNN Computations with a Hash-based Decoupled  Spatial Accelerator
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Shivdikar%2C+K">Kaustubh Shivdikar</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agostini%2C+N+B">Nicolas Bohm Agostini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jayaweera%2C+M">Malith Jayaweera</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jonatan%2C+G">Gilbert Jonatan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Abellan%2C+J+L">Jose L. Abellan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Joshi%2C+A">Ajay Joshi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">John Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kaeli%2C+D">David Kaeli</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Visit <a href="https://neurachip.us">this https URL</a> for WebGUI based simulations
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1140">[1140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15549" title="Abstract">arXiv:2404.15549</a> (replaced) [<a href="/pdf/2404.15549" title="Download PDF">pdf</a>, <a href="/format/2404.15549" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PRISM: Patient Records Interpretation for Semantic Clinical Trial  Matching using Large Language Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+S+K">Shashi Kant Gupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Basu%2C+A">Aditya Basu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nievas%2C+M">Mauro Nievas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Thomas%2C+J">Jerrin Thomas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wolfrath%2C+N">Nathan Wolfrath</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ramamurthi%2C+A">Adhitya Ramamurthi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Taylor%2C+B">Bradley Taylor</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kothari%2C+A+N">Anai N. Kothari</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schwind%2C+R">Regina Schwind</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Miller%2C+T+M">Therica M. Miller</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Nadaf-Rahrov%2C+S">Sorena Nadaf-Rahrov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanshan Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Singh%2C+H">Hrituraj Singh</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 30 Pages, 8 Figures, Supplementary Work Attached
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1141">[1141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15583" title="Abstract">arXiv:2404.15583</a> (replaced) [<a href="/pdf/2404.15583" title="Download PDF">pdf</a>, <a href="/format/2404.15583" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Multi-Agent Reinforcement Learning for Energy Networks: Computational  Challenges, Progress and Open Problems
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Keren%2C+S">Sarah Keren</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Essayeh%2C+C">Chaimaa Essayeh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Albrecht%2C+S+V">Stefano V. Albrecht</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mortsyn%2C+T">Thomas Mortsyn</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1142">[1142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15633" title="Abstract">arXiv:2404.15633</a> (replaced) [<a href="/pdf/2404.15633" title="Download PDF">pdf</a>, <a href="/format/2404.15633" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Artificial Intelligence for Multi-Unit Auction design
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Khezr%2C+P">Peyman Khezr</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Taylor%2C+K">Kendall Taylor</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Theoretical Economics (econ.TH)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1143">[1143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15677" title="Abstract">arXiv:2404.15677</a> (replaced) [<a href="/pdf/2404.15677" title="Download PDF">pdf</a>, <a href="/format/2404.15677" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> CharacterFactory: Sampling Consistent Characters with GANs for Diffusion  Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qinghe Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Baolu Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaomin Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+B">Bing Cao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+L">Liqian Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+H">Huchuan Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jia%2C+X">Xu Jia</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Code will be released very soon: <a href="https://github.com/qinghew/CharacterFactory">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1144">[1144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.15686" title="Abstract">arXiv:2404.15686</a> (replaced) [<a href="/pdf/2404.15686" title="Download PDF">pdf</a>, <a href="/ps/2404.15686" title="Download PostScript">ps</a>, <a href="/format/2404.15686" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Noise Variance Optimization in Differential Privacy: A Game-Theoretic  Approach Through Per-Instance Differential Privacy
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ryu%2C+S">Sehyun Ryu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jang%2C+J">Jonggyu Jang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+H+J">Hyun Jong Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1145">[1145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16122" title="Abstract">arXiv:2404.16122</a> (replaced) [<a href="/pdf/2404.16122" title="Download PDF">pdf</a>, <a href="/ps/2404.16122" title="Download PostScript">ps</a>, <a href="/format/2404.16122" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Generalized Optimization Modulo Theories
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Tsiskaridze%2C+N">Nestan Tsiskaridze</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Barrett%2C+C">Clark Barrett</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tinelli%2C+C">Cesare Tinelli</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1146">[1146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16139" title="Abstract">arXiv:2404.16139</a> (replaced) [<a href="/pdf/2404.16139" title="Download PDF">pdf</a>, <a href="/format/2404.16139" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Survey on Intermediate Fusion Methods for Collaborative Perception  Categorized by Real World Challenges
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Yazgan%2C+M">Melih Yazgan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Graf%2C+T">Thomas Graf</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+M">Min Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fleck%2C+T">Tobias Fleck</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zoellner%2C+J+M">J. Marius Zoellner</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 8 pages, 6 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1147">[1147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16244" title="Abstract">arXiv:2404.16244</a> (replaced) [<a href="/pdf/2404.16244" title="Download PDF">pdf</a>, <a href="/format/2404.16244" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Ethics of Advanced AI Assistants
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gabriel%2C+I">Iason Gabriel</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Manzini%2C+A">Arianna Manzini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Keeling%2C+G">Geoff Keeling</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hendricks%2C+L+A">Lisa Anne Hendricks</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rieser%2C+V">Verena Rieser</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Iqbal%2C+H">Hasan Iqbal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Toma%C5%A1ev%2C+N">Nenad Tomašev</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ktena%2C+I">Ira Ktena</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kenton%2C+Z">Zachary Kenton</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rodriguez%2C+M">Mikel Rodriguez</a>, 
  <a href="/search/cs?searchtype=author&amp;query=El-Sayed%2C+S">Seliem El-Sayed</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Brown%2C+S">Sasha Brown</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Akbulut%2C+C">Canfer Akbulut</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Trask%2C+A">Andrew Trask</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hughes%2C+E">Edward Hughes</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bergman%2C+A+S">A. Stevie Bergman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shelby%2C+R">Renee Shelby</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Marchal%2C+N">Nahema Marchal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Griffin%2C+C">Conor Griffin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mateos-Garcia%2C+J">Juan Mateos-Garcia</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Weidinger%2C+L">Laura Weidinger</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Street%2C+W">Winnie Street</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lange%2C+B">Benjamin Lange</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ingerman%2C+A">Alex Ingerman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lentz%2C+A">Alison Lentz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Enger%2C+R">Reed Enger</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Barakat%2C+A">Andrew Barakat</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Krakovna%2C+V">Victoria Krakovna</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Siy%2C+J+O">John Oliver Siy</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kurth-Nelson%2C+Z">Zeb Kurth-Nelson</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McCroskery%2C+A">Amanda McCroskery</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bolina%2C+V">Vijay Bolina</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Law%2C+H">Harry Law</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shanahan%2C+M">Murray Shanahan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Alberts%2C+L">Lize Alberts</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Balle%2C+B">Borja Balle</a>, 
  <a href="/search/cs?searchtype=author&amp;query=de+Haas%2C+S">Sarah de Haas</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ibitoye%2C+Y">Yetunde Ibitoye</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dafoe%2C+A">Allan Dafoe</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Goldberg%2C+B">Beth Goldberg</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Krier%2C+S">Sébastien Krier</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Reese%2C+A">Alexander Reese</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Witherspoon%2C+S">Sims Witherspoon</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hawkins%2C+W">Will Hawkins</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rauh%2C+M">Maribeth Rauh</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wallace%2C+D">Don Wallace</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Franklin%2C+M">Matija Franklin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Goldstein%2C+J+A">Josh A. Goldstein</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lehman%2C+J">Joel Lehman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Klenk%2C+M">Michael Klenk</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Vallor%2C+S">Shannon Vallor</a>,  et al. (6 additional authors not shown)
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1148">[1148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16266" title="Abstract">arXiv:2404.16266</a> (replaced) [<a href="/pdf/2404.16266" title="Download PDF">pdf</a>, <a href="/format/2404.16266" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> A Multi-objective Optimization Benchmark Test Suite for Real-time  Semantic Segmentation
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yifan Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+Z">Zhenyu Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhichao Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+R">Ran Cheng</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> GECCO 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neural and Evolutionary Computing (cs.NE)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1149">[1149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16282" title="Abstract">arXiv:2404.16282</a> (replaced) [<a href="/pdf/2404.16282" title="Download PDF">pdf</a>, <a href="/format/2404.16282" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Adaptive tracking control for non-periodic reference signals under  quantized observations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Kong%2C+C">Chuiliu Kong</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Wang%2C+Y">Ying Wang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1150">[1150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16318" title="Abstract">arXiv:2404.16318</a> (replaced) [<a href="/pdf/2404.16318" title="Download PDF">pdf</a>, <a href="/format/2404.16318" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Continuous-Time Weighted-Median Opinion Dynamics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Han%2C+Y">Yi Han</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Chen%2C+G">Ge Chen</a>, 
  <a href="/search/eess?searchtype=author&amp;query=D%C3%B6rfler%2C+F">Florian Dörfler</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Mei%2C+W">Wenjun Mei</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 13 pages, 1 figure
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1151">[1151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16348" title="Abstract">arXiv:2404.16348</a> (replaced) [<a href="/pdf/2404.16348" title="Download PDF">pdf</a>, <a href="/format/2404.16348" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Dual Expert Distillation Network for Generalized Zero-Shot Learning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Rao%2C+Z">Zhijie Rao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Guo%2C+J">Jingcai Guo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lu%2C+X">Xiaocheng Lu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+J">Jingming Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jie Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Haozhao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+K">Kang Wei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cao%2C+X">Xiaofeng Cao</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 9 pages, 4 figures; Accepted to IJCAI 2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1152">[1152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16364" title="Abstract">arXiv:2404.16364</a> (replaced) [<a href="/pdf/2404.16364" title="Download PDF">pdf</a>, <a href="/format/2404.16364" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> ReZero: Boosting MCTS-based Algorithms by Just-in-Time and Speedy  Reanalyze
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xuan%2C+C">Chunyu Xuan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Niu%2C+Y">Yazhe Niu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pu%2C+Y">Yuan Pu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hu%2C+S">Shuai Hu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yu Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jing Yang</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1153">[1153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16421" title="Abstract">arXiv:2404.16421</a> (replaced) [<a href="/pdf/2404.16421" title="Download PDF">pdf</a>, <a href="/format/2404.16421" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SynCellFactory: Generative Data Augmentation for Cell Tracking
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Sturm%2C+M">Moritz Sturm</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cerrone%2C+L">Lorenzo Cerrone</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hamprecht%2C+F+A">Fred A. Hamprecht</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1154">[1154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16556" title="Abstract">arXiv:2404.16556</a> (replaced) [<a href="/pdf/2404.16556" title="Download PDF">pdf</a>, <a href="/format/2404.16556" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Conditional Distribution Modelling for Few-Shot Image Synthesis with  Diffusion Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+P">Parul Gupta</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hayat%2C+M">Munawar Hayat</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dhall%2C+A">Abhinav Dhall</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Do%2C+T">Thanh-Toan Do</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1155">[1155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16592" title="Abstract">arXiv:2404.16592</a> (replaced) [<a href="/pdf/2404.16592" title="Download PDF">pdf</a>, <a href="/ps/2404.16592" title="Download PostScript">ps</a>, <a href="/format/2404.16592" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Uninterrupted Maximum Flow on Signalized Traffic Networks
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/eess?searchtype=author&amp;query=Friedman%2C+M+H">Melvin H. Friedman</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Mark%2C+B+L">Brian L. Mark</a>, 
  <a href="/search/eess?searchtype=author&amp;query=Gartner%2C+N+H">Nathan H. Gartner</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 51 pages, 30 figures, 5 tables
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1156">[1156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16612" title="Abstract">arXiv:2404.16612</a> (replaced) [<a href="/pdf/2404.16612" title="Download PDF">pdf</a>, <a href="/format/2404.16612" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MuseumMaker: Continual Style Customization without Catastrophic  Forgetting
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chenxi Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+G">Gan Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liang%2C+W">Wenqi Liang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dong%2C+J">Jiahua Dong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Qin%2C+C">Can Qin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cong%2C+Y">Yang Cong</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1157">[1157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16617" title="Abstract">arXiv:2404.16617</a> (replaced) [<a href="/e-print/2404.16617" title="Download source">src</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Denoising: from classical methods to deep CNNs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Campagne%2C+J">Jean-Eric Campagne</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> This document uses works by authors not yet presented to the community and may appear to be original
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; History and Overview (math.HO)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1158">[1158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16666" title="Abstract">arXiv:2404.16666</a> (replaced) [<a href="/pdf/2404.16666" title="Download PDF">pdf</a>, <a href="/format/2404.16666" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PhyRecon: Physically Plausible Neural Scene Reconstruction
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ni%2C+J">Junfeng Ni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yixin Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jing%2C+B">Bohan Jing</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+N">Nan Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bin Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Dai%2C+B">Bo Dai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yixin Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+S">Song-Chun Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Huang%2C+S">Siyuan Huang</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> project page: <a href="https://phyrecon.github.io/">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1159">[1159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16706" title="Abstract">arXiv:2404.16706</a> (replaced) [<a href="/pdf/2404.16706" title="Download PDF">pdf</a>, <a href="/format/2404.16706" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Efficient and Near-Optimal Noise Generation for Streaming Differential  Privacy
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Dvijotham%2C+K">Krishnamurthy Dvijotham</a>, 
  <a href="/search/cs?searchtype=author&amp;query=McMahan%2C+H+B">H. Brendan McMahan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Pillutla%2C+K">Krishna Pillutla</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Steinke%2C+T">Thomas Steinke</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Thakurta%2C+A">Abhradeep Thakurta</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1160">[1160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16710" title="Abstract">arXiv:2404.16710</a> (replaced) [<a href="/pdf/2404.16710" title="Download PDF">pdf</a>, <a href="/format/2404.16710" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Elhoushi%2C+M">Mostafa Elhoushi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shrivastava%2C+A">Akshat Shrivastava</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liskovich%2C+D">Diana Liskovich</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hosmer%2C+B">Basil Hosmer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wasti%2C+B">Bram Wasti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lai%2C+L">Liangzhen Lai</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mahmoud%2C+A">Anas Mahmoud</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Acun%2C+B">Bilge Acun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+S">Saurabh Agarwal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Roman%2C+A">Ahmed Roman</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Aly%2C+A+A">Ahmed A Aly</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+B">Beidi Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+C">Carole-Jean Wu</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Code open sourcing is in progress
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1161">[1161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16829" title="Abstract">arXiv:2404.16829</a> (replaced) [<a href="/pdf/2404.16829" title="Download PDF">pdf</a>, <a href="/format/2404.16829" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Make-it-Real: Unleashing Large Multimodal Model's Ability for Painting  3D Objects with Realistic Materials
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fang%2C+Y">Ye Fang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zeyi Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+T">Tong Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaqi Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziwei Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wetzstein%2C+G">Gordon Wetzstein</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+D">Dahua Lin</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Project Page: <a href="https://sunzey.github.io/Make-it-Real/">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1162">[1162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16831" title="Abstract">arXiv:2404.16831</a> (replaced) [<a href="/pdf/2404.16831" title="Download PDF">pdf</a>, <a href="/format/2404.16831" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> The Third Monocular Depth Estimation Challenge
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Spencer%2C+J">Jaime Spencer</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tosi%2C+F">Fabio Tosi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Poggi%2C+M">Matteo Poggi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Arora%2C+R+S">Ripudaman Singh Arora</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Russell%2C+C">Chris Russell</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hadfield%2C+S">Simon Hadfield</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bowden%2C+R">Richard Bowden</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+G">GuangYuan Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">ZhengXin Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rao%2C+Q">Qiang Rao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bao%2C+Y">YiPing Bao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiao Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D">Dohyeong Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">Jinseong Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+M">Myunghyun Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lavreniuk%2C+M">Mykola Lavreniuk</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+R">Rui Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mao%2C+Q">Qing Mao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+J">Jiang Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yu Zhu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jinqiu Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yanning Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Patni%2C+S">Suraj Patni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+A">Aradhye Agarwal</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Arora%2C+C">Chetan Arora</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+P">Pihai Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+K">Kui Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wu%2C+G">Gang Wu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jian Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xianming Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+J">Junjun Jiang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xidan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wei%2C+J">Jianing Wei</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+F">Fangjun Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tan%2C+Z">Zhiming Tan</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiabao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Luginov%2C+A">Albert Luginov</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Shahzad%2C+M">Muhammad Shahzad</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hosseini%2C+S">Seyed Hosseini</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Trajcevski%2C+A">Aleksander Trajcevski</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Elder%2C+J+H">James H. Elder</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> To appear in CVPRW2024
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1163">[1163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16969" title="Abstract">arXiv:2404.16969</a> (replaced) [<a href="/pdf/2404.16969" title="Download PDF">pdf</a>, <a href="/format/2404.16969" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> COCOLA: Coherence-Oriented Contrastive Learning of Musical Audio  Representations
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Ciranni%2C+R">Ruben Ciranni</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Postolache%2C+E">Emilian Postolache</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mariani%2C+G">Giorgio Mariani</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mancusi%2C+M">Michele Mancusi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cosmo%2C+L">Luca Cosmo</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Rodol%C3%A0%2C+E">Emanuele Rodolà</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> Demo page: <a href="https://github.com/gladia-research-group/cocola">this https URL</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1164">[1164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16986" title="Abstract">arXiv:2404.16986</a> (replaced) [<a href="/pdf/2404.16986" title="Download PDF">pdf</a>, <a href="/format/2404.16986" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Piecewise Stochastic Barrier Functions
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Mazouz%2C+R">Rayan Mazouz</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mathiesen%2C+F+B">Frederik Baymler Mathiesen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Laurenti%2C+L">Luca Laurenti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lahijanian%2C+M">Morteza Lahijanian</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1165">[1165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.16994" title="Abstract">arXiv:2404.16994</a> (replaced) [<a href="/pdf/2404.16994" title="Download PDF">pdf</a>, <a href="/format/2404.16994" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video  Dense Captioning
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+L">Lin Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yilin Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+D">Daquan Zhou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhijie Lin</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ng%2C+S+K">See Kiong Ng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Feng%2C+J">Jiashi Feng</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1166">[1166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17113" title="Abstract">arXiv:2404.17113</a> (replaced) [<a href="/pdf/2404.17113" title="Download PDF">pdf</a>, <a href="/format/2404.17113" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MER 2024: Semi-Supervised Learning, Noise Robustness, and  Open-Vocabulary Multimodal Emotion Recognition
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Lian%2C+Z">Zheng Lian</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+H">Haiyang Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sun%2C+L">Licai Sun</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wen%2C+Z">Zhuofan Wen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Siyuan Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Shun Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gu%2C+H">Hao Gu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jinming Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Z">Ziyang Ma</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xie Chen</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Yi%2C+J">Jiangyan Yi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+R">Rui Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Xu%2C+K">Kele Xu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Liu%2C+B">Bin Liu</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Cambria%2C+E">Erik Cambria</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+G">Guoying Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Schuller%2C+B+W">Björn W. Schuller</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Tao%2C+J">Jianhua Tao</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1167">[1167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17120" title="Abstract">arXiv:2404.17120</a> (replaced) [<a href="/pdf/2404.17120" title="Download PDF">pdf</a>, <a href="/format/2404.17120" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Talking Nonsense: Probing Large Language Models' Understanding of  Adversarial Gibberish Inputs
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Cherepanova%2C+V">Valeriia Cherepanova</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zou%2C+J">James Zou</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1168">[1168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17179" title="Abstract">arXiv:2404.17179</a> (replaced) [<a href="/pdf/2404.17179" title="Download PDF">pdf</a>, <a href="/format/2404.17179" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Meta-Object: Interactive and Multisensory Virtual Object Learned from  the Real World for the Post-Metaverse
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D">Dooyoung Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ha%2C+T">Taewook Ha</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Hong%2C+J">Jinseok Hong</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Kim%2C+S">Seonji Kim</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Choi%2C+S">Selin Choi</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Ko%2C+H">Heejeong Ko</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Woo%2C+W">Woontack Woo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 12 pages, 4 figures, under review in the IEEE CG&amp;A magazine
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Emerging Technologies (cs.ET)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1169">[1169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17205" title="Abstract">arXiv:2404.17205</a> (replaced) [<a href="/pdf/2404.17205" title="Download PDF">pdf</a>, <a href="/format/2404.17205" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Two in One Go: Single-stage Emotion Recognition with Decoupled  Subject-context Transformer
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xinpeng Li</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Teng Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jian Zhao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mao%2C+S">Shuyi Mao</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jinbao Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+F">Feng Zheng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peng%2C+X">Xiaojiang Peng</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xuelong Li</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1170">[1170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17255" title="Abstract">arXiv:2404.17255</a> (replaced) [<a href="/pdf/2404.17255" title="Download PDF">pdf</a>, <a href="/format/2404.17255" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> SDFD: Building a Versatile Synthetic Face Image Dataset with Diverse  Attributes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Baltsou%2C+G">Georgia Baltsou</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Sarridis%2C+I">Ioannis Sarridis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Koutlis%2C+C">Christos Koutlis</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Papadopoulos%2C+S">Symeon Papadopoulos</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1171">[1171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17364" title="Abstract">arXiv:2404.17364</a> (replaced) [<a href="/pdf/2404.17364" title="Download PDF">pdf</a>, <a href="/format/2404.17364" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> MV-VTON: Multi-View Virtual Try-On with Diffusion Models
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Haoyu Wang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhilu Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Di%2C+D">Donglin Di</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shiliang Zhang</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Zuo%2C+W">Wangmeng Zuo</a>
  </div>
  <div class="list-comments mathjax">
  <span class="descriptor">Comments:</span> 15 pages
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1172">[1172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17413" title="Abstract">arXiv:2404.17413</a> (replaced) [<a href="/pdf/2404.17413" title="Download PDF">pdf</a>, <a href="/ps/2404.17413" title="Download PostScript">ps</a>, <a href="/format/2404.17413" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Voting with Partial Orders: The Plurality and Anti-Plurality Classes
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Fioravanti%2C+F">Federico Fioravanti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Endriss%2C+U">Ulle Endriss</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)
  
  </div>
  </div>
  </dd>
  <dt><a name="item1173">[1173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17421" title="Abstract">arXiv:2404.17421</a> (replaced) [<a href="/pdf/2404.17421" title="Download PDF">pdf</a>, <a href="/format/2404.17421" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> Automata-Theoretic Characterisations of Branching-Time Temporal Logics
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=Benerecetti%2C+M">Massimo Benerecetti</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Bozzelli%2C+L">Laura Bozzelli</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Mogavero%2C+F">Fabio Mogavero</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Peron%2C+A">Adriano Peron</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>
  
  </div>
  </div>
  </dd>
  <dt><a name="item1174">[1174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2404.17524" title="Abstract">arXiv:2404.17524</a> (replaced) [<a href="/pdf/2404.17524" title="Download PDF">pdf</a>, <a href="/format/2404.17524" title="Other formats">other</a>]</span></dt>
  <dd>
  <div class="meta">
  <div class="list-title mathjax">
  <span class="descriptor">Title:</span> On the Use of Large Language Models to Generate Capability Ontologies
  </div>
  <div class="list-authors">
  <span class="descriptor">Authors:</span> 
  <a href="/search/cs?searchtype=author&amp;query=da+Silva%2C+L+M+V">Luis Miguel Vieira da Silva</a>, 
  <a href="/search/cs?searchtype=author&amp;query=K%C3%B6cher%2C+A">Aljosha Köcher</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Gehlhoff%2C+F">Felix Gehlhoff</a>, 
  <a href="/search/cs?searchtype=author&amp;query=Fay%2C+A">Alexander Fay</a>
  </div>
  <div class="list-subjects">
  <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
  
  </div>
  </div>
  </dd>
  </dl>
  <ul>
  <li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
  <li><a href="#item635">Cross-lists</a></li>
  <li><a href="#item705">Replacements</a></li>
  </ul>
  <small>[ total of 1174 entries:  <b>1-1174</b>  ]</small><br>
  <small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br>
  </div></html>